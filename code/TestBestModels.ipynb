{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Best Models\n",
    "\n",
    "Test notebook to generate the statistics of the different models found with AMS. First load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import stats\n",
    "\n",
    "#sys.path.append('/Users/davidlaredorazo/Documents/University_of_California/Research/Projects')\n",
    "sys.path.append('/media/controlslab/DATA/Projects')\n",
    "\n",
    "import ann_framework.aux_functions as aux_functions\n",
    "\n",
    "import automatic_model_selection\n",
    "from automatic_model_selection import Configuration\n",
    "from ann_encoding_rules import Layers\n",
    "import fetch_to_keras\n",
    "#from CMAPSAuxFunctions import TrainValTensorBoard\n",
    "\n",
    "#Tunable model\n",
    "from ann_framework.tunable_model.tunable_model import SequenceTunableModelRegression, SequenceTunableModelClassification\n",
    "\n",
    "#Data handlers\n",
    "from ann_framework.data_handlers.data_handler_CMAPSS import CMAPSSDataHandler\n",
    "from ann_framework.data_handlers.data_handler_MNIST import MNISTDataHandler\n",
    "from ann_framework.data_handlers.data_handler_CIFAR10 import CIFAR10DataHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given a model, get the compiled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model(model, problem_type, optimizer_params=[]):\n",
    "    \"\"\"Obtain a keras compiled model\"\"\"\n",
    "    \n",
    "    #Shared parameters for the models\n",
    "    optimizer = Adam(lr=0.001, beta_1=0.5)\n",
    "    \n",
    "    if problem_type == 1:\n",
    "        lossFunction = \"mean_squared_error\"\n",
    "        metrics = [\"mse\"]\n",
    "    elif problem_type == 2:\n",
    "        lossFunction = \"categorical_crossentropy\"\n",
    "        metrics = [\"accuracy\"]\n",
    "    else:\n",
    "        print(\"Problem type not defined\")\n",
    "        model = None\n",
    "        return\n",
    "    \n",
    "    #Create and compile the models\n",
    "    model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_tunable_model(model_genotype, problem_type, input_shape, data_handler, model_number):\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    model = fetch_to_keras.decode_genotype(model_genotype, problem_type, input_shape, 1)\n",
    "    \n",
    "    model = get_compiled_model(model, problem_type, optimizer_params=[])\n",
    "    \n",
    "    if problem_type == 1:\n",
    "        tModel = SequenceTunableModelRegression('ModelReg_SN_'+str(model_number), model, lib_type='keras', data_handler=data_handler)\n",
    "    else:\n",
    "        tModel = SequenceTunableModelClassification('ModelClass_SN_'+str(model_number), model, lib_type='keras', data_handler=data_handler)\n",
    "        \n",
    "    return tModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cmaps data handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmaps_dhandler(data_scaler=None):\n",
    "\n",
    "    #Selected as per CNN paper\n",
    "    features = ['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', 'BPR', \n",
    "    'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "    selected_indices = np.array([2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21])\n",
    "    selected_features = list(features[i] for i in selected_indices-1)\n",
    "    data_folder = '../CMAPSSData'\n",
    "\n",
    "    window_size = 25\n",
    "    window_stride = 1\n",
    "    max_rul = 130\n",
    "\n",
    "    dHandler_cmaps = CMAPSSDataHandler(data_folder, 1, selected_features,\n",
    "                                       max_rul, window_size, window_stride, data_scaler=data_scaler)\n",
    "\n",
    "    input_shape = (len(selected_features)*window_size, )\n",
    "\n",
    "    return dHandler_cmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_file, weights_file=\"\", problem_type=1):\n",
    "    \n",
    "    p_type = \"\"\n",
    "    \n",
    "    # load json and create model\n",
    "    json_file = open(model_file, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    print(\"Loaded model from disk\") \n",
    "        \n",
    "    #Load weights if specified\n",
    "    if weights_file != \"\":\n",
    "        # load weights into new model\n",
    "        loaded_model.load_weights(weights_file)\n",
    "        print(\"Loaded weights from disk\") \n",
    "    else:\n",
    "        print(\"Model needs training\")\n",
    "        \n",
    "    optimizer = Adam(lr=0.001, beta_1=0.5)\n",
    "    \n",
    "    if problem_type == 1:\n",
    "        p_type = \"regression\"\n",
    "        lossFunction = \"mean_squared_error\"\n",
    "        metrics = [\"mse\"]\n",
    "    elif problem_type == 2:\n",
    "        p_type = \"classification\"\n",
    "        lossFunction = \"categorical_crossentropy\"\n",
    "        metrics = [\"accuracy\"]\n",
    "    else:\n",
    "        print(\"Problem type not defined\")\n",
    "        model = None\n",
    "        return\n",
    "    \n",
    "    #Create and compile the models\n",
    "    loaded_model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    print(\"Created model for \" + p_type + \" with loss function \" + lossFunction)\n",
    "\n",
    "    return loaded_model\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load each of the models and test them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_folder = 'best_models'\n",
    "test_sets = {'cifar10':(CIFAR10DataHandler, None, 2), \n",
    "             'cmapss':(cmaps_dhandler, MinMaxScaler(feature_range=(-1, 1)), 1), \n",
    "             'mnist':((MNISTDataHandler), None, 2)}\n",
    "alpha_folders = ['alpha0.6', 'alpha0.8', 'alpha1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data. Cros-Validation ratio 0\n",
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(50000, 3072)\n",
      "(50000, 10)\n",
      "Testing data (X, y)\n",
      "(10000, 3072)\n",
      "(10000, 10)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[0.23137255 0.24313726 0.24705882 ... 0.48235294 0.36078432 0.28235295]\n",
      " [0.6039216  0.69411767 0.73333335 ... 0.56078434 0.52156866 0.5647059 ]\n",
      " [1.         1.         1.         ... 0.3137255  0.3372549  0.32941177]\n",
      " [0.10980392 0.09803922 0.03921569 ... 0.28235295 0.25490198 0.18039216]\n",
      " [0.6666667  0.7058824  0.7764706  ... 0.28627452 0.3019608  0.3137255 ]]\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Testing data (X, y)\n",
      "[[0.61960787 0.4392157  0.19215687 ... 0.08235294 0.2627451  0.43137255]\n",
      " [0.92156863 0.92156863 0.92156863 ... 0.7294118  0.78431374 0.78039217]\n",
      " [0.61960787 0.74509805 0.87058824 ... 0.02745098 0.03137255 0.02745098]\n",
      " [0.60784316 0.6117647  0.58431375 ... 0.28627452 0.26666668 0.19607843]\n",
      " [0.25490198 0.26666668 0.19607843 ... 0.5019608  0.6117647  0.45882353]]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "Validation on model:best_models/cifar10/alpha0.6/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 296)               909608    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 584)               173448    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5850      \n",
      "=================================================================\n",
      "Total params: 1,088,906\n",
      "Trainable params: 1,088,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "25000/25000 [==============================] - 0s 14us/step - loss: 2.1907 - acc: 0.2093\n",
      "Epoch 2/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.9559 - acc: 0.2947\n",
      "Epoch 3/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.8687 - acc: 0.3265\n",
      "Epoch 4/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.7979 - acc: 0.3542\n",
      "Epoch 5/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.7591 - acc: 0.3668\n",
      "Epoch 6/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.7429 - acc: 0.3779\n",
      "Epoch 7/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6933 - acc: 0.3966\n",
      "Epoch 8/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6493 - acc: 0.4120\n",
      "Epoch 9/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6248 - acc: 0.4209\n",
      "Epoch 10/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6074 - acc: 0.4271A: 0s - loss: 1.5922 - acc: 0.43\n",
      "Epoch 11/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6117 - acc: 0.4269\n",
      "Epoch 12/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5429 - acc: 0.4494\n",
      "Epoch 13/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5341 - acc: 0.4514\n",
      "Epoch 14/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5190 - acc: 0.4623\n",
      "Epoch 15/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4932 - acc: 0.4659A: 0s - loss: 1.4955 - acc: 0.46\n",
      "Epoch 16/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5189 - acc: 0.4594\n",
      "Epoch 17/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4683 - acc: 0.4775\n",
      "Epoch 18/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4639 - acc: 0.4779\n",
      "Epoch 19/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4389 - acc: 0.4882\n",
      "Epoch 20/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4283 - acc: 0.4936\n",
      "Epoch 21/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4018 - acc: 0.5030\n",
      "Epoch 22/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3938 - acc: 0.5054\n",
      "Epoch 23/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3976 - acc: 0.5036\n",
      "Epoch 24/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3393 - acc: 0.5248\n",
      "Epoch 25/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3539 - acc: 0.5214\n",
      "Epoch 26/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3599 - acc: 0.5178\n",
      "Epoch 27/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3204 - acc: 0.5292\n",
      "Epoch 28/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3260 - acc: 0.5302\n",
      "Epoch 29/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3010 - acc: 0.5362\n",
      "Epoch 30/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3124 - acc: 0.5327\n",
      "Epoch 31/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.2775 - acc: 0.5447\n",
      "Epoch 32/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.2670 - acc: 0.5528\n",
      "Epoch 33/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.2667 - acc: 0.5488\n",
      "Epoch 34/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.2449 - acc: 0.5609\n",
      "Epoch 35/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.2366 - acc: 0.5606\n",
      "Epoch 36/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.2035 - acc: 0.5729\n",
      "Epoch 37/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.2134 - acc: 0.5663\n",
      "Epoch 38/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.2040 - acc: 0.5743\n",
      "Epoch 39/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.1797 - acc: 0.5795\n",
      "Epoch 40/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.1744 - acc: 0.5816\n",
      "Epoch 41/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.1669 - acc: 0.5875\n",
      "Epoch 42/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.1517 - acc: 0.5891\n",
      "Epoch 43/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.1395 - acc: 0.5983\n",
      "Epoch 44/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.1376 - acc: 0.5967\n",
      "Epoch 45/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.1236 - acc: 0.6018\n",
      "Epoch 46/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.1048 - acc: 0.6075\n",
      "Epoch 47/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.0912 - acc: 0.6135\n",
      "Epoch 48/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.0844 - acc: 0.6168\n",
      "Epoch 49/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.0738 - acc: 0.6217\n",
      "Epoch 50/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.0729 - acc: 0.6177\n",
      "Epoch 51/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.0568 - acc: 0.6247\n",
      "Epoch 52/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.0587 - acc: 0.6252\n",
      "Epoch 53/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.0285 - acc: 0.6380\n",
      "Epoch 54/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.1747 - acc: 0.5934\n",
      "Epoch 55/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.0071 - acc: 0.6448\n",
      "Epoch 56/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.9904 - acc: 0.6524\n",
      "Epoch 57/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.9956 - acc: 0.6479\n",
      "Epoch 58/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.9755 - acc: 0.6552\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.9642 - acc: 0.6608\n",
      "Epoch 60/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.9579 - acc: 0.6623\n",
      "Epoch 61/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.9468 - acc: 0.6660\n",
      "Epoch 62/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.9387 - acc: 0.6674\n",
      "Epoch 63/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.9154 - acc: 0.6784\n",
      "Epoch 64/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.9408 - acc: 0.6675\n",
      "Epoch 65/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.9167 - acc: 0.6769\n",
      "Epoch 66/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.9000 - acc: 0.6833\n",
      "Epoch 67/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.8862 - acc: 0.6904\n",
      "Epoch 68/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.8750 - acc: 0.6902\n",
      "Epoch 69/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.8676 - acc: 0.6922\n",
      "Epoch 70/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.8641 - acc: 0.6972\n",
      "Epoch 71/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.8673 - acc: 0.6934\n",
      "Epoch 72/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.8463 - acc: 0.7020\n",
      "Epoch 73/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.8333 - acc: 0.7045\n",
      "Epoch 74/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.8422 - acc: 0.7010\n",
      "Epoch 75/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.8043 - acc: 0.7174\n",
      "Epoch 76/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.8166 - acc: 0.7138\n",
      "Epoch 77/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7940 - acc: 0.7211\n",
      "Epoch 78/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7933 - acc: 0.7180\n",
      "Epoch 79/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7843 - acc: 0.7213\n",
      "Epoch 80/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7844 - acc: 0.7236\n",
      "Epoch 81/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7666 - acc: 0.7307\n",
      "Epoch 82/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7557 - acc: 0.7353\n",
      "Epoch 83/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7458 - acc: 0.7381\n",
      "Epoch 84/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7350 - acc: 0.7409\n",
      "Epoch 85/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7200 - acc: 0.7507\n",
      "Epoch 86/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7025 - acc: 0.7556\n",
      "Epoch 87/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7223 - acc: 0.7457\n",
      "Epoch 88/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.6890 - acc: 0.7570\n",
      "Epoch 89/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7012 - acc: 0.7544\n",
      "Epoch 90/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7127 - acc: 0.7476\n",
      "Epoch 91/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.6884 - acc: 0.7590\n",
      "Epoch 92/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.6840 - acc: 0.7619\n",
      "Epoch 93/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.6679 - acc: 0.7678\n",
      "Epoch 94/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.6545 - acc: 0.7735\n",
      "Epoch 95/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.6587 - acc: 0.7712\n",
      "Epoch 96/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.6352 - acc: 0.7821\n",
      "Epoch 97/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.6468 - acc: 0.7746\n",
      "Epoch 98/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.6165 - acc: 0.7896\n",
      "Epoch 99/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.6189 - acc: 0.7864\n",
      "Epoch 100/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.6202 - acc: 0.7865\n",
      "25000/25000 [==============================] - 0s 16us/step\n",
      "10000/10000 [==============================] - 0s 16us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 296)               909608    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 584)               173448    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5850      \n",
      "=================================================================\n",
      "Total params: 1,088,906\n",
      "Trainable params: 1,088,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "25000/25000 [==============================] - 0s 13us/step - loss: 2.1539 - acc: 0.2206\n",
      "Epoch 2/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.9055 - acc: 0.3153\n",
      "Epoch 3/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.8271 - acc: 0.3484\n",
      "Epoch 4/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.8089 - acc: 0.3484\n",
      "Epoch 5/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.7138 - acc: 0.3903\n",
      "Epoch 6/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.7265 - acc: 0.3801\n",
      "Epoch 7/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6639 - acc: 0.4071\n",
      "Epoch 8/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6351 - acc: 0.4176\n",
      "Epoch 9/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6060 - acc: 0.4295\n",
      "Epoch 10/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6216 - acc: 0.4239\n",
      "Epoch 11/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5925 - acc: 0.4350\n",
      "Epoch 12/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5375 - acc: 0.4518\n",
      "Epoch 13/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5341 - acc: 0.4559\n",
      "Epoch 14/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4969 - acc: 0.4692\n",
      "Epoch 15/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4909 - acc: 0.4689\n",
      "Epoch 16/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4561 - acc: 0.4828\n",
      "Epoch 17/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4595 - acc: 0.4804\n",
      "Epoch 18/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4246 - acc: 0.4914\n",
      "Epoch 19/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4183 - acc: 0.4980\n",
      "Epoch 20/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4333 - acc: 0.4919\n",
      "Epoch 21/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3809 - acc: 0.5091\n",
      "Epoch 22/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3724 - acc: 0.5100\n",
      "Epoch 23/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3561 - acc: 0.5182\n",
      "Epoch 24/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3415 - acc: 0.5272\n",
      "Epoch 25/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3250 - acc: 0.5322\n",
      "Epoch 26/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3222 - acc: 0.5308\n",
      "Epoch 27/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3063 - acc: 0.5375\n",
      "Epoch 28/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.2941 - acc: 0.5414\n",
      "Epoch 29/100\n",
      "25000/25000 [==============================] - ETA: 0s - loss: 1.2700 - acc: 0.5520- ETA: 0s - loss: 1.2865 - acc: 0.5 - 0s 8us/step - loss: 1.2714 - acc: 0.5526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.2577 - acc: 0.5548\n",
      "Epoch 31/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.2497 - acc: 0.5573\n",
      "Epoch 32/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.2289 - acc: 0.5658\n",
      "Epoch 33/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.2245 - acc: 0.5681\n",
      "Epoch 34/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.2114 - acc: 0.5720\n",
      "Epoch 35/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.1880 - acc: 0.5800\n",
      "Epoch 36/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.1751 - acc: 0.5824\n",
      "Epoch 37/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.1696 - acc: 0.5882\n",
      "Epoch 38/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.1535 - acc: 0.5915\n",
      "Epoch 39/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.1379 - acc: 0.5962A: 0s - loss: 1.1316 - acc: 0.60\n",
      "Epoch 40/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.1219 - acc: 0.6029\n",
      "Epoch 41/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.1355 - acc: 0.5956A: 0s - loss: 1.1363 - acc: 0.593\n",
      "Epoch 42/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.1110 - acc: 0.6083\n",
      "Epoch 43/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.0936 - acc: 0.6110A: 0s - loss: 1.0973 - acc: 0.61\n",
      "Epoch 44/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.1020 - acc: 0.6083\n",
      "Epoch 45/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.0699 - acc: 0.6218\n",
      "Epoch 46/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.0558 - acc: 0.6279\n",
      "Epoch 47/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.0360 - acc: 0.6361A: 0s - loss: 1.0322 - acc: 0.6\n",
      "Epoch 48/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.0361 - acc: 0.6336\n",
      "Epoch 49/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.0256 - acc: 0.6376\n",
      "Epoch 50/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.0283 - acc: 0.6370\n",
      "Epoch 51/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.9949 - acc: 0.6458\n",
      "Epoch 52/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.0013 - acc: 0.6432\n",
      "Epoch 53/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.9924 - acc: 0.6476\n",
      "Epoch 54/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.9695 - acc: 0.6529\n",
      "Epoch 55/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.9584 - acc: 0.6597\n",
      "Epoch 56/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.9441 - acc: 0.6678\n",
      "Epoch 57/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.9334 - acc: 0.6690\n",
      "Epoch 58/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.9153 - acc: 0.6789\n",
      "Epoch 59/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.9093 - acc: 0.6776\n",
      "Epoch 60/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.9034 - acc: 0.6807\n",
      "Epoch 61/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.9278 - acc: 0.6734\n",
      "Epoch 62/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.8846 - acc: 0.6877\n",
      "Epoch 63/100\n",
      "25000/25000 [==============================] - ETA: 0s - loss: 0.8555 - acc: 0.698 - 0s 8us/step - loss: 0.8586 - acc: 0.6978\n",
      "Epoch 64/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.8572 - acc: 0.6970\n",
      "Epoch 65/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.8470 - acc: 0.7039\n",
      "Epoch 66/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.8295 - acc: 0.7082\n",
      "Epoch 67/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.8239 - acc: 0.7114\n",
      "Epoch 68/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.8139 - acc: 0.7107\n",
      "Epoch 69/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7910 - acc: 0.7216\n",
      "Epoch 70/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7866 - acc: 0.7213\n",
      "Epoch 71/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7869 - acc: 0.7231\n",
      "Epoch 72/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7741 - acc: 0.7285\n",
      "Epoch 73/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7498 - acc: 0.7367\n",
      "Epoch 74/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7712 - acc: 0.7261\n",
      "Epoch 75/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7248 - acc: 0.7477\n",
      "Epoch 76/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7292 - acc: 0.7444\n",
      "Epoch 77/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7313 - acc: 0.7431\n",
      "Epoch 78/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7038 - acc: 0.7541\n",
      "Epoch 79/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.7111 - acc: 0.7502\n",
      "Epoch 80/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.6899 - acc: 0.7584\n",
      "Epoch 81/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.6753 - acc: 0.7652\n",
      "Epoch 82/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.6834 - acc: 0.7586\n",
      "Epoch 83/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.6780 - acc: 0.7630\n",
      "Epoch 84/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.6565 - acc: 0.7722\n",
      "Epoch 85/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.6658 - acc: 0.7655\n",
      "Epoch 86/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.6361 - acc: 0.7787\n",
      "Epoch 87/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.6224 - acc: 0.7851\n",
      "Epoch 88/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.6244 - acc: 0.7848\n",
      "Epoch 89/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.6099 - acc: 0.7896\n",
      "Epoch 90/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.5923 - acc: 0.7964\n",
      "Epoch 91/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.5967 - acc: 0.7951\n",
      "Epoch 92/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.5801 - acc: 0.7981\n",
      "Epoch 93/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.5761 - acc: 0.8006\n",
      "Epoch 94/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.5708 - acc: 0.8050\n",
      "Epoch 95/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.5525 - acc: 0.8122\n",
      "Epoch 96/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.5500 - acc: 0.8140\n",
      "Epoch 97/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.5707 - acc: 0.8023\n",
      "Epoch 98/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.5315 - acc: 0.8191\n",
      "Epoch 99/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.5488 - acc: 0.8096\n",
      "Epoch 100/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 0.5183 - acc: 0.8240\n",
      "25000/25000 [==============================] - 0s 17us/step\n",
      "10000/10000 [==============================] - 0s 16us/step\n",
      "Loading data. Cros-Validation ratio 0\n",
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(50000, 3072)\n",
      "(50000, 10)\n",
      "Testing data (X, y)\n",
      "(10000, 3072)\n",
      "(10000, 10)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[0.23137255 0.24313726 0.24705882 ... 0.48235294 0.36078432 0.28235295]\n",
      " [0.6039216  0.69411767 0.73333335 ... 0.56078434 0.52156866 0.5647059 ]\n",
      " [1.         1.         1.         ... 0.3137255  0.3372549  0.32941177]\n",
      " [0.10980392 0.09803922 0.03921569 ... 0.28235295 0.25490198 0.18039216]\n",
      " [0.6666667  0.7058824  0.7764706  ... 0.28627452 0.3019608  0.3137255 ]]\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Testing data (X, y)\n",
      "[[0.61960787 0.4392157  0.19215687 ... 0.08235294 0.2627451  0.43137255]\n",
      " [0.92156863 0.92156863 0.92156863 ... 0.7294118  0.78431374 0.78039217]\n",
      " [0.61960787 0.74509805 0.87058824 ... 0.02745098 0.03137255 0.02745098]\n",
      " [0.60784316 0.6117647  0.58431375 ... 0.28627452 0.26666668 0.19607843]\n",
      " [0.25490198 0.26666668 0.19607843 ... 0.5019608  0.6117647  0.45882353]]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "Validation on model:best_models/cifar10/alpha0.8/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 240)               737520    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2410      \n",
      "=================================================================\n",
      "Total params: 739,930\n",
      "Trainable params: 739,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "25000/25000 [==============================] - 0s 12us/step - loss: 2.1024 - acc: 0.2377\n",
      "Epoch 2/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.9084 - acc: 0.3235\n",
      "Epoch 3/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.8401 - acc: 0.3500\n",
      "Epoch 4/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7992 - acc: 0.3690\n",
      "Epoch 5/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7711 - acc: 0.3732\n",
      "Epoch 6/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7343 - acc: 0.3884\n",
      "Epoch 7/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7145 - acc: 0.3952\n",
      "Epoch 8/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6796 - acc: 0.4088\n",
      "Epoch 9/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6573 - acc: 0.4182\n",
      "Epoch 10/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6387 - acc: 0.4219\n",
      "Epoch 11/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6204 - acc: 0.4274\n",
      "Epoch 12/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5945 - acc: 0.4404\n",
      "Epoch 13/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5836 - acc: 0.4450\n",
      "Epoch 14/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5645 - acc: 0.4502\n",
      "Epoch 15/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5524 - acc: 0.4532\n",
      "Epoch 16/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5284 - acc: 0.4646\n",
      "Epoch 17/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5214 - acc: 0.4637\n",
      "Epoch 18/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5054 - acc: 0.4728\n",
      "Epoch 19/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4951 - acc: 0.4779\n",
      "Epoch 20/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4899 - acc: 0.4816\n",
      "Epoch 21/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4696 - acc: 0.4838\n",
      "Epoch 22/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4536 - acc: 0.4941\n",
      "Epoch 23/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4468 - acc: 0.4916\n",
      "Epoch 24/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4328 - acc: 0.4984\n",
      "Epoch 25/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4308 - acc: 0.4992\n",
      "Epoch 26/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4119 - acc: 0.5046\n",
      "Epoch 27/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4029 - acc: 0.5090\n",
      "Epoch 28/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3928 - acc: 0.5138\n",
      "Epoch 29/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3847 - acc: 0.5134\n",
      "Epoch 30/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3667 - acc: 0.5209\n",
      "Epoch 31/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3625 - acc: 0.5201\n",
      "Epoch 32/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3554 - acc: 0.5273\n",
      "Epoch 33/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3393 - acc: 0.5339\n",
      "Epoch 34/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3290 - acc: 0.5348\n",
      "Epoch 35/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3185 - acc: 0.5386\n",
      "Epoch 36/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3086 - acc: 0.5440\n",
      "Epoch 37/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3071 - acc: 0.5437\n",
      "Epoch 38/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2938 - acc: 0.5484\n",
      "Epoch 39/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2822 - acc: 0.5521\n",
      "Epoch 40/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2762 - acc: 0.5541\n",
      "Epoch 41/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2674 - acc: 0.5582\n",
      "Epoch 42/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2553 - acc: 0.5634\n",
      "Epoch 43/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2499 - acc: 0.5670\n",
      "Epoch 44/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2431 - acc: 0.5654\n",
      "Epoch 45/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2312 - acc: 0.5696\n",
      "Epoch 46/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2289 - acc: 0.5705\n",
      "Epoch 47/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2238 - acc: 0.5730\n",
      "Epoch 48/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2086 - acc: 0.5796\n",
      "Epoch 49/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1969 - acc: 0.5844\n",
      "Epoch 50/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1871 - acc: 0.5871\n",
      "Epoch 51/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1862 - acc: 0.5869\n",
      "Epoch 52/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1816 - acc: 0.5928\n",
      "Epoch 53/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1707 - acc: 0.5950\n",
      "Epoch 54/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1744 - acc: 0.5924\n",
      "Epoch 55/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1491 - acc: 0.6016\n",
      "Epoch 56/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1500 - acc: 0.6010\n",
      "Epoch 57/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1310 - acc: 0.6112\n",
      "Epoch 58/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1266 - acc: 0.6116\n",
      "Epoch 59/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1221 - acc: 0.6142\n",
      "Epoch 60/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1165 - acc: 0.6153\n",
      "Epoch 61/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1059 - acc: 0.6176\n",
      "Epoch 62/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1073 - acc: 0.6181\n",
      "Epoch 63/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0959 - acc: 0.6208\n",
      "Epoch 64/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0804 - acc: 0.6304\n",
      "Epoch 65/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0849 - acc: 0.6266\n",
      "Epoch 66/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0863 - acc: 0.6219\n",
      "Epoch 67/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0625 - acc: 0.6385\n",
      "Epoch 68/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0701 - acc: 0.6345\n",
      "Epoch 69/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0437 - acc: 0.6423\n",
      "Epoch 70/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0413 - acc: 0.6464\n",
      "Epoch 71/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0359 - acc: 0.6482\n",
      "Epoch 72/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0265 - acc: 0.6494\n",
      "Epoch 73/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0226 - acc: 0.6494\n",
      "Epoch 74/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0274 - acc: 0.6480\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0066 - acc: 0.6582\n",
      "Epoch 76/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9979 - acc: 0.6589\n",
      "Epoch 77/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9935 - acc: 0.6640\n",
      "Epoch 78/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0005 - acc: 0.6590\n",
      "Epoch 79/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9767 - acc: 0.6678\n",
      "Epoch 80/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9831 - acc: 0.6653\n",
      "Epoch 81/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9692 - acc: 0.6722\n",
      "Epoch 82/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9621 - acc: 0.6744\n",
      "Epoch 83/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9599 - acc: 0.6766\n",
      "Epoch 84/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9641 - acc: 0.6738\n",
      "Epoch 85/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9552 - acc: 0.6766\n",
      "Epoch 86/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9385 - acc: 0.6844\n",
      "Epoch 87/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9394 - acc: 0.6831\n",
      "Epoch 88/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9263 - acc: 0.6891\n",
      "Epoch 89/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9222 - acc: 0.6919\n",
      "Epoch 90/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9145 - acc: 0.6933\n",
      "Epoch 91/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9137 - acc: 0.6928\n",
      "Epoch 92/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9026 - acc: 0.6990\n",
      "Epoch 93/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.8939 - acc: 0.7034\n",
      "Epoch 94/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9059 - acc: 0.6944\n",
      "Epoch 95/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.8956 - acc: 0.7000\n",
      "Epoch 96/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.8822 - acc: 0.7056\n",
      "Epoch 97/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.8819 - acc: 0.7062\n",
      "Epoch 98/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.8663 - acc: 0.7126\n",
      "Epoch 99/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.8610 - acc: 0.7127\n",
      "Epoch 100/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.8675 - acc: 0.7123\n",
      "25000/25000 [==============================] - 0s 16us/step\n",
      "10000/10000 [==============================] - 0s 15us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 240)               737520    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2410      \n",
      "=================================================================\n",
      "Total params: 739,930\n",
      "Trainable params: 739,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "25000/25000 [==============================] - 0s 12us/step - loss: 2.0771 - acc: 0.2545\n",
      "Epoch 2/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.8871 - acc: 0.3298\n",
      "Epoch 3/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.8245 - acc: 0.3532\n",
      "Epoch 4/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7919 - acc: 0.3688\n",
      "Epoch 5/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7456 - acc: 0.3873\n",
      "Epoch 6/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7184 - acc: 0.3952\n",
      "Epoch 7/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7011 - acc: 0.4024\n",
      "Epoch 8/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6748 - acc: 0.4127\n",
      "Epoch 9/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6494 - acc: 0.4225\n",
      "Epoch 10/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6293 - acc: 0.4270\n",
      "Epoch 11/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6079 - acc: 0.4374\n",
      "Epoch 12/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5950 - acc: 0.4421\n",
      "Epoch 13/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5874 - acc: 0.4401\n",
      "Epoch 14/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5683 - acc: 0.4491\n",
      "Epoch 15/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5466 - acc: 0.4581\n",
      "Epoch 16/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5386 - acc: 0.4598\n",
      "Epoch 17/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5297 - acc: 0.4639\n",
      "Epoch 18/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5095 - acc: 0.4717\n",
      "Epoch 19/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5135 - acc: 0.4701\n",
      "Epoch 20/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4904 - acc: 0.4811\n",
      "Epoch 21/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4757 - acc: 0.4849\n",
      "Epoch 22/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4662 - acc: 0.4893\n",
      "Epoch 23/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4664 - acc: 0.4873\n",
      "Epoch 24/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4531 - acc: 0.4940\n",
      "Epoch 25/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4414 - acc: 0.4992\n",
      "Epoch 26/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4221 - acc: 0.5053\n",
      "Epoch 27/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4269 - acc: 0.4999\n",
      "Epoch 28/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4038 - acc: 0.5103\n",
      "Epoch 29/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3903 - acc: 0.5153\n",
      "Epoch 30/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3948 - acc: 0.5132\n",
      "Epoch 31/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3847 - acc: 0.5140\n",
      "Epoch 32/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3838 - acc: 0.5187\n",
      "Epoch 33/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3634 - acc: 0.5251\n",
      "Epoch 34/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3522 - acc: 0.5310\n",
      "Epoch 35/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3415 - acc: 0.5320\n",
      "Epoch 36/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3427 - acc: 0.5322\n",
      "Epoch 37/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3307 - acc: 0.5393\n",
      "Epoch 38/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3319 - acc: 0.5383\n",
      "Epoch 39/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3079 - acc: 0.5458\n",
      "Epoch 40/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2946 - acc: 0.5519\n",
      "Epoch 41/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2909 - acc: 0.5522\n",
      "Epoch 42/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2860 - acc: 0.5521\n",
      "Epoch 43/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2701 - acc: 0.5602\n",
      "Epoch 44/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2688 - acc: 0.5606\n",
      "Epoch 45/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2545 - acc: 0.5673\n",
      "Epoch 46/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2550 - acc: 0.5670\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2572 - acc: 0.5637\n",
      "Epoch 48/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2320 - acc: 0.5754\n",
      "Epoch 49/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2280 - acc: 0.5770\n",
      "Epoch 50/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2293 - acc: 0.5730\n",
      "Epoch 51/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1976 - acc: 0.5883\n",
      "Epoch 52/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2049 - acc: 0.5883\n",
      "Epoch 53/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2052 - acc: 0.5845\n",
      "Epoch 54/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1944 - acc: 0.5877\n",
      "Epoch 55/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1766 - acc: 0.5958\n",
      "Epoch 56/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1814 - acc: 0.5926\n",
      "Epoch 57/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1755 - acc: 0.5938\n",
      "Epoch 58/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1543 - acc: 0.6033\n",
      "Epoch 59/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1506 - acc: 0.6077\n",
      "Epoch 60/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1427 - acc: 0.6090\n",
      "Epoch 61/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1451 - acc: 0.6057\n",
      "Epoch 62/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1469 - acc: 0.6070\n",
      "Epoch 63/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1255 - acc: 0.6151\n",
      "Epoch 64/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1261 - acc: 0.6148\n",
      "Epoch 65/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1153 - acc: 0.6189\n",
      "Epoch 66/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1054 - acc: 0.6236\n",
      "Epoch 67/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0918 - acc: 0.6296\n",
      "Epoch 68/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0839 - acc: 0.6292\n",
      "Epoch 69/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0878 - acc: 0.6282\n",
      "Epoch 70/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0793 - acc: 0.6307\n",
      "Epoch 71/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.0632 - acc: 0.6369\n",
      "Epoch 72/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0663 - acc: 0.6354\n",
      "Epoch 73/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0579 - acc: 0.6420\n",
      "Epoch 74/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0454 - acc: 0.6461\n",
      "Epoch 75/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0429 - acc: 0.6481\n",
      "Epoch 76/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0519 - acc: 0.6388\n",
      "Epoch 77/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0383 - acc: 0.6444\n",
      "Epoch 78/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0166 - acc: 0.6560\n",
      "Epoch 79/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.0121 - acc: 0.6553\n",
      "Epoch 80/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0120 - acc: 0.6562\n",
      "Epoch 81/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0040 - acc: 0.6632\n",
      "Epoch 82/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 0.9965 - acc: 0.6634\n",
      "Epoch 83/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9930 - acc: 0.6657\n",
      "Epoch 84/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9957 - acc: 0.6607\n",
      "Epoch 85/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9848 - acc: 0.6703\n",
      "Epoch 86/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9809 - acc: 0.6681\n",
      "Epoch 87/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9601 - acc: 0.6763\n",
      "Epoch 88/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9643 - acc: 0.6764\n",
      "Epoch 89/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9564 - acc: 0.6797\n",
      "Epoch 90/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9592 - acc: 0.6786\n",
      "Epoch 91/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9554 - acc: 0.6773\n",
      "Epoch 92/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9386 - acc: 0.6860\n",
      "Epoch 93/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9369 - acc: 0.6874\n",
      "Epoch 94/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9324 - acc: 0.6861\n",
      "Epoch 95/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9120 - acc: 0.6964\n",
      "Epoch 96/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9262 - acc: 0.6892\n",
      "Epoch 97/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.9047 - acc: 0.6979\n",
      "Epoch 98/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.8977 - acc: 0.7023\n",
      "Epoch 99/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 0.9114 - acc: 0.6934\n",
      "Epoch 100/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 0.8953 - acc: 0.7036\n",
      "25000/25000 [==============================] - 0s 16us/step\n",
      "10000/10000 [==============================] - 0s 15us/step\n",
      "Loading data. Cros-Validation ratio 0\n",
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(50000, 3072)\n",
      "(50000, 10)\n",
      "Testing data (X, y)\n",
      "(10000, 3072)\n",
      "(10000, 10)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[0.23137255 0.24313726 0.24705882 ... 0.48235294 0.36078432 0.28235295]\n",
      " [0.6039216  0.69411767 0.73333335 ... 0.56078434 0.52156866 0.5647059 ]\n",
      " [1.         1.         1.         ... 0.3137255  0.3372549  0.32941177]\n",
      " [0.10980392 0.09803922 0.03921569 ... 0.28235295 0.25490198 0.18039216]\n",
      " [0.6666667  0.7058824  0.7764706  ... 0.28627452 0.3019608  0.3137255 ]]\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Testing data (X, y)\n",
      "[[0.61960787 0.4392157  0.19215687 ... 0.08235294 0.2627451  0.43137255]\n",
      " [0.92156863 0.92156863 0.92156863 ... 0.7294118  0.78431374 0.78039217]\n",
      " [0.61960787 0.74509805 0.87058824 ... 0.02745098 0.03137255 0.02745098]\n",
      " [0.60784316 0.6117647  0.58431375 ... 0.28627452 0.26666668 0.19607843]\n",
      " [0.25490198 0.26666668 0.19607843 ... 0.5019608  0.6117647  0.45882353]]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "Validation on model:best_models/cifar10/alpha1/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 136)               417928    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 136)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1370      \n",
      "=================================================================\n",
      "Total params: 419,298\n",
      "Trainable params: 419,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "25000/25000 [==============================] - 0s 12us/step - loss: 2.1150 - acc: 0.2319\n",
      "Epoch 2/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.9409 - acc: 0.3080\n",
      "Epoch 3/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.8782 - acc: 0.3334\n",
      "Epoch 4/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.8430 - acc: 0.3468\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.8082 - acc: 0.3596\n",
      "Epoch 6/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7818 - acc: 0.3690\n",
      "Epoch 7/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7630 - acc: 0.3772\n",
      "Epoch 8/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7483 - acc: 0.3832\n",
      "Epoch 9/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7251 - acc: 0.3933\n",
      "Epoch 10/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7070 - acc: 0.3988\n",
      "Epoch 11/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6875 - acc: 0.4073\n",
      "Epoch 12/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6818 - acc: 0.4066\n",
      "Epoch 13/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6654 - acc: 0.4138\n",
      "Epoch 14/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6550 - acc: 0.4187\n",
      "Epoch 15/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6450 - acc: 0.4247\n",
      "Epoch 16/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6261 - acc: 0.4301\n",
      "Epoch 17/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6224 - acc: 0.4297\n",
      "Epoch 18/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6101 - acc: 0.4370\n",
      "Epoch 19/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6005 - acc: 0.4366\n",
      "Epoch 20/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5913 - acc: 0.4427\n",
      "Epoch 21/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5882 - acc: 0.4424\n",
      "Epoch 22/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5786 - acc: 0.4476\n",
      "Epoch 23/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5737 - acc: 0.4494\n",
      "Epoch 24/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5664 - acc: 0.4524\n",
      "Epoch 25/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5581 - acc: 0.4574\n",
      "Epoch 26/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5593 - acc: 0.4541\n",
      "Epoch 27/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5414 - acc: 0.4636\n",
      "Epoch 28/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5352 - acc: 0.4636\n",
      "Epoch 29/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5324 - acc: 0.4587\n",
      "Epoch 30/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5267 - acc: 0.4625\n",
      "Epoch 31/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5204 - acc: 0.4682\n",
      "Epoch 32/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5129 - acc: 0.4707\n",
      "Epoch 33/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5075 - acc: 0.4724\n",
      "Epoch 34/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5079 - acc: 0.4709\n",
      "Epoch 35/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4978 - acc: 0.4761\n",
      "Epoch 36/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4888 - acc: 0.4781\n",
      "Epoch 37/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4833 - acc: 0.4807\n",
      "Epoch 38/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4840 - acc: 0.4816\n",
      "Epoch 39/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4824 - acc: 0.4798\n",
      "Epoch 40/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4754 - acc: 0.4867\n",
      "Epoch 41/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4685 - acc: 0.4850\n",
      "Epoch 42/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4638 - acc: 0.4868\n",
      "Epoch 43/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4516 - acc: 0.4948\n",
      "Epoch 44/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4565 - acc: 0.4880\n",
      "Epoch 45/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4506 - acc: 0.4911\n",
      "Epoch 46/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4482 - acc: 0.4913\n",
      "Epoch 47/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4358 - acc: 0.4982\n",
      "Epoch 48/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4266 - acc: 0.5031\n",
      "Epoch 49/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4357 - acc: 0.4976\n",
      "Epoch 50/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4298 - acc: 0.4992\n",
      "Epoch 51/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4275 - acc: 0.5024\n",
      "Epoch 52/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4197 - acc: 0.5051\n",
      "Epoch 53/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4101 - acc: 0.5066\n",
      "Epoch 54/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4155 - acc: 0.5060\n",
      "Epoch 55/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4073 - acc: 0.5042\n",
      "Epoch 56/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4086 - acc: 0.5108\n",
      "Epoch 57/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4056 - acc: 0.5065\n",
      "Epoch 58/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3982 - acc: 0.5107\n",
      "Epoch 59/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3971 - acc: 0.5110\n",
      "Epoch 60/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3890 - acc: 0.5105\n",
      "Epoch 61/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3936 - acc: 0.5124\n",
      "Epoch 62/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3878 - acc: 0.5136\n",
      "Epoch 63/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3809 - acc: 0.5185\n",
      "Epoch 64/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3765 - acc: 0.5193\n",
      "Epoch 65/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3749 - acc: 0.5174\n",
      "Epoch 66/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3693 - acc: 0.5185\n",
      "Epoch 67/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3612 - acc: 0.5226\n",
      "Epoch 68/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3599 - acc: 0.5232\n",
      "Epoch 69/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3598 - acc: 0.5254\n",
      "Epoch 70/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3574 - acc: 0.5263\n",
      "Epoch 71/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3495 - acc: 0.5270\n",
      "Epoch 72/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3529 - acc: 0.5270\n",
      "Epoch 73/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3511 - acc: 0.5260\n",
      "Epoch 74/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3501 - acc: 0.5273\n",
      "Epoch 75/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3439 - acc: 0.5288\n",
      "Epoch 76/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3319 - acc: 0.5325\n",
      "Epoch 77/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3399 - acc: 0.5293\n",
      "Epoch 78/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3276 - acc: 0.5332\n",
      "Epoch 79/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3220 - acc: 0.5354\n",
      "Epoch 80/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3233 - acc: 0.5371\n",
      "Epoch 81/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3203 - acc: 0.5363\n",
      "Epoch 82/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3182 - acc: 0.5365\n",
      "Epoch 83/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3116 - acc: 0.5369\n",
      "Epoch 84/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3126 - acc: 0.5436\n",
      "Epoch 85/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3100 - acc: 0.5416\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3049 - acc: 0.5442\n",
      "Epoch 87/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3056 - acc: 0.5408\n",
      "Epoch 88/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2977 - acc: 0.5440\n",
      "Epoch 89/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2938 - acc: 0.5451\n",
      "Epoch 90/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2939 - acc: 0.5464\n",
      "Epoch 91/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2919 - acc: 0.5483\n",
      "Epoch 92/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2992 - acc: 0.5461\n",
      "Epoch 93/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2795 - acc: 0.5548\n",
      "Epoch 94/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2838 - acc: 0.5472\n",
      "Epoch 95/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2753 - acc: 0.5546\n",
      "Epoch 96/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2829 - acc: 0.5522\n",
      "Epoch 97/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2821 - acc: 0.5500\n",
      "Epoch 98/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2771 - acc: 0.5534\n",
      "Epoch 99/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2713 - acc: 0.5539\n",
      "Epoch 100/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2656 - acc: 0.5528\n",
      "25000/25000 [==============================] - 0s 16us/step\n",
      "10000/10000 [==============================] - 0s 16us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 136)               417928    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 136)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1370      \n",
      "=================================================================\n",
      "Total params: 419,298\n",
      "Trainable params: 419,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "25000/25000 [==============================] - 0s 12us/step - loss: 2.1599 - acc: 0.2126\n",
      "Epoch 2/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.9646 - acc: 0.2931\n",
      "Epoch 3/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.8968 - acc: 0.3205\n",
      "Epoch 4/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.8561 - acc: 0.3372\n",
      "Epoch 5/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.8211 - acc: 0.3542\n",
      "Epoch 6/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.8064 - acc: 0.3622\n",
      "Epoch 7/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7806 - acc: 0.3683\n",
      "Epoch 8/100\n",
      "25000/25000 [==============================] - 0s 10us/step - loss: 1.7559 - acc: 0.3780\n",
      "Epoch 9/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7433 - acc: 0.3837\n",
      "Epoch 10/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7276 - acc: 0.3897\n",
      "Epoch 11/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7139 - acc: 0.3944\n",
      "Epoch 12/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6993 - acc: 0.3969\n",
      "Epoch 13/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6879 - acc: 0.4020\n",
      "Epoch 14/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6737 - acc: 0.4111\n",
      "Epoch 15/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6595 - acc: 0.4124\n",
      "Epoch 16/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6537 - acc: 0.4176\n",
      "Epoch 17/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6389 - acc: 0.4227\n",
      "Epoch 18/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6325 - acc: 0.4229\n",
      "Epoch 19/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6309 - acc: 0.4286\n",
      "Epoch 20/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6185 - acc: 0.4303\n",
      "Epoch 21/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6141 - acc: 0.4307\n",
      "Epoch 22/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5974 - acc: 0.4378\n",
      "Epoch 23/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5978 - acc: 0.4400\n",
      "Epoch 24/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5864 - acc: 0.4424\n",
      "Epoch 25/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5816 - acc: 0.4406\n",
      "Epoch 26/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5705 - acc: 0.4497\n",
      "Epoch 27/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5658 - acc: 0.4460\n",
      "Epoch 28/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5643 - acc: 0.4502\n",
      "Epoch 29/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5574 - acc: 0.4557\n",
      "Epoch 30/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5487 - acc: 0.4536\n",
      "Epoch 31/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5471 - acc: 0.4598\n",
      "Epoch 32/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5359 - acc: 0.4598\n",
      "Epoch 33/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5281 - acc: 0.4616\n",
      "Epoch 34/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5315 - acc: 0.4628\n",
      "Epoch 35/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5175 - acc: 0.4629\n",
      "Epoch 36/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5211 - acc: 0.4641\n",
      "Epoch 37/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5178 - acc: 0.4658\n",
      "Epoch 38/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5091 - acc: 0.4676\n",
      "Epoch 39/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5036 - acc: 0.4726\n",
      "Epoch 40/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4918 - acc: 0.4756\n",
      "Epoch 41/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4930 - acc: 0.4762\n",
      "Epoch 42/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4930 - acc: 0.4711\n",
      "Epoch 43/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4846 - acc: 0.4782\n",
      "Epoch 44/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4778 - acc: 0.4834\n",
      "Epoch 45/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4664 - acc: 0.4833\n",
      "Epoch 46/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4675 - acc: 0.4846\n",
      "Epoch 47/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4573 - acc: 0.4872\n",
      "Epoch 48/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4574 - acc: 0.4870\n",
      "Epoch 49/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4530 - acc: 0.4877\n",
      "Epoch 50/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4502 - acc: 0.4890\n",
      "Epoch 51/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4473 - acc: 0.4916\n",
      "Epoch 52/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4448 - acc: 0.4913\n",
      "Epoch 53/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4447 - acc: 0.4927\n",
      "Epoch 54/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4333 - acc: 0.4961\n",
      "Epoch 55/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4296 - acc: 0.4982\n",
      "Epoch 56/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4255 - acc: 0.4984\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4251 - acc: 0.4994\n",
      "Epoch 58/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4262 - acc: 0.4968\n",
      "Epoch 59/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4165 - acc: 0.4993\n",
      "Epoch 60/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4081 - acc: 0.5001\n",
      "Epoch 61/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4098 - acc: 0.5026\n",
      "Epoch 62/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4065 - acc: 0.5022\n",
      "Epoch 63/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4068 - acc: 0.5069\n",
      "Epoch 64/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4032 - acc: 0.5062\n",
      "Epoch 65/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3937 - acc: 0.5088\n",
      "Epoch 66/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3927 - acc: 0.5112\n",
      "Epoch 67/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3894 - acc: 0.5103\n",
      "Epoch 68/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3822 - acc: 0.5124\n",
      "Epoch 69/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3799 - acc: 0.5146\n",
      "Epoch 70/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3799 - acc: 0.5112\n",
      "Epoch 71/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3741 - acc: 0.5137\n",
      "Epoch 72/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3681 - acc: 0.5164\n",
      "Epoch 73/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3694 - acc: 0.5194\n",
      "Epoch 74/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3694 - acc: 0.5160\n",
      "Epoch 75/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3659 - acc: 0.5196\n",
      "Epoch 76/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3548 - acc: 0.5235\n",
      "Epoch 77/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3615 - acc: 0.5204\n",
      "Epoch 78/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3468 - acc: 0.5229\n",
      "Epoch 79/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3511 - acc: 0.5275\n",
      "Epoch 80/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3478 - acc: 0.5272\n",
      "Epoch 81/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3437 - acc: 0.5270\n",
      "Epoch 82/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3443 - acc: 0.5268\n",
      "Epoch 83/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3346 - acc: 0.5305\n",
      "Epoch 84/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3336 - acc: 0.5285\n",
      "Epoch 85/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3333 - acc: 0.5278\n",
      "Epoch 86/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3248 - acc: 0.5345\n",
      "Epoch 87/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3202 - acc: 0.5370\n",
      "Epoch 88/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3235 - acc: 0.5319\n",
      "Epoch 89/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3174 - acc: 0.5357\n",
      "Epoch 90/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3119 - acc: 0.5355\n",
      "Epoch 91/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3168 - acc: 0.5345\n",
      "Epoch 92/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3093 - acc: 0.5364\n",
      "Epoch 93/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3083 - acc: 0.5360\n",
      "Epoch 94/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3045 - acc: 0.5424\n",
      "Epoch 95/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3055 - acc: 0.5390\n",
      "Epoch 96/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3005 - acc: 0.5400\n",
      "Epoch 97/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3029 - acc: 0.5399\n",
      "Epoch 98/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2985 - acc: 0.5442\n",
      "Epoch 99/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2906 - acc: 0.5471\n",
      "Epoch 100/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2957 - acc: 0.5407\n",
      "25000/25000 [==============================] - 0s 17us/step\n",
      "10000/10000 [==============================] - 0s 16us/step\n",
      "Loading data for dataset 1 with window_size of 25, stride of 1 and maxRUL of 130. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(18231, 350)\n",
      "(18231, 1)\n",
      "Testing data (X, y)\n",
      "(100, 350)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.63253012 -0.18639634 -0.38048616 ... -0.16666667  0.25581395\n",
      "   0.47638774]\n",
      " [-0.43373494 -0.09396119 -0.29473329 ...  0.          0.11627907\n",
      "   0.43800055]\n",
      " [-0.31325301 -0.26095487 -0.25894666 ... -0.16666667  0.31782946\n",
      "   0.52720243]\n",
      " [-0.31325301 -0.48768258 -0.33760972 ... -0.66666667  0.34883721\n",
      "   0.07677437]\n",
      " [-0.30120482 -0.48506649 -0.19074949 ... -0.16666667  0.2248062\n",
      "   0.28555648]]\n",
      "[[130.]\n",
      " [130.]\n",
      " [130.]\n",
      " [130.]\n",
      " [130.]]\n",
      "Testing data (X, y)\n",
      "[[-0.45783133 -0.46370177 -0.23733964 ... -0.16666667  0.03875969\n",
      "   0.27312897]\n",
      " [ 0.27710843 -0.16590364 -0.24206617 ... -0.5         0.03875969\n",
      "   0.01518917]\n",
      " [ 0.31325301 -0.19468062 -0.06684673 ...  0.16666667  0.2248062\n",
      "   0.04888152]\n",
      " [-0.23493976 -0.03291912 -0.08845375 ...  0.16666667 -0.31782946\n",
      "   0.004971  ]\n",
      " [ 0.09638554 -0.09439721  0.14280891 ...  0.         -0.05426357\n",
      "   0.42916321]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n",
      "Validation on model:best_models/cmapss/alpha0.6/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 792)               277992    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 792)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 712)               564616    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 713       \n",
      "=================================================================\n",
      "Total params: 843,321\n",
      "Trainable params: 843,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "9115/9115 [==============================] - 0s 19us/step - loss: 3107.2829 - mean_squared_error: 3107.2829\n",
      "Epoch 2/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 487.8057 - mean_squared_error: 487.8057\n",
      "Epoch 3/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 370.1275 - mean_squared_error: 370.1275\n",
      "Epoch 4/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 333.9823 - mean_squared_error: 333.9823\n",
      "Epoch 5/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 298.5386 - mean_squared_error: 298.5386\n",
      "Epoch 6/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 315.0612 - mean_squared_error: 315.0612\n",
      "Epoch 7/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 280.7363 - mean_squared_error: 280.7363\n",
      "Epoch 8/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 264.4267 - mean_squared_error: 264.4267\n",
      "Epoch 9/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 267.3875 - mean_squared_error: 267.3875\n",
      "Epoch 10/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 251.4537 - mean_squared_error: 251.4537\n",
      "Epoch 11/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 261.5855 - mean_squared_error: 261.5855\n",
      "Epoch 12/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 258.7304 - mean_squared_error: 258.7304\n",
      "Epoch 13/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 257.4805 - mean_squared_error: 257.4805\n",
      "Epoch 14/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 269.5187 - mean_squared_error: 269.5187\n",
      "Epoch 15/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 252.7279 - mean_squared_error: 252.7279\n",
      "Epoch 16/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 243.2831 - mean_squared_error: 243.2831\n",
      "Epoch 17/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 264.1253 - mean_squared_error: 264.1253\n",
      "Epoch 18/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 236.3202 - mean_squared_error: 236.3202\n",
      "Epoch 19/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 243.1586 - mean_squared_error: 243.1586\n",
      "Epoch 20/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 261.0868 - mean_squared_error: 261.0868\n",
      "Epoch 21/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 234.9295 - mean_squared_error: 234.9295\n",
      "Epoch 22/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 247.2184 - mean_squared_error: 247.2184\n",
      "Epoch 23/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 240.8986 - mean_squared_error: 240.8986\n",
      "Epoch 24/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 245.5053 - mean_squared_error: 245.5053\n",
      "Epoch 25/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 244.3470 - mean_squared_error: 244.3470\n",
      "Epoch 26/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 249.2403 - mean_squared_error: 249.2403\n",
      "Epoch 27/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 226.9431 - mean_squared_error: 226.9431\n",
      "Epoch 28/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 250.9542 - mean_squared_error: 250.9542\n",
      "Epoch 29/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 236.1591 - mean_squared_error: 236.1591\n",
      "Epoch 30/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 229.0132 - mean_squared_error: 229.0132\n",
      "Epoch 31/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 231.9379 - mean_squared_error: 231.9379\n",
      "Epoch 32/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 227.6065 - mean_squared_error: 227.6065\n",
      "Epoch 33/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 240.5539 - mean_squared_error: 240.5539\n",
      "Epoch 34/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 222.7323 - mean_squared_error: 222.7323\n",
      "Epoch 35/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 224.0410 - mean_squared_error: 224.0410\n",
      "Epoch 36/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 226.1416 - mean_squared_error: 226.1416\n",
      "Epoch 37/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 216.3500 - mean_squared_error: 216.3500\n",
      "Epoch 38/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 230.5140 - mean_squared_error: 230.5140\n",
      "Epoch 39/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 224.1955 - mean_squared_error: 224.1955\n",
      "Epoch 40/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 206.9431 - mean_squared_error: 206.9431\n",
      "Epoch 41/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 217.7547 - mean_squared_error: 217.7547\n",
      "Epoch 42/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 212.2517 - mean_squared_error: 212.2517\n",
      "Epoch 43/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 229.0611 - mean_squared_error: 229.0611\n",
      "Epoch 44/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 207.2068 - mean_squared_error: 207.2068\n",
      "Epoch 45/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 199.5730 - mean_squared_error: 199.5730\n",
      "Epoch 46/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 221.9382 - mean_squared_error: 221.9382\n",
      "Epoch 47/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 196.9521 - mean_squared_error: 196.9521\n",
      "Epoch 48/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 199.6480 - mean_squared_error: 199.6480\n",
      "Epoch 49/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 221.3360 - mean_squared_error: 221.3360\n",
      "Epoch 50/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 234.4827 - mean_squared_error: 234.4827\n",
      "Epoch 51/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 189.9105 - mean_squared_error: 189.9105\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9115/9115 [==============================] - 0s 4us/step - loss: 181.0407 - mean_squared_error: 181.0407\n",
      "Epoch 53/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 194.8269 - mean_squared_error: 194.8269\n",
      "Epoch 54/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 242.9759 - mean_squared_error: 242.9759\n",
      "Epoch 55/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 202.8541 - mean_squared_error: 202.8541\n",
      "Epoch 56/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 190.9444 - mean_squared_error: 190.9444\n",
      "Epoch 57/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 204.1350 - mean_squared_error: 204.1350\n",
      "Epoch 58/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 190.1672 - mean_squared_error: 190.1672\n",
      "Epoch 59/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 187.6183 - mean_squared_error: 187.6183\n",
      "Epoch 60/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 199.1650 - mean_squared_error: 199.1650\n",
      "Epoch 61/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 194.4610 - mean_squared_error: 194.4610\n",
      "Epoch 62/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 188.4893 - mean_squared_error: 188.4893\n",
      "Epoch 63/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 205.2854 - mean_squared_error: 205.2854\n",
      "Epoch 64/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 189.9648 - mean_squared_error: 189.9648\n",
      "Epoch 65/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 180.9518 - mean_squared_error: 180.9518\n",
      "Epoch 66/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 179.3926 - mean_squared_error: 179.3926\n",
      "Epoch 67/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 161.2307 - mean_squared_error: 161.2307\n",
      "Epoch 68/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 172.4736 - mean_squared_error: 172.4736\n",
      "Epoch 69/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 176.3936 - mean_squared_error: 176.3936\n",
      "Epoch 70/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 181.2036 - mean_squared_error: 181.2036\n",
      "Epoch 71/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 179.6708 - mean_squared_error: 179.6708\n",
      "Epoch 72/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 174.4768 - mean_squared_error: 174.4768\n",
      "Epoch 73/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 152.7451 - mean_squared_error: 152.7451\n",
      "Epoch 74/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 170.4484 - mean_squared_error: 170.4484\n",
      "Epoch 75/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 170.9477 - mean_squared_error: 170.9477\n",
      "Epoch 76/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 195.3023 - mean_squared_error: 195.3023\n",
      "Epoch 77/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 164.9368 - mean_squared_error: 164.9368\n",
      "Epoch 78/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 153.4693 - mean_squared_error: 153.4693\n",
      "Epoch 79/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 168.5972 - mean_squared_error: 168.5972\n",
      "Epoch 80/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 172.1037 - mean_squared_error: 172.1037\n",
      "Epoch 81/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 163.9317 - mean_squared_error: 163.9317\n",
      "Epoch 82/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 165.0790 - mean_squared_error: 165.0790\n",
      "Epoch 83/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 188.4369 - mean_squared_error: 188.4369\n",
      "Epoch 84/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 170.2707 - mean_squared_error: 170.2707\n",
      "Epoch 85/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 150.6868 - mean_squared_error: 150.6868\n",
      "Epoch 86/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 137.9767 - mean_squared_error: 137.9767\n",
      "Epoch 87/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 172.2022 - mean_squared_error: 172.2022\n",
      "Epoch 88/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 155.4865 - mean_squared_error: 155.4865\n",
      "Epoch 89/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 150.5744 - mean_squared_error: 150.5744\n",
      "Epoch 90/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 145.1446 - mean_squared_error: 145.1446\n",
      "Epoch 91/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 156.5092 - mean_squared_error: 156.5092\n",
      "Epoch 92/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 133.4362 - mean_squared_error: 133.4362\n",
      "Epoch 93/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 149.1238 - mean_squared_error: 149.1238\n",
      "Epoch 94/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 119.5565 - mean_squared_error: 119.5565\n",
      "Epoch 95/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 130.1883 - mean_squared_error: 130.1883\n",
      "Epoch 96/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 225.2445 - mean_squared_error: 225.2445\n",
      "Epoch 97/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 139.2593 - mean_squared_error: 139.2593\n",
      "Epoch 98/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 142.0342 - mean_squared_error: 142.0342\n",
      "Epoch 99/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 145.3634 - mean_squared_error: 145.3634\n",
      "Epoch 100/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 132.9318 - mean_squared_error: 132.9318\n",
      "9116/9116 [==============================] - 0s 13us/step\n",
      "100/100 [==============================] - 0s 20us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 792)               277992    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 792)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 712)               564616    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 713       \n",
      "=================================================================\n",
      "Total params: 843,321\n",
      "Trainable params: 843,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "9116/9116 [==============================] - 0s 19us/step - loss: 2923.2250 - mean_squared_error: 2923.2250\n",
      "Epoch 2/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 477.8705 - mean_squared_error: 477.8705\n",
      "Epoch 3/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 373.8655 - mean_squared_error: 373.8655\n",
      "Epoch 4/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 315.0998 - mean_squared_error: 315.0998\n",
      "Epoch 5/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 307.5220 - mean_squared_error: 307.5220\n",
      "Epoch 6/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 277.5865 - mean_squared_error: 277.5865\n",
      "Epoch 7/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 272.7370 - mean_squared_error: 272.7370\n",
      "Epoch 8/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 260.7781 - mean_squared_error: 260.7781\n",
      "Epoch 9/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 247.5241 - mean_squared_error: 247.5241\n",
      "Epoch 10/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 250.8337 - mean_squared_error: 250.8337\n",
      "Epoch 11/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 264.4388 - mean_squared_error: 264.4388\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9116/9116 [==============================] - 0s 4us/step - loss: 248.4723 - mean_squared_error: 248.4723\n",
      "Epoch 13/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 249.0977 - mean_squared_error: 249.0977\n",
      "Epoch 14/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 250.4922 - mean_squared_error: 250.4922\n",
      "Epoch 15/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 243.7573 - mean_squared_error: 243.7573\n",
      "Epoch 16/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 246.2037 - mean_squared_error: 246.2037\n",
      "Epoch 17/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 241.5088 - mean_squared_error: 241.5088\n",
      "Epoch 18/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 241.7234 - mean_squared_error: 241.7234\n",
      "Epoch 19/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 234.4831 - mean_squared_error: 234.4831\n",
      "Epoch 20/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 240.3801 - mean_squared_error: 240.3801\n",
      "Epoch 21/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 235.0740 - mean_squared_error: 235.0740\n",
      "Epoch 22/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 250.7608 - mean_squared_error: 250.7608\n",
      "Epoch 23/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 242.9817 - mean_squared_error: 242.9817\n",
      "Epoch 24/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 224.0165 - mean_squared_error: 224.0165\n",
      "Epoch 25/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 229.1317 - mean_squared_error: 229.1317\n",
      "Epoch 26/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 232.2263 - mean_squared_error: 232.2263\n",
      "Epoch 27/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 232.7811 - mean_squared_error: 232.7811\n",
      "Epoch 28/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 211.3294 - mean_squared_error: 211.3294\n",
      "Epoch 29/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 219.2611 - mean_squared_error: 219.2611\n",
      "Epoch 30/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 207.2883 - mean_squared_error: 207.2883\n",
      "Epoch 31/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 232.6572 - mean_squared_error: 232.6572\n",
      "Epoch 32/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 238.6033 - mean_squared_error: 238.6033\n",
      "Epoch 33/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 229.1971 - mean_squared_error: 229.1971\n",
      "Epoch 34/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 225.4068 - mean_squared_error: 225.4068\n",
      "Epoch 35/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 210.5758 - mean_squared_error: 210.5758\n",
      "Epoch 36/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 209.8079 - mean_squared_error: 209.8079\n",
      "Epoch 37/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 243.7173 - mean_squared_error: 243.7173\n",
      "Epoch 38/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 208.5646 - mean_squared_error: 208.5646\n",
      "Epoch 39/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 202.9208 - mean_squared_error: 202.9208\n",
      "Epoch 40/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 234.2702 - mean_squared_error: 234.2702\n",
      "Epoch 41/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 223.1177 - mean_squared_error: 223.1177\n",
      "Epoch 42/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 217.7480 - mean_squared_error: 217.7480\n",
      "Epoch 43/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 204.9129 - mean_squared_error: 204.9129\n",
      "Epoch 44/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 187.9616 - mean_squared_error: 187.9616\n",
      "Epoch 45/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 208.8069 - mean_squared_error: 208.8069\n",
      "Epoch 46/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 208.4322 - mean_squared_error: 208.4322\n",
      "Epoch 47/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 214.6871 - mean_squared_error: 214.6871\n",
      "Epoch 48/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 197.1234 - mean_squared_error: 197.1234\n",
      "Epoch 49/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 208.9246 - mean_squared_error: 208.9246\n",
      "Epoch 50/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 203.1653 - mean_squared_error: 203.1653\n",
      "Epoch 51/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 188.6831 - mean_squared_error: 188.6831\n",
      "Epoch 52/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 188.9127 - mean_squared_error: 188.9127\n",
      "Epoch 53/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 198.7436 - mean_squared_error: 198.7436\n",
      "Epoch 54/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 221.8125 - mean_squared_error: 221.8125\n",
      "Epoch 55/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 182.7608 - mean_squared_error: 182.7608\n",
      "Epoch 56/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 187.9086 - mean_squared_error: 187.9086\n",
      "Epoch 57/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 194.3546 - mean_squared_error: 194.3546\n",
      "Epoch 58/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 183.9416 - mean_squared_error: 183.9416\n",
      "Epoch 59/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 194.1813 - mean_squared_error: 194.1813\n",
      "Epoch 60/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 196.0796 - mean_squared_error: 196.0796\n",
      "Epoch 61/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 177.4548 - mean_squared_error: 177.4548\n",
      "Epoch 62/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 203.4253 - mean_squared_error: 203.4253\n",
      "Epoch 63/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 194.1159 - mean_squared_error: 194.1159\n",
      "Epoch 64/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 173.3872 - mean_squared_error: 173.3872\n",
      "Epoch 65/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 178.4918 - mean_squared_error: 178.4918\n",
      "Epoch 66/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 173.8642 - mean_squared_error: 173.8642\n",
      "Epoch 67/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 200.3524 - mean_squared_error: 200.3524\n",
      "Epoch 68/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 163.6227 - mean_squared_error: 163.6227\n",
      "Epoch 69/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 177.8193 - mean_squared_error: 177.8193\n",
      "Epoch 70/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 192.4072 - mean_squared_error: 192.4072\n",
      "Epoch 71/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 161.0870 - mean_squared_error: 161.0870\n",
      "Epoch 72/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 178.8215 - mean_squared_error: 178.8215\n",
      "Epoch 73/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 164.9457 - mean_squared_error: 164.9457\n",
      "Epoch 74/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 172.8152 - mean_squared_error: 172.8152\n",
      "Epoch 75/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 178.7591 - mean_squared_error: 178.7591\n",
      "Epoch 76/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 161.2771 - mean_squared_error: 161.2771\n",
      "Epoch 77/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 152.8400 - mean_squared_error: 152.8400\n",
      "Epoch 78/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 161.4297 - mean_squared_error: 161.4297\n",
      "Epoch 79/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 159.3483 - mean_squared_error: 159.3483\n",
      "Epoch 80/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 145.7926 - mean_squared_error: 145.7926\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9116/9116 [==============================] - 0s 4us/step - loss: 168.7913 - mean_squared_error: 168.7913\n",
      "Epoch 82/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 169.4153 - mean_squared_error: 169.4153\n",
      "Epoch 83/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 159.2221 - mean_squared_error: 159.2221\n",
      "Epoch 84/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 155.2231 - mean_squared_error: 155.2231\n",
      "Epoch 85/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 158.2511 - mean_squared_error: 158.2511\n",
      "Epoch 86/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 135.5456 - mean_squared_error: 135.5456\n",
      "Epoch 87/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 165.3276 - mean_squared_error: 165.3276\n",
      "Epoch 88/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 162.1773 - mean_squared_error: 162.1773\n",
      "Epoch 89/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 142.2810 - mean_squared_error: 142.2810\n",
      "Epoch 90/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 142.2096 - mean_squared_error: 142.2096\n",
      "Epoch 91/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 145.0290 - mean_squared_error: 145.0290\n",
      "Epoch 92/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 137.5370 - mean_squared_error: 137.5370\n",
      "Epoch 93/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 142.0503 - mean_squared_error: 142.0503\n",
      "Epoch 94/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 156.2502 - mean_squared_error: 156.2502\n",
      "Epoch 95/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 151.0887 - mean_squared_error: 151.0887\n",
      "Epoch 96/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 139.2927 - mean_squared_error: 139.2927\n",
      "Epoch 97/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 165.4328 - mean_squared_error: 165.4328\n",
      "Epoch 98/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 135.7209 - mean_squared_error: 135.7209\n",
      "Epoch 99/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 141.3469 - mean_squared_error: 141.3469\n",
      "Epoch 100/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 134.5269 - mean_squared_error: 134.5269\n",
      "9115/9115 [==============================] - 0s 13us/step\n",
      "100/100 [==============================] - 0s 19us/step\n",
      "Loading data for dataset 1 with window_size of 25, stride of 1 and maxRUL of 130. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(18231, 350)\n",
      "(18231, 1)\n",
      "Testing data (X, y)\n",
      "(100, 350)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.63253012 -0.18639634 -0.38048616 ... -0.16666667  0.25581395\n",
      "   0.47638774]\n",
      " [-0.43373494 -0.09396119 -0.29473329 ...  0.          0.11627907\n",
      "   0.43800055]\n",
      " [-0.31325301 -0.26095487 -0.25894666 ... -0.16666667  0.31782946\n",
      "   0.52720243]\n",
      " [-0.31325301 -0.48768258 -0.33760972 ... -0.66666667  0.34883721\n",
      "   0.07677437]\n",
      " [-0.30120482 -0.48506649 -0.19074949 ... -0.16666667  0.2248062\n",
      "   0.28555648]]\n",
      "[[130.]\n",
      " [130.]\n",
      " [130.]\n",
      " [130.]\n",
      " [130.]]\n",
      "Testing data (X, y)\n",
      "[[-0.45783133 -0.46370177 -0.23733964 ... -0.16666667  0.03875969\n",
      "   0.27312897]\n",
      " [ 0.27710843 -0.16590364 -0.24206617 ... -0.5         0.03875969\n",
      "   0.01518917]\n",
      " [ 0.31325301 -0.19468062 -0.06684673 ...  0.16666667  0.2248062\n",
      "   0.04888152]\n",
      " [-0.23493976 -0.03291912 -0.08845375 ...  0.16666667 -0.31782946\n",
      "   0.004971  ]\n",
      " [ 0.09638554 -0.09439721  0.14280891 ...  0.         -0.05426357\n",
      "   0.42916321]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n",
      "Validation on model:best_models/cmapss/alpha0.8/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 624)               219024    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 624)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 464)               290000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 464)               215760    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 465       \n",
      "=================================================================\n",
      "Total params: 725,249\n",
      "Trainable params: 725,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "9115/9115 [==============================] - 0s 22us/step - loss: 2743.9385 - mean_squared_error: 2743.9385\n",
      "Epoch 2/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 435.0743 - mean_squared_error: 435.0743\n",
      "Epoch 3/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 378.6702 - mean_squared_error: 378.6702\n",
      "Epoch 4/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 360.9608 - mean_squared_error: 360.9608\n",
      "Epoch 5/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 326.2121 - mean_squared_error: 326.2121\n",
      "Epoch 6/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 277.2203 - mean_squared_error: 277.2203\n",
      "Epoch 7/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 272.0345 - mean_squared_error: 272.0345\n",
      "Epoch 8/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 295.1926 - mean_squared_error: 295.1926\n",
      "Epoch 9/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 297.5394 - mean_squared_error: 297.5394\n",
      "Epoch 10/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 254.7653 - mean_squared_error: 254.7653\n",
      "Epoch 11/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 271.2236 - mean_squared_error: 271.2236\n",
      "Epoch 12/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 282.3966 - mean_squared_error: 282.3966\n",
      "Epoch 13/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 292.3915 - mean_squared_error: 292.3915\n",
      "Epoch 14/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 269.1916 - mean_squared_error: 269.1916\n",
      "Epoch 15/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 262.2707 - mean_squared_error: 262.2707\n",
      "Epoch 16/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 268.3330 - mean_squared_error: 268.3330\n",
      "Epoch 17/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 293.9013 - mean_squared_error: 293.9013\n",
      "Epoch 18/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 247.0825 - mean_squared_error: 247.0825\n",
      "Epoch 19/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 266.5278 - mean_squared_error: 266.5278\n",
      "Epoch 20/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 256.5078 - mean_squared_error: 256.5078\n",
      "Epoch 21/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 226.6513 - mean_squared_error: 226.6513\n",
      "Epoch 22/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 253.4231 - mean_squared_error: 253.4231\n",
      "Epoch 23/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 213.7407 - mean_squared_error: 213.7407\n",
      "Epoch 24/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 295.8707 - mean_squared_error: 295.8707\n",
      "Epoch 25/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 226.4538 - mean_squared_error: 226.4538\n",
      "Epoch 26/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 259.2845 - mean_squared_error: 259.2845\n",
      "Epoch 27/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 227.7958 - mean_squared_error: 227.7958\n",
      "Epoch 28/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 219.4658 - mean_squared_error: 219.4658\n",
      "Epoch 29/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 227.7144 - mean_squared_error: 227.7144\n",
      "Epoch 30/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 238.5105 - mean_squared_error: 238.5105\n",
      "Epoch 31/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 218.3549 - mean_squared_error: 218.3549\n",
      "Epoch 32/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 248.8068 - mean_squared_error: 248.8068\n",
      "Epoch 33/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 261.9211 - mean_squared_error: 261.9211\n",
      "Epoch 34/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 222.7656 - mean_squared_error: 222.7656\n",
      "Epoch 35/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 276.4903 - mean_squared_error: 276.4903\n",
      "Epoch 36/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 224.5481 - mean_squared_error: 224.5481\n",
      "Epoch 37/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 209.0461 - mean_squared_error: 209.0461\n",
      "Epoch 38/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 204.9292 - mean_squared_error: 204.9292\n",
      "Epoch 39/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 228.0816 - mean_squared_error: 228.0816\n",
      "Epoch 40/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 180.6649 - mean_squared_error: 180.6649\n",
      "Epoch 41/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 233.2213 - mean_squared_error: 233.2213\n",
      "Epoch 42/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 218.5856 - mean_squared_error: 218.5856\n",
      "Epoch 43/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 210.3252 - mean_squared_error: 210.3252\n",
      "Epoch 44/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 215.6308 - mean_squared_error: 215.6308\n",
      "Epoch 45/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 248.5735 - mean_squared_error: 248.5735\n",
      "Epoch 46/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 176.9005 - mean_squared_error: 176.9005\n",
      "Epoch 47/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 198.2277 - mean_squared_error: 198.2277\n",
      "Epoch 48/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 210.6610 - mean_squared_error: 210.6610\n",
      "Epoch 49/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 186.5256 - mean_squared_error: 186.5256\n",
      "Epoch 50/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 182.2138 - mean_squared_error: 182.2138\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9115/9115 [==============================] - 0s 4us/step - loss: 243.2289 - mean_squared_error: 243.2289\n",
      "Epoch 52/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 185.3213 - mean_squared_error: 185.3213\n",
      "Epoch 53/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 164.7923 - mean_squared_error: 164.7923\n",
      "Epoch 54/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 195.0526 - mean_squared_error: 195.0526\n",
      "Epoch 55/100\n",
      "9115/9115 [==============================] - 0s 5us/step - loss: 227.1035 - mean_squared_error: 227.1035\n",
      "Epoch 56/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 198.0694 - mean_squared_error: 198.0694\n",
      "Epoch 57/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 175.5155 - mean_squared_error: 175.5155\n",
      "Epoch 58/100\n",
      "9115/9115 [==============================] - 0s 5us/step - loss: 187.6808 - mean_squared_error: 187.6808\n",
      "Epoch 59/100\n",
      "9115/9115 [==============================] - 0s 5us/step - loss: 183.3129 - mean_squared_error: 183.3129\n",
      "Epoch 60/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 148.6956 - mean_squared_error: 148.6956\n",
      "Epoch 61/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 160.8633 - mean_squared_error: 160.8633\n",
      "Epoch 62/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 180.5653 - mean_squared_error: 180.5653\n",
      "Epoch 63/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 260.1837 - mean_squared_error: 260.1837\n",
      "Epoch 64/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 164.0572 - mean_squared_error: 164.0572\n",
      "Epoch 65/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 171.9814 - mean_squared_error: 171.9814\n",
      "Epoch 66/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 171.6021 - mean_squared_error: 171.6021\n",
      "Epoch 67/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 153.1010 - mean_squared_error: 153.1010\n",
      "Epoch 68/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 169.6089 - mean_squared_error: 169.6089\n",
      "Epoch 69/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 190.2444 - mean_squared_error: 190.2444\n",
      "Epoch 70/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 148.6361 - mean_squared_error: 148.6361\n",
      "Epoch 71/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 153.1907 - mean_squared_error: 153.1907\n",
      "Epoch 72/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 167.2479 - mean_squared_error: 167.2479\n",
      "Epoch 73/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 120.2952 - mean_squared_error: 120.2952\n",
      "Epoch 74/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 196.7578 - mean_squared_error: 196.7578\n",
      "Epoch 75/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 165.6862 - mean_squared_error: 165.6862\n",
      "Epoch 76/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 164.6030 - mean_squared_error: 164.6030\n",
      "Epoch 77/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 126.8553 - mean_squared_error: 126.8553\n",
      "Epoch 78/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 173.5653 - mean_squared_error: 173.5653\n",
      "Epoch 79/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 138.2793 - mean_squared_error: 138.2793\n",
      "Epoch 80/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 175.6794 - mean_squared_error: 175.6794\n",
      "Epoch 81/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 181.0824 - mean_squared_error: 181.0824\n",
      "Epoch 82/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 130.3585 - mean_squared_error: 130.3585\n",
      "Epoch 83/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 135.9057 - mean_squared_error: 135.9057\n",
      "Epoch 84/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 164.9176 - mean_squared_error: 164.9176\n",
      "Epoch 85/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 132.3491 - mean_squared_error: 132.3491\n",
      "Epoch 86/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 122.6874 - mean_squared_error: 122.6874\n",
      "Epoch 87/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 136.1816 - mean_squared_error: 136.1816\n",
      "Epoch 88/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 146.1117 - mean_squared_error: 146.1117\n",
      "Epoch 89/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 190.2719 - mean_squared_error: 190.2719\n",
      "Epoch 90/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 136.6547 - mean_squared_error: 136.6547\n",
      "Epoch 91/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 128.6798 - mean_squared_error: 128.6798\n",
      "Epoch 92/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 126.2795 - mean_squared_error: 126.2795\n",
      "Epoch 93/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 127.4874 - mean_squared_error: 127.4874\n",
      "Epoch 94/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 138.6488 - mean_squared_error: 138.6488\n",
      "Epoch 95/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 99.4099 - mean_squared_error: 99.4099\n",
      "Epoch 96/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 125.4515 - mean_squared_error: 125.4515\n",
      "Epoch 97/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 126.4569 - mean_squared_error: 126.4569\n",
      "Epoch 98/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 136.5083 - mean_squared_error: 136.5083\n",
      "Epoch 99/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 127.7222 - mean_squared_error: 127.7222\n",
      "Epoch 100/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 141.8808 - mean_squared_error: 141.8808\n",
      "9116/9116 [==============================] - 0s 14us/step\n",
      "100/100 [==============================] - 0s 21us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 624)               219024    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 624)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 464)               290000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 464)               215760    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 465       \n",
      "=================================================================\n",
      "Total params: 725,249\n",
      "Trainable params: 725,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "9116/9116 [==============================] - 0s 21us/step - loss: 2817.2527 - mean_squared_error: 2817.2527\n",
      "Epoch 2/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 444.8424 - mean_squared_error: 444.8424\n",
      "Epoch 3/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 410.9134 - mean_squared_error: 410.9134\n",
      "Epoch 4/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 318.7434 - mean_squared_error: 318.7434\n",
      "Epoch 5/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 326.7434 - mean_squared_error: 326.7434\n",
      "Epoch 6/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 286.2423 - mean_squared_error: 286.2423\n",
      "Epoch 7/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 278.3528 - mean_squared_error: 278.3528\n",
      "Epoch 8/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 293.5406 - mean_squared_error: 293.5406\n",
      "Epoch 9/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 273.5659 - mean_squared_error: 273.5659\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9116/9116 [==============================] - 0s 4us/step - loss: 267.5224 - mean_squared_error: 267.5224\n",
      "Epoch 11/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 269.5965 - mean_squared_error: 269.5965\n",
      "Epoch 12/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 280.9854 - mean_squared_error: 280.9854\n",
      "Epoch 13/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 290.8971 - mean_squared_error: 290.8971\n",
      "Epoch 14/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 266.9062 - mean_squared_error: 266.9062\n",
      "Epoch 15/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 239.4563 - mean_squared_error: 239.4563\n",
      "Epoch 16/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 274.6261 - mean_squared_error: 274.6261\n",
      "Epoch 17/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 241.7582 - mean_squared_error: 241.7582\n",
      "Epoch 18/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 241.8627 - mean_squared_error: 241.8627\n",
      "Epoch 19/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 255.7649 - mean_squared_error: 255.7649\n",
      "Epoch 20/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 229.6674 - mean_squared_error: 229.6674\n",
      "Epoch 21/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 229.3411 - mean_squared_error: 229.3411\n",
      "Epoch 22/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 259.0386 - mean_squared_error: 259.0386\n",
      "Epoch 23/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 257.0957 - mean_squared_error: 257.0957\n",
      "Epoch 24/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 259.0822 - mean_squared_error: 259.0822\n",
      "Epoch 25/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 256.2757 - mean_squared_error: 256.2757\n",
      "Epoch 26/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 234.6350 - mean_squared_error: 234.6350\n",
      "Epoch 27/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 225.0430 - mean_squared_error: 225.0430\n",
      "Epoch 28/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 223.7331 - mean_squared_error: 223.7331\n",
      "Epoch 29/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 269.5560 - mean_squared_error: 269.5560\n",
      "Epoch 30/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 224.5766 - mean_squared_error: 224.5766\n",
      "Epoch 31/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 193.2302 - mean_squared_error: 193.2302\n",
      "Epoch 32/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 240.3297 - mean_squared_error: 240.3297\n",
      "Epoch 33/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 226.2925 - mean_squared_error: 226.2925\n",
      "Epoch 34/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 207.6904 - mean_squared_error: 207.6904\n",
      "Epoch 35/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 226.7349 - mean_squared_error: 226.7349\n",
      "Epoch 36/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 227.1922 - mean_squared_error: 227.1922\n",
      "Epoch 37/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 215.0806 - mean_squared_error: 215.0806\n",
      "Epoch 38/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 323.3321 - mean_squared_error: 323.3321\n",
      "Epoch 39/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 199.3319 - mean_squared_error: 199.3319\n",
      "Epoch 40/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 215.5475 - mean_squared_error: 215.5475\n",
      "Epoch 41/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 215.6372 - mean_squared_error: 215.6372\n",
      "Epoch 42/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 231.3489 - mean_squared_error: 231.3489\n",
      "Epoch 43/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 216.9715 - mean_squared_error: 216.9715\n",
      "Epoch 44/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 183.1945 - mean_squared_error: 183.1945\n",
      "Epoch 45/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 223.4454 - mean_squared_error: 223.4454\n",
      "Epoch 46/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 194.9364 - mean_squared_error: 194.9364\n",
      "Epoch 47/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 214.5578 - mean_squared_error: 214.5578\n",
      "Epoch 48/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 172.1585 - mean_squared_error: 172.1585\n",
      "Epoch 49/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 199.9473 - mean_squared_error: 199.9473\n",
      "Epoch 50/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 186.6780 - mean_squared_error: 186.6780\n",
      "Epoch 51/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 223.2207 - mean_squared_error: 223.2207\n",
      "Epoch 52/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 190.4912 - mean_squared_error: 190.4912\n",
      "Epoch 53/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 236.3819 - mean_squared_error: 236.3819\n",
      "Epoch 54/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 164.7707 - mean_squared_error: 164.7707\n",
      "Epoch 55/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 184.3232 - mean_squared_error: 184.3232\n",
      "Epoch 56/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 173.0265 - mean_squared_error: 173.0265\n",
      "Epoch 57/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 182.0412 - mean_squared_error: 182.0412\n",
      "Epoch 58/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 188.7325 - mean_squared_error: 188.7325\n",
      "Epoch 59/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 178.1697 - mean_squared_error: 178.1697\n",
      "Epoch 60/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 199.8264 - mean_squared_error: 199.8264\n",
      "Epoch 61/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 151.9234 - mean_squared_error: 151.9234\n",
      "Epoch 62/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 186.4141 - mean_squared_error: 186.4141\n",
      "Epoch 63/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 200.8818 - mean_squared_error: 200.8818\n",
      "Epoch 64/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 158.4984 - mean_squared_error: 158.4984\n",
      "Epoch 65/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 187.8549 - mean_squared_error: 187.8549\n",
      "Epoch 66/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 165.4649 - mean_squared_error: 165.4649\n",
      "Epoch 67/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 197.5500 - mean_squared_error: 197.5500\n",
      "Epoch 68/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 158.3887 - mean_squared_error: 158.3887\n",
      "Epoch 69/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 182.3134 - mean_squared_error: 182.3134\n",
      "Epoch 70/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 172.1186 - mean_squared_error: 172.1186\n",
      "Epoch 71/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 138.9885 - mean_squared_error: 138.9885\n",
      "Epoch 72/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 173.3661 - mean_squared_error: 173.3661\n",
      "Epoch 73/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 152.2818 - mean_squared_error: 152.2818\n",
      "Epoch 74/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 146.8944 - mean_squared_error: 146.8944\n",
      "Epoch 75/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 170.7082 - mean_squared_error: 170.7082\n",
      "Epoch 76/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 156.9330 - mean_squared_error: 156.9330\n",
      "Epoch 77/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 176.5106 - mean_squared_error: 176.5106\n",
      "Epoch 78/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 137.2399 - mean_squared_error: 137.2399\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9116/9116 [==============================] - 0s 4us/step - loss: 167.4034 - mean_squared_error: 167.4034\n",
      "Epoch 80/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 148.3293 - mean_squared_error: 148.3293\n",
      "Epoch 81/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 156.3447 - mean_squared_error: 156.3447\n",
      "Epoch 82/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 131.4900 - mean_squared_error: 131.4900\n",
      "Epoch 83/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 155.8518 - mean_squared_error: 155.8518\n",
      "Epoch 84/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 129.3763 - mean_squared_error: 129.3763\n",
      "Epoch 85/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 139.9777 - mean_squared_error: 139.9777\n",
      "Epoch 86/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 171.4142 - mean_squared_error: 171.4142\n",
      "Epoch 87/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 142.7582 - mean_squared_error: 142.7582\n",
      "Epoch 88/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 132.8365 - mean_squared_error: 132.8365\n",
      "Epoch 89/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 141.5334 - mean_squared_error: 141.5334\n",
      "Epoch 90/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 142.0197 - mean_squared_error: 142.0197\n",
      "Epoch 91/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 140.2748 - mean_squared_error: 140.2748\n",
      "Epoch 92/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 148.9414 - mean_squared_error: 148.9414\n",
      "Epoch 93/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 131.7135 - mean_squared_error: 131.7135\n",
      "Epoch 94/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 127.8117 - mean_squared_error: 127.8117\n",
      "Epoch 95/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 143.9918 - mean_squared_error: 143.9918\n",
      "Epoch 96/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 108.6338 - mean_squared_error: 108.6338\n",
      "Epoch 97/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 131.4334 - mean_squared_error: 131.4334\n",
      "Epoch 98/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 122.6631 - mean_squared_error: 122.6631\n",
      "Epoch 99/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 105.9446 - mean_squared_error: 105.9446\n",
      "Epoch 100/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 157.0609 - mean_squared_error: 157.0609\n",
      "9115/9115 [==============================] - 0s 14us/step\n",
      "100/100 [==============================] - 0s 22us/step\n",
      "Loading data for dataset 1 with window_size of 25, stride of 1 and maxRUL of 130. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(18231, 350)\n",
      "(18231, 1)\n",
      "Testing data (X, y)\n",
      "(100, 350)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.63253012 -0.18639634 -0.38048616 ... -0.16666667  0.25581395\n",
      "   0.47638774]\n",
      " [-0.43373494 -0.09396119 -0.29473329 ...  0.          0.11627907\n",
      "   0.43800055]\n",
      " [-0.31325301 -0.26095487 -0.25894666 ... -0.16666667  0.31782946\n",
      "   0.52720243]\n",
      " [-0.31325301 -0.48768258 -0.33760972 ... -0.66666667  0.34883721\n",
      "   0.07677437]\n",
      " [-0.30120482 -0.48506649 -0.19074949 ... -0.16666667  0.2248062\n",
      "   0.28555648]]\n",
      "[[130.]\n",
      " [130.]\n",
      " [130.]\n",
      " [130.]\n",
      " [130.]]\n",
      "Testing data (X, y)\n",
      "[[-0.45783133 -0.46370177 -0.23733964 ... -0.16666667  0.03875969\n",
      "   0.27312897]\n",
      " [ 0.27710843 -0.16590364 -0.24206617 ... -0.5         0.03875969\n",
      "   0.01518917]\n",
      " [ 0.31325301 -0.19468062 -0.06684673 ...  0.16666667  0.2248062\n",
      "   0.04888152]\n",
      " [-0.23493976 -0.03291912 -0.08845375 ...  0.16666667 -0.31782946\n",
      "   0.004971  ]\n",
      " [ 0.09638554 -0.09439721  0.14280891 ...  0.         -0.05426357\n",
      "   0.42916321]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n",
      "Validation on model:best_models/cmapss/alpha1/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 992)               348192    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 992)               985056    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 608)               603744    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 609       \n",
      "=================================================================\n",
      "Total params: 1,937,601\n",
      "Trainable params: 1,937,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "9115/9115 [==============================] - 0s 24us/step - loss: 2334.9594 - mean_squared_error: 2334.9594\n",
      "Epoch 2/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 493.3137 - mean_squared_error: 493.3137\n",
      "Epoch 3/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 436.0480 - mean_squared_error: 436.0480\n",
      "Epoch 4/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 420.7767 - mean_squared_error: 420.7767\n",
      "Epoch 5/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 295.9917 - mean_squared_error: 295.9917\n",
      "Epoch 6/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 339.5449 - mean_squared_error: 339.5449\n",
      "Epoch 7/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 290.6338 - mean_squared_error: 290.6338\n",
      "Epoch 8/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 332.8507 - mean_squared_error: 332.8507\n",
      "Epoch 9/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 307.2662 - mean_squared_error: 307.2662\n",
      "Epoch 10/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 270.3900 - mean_squared_error: 270.3900\n",
      "Epoch 11/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 305.0796 - mean_squared_error: 305.0796\n",
      "Epoch 12/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 288.1684 - mean_squared_error: 288.1684\n",
      "Epoch 13/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 277.6283 - mean_squared_error: 277.6283\n",
      "Epoch 14/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 282.8491 - mean_squared_error: 282.8491\n",
      "Epoch 15/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 267.1112 - mean_squared_error: 267.1112\n",
      "Epoch 16/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 283.0443 - mean_squared_error: 283.0443\n",
      "Epoch 17/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 262.3990 - mean_squared_error: 262.3990\n",
      "Epoch 18/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 234.8597 - mean_squared_error: 234.8597\n",
      "Epoch 19/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 236.9227 - mean_squared_error: 236.9227\n",
      "Epoch 20/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 289.0398 - mean_squared_error: 289.0398\n",
      "Epoch 21/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 274.2174 - mean_squared_error: 274.2174\n",
      "Epoch 22/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 257.6949 - mean_squared_error: 257.6949\n",
      "Epoch 23/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 233.3543 - mean_squared_error: 233.3543\n",
      "Epoch 24/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 277.7890 - mean_squared_error: 277.7890\n",
      "Epoch 25/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 232.5858 - mean_squared_error: 232.5858\n",
      "Epoch 26/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 262.6716 - mean_squared_error: 262.6716\n",
      "Epoch 27/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 250.5010 - mean_squared_error: 250.5010\n",
      "Epoch 28/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 251.5760 - mean_squared_error: 251.5760\n",
      "Epoch 29/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 223.5694 - mean_squared_error: 223.5694\n",
      "Epoch 30/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 243.7709 - mean_squared_error: 243.7709\n",
      "Epoch 31/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 194.1007 - mean_squared_error: 194.1007\n",
      "Epoch 32/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 296.5914 - mean_squared_error: 296.5914\n",
      "Epoch 33/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 209.2672 - mean_squared_error: 209.2672\n",
      "Epoch 34/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 266.3932 - mean_squared_error: 266.3932\n",
      "Epoch 35/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 202.4630 - mean_squared_error: 202.4630\n",
      "Epoch 36/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 208.2330 - mean_squared_error: 208.2330\n",
      "Epoch 37/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 219.5921 - mean_squared_error: 219.5921\n",
      "Epoch 38/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 201.6520 - mean_squared_error: 201.6520\n",
      "Epoch 39/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 192.9305 - mean_squared_error: 192.9305\n",
      "Epoch 40/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 232.8890 - mean_squared_error: 232.8890\n",
      "Epoch 41/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 221.1463 - mean_squared_error: 221.1463\n",
      "Epoch 42/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 189.9365 - mean_squared_error: 189.9365\n",
      "Epoch 43/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 200.7787 - mean_squared_error: 200.7787\n",
      "Epoch 44/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 198.3414 - mean_squared_error: 198.3414\n",
      "Epoch 45/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 174.8044 - mean_squared_error: 174.8044\n",
      "Epoch 46/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 225.3379 - mean_squared_error: 225.3379\n",
      "Epoch 47/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 207.0050 - mean_squared_error: 207.0050\n",
      "Epoch 48/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 201.5827 - mean_squared_error: 201.5827\n",
      "Epoch 49/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 177.2975 - mean_squared_error: 177.2975\n",
      "Epoch 50/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 165.2983 - mean_squared_error: 165.2983\n",
      "Epoch 51/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 198.1237 - mean_squared_error: 198.1237\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9115/9115 [==============================] - 0s 6us/step - loss: 153.3162 - mean_squared_error: 153.3162\n",
      "Epoch 53/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 220.5468 - mean_squared_error: 220.5468\n",
      "Epoch 54/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 166.3036 - mean_squared_error: 166.3036\n",
      "Epoch 55/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 182.0262 - mean_squared_error: 182.0262\n",
      "Epoch 56/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 167.4333 - mean_squared_error: 167.4333\n",
      "Epoch 57/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 163.9536 - mean_squared_error: 163.9536\n",
      "Epoch 58/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 143.9668 - mean_squared_error: 143.9668\n",
      "Epoch 59/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 170.9369 - mean_squared_error: 170.9369\n",
      "Epoch 60/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 166.4739 - mean_squared_error: 166.4739\n",
      "Epoch 61/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 151.9133 - mean_squared_error: 151.9133\n",
      "Epoch 62/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 147.4281 - mean_squared_error: 147.4281\n",
      "Epoch 63/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 180.1029 - mean_squared_error: 180.1029\n",
      "Epoch 64/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 143.3084 - mean_squared_error: 143.3084\n",
      "Epoch 65/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 137.6524 - mean_squared_error: 137.6524\n",
      "Epoch 66/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 159.6472 - mean_squared_error: 159.6472\n",
      "Epoch 67/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 119.9231 - mean_squared_error: 119.9231\n",
      "Epoch 68/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 150.4547 - mean_squared_error: 150.4547\n",
      "Epoch 69/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 160.0535 - mean_squared_error: 160.0535\n",
      "Epoch 70/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 138.1051 - mean_squared_error: 138.1051\n",
      "Epoch 71/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 165.1327 - mean_squared_error: 165.1327\n",
      "Epoch 72/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 131.7265 - mean_squared_error: 131.7265\n",
      "Epoch 73/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 124.4735 - mean_squared_error: 124.4735\n",
      "Epoch 74/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 125.3717 - mean_squared_error: 125.3717\n",
      "Epoch 75/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 134.0313 - mean_squared_error: 134.0313\n",
      "Epoch 76/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 173.1248 - mean_squared_error: 173.1248\n",
      "Epoch 77/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 138.6351 - mean_squared_error: 138.6351\n",
      "Epoch 78/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 142.5833 - mean_squared_error: 142.5833\n",
      "Epoch 79/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 164.2350 - mean_squared_error: 164.2350\n",
      "Epoch 80/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 125.4223 - mean_squared_error: 125.4223\n",
      "Epoch 81/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 117.3608 - mean_squared_error: 117.3608\n",
      "Epoch 82/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 118.7225 - mean_squared_error: 118.7225\n",
      "Epoch 83/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 109.1808 - mean_squared_error: 109.1808\n",
      "Epoch 84/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 111.5612 - mean_squared_error: 111.5612\n",
      "Epoch 85/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 108.3624 - mean_squared_error: 108.3624\n",
      "Epoch 86/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 176.1707 - mean_squared_error: 176.1707\n",
      "Epoch 87/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 99.0236 - mean_squared_error: 99.0236\n",
      "Epoch 88/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 97.1425 - mean_squared_error: 97.1425\n",
      "Epoch 89/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 112.3697 - mean_squared_error: 112.3697\n",
      "Epoch 90/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 98.0619 - mean_squared_error: 98.0619\n",
      "Epoch 91/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 100.1622 - mean_squared_error: 100.1622\n",
      "Epoch 92/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 122.2013 - mean_squared_error: 122.2013\n",
      "Epoch 93/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 94.8358 - mean_squared_error: 94.8358\n",
      "Epoch 94/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 129.6847 - mean_squared_error: 129.6847\n",
      "Epoch 95/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 87.6218 - mean_squared_error: 87.6218\n",
      "Epoch 96/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 90.5950 - mean_squared_error: 90.5950\n",
      "Epoch 97/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 91.3983 - mean_squared_error: 91.3983\n",
      "Epoch 98/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 72.6910 - mean_squared_error: 72.6910\n",
      "Epoch 99/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 137.0402 - mean_squared_error: 137.0402\n",
      "Epoch 100/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 122.4454 - mean_squared_error: 122.4454\n",
      "9116/9116 [==============================] - 0s 14us/step\n",
      "100/100 [==============================] - 0s 19us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 992)               348192    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 992)               985056    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 608)               603744    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 609       \n",
      "=================================================================\n",
      "Total params: 1,937,601\n",
      "Trainable params: 1,937,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "9116/9116 [==============================] - 0s 23us/step - loss: 2298.0774 - mean_squared_error: 2298.0774\n",
      "Epoch 2/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 454.3268 - mean_squared_error: 454.3268\n",
      "Epoch 3/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 378.1145 - mean_squared_error: 378.1145\n",
      "Epoch 4/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 487.8430 - mean_squared_error: 487.8430\n",
      "Epoch 5/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 331.5862 - mean_squared_error: 331.5862\n",
      "Epoch 6/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 261.0928 - mean_squared_error: 261.0928\n",
      "Epoch 7/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 348.6919 - mean_squared_error: 348.6919\n",
      "Epoch 8/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 290.1073 - mean_squared_error: 290.1073\n",
      "Epoch 9/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 275.6756 - mean_squared_error: 275.6756\n",
      "Epoch 10/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 297.8960 - mean_squared_error: 297.8960\n",
      "Epoch 11/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 284.3625 - mean_squared_error: 284.3625\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9116/9116 [==============================] - 0s 6us/step - loss: 273.3873 - mean_squared_error: 273.3873\n",
      "Epoch 13/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 266.4762 - mean_squared_error: 266.4762\n",
      "Epoch 14/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 250.8941 - mean_squared_error: 250.8941\n",
      "Epoch 15/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 267.2385 - mean_squared_error: 267.2385\n",
      "Epoch 16/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 235.3989 - mean_squared_error: 235.3989\n",
      "Epoch 17/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 319.3962 - mean_squared_error: 319.3962\n",
      "Epoch 18/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 271.2642 - mean_squared_error: 271.2642\n",
      "Epoch 19/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 248.8593 - mean_squared_error: 248.8593\n",
      "Epoch 20/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 228.9820 - mean_squared_error: 228.9820\n",
      "Epoch 21/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 279.3232 - mean_squared_error: 279.3232\n",
      "Epoch 22/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 215.8001 - mean_squared_error: 215.8001\n",
      "Epoch 23/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 260.3894 - mean_squared_error: 260.3894\n",
      "Epoch 24/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 236.8924 - mean_squared_error: 236.8924\n",
      "Epoch 25/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 281.6077 - mean_squared_error: 281.6077\n",
      "Epoch 26/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 220.3633 - mean_squared_error: 220.3633\n",
      "Epoch 27/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 219.2945 - mean_squared_error: 219.2945\n",
      "Epoch 28/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 198.7510 - mean_squared_error: 198.7510\n",
      "Epoch 29/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 270.2517 - mean_squared_error: 270.2517\n",
      "Epoch 30/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 228.3966 - mean_squared_error: 228.3966\n",
      "Epoch 31/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 226.4895 - mean_squared_error: 226.4895\n",
      "Epoch 32/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 210.0622 - mean_squared_error: 210.0622\n",
      "Epoch 33/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 255.1071 - mean_squared_error: 255.1071\n",
      "Epoch 34/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 211.7004 - mean_squared_error: 211.7004\n",
      "Epoch 35/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 236.4909 - mean_squared_error: 236.4909\n",
      "Epoch 36/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 242.9999 - mean_squared_error: 242.9999\n",
      "Epoch 37/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 214.8648 - mean_squared_error: 214.8648\n",
      "Epoch 38/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 190.1046 - mean_squared_error: 190.1046\n",
      "Epoch 39/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 232.0185 - mean_squared_error: 232.0185\n",
      "Epoch 40/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 167.1255 - mean_squared_error: 167.1255\n",
      "Epoch 41/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 222.1256 - mean_squared_error: 222.1256\n",
      "Epoch 42/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 211.3486 - mean_squared_error: 211.3486\n",
      "Epoch 43/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 220.6403 - mean_squared_error: 220.6403\n",
      "Epoch 44/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 213.6377 - mean_squared_error: 213.6377\n",
      "Epoch 45/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 180.9229 - mean_squared_error: 180.9229\n",
      "Epoch 46/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 181.4021 - mean_squared_error: 181.4021\n",
      "Epoch 47/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 193.0504 - mean_squared_error: 193.0504\n",
      "Epoch 48/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 226.3984 - mean_squared_error: 226.3984\n",
      "Epoch 49/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 162.7881 - mean_squared_error: 162.7881\n",
      "Epoch 50/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 198.1570 - mean_squared_error: 198.1570\n",
      "Epoch 51/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 194.3210 - mean_squared_error: 194.3210\n",
      "Epoch 52/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 166.4733 - mean_squared_error: 166.4733\n",
      "Epoch 53/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 184.3058 - mean_squared_error: 184.3058\n",
      "Epoch 54/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 171.5328 - mean_squared_error: 171.5328\n",
      "Epoch 55/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 166.7605 - mean_squared_error: 166.7605\n",
      "Epoch 56/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 176.6137 - mean_squared_error: 176.6137\n",
      "Epoch 57/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 156.4116 - mean_squared_error: 156.4116\n",
      "Epoch 58/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 150.8814 - mean_squared_error: 150.8814\n",
      "Epoch 59/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 167.3536 - mean_squared_error: 167.3536\n",
      "Epoch 60/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 157.2266 - mean_squared_error: 157.2266\n",
      "Epoch 61/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 153.9572 - mean_squared_error: 153.9572\n",
      "Epoch 62/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 209.1330 - mean_squared_error: 209.1330\n",
      "Epoch 63/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 136.2676 - mean_squared_error: 136.2676\n",
      "Epoch 64/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 194.5607 - mean_squared_error: 194.5607\n",
      "Epoch 65/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 155.6773 - mean_squared_error: 155.6773\n",
      "Epoch 66/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 148.6627 - mean_squared_error: 148.6627\n",
      "Epoch 67/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 160.4331 - mean_squared_error: 160.4331\n",
      "Epoch 68/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 104.6569 - mean_squared_error: 104.6569\n",
      "Epoch 69/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 171.2641 - mean_squared_error: 171.2641\n",
      "Epoch 70/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 166.1077 - mean_squared_error: 166.1077\n",
      "Epoch 71/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 140.6639 - mean_squared_error: 140.6639\n",
      "Epoch 72/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 170.7077 - mean_squared_error: 170.7077\n",
      "Epoch 73/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 114.0683 - mean_squared_error: 114.0683\n",
      "Epoch 74/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 144.2777 - mean_squared_error: 144.2777\n",
      "Epoch 75/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 118.0331 - mean_squared_error: 118.0331\n",
      "Epoch 76/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 117.8991 - mean_squared_error: 117.8991\n",
      "Epoch 77/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 129.0995 - mean_squared_error: 129.0995\n",
      "Epoch 78/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 134.1284 - mean_squared_error: 134.1284\n",
      "Epoch 79/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 127.9864 - mean_squared_error: 127.9864\n",
      "Epoch 80/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 123.5817 - mean_squared_error: 123.5817\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9116/9116 [==============================] - 0s 6us/step - loss: 128.3732 - mean_squared_error: 128.3732\n",
      "Epoch 82/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 100.4343 - mean_squared_error: 100.4343\n",
      "Epoch 83/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 124.4484 - mean_squared_error: 124.4484\n",
      "Epoch 84/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 147.5828 - mean_squared_error: 147.5828\n",
      "Epoch 85/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 133.1945 - mean_squared_error: 133.1945\n",
      "Epoch 86/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 238.1373 - mean_squared_error: 238.1373\n",
      "Epoch 87/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 111.1851 - mean_squared_error: 111.1851\n",
      "Epoch 88/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 126.3655 - mean_squared_error: 126.3655\n",
      "Epoch 89/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 103.1835 - mean_squared_error: 103.1835\n",
      "Epoch 90/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 112.6658 - mean_squared_error: 112.6658\n",
      "Epoch 91/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 98.5764 - mean_squared_error: 98.5764\n",
      "Epoch 92/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 123.8320 - mean_squared_error: 123.8320\n",
      "Epoch 93/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 99.8298 - mean_squared_error: 99.8298\n",
      "Epoch 94/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 98.6756 - mean_squared_error: 98.6756\n",
      "Epoch 95/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 118.6763 - mean_squared_error: 118.6763\n",
      "Epoch 96/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 88.1197 - mean_squared_error: 88.1197\n",
      "Epoch 97/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 101.1345 - mean_squared_error: 101.1345\n",
      "Epoch 98/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 77.2446 - mean_squared_error: 77.2446\n",
      "Epoch 99/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 145.5263 - mean_squared_error: 145.5263\n",
      "Epoch 100/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 83.1168 - mean_squared_error: 83.1168\n",
      "9115/9115 [==============================] - 0s 13us/step\n",
      "100/100 [==============================] - 0s 18us/step\n",
      "Loading data. Cross-Validation ratio 0\n",
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(60000, 784)\n",
      "(60000, 10)\n",
      "Testing data (X, y)\n",
      "(10000, 784)\n",
      "(10000, 10)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Testing data (X, y)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "Validation on model:best_models/mnist/alpha0.6/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 56)                43960     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 56)                3192      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                570       \n",
      "=================================================================\n",
      "Total params: 47,722\n",
      "Trainable params: 47,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "30000/30000 [==============================] - 0s 8us/step - loss: 0.9407 - acc: 0.7554\n",
      "Epoch 2/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.3474 - acc: 0.9023\n",
      "Epoch 3/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2770 - acc: 0.9214\n",
      "Epoch 4/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2393 - acc: 0.9315\n",
      "Epoch 5/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2105 - acc: 0.9395\n",
      "Epoch 6/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1890 - acc: 0.9455\n",
      "Epoch 7/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1717 - acc: 0.9500\n",
      "Epoch 8/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1569 - acc: 0.9548\n",
      "Epoch 9/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1424 - acc: 0.9588\n",
      "Epoch 10/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1321 - acc: 0.9615\n",
      "Epoch 11/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1214 - acc: 0.9647\n",
      "Epoch 12/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1135 - acc: 0.9660\n",
      "Epoch 13/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1048 - acc: 0.9688\n",
      "Epoch 14/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0987 - acc: 0.9704\n",
      "Epoch 15/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0906 - acc: 0.9736\n",
      "Epoch 16/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0852 - acc: 0.9754\n",
      "Epoch 17/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0792 - acc: 0.9764\n",
      "Epoch 18/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0731 - acc: 0.9787\n",
      "Epoch 19/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0691 - acc: 0.9804\n",
      "Epoch 20/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0647 - acc: 0.9810\n",
      "Epoch 21/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0608 - acc: 0.9823\n",
      "Epoch 22/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0565 - acc: 0.9842\n",
      "Epoch 23/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0529 - acc: 0.9853\n",
      "Epoch 24/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0503 - acc: 0.9859\n",
      "Epoch 25/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0473 - acc: 0.9864\n",
      "Epoch 26/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0442 - acc: 0.9884\n",
      "Epoch 27/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0411 - acc: 0.9888\n",
      "Epoch 28/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0388 - acc: 0.9888\n",
      "Epoch 29/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0358 - acc: 0.9905\n",
      "Epoch 30/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0338 - acc: 0.9913\n",
      "Epoch 31/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0319 - acc: 0.9920\n",
      "Epoch 32/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0299 - acc: 0.9929\n",
      "Epoch 33/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0279 - acc: 0.9937\n",
      "Epoch 34/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0253 - acc: 0.9947\n",
      "Epoch 35/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0243 - acc: 0.9946\n",
      "Epoch 36/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0225 - acc: 0.9952\n",
      "Epoch 37/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0209 - acc: 0.9959\n",
      "Epoch 38/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0193 - acc: 0.9963\n",
      "Epoch 39/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0180 - acc: 0.9963\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0171 - acc: 0.9967\n",
      "Epoch 41/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0158 - acc: 0.9978\n",
      "Epoch 42/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0152 - acc: 0.9974\n",
      "Epoch 43/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0142 - acc: 0.9979\n",
      "Epoch 44/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0126 - acc: 0.9982\n",
      "Epoch 45/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0118 - acc: 0.9985\n",
      "Epoch 46/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0111 - acc: 0.9987\n",
      "Epoch 47/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0099 - acc: 0.9989\n",
      "Epoch 48/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0101 - acc: 0.9987\n",
      "Epoch 49/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0093 - acc: 0.9991\n",
      "Epoch 50/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0081 - acc: 0.9995\n",
      "Epoch 51/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0079 - acc: 0.9990\n",
      "Epoch 52/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0072 - acc: 0.9994\n",
      "Epoch 53/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0070 - acc: 0.9994\n",
      "Epoch 54/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0066 - acc: 0.9994\n",
      "Epoch 55/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0056 - acc: 0.9996\n",
      "Epoch 56/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0053 - acc: 0.9996\n",
      "Epoch 57/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0047 - acc: 0.9998\n",
      "Epoch 58/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0043 - acc: 0.9998\n",
      "Epoch 59/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0043 - acc: 0.9999\n",
      "Epoch 60/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0042 - acc: 0.9999\n",
      "Epoch 61/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0036 - acc: 0.9999\n",
      "Epoch 62/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0033 - acc: 0.9999\n",
      "Epoch 63/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 9.0286e-04 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 9.0288e-04 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 8.3936e-04 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 7.7853e-04 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 7.4208e-04 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 7.2212e-04 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 6.7566e-04 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 6.3863e-04 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 6.1788e-04 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 5.8873e-04 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 5.8296e-04 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 5.3970e-04 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 5.1354e-04 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 5.0368e-04 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 4.6920e-04 - acc: 1.0000\n",
      "30000/30000 [==============================] - 0s 14us/step\n",
      "10000/10000 [==============================] - 0s 14us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 56)                43960     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 56)                3192      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                570       \n",
      "=================================================================\n",
      "Total params: 47,722\n",
      "Trainable params: 47,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "30000/30000 [==============================] - 0s 8us/step - loss: 0.9727 - acc: 0.7420\n",
      "Epoch 2/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.3340 - acc: 0.9077\n",
      "Epoch 3/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2655 - acc: 0.9246\n",
      "Epoch 4/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2293 - acc: 0.9332\n",
      "Epoch 5/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2046 - acc: 0.9413\n",
      "Epoch 6/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1840 - acc: 0.9468\n",
      "Epoch 7/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1662 - acc: 0.9527\n",
      "Epoch 8/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1527 - acc: 0.9551\n",
      "Epoch 9/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1400 - acc: 0.9600\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1292 - acc: 0.9627\n",
      "Epoch 11/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1203 - acc: 0.9663\n",
      "Epoch 12/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1118 - acc: 0.9682\n",
      "Epoch 13/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1048 - acc: 0.9698\n",
      "Epoch 14/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0973 - acc: 0.9721\n",
      "Epoch 15/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0903 - acc: 0.9748\n",
      "Epoch 16/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0850 - acc: 0.9756\n",
      "Epoch 17/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0783 - acc: 0.9776\n",
      "Epoch 18/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0739 - acc: 0.9793\n",
      "Epoch 19/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0693 - acc: 0.9806\n",
      "Epoch 20/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0640 - acc: 0.9828\n",
      "Epoch 21/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0601 - acc: 0.9830\n",
      "Epoch 22/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0568 - acc: 0.9845\n",
      "Epoch 23/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0524 - acc: 0.9855\n",
      "Epoch 24/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0493 - acc: 0.9866\n",
      "Epoch 25/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0465 - acc: 0.9881\n",
      "Epoch 26/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0437 - acc: 0.9892\n",
      "Epoch 27/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0414 - acc: 0.9895\n",
      "Epoch 28/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0391 - acc: 0.9899\n",
      "Epoch 29/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0363 - acc: 0.9907\n",
      "Epoch 30/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 31/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0312 - acc: 0.9930\n",
      "Epoch 32/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0294 - acc: 0.9934\n",
      "Epoch 33/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0274 - acc: 0.9939\n",
      "Epoch 34/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0257 - acc: 0.9946\n",
      "Epoch 35/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0241 - acc: 0.9948\n",
      "Epoch 36/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0229 - acc: 0.9950\n",
      "Epoch 37/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0210 - acc: 0.9957\n",
      "Epoch 38/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0215 - acc: 0.9952\n",
      "Epoch 39/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0184 - acc: 0.9962\n",
      "Epoch 40/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0176 - acc: 0.9967\n",
      "Epoch 41/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0159 - acc: 0.9971\n",
      "Epoch 42/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0153 - acc: 0.9974\n",
      "Epoch 43/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0141 - acc: 0.9977\n",
      "Epoch 44/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0130 - acc: 0.9980\n",
      "Epoch 45/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0120 - acc: 0.9982\n",
      "Epoch 46/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0113 - acc: 0.9982\n",
      "Epoch 47/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0108 - acc: 0.9983\n",
      "Epoch 48/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0101 - acc: 0.9985\n",
      "Epoch 49/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0089 - acc: 0.9990\n",
      "Epoch 50/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0092 - acc: 0.9989\n",
      "Epoch 51/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0080 - acc: 0.9992\n",
      "Epoch 52/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0074 - acc: 0.9992\n",
      "Epoch 53/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0069 - acc: 0.9995\n",
      "Epoch 54/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0064 - acc: 0.9996\n",
      "Epoch 55/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0058 - acc: 0.9998\n",
      "Epoch 56/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0057 - acc: 0.9997\n",
      "Epoch 57/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0055 - acc: 0.9997\n",
      "Epoch 58/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0050 - acc: 0.9998\n",
      "Epoch 59/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0046 - acc: 0.9998\n",
      "Epoch 60/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0041 - acc: 0.9998\n",
      "Epoch 61/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0037 - acc: 0.9999\n",
      "Epoch 63/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0035 - acc: 0.9999\n",
      "Epoch 64/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0032 - acc: 0.9999\n",
      "Epoch 65/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 9.5405e-04 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 9.5413e-04 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 8.9388e-04 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 8.6415e-04 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 7.9586e-04 - acc: 1.0000\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 0s 4us/step - loss: 7.6662e-04 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 7.3348e-04 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 7.2654e-04 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 6.6066e-04 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 6.3121e-04 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 5.9858e-04 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 5.7990e-04 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 5.5489e-04 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 5.3262e-04 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 5.1015e-04 - acc: 1.0000\n",
      "30000/30000 [==============================] - 0s 14us/step\n",
      "10000/10000 [==============================] - 0s 14us/step\n",
      "Loading data. Cross-Validation ratio 0\n",
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(60000, 784)\n",
      "(60000, 10)\n",
      "Testing data (X, y)\n",
      "(10000, 784)\n",
      "(10000, 10)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Testing data (X, y)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "Validation on model:best_models/mnist/alpha0.8/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 24)                18840     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                250       \n",
      "=================================================================\n",
      "Total params: 19,090\n",
      "Trainable params: 19,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "30000/30000 [==============================] - 0s 7us/step - loss: 1.2475 - acc: 0.6700\n",
      "Epoch 2/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.5141 - acc: 0.8762\n",
      "Epoch 3/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.3951 - acc: 0.8964\n",
      "Epoch 4/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.3458 - acc: 0.9063\n",
      "Epoch 5/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.3175 - acc: 0.9139\n",
      "Epoch 6/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2982 - acc: 0.9183\n",
      "Epoch 7/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2839 - acc: 0.9207\n",
      "Epoch 8/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2722 - acc: 0.9245\n",
      "Epoch 9/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2623 - acc: 0.9265\n",
      "Epoch 10/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2531 - acc: 0.9293\n",
      "Epoch 11/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2450 - acc: 0.9322\n",
      "Epoch 12/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2379 - acc: 0.9346\n",
      "Epoch 13/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2305 - acc: 0.9362\n",
      "Epoch 14/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2238 - acc: 0.9382\n",
      "Epoch 15/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2176 - acc: 0.9406\n",
      "Epoch 16/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2111 - acc: 0.9426\n",
      "Epoch 17/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2056 - acc: 0.9440\n",
      "Epoch 18/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2001 - acc: 0.9452\n",
      "Epoch 19/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1943 - acc: 0.9472\n",
      "Epoch 20/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1893 - acc: 0.9490\n",
      "Epoch 21/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1840 - acc: 0.9498\n",
      "Epoch 22/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1799 - acc: 0.9519\n",
      "Epoch 23/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1757 - acc: 0.9531\n",
      "Epoch 24/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1709 - acc: 0.9545\n",
      "Epoch 25/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1669 - acc: 0.9553\n",
      "Epoch 26/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1631 - acc: 0.9567\n",
      "Epoch 27/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1590 - acc: 0.9577\n",
      "Epoch 28/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1556 - acc: 0.9588\n",
      "Epoch 29/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1519 - acc: 0.9593\n",
      "Epoch 30/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1495 - acc: 0.9597\n",
      "Epoch 31/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1459 - acc: 0.9607\n",
      "Epoch 32/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1429 - acc: 0.9620\n",
      "Epoch 33/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1403 - acc: 0.9624\n",
      "Epoch 34/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1367 - acc: 0.9631\n",
      "Epoch 35/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1345 - acc: 0.9633\n",
      "Epoch 36/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1316 - acc: 0.9639\n",
      "Epoch 37/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1289 - acc: 0.9653\n",
      "Epoch 38/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1259 - acc: 0.9656\n",
      "Epoch 39/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1236 - acc: 0.9657\n",
      "Epoch 40/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1214 - acc: 0.9674\n",
      "Epoch 41/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1189 - acc: 0.9671\n",
      "Epoch 42/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1176 - acc: 0.9675\n",
      "Epoch 43/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1149 - acc: 0.9685\n",
      "Epoch 44/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1126 - acc: 0.9684\n",
      "Epoch 45/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1108 - acc: 0.9698\n",
      "Epoch 46/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1084 - acc: 0.9702\n",
      "Epoch 47/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1065 - acc: 0.9711\n",
      "Epoch 48/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1050 - acc: 0.9712\n",
      "Epoch 49/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1030 - acc: 0.9719\n",
      "Epoch 50/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1014 - acc: 0.9717\n",
      "Epoch 51/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0995 - acc: 0.9728\n",
      "Epoch 52/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0976 - acc: 0.9733\n",
      "Epoch 53/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0961 - acc: 0.9734\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0941 - acc: 0.9748\n",
      "Epoch 55/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0930 - acc: 0.9744\n",
      "Epoch 56/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0910 - acc: 0.9752\n",
      "Epoch 57/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0896 - acc: 0.9766\n",
      "Epoch 58/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0881 - acc: 0.9759\n",
      "Epoch 59/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0867 - acc: 0.9766\n",
      "Epoch 60/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0848 - acc: 0.9769\n",
      "Epoch 61/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0842 - acc: 0.9774\n",
      "Epoch 62/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0825 - acc: 0.9778\n",
      "Epoch 63/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0812 - acc: 0.9781\n",
      "Epoch 64/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0799 - acc: 0.9783\n",
      "Epoch 65/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0787 - acc: 0.9787\n",
      "Epoch 66/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0774 - acc: 0.9794\n",
      "Epoch 67/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0763 - acc: 0.9796\n",
      "Epoch 68/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0751 - acc: 0.9799\n",
      "Epoch 69/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0739 - acc: 0.9804\n",
      "Epoch 70/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0727 - acc: 0.9810\n",
      "Epoch 71/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0712 - acc: 0.9812\n",
      "Epoch 72/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0706 - acc: 0.9812\n",
      "Epoch 73/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0695 - acc: 0.9813\n",
      "Epoch 74/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0680 - acc: 0.9827\n",
      "Epoch 75/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0675 - acc: 0.9823\n",
      "Epoch 76/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0660 - acc: 0.9826\n",
      "Epoch 77/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0651 - acc: 0.9833\n",
      "Epoch 78/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0642 - acc: 0.9830\n",
      "Epoch 79/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0634 - acc: 0.9836\n",
      "Epoch 80/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0628 - acc: 0.9836\n",
      "Epoch 81/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0615 - acc: 0.9837\n",
      "Epoch 82/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0604 - acc: 0.9849\n",
      "Epoch 83/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0593 - acc: 0.9842\n",
      "Epoch 84/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0592 - acc: 0.9842\n",
      "Epoch 85/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0574 - acc: 0.9854\n",
      "Epoch 86/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0568 - acc: 0.9848\n",
      "Epoch 87/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0560 - acc: 0.9858\n",
      "Epoch 88/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0551 - acc: 0.9860\n",
      "Epoch 89/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0545 - acc: 0.9861\n",
      "Epoch 90/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0537 - acc: 0.9861\n",
      "Epoch 91/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0527 - acc: 0.9863\n",
      "Epoch 92/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0516 - acc: 0.9871\n",
      "Epoch 93/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0514 - acc: 0.9867\n",
      "Epoch 94/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0506 - acc: 0.9875\n",
      "Epoch 95/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0497 - acc: 0.9879\n",
      "Epoch 96/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0488 - acc: 0.9876\n",
      "Epoch 97/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0481 - acc: 0.9882\n",
      "Epoch 98/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0474 - acc: 0.9880\n",
      "Epoch 99/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0466 - acc: 0.9887\n",
      "Epoch 100/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0458 - acc: 0.9887\n",
      "30000/30000 [==============================] - 0s 14us/step\n",
      "10000/10000 [==============================] - 0s 13us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 24)                18840     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                250       \n",
      "=================================================================\n",
      "Total params: 19,090\n",
      "Trainable params: 19,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "30000/30000 [==============================] - 0s 7us/step - loss: 1.3055 - acc: 0.6672\n",
      "Epoch 2/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.5460 - acc: 0.8695\n",
      "Epoch 3/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.4070 - acc: 0.8914\n",
      "Epoch 4/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.3475 - acc: 0.9036\n",
      "Epoch 5/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.3125 - acc: 0.9124\n",
      "Epoch 6/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2881 - acc: 0.9194\n",
      "Epoch 7/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2697 - acc: 0.9239\n",
      "Epoch 8/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2547 - acc: 0.9279\n",
      "Epoch 9/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2426 - acc: 0.9312\n",
      "Epoch 10/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2314 - acc: 0.9338\n",
      "Epoch 11/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2217 - acc: 0.9374\n",
      "Epoch 12/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2139 - acc: 0.9389\n",
      "Epoch 13/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2056 - acc: 0.9411\n",
      "Epoch 14/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1996 - acc: 0.9437\n",
      "Epoch 15/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1933 - acc: 0.9456\n",
      "Epoch 16/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1867 - acc: 0.9462\n",
      "Epoch 17/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1813 - acc: 0.9485\n",
      "Epoch 18/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1766 - acc: 0.9502\n",
      "Epoch 19/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1721 - acc: 0.9508\n",
      "Epoch 20/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1672 - acc: 0.9529\n",
      "Epoch 21/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1630 - acc: 0.9532\n",
      "Epoch 22/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1592 - acc: 0.9542\n",
      "Epoch 23/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1556 - acc: 0.9559\n",
      "Epoch 24/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1519 - acc: 0.9555\n",
      "Epoch 25/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1490 - acc: 0.9563\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1461 - acc: 0.9582\n",
      "Epoch 27/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1429 - acc: 0.9594\n",
      "Epoch 28/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1395 - acc: 0.9598\n",
      "Epoch 29/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1367 - acc: 0.9607\n",
      "Epoch 30/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1348 - acc: 0.9610\n",
      "Epoch 31/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1323 - acc: 0.9610\n",
      "Epoch 32/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1286 - acc: 0.9632\n",
      "Epoch 33/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1274 - acc: 0.9632\n",
      "Epoch 34/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1247 - acc: 0.9643\n",
      "Epoch 35/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1224 - acc: 0.9648\n",
      "Epoch 36/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1208 - acc: 0.9654\n",
      "Epoch 37/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1185 - acc: 0.9664\n",
      "Epoch 38/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1164 - acc: 0.9666\n",
      "Epoch 39/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1144 - acc: 0.9678\n",
      "Epoch 40/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1126 - acc: 0.9677\n",
      "Epoch 41/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1108 - acc: 0.9687\n",
      "Epoch 42/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1087 - acc: 0.9692\n",
      "Epoch 43/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1074 - acc: 0.9702\n",
      "Epoch 44/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1057 - acc: 0.9709\n",
      "Epoch 45/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1042 - acc: 0.9709\n",
      "Epoch 46/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1022 - acc: 0.9713\n",
      "Epoch 47/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1007 - acc: 0.9720\n",
      "Epoch 48/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0992 - acc: 0.9724\n",
      "Epoch 49/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0982 - acc: 0.9717\n",
      "Epoch 50/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0965 - acc: 0.9728\n",
      "Epoch 51/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0951 - acc: 0.9733\n",
      "Epoch 52/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0939 - acc: 0.9739\n",
      "Epoch 53/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0927 - acc: 0.9743\n",
      "Epoch 54/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0905 - acc: 0.9755\n",
      "Epoch 55/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0897 - acc: 0.9752\n",
      "Epoch 56/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0882 - acc: 0.9761\n",
      "Epoch 57/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0870 - acc: 0.9757\n",
      "Epoch 58/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0859 - acc: 0.9769\n",
      "Epoch 59/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0845 - acc: 0.9773\n",
      "Epoch 60/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0837 - acc: 0.9769\n",
      "Epoch 61/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0825 - acc: 0.9777\n",
      "Epoch 62/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0810 - acc: 0.9777\n",
      "Epoch 63/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0806 - acc: 0.9789\n",
      "Epoch 64/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0790 - acc: 0.9786\n",
      "Epoch 65/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0782 - acc: 0.9790\n",
      "Epoch 66/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0772 - acc: 0.9783\n",
      "Epoch 67/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0763 - acc: 0.9797\n",
      "Epoch 68/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0755 - acc: 0.9799\n",
      "Epoch 69/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0739 - acc: 0.9804\n",
      "Epoch 70/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0729 - acc: 0.9804\n",
      "Epoch 71/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0718 - acc: 0.9806\n",
      "Epoch 72/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0709 - acc: 0.9812\n",
      "Epoch 73/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0701 - acc: 0.9812\n",
      "Epoch 74/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0693 - acc: 0.9811\n",
      "Epoch 75/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0683 - acc: 0.9824\n",
      "Epoch 76/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0677 - acc: 0.9823\n",
      "Epoch 77/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0666 - acc: 0.9824\n",
      "Epoch 78/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0660 - acc: 0.9825\n",
      "Epoch 79/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0649 - acc: 0.9831\n",
      "Epoch 80/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0647 - acc: 0.9831\n",
      "Epoch 81/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0633 - acc: 0.9835\n",
      "Epoch 82/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0623 - acc: 0.9833\n",
      "Epoch 83/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0617 - acc: 0.9840\n",
      "Epoch 84/100\n",
      "30000/30000 [==============================] - 0s 3us/step - loss: 0.0611 - acc: 0.9844\n",
      "Epoch 85/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0605 - acc: 0.9845\n",
      "Epoch 86/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0594 - acc: 0.9851\n",
      "Epoch 87/100\n",
      "30000/30000 [==============================] - 0s 3us/step - loss: 0.0584 - acc: 0.9845\n",
      "Epoch 88/100\n",
      "30000/30000 [==============================] - 0s 3us/step - loss: 0.0581 - acc: 0.9852\n",
      "Epoch 89/100\n",
      "30000/30000 [==============================] - 0s 3us/step - loss: 0.0573 - acc: 0.9852\n",
      "Epoch 90/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0563 - acc: 0.9859\n",
      "Epoch 91/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0556 - acc: 0.9864\n",
      "Epoch 92/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0548 - acc: 0.9860\n",
      "Epoch 93/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0544 - acc: 0.9864\n",
      "Epoch 94/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0537 - acc: 0.9864\n",
      "Epoch 95/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0526 - acc: 0.9868\n",
      "Epoch 96/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0519 - acc: 0.9869\n",
      "Epoch 97/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0511 - acc: 0.9878\n",
      "Epoch 98/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0506 - acc: 0.9875\n",
      "Epoch 99/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0506 - acc: 0.9872\n",
      "Epoch 100/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0497 - acc: 0.9880\n",
      "30000/30000 [==============================] - 0s 14us/step\n",
      "10000/10000 [==============================] - 0s 13us/step\n",
      "Loading data. Cross-Validation ratio 0\n",
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(60000, 784)\n",
      "(60000, 10)\n",
      "Testing data (X, y)\n",
      "(10000, 784)\n",
      "(10000, 10)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Testing data (X, y)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "Validation on model:best_models/mnist/alpha1/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 96)                1632      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                970       \n",
      "=================================================================\n",
      "Total params: 15,162\n",
      "Trainable params: 15,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30000/30000 [==============================] - 0s 8us/step - loss: 1.3167 - acc: 0.6391\n",
      "Epoch 2/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.4374 - acc: 0.8814\n",
      "Epoch 3/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.3295 - acc: 0.9054\n",
      "Epoch 4/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2890 - acc: 0.9162\n",
      "Epoch 5/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2605 - acc: 0.9246\n",
      "Epoch 6/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2418 - acc: 0.9294\n",
      "Epoch 7/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2246 - acc: 0.9346\n",
      "Epoch 8/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2111 - acc: 0.9387\n",
      "Epoch 9/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1980 - acc: 0.9415\n",
      "Epoch 10/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1886 - acc: 0.9444\n",
      "Epoch 11/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1791 - acc: 0.9475\n",
      "Epoch 12/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1715 - acc: 0.9497\n",
      "Epoch 13/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1637 - acc: 0.9523\n",
      "Epoch 14/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1580 - acc: 0.9536\n",
      "Epoch 15/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1520 - acc: 0.9552\n",
      "Epoch 16/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1463 - acc: 0.9568\n",
      "Epoch 17/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1414 - acc: 0.9588\n",
      "Epoch 18/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1372 - acc: 0.9603\n",
      "Epoch 19/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1333 - acc: 0.9615\n",
      "Epoch 20/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1296 - acc: 0.9622\n",
      "Epoch 21/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1260 - acc: 0.9635\n",
      "Epoch 22/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1230 - acc: 0.9641\n",
      "Epoch 23/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1197 - acc: 0.9644\n",
      "Epoch 24/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1159 - acc: 0.9667\n",
      "Epoch 25/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1142 - acc: 0.9668\n",
      "Epoch 26/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1111 - acc: 0.9679\n",
      "Epoch 27/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1081 - acc: 0.9684\n",
      "Epoch 28/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1064 - acc: 0.9691\n",
      "Epoch 29/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1034 - acc: 0.9697\n",
      "Epoch 30/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1005 - acc: 0.9706\n",
      "Epoch 31/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0985 - acc: 0.9718\n",
      "Epoch 32/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0970 - acc: 0.9725\n",
      "Epoch 33/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0946 - acc: 0.9726\n",
      "Epoch 34/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0929 - acc: 0.9731\n",
      "Epoch 35/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0911 - acc: 0.9730\n",
      "Epoch 36/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0895 - acc: 0.9738\n",
      "Epoch 37/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0866 - acc: 0.9753\n",
      "Epoch 38/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0848 - acc: 0.9754\n",
      "Epoch 39/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0832 - acc: 0.9757\n",
      "Epoch 40/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0815 - acc: 0.9760\n",
      "Epoch 41/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0790 - acc: 0.9767\n",
      "Epoch 42/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0783 - acc: 0.9771\n",
      "Epoch 43/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0763 - acc: 0.9786\n",
      "Epoch 44/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0752 - acc: 0.9784\n",
      "Epoch 45/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0736 - acc: 0.9783\n",
      "Epoch 46/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0719 - acc: 0.9786\n",
      "Epoch 47/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0718 - acc: 0.9792\n",
      "Epoch 48/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0688 - acc: 0.9807\n",
      "Epoch 49/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0682 - acc: 0.9799\n",
      "Epoch 50/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0669 - acc: 0.9815\n",
      "Epoch 51/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0651 - acc: 0.9803\n",
      "Epoch 52/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0640 - acc: 0.9815\n",
      "Epoch 53/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0637 - acc: 0.9822\n",
      "Epoch 54/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0611 - acc: 0.9826\n",
      "Epoch 55/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0607 - acc: 0.9825\n",
      "Epoch 56/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0597 - acc: 0.9828\n",
      "Epoch 57/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0578 - acc: 0.9840\n",
      "Epoch 58/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0567 - acc: 0.9846\n",
      "Epoch 59/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0552 - acc: 0.9846\n",
      "Epoch 60/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0548 - acc: 0.9851\n",
      "Epoch 61/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0542 - acc: 0.9845\n",
      "Epoch 62/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0528 - acc: 0.9855\n",
      "Epoch 63/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0518 - acc: 0.9850\n",
      "Epoch 64/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0509 - acc: 0.9858\n",
      "Epoch 65/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0492 - acc: 0.9861\n",
      "Epoch 66/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0492 - acc: 0.9866\n",
      "Epoch 67/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0476 - acc: 0.9871\n",
      "Epoch 68/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0469 - acc: 0.9873\n",
      "Epoch 69/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0457 - acc: 0.9878\n",
      "Epoch 70/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0444 - acc: 0.9887\n",
      "Epoch 71/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0451 - acc: 0.9877\n",
      "Epoch 72/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0431 - acc: 0.9886\n",
      "Epoch 73/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0431 - acc: 0.9884\n",
      "Epoch 74/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0411 - acc: 0.9893\n",
      "Epoch 75/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0415 - acc: 0.9891\n",
      "Epoch 76/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0404 - acc: 0.9895\n",
      "Epoch 77/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0400 - acc: 0.9894\n",
      "Epoch 78/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0385 - acc: 0.9899\n",
      "Epoch 79/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0381 - acc: 0.9899\n",
      "Epoch 80/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0364 - acc: 0.9912\n",
      "Epoch 81/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0365 - acc: 0.9905\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0350 - acc: 0.9908\n",
      "Epoch 83/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0335 - acc: 0.9925\n",
      "Epoch 84/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0342 - acc: 0.9911\n",
      "Epoch 85/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 86/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0328 - acc: 0.9914\n",
      "Epoch 87/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0321 - acc: 0.9919\n",
      "Epoch 88/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0314 - acc: 0.9923\n",
      "Epoch 89/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0305 - acc: 0.9930\n",
      "Epoch 90/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0298 - acc: 0.9935\n",
      "Epoch 91/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0294 - acc: 0.9930\n",
      "Epoch 92/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0285 - acc: 0.9938\n",
      "Epoch 93/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0282 - acc: 0.9936\n",
      "Epoch 94/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0274 - acc: 0.9934\n",
      "Epoch 95/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0271 - acc: 0.9939\n",
      "Epoch 96/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0264 - acc: 0.9940\n",
      "Epoch 97/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0265 - acc: 0.9937\n",
      "Epoch 98/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0256 - acc: 0.9943\n",
      "Epoch 99/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0246 - acc: 0.9948\n",
      "Epoch 100/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0244 - acc: 0.9949\n",
      "30000/30000 [==============================] - 0s 14us/step\n",
      "10000/10000 [==============================] - 0s 13us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 96)                1632      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                970       \n",
      "=================================================================\n",
      "Total params: 15,162\n",
      "Trainable params: 15,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "30000/30000 [==============================] - 0s 8us/step - loss: 1.2952 - acc: 0.6058\n",
      "Epoch 2/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.4384 - acc: 0.8827\n",
      "Epoch 3/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.3369 - acc: 0.9054\n",
      "Epoch 4/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2999 - acc: 0.9141\n",
      "Epoch 5/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2761 - acc: 0.9193\n",
      "Epoch 6/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2606 - acc: 0.9243\n",
      "Epoch 7/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2467 - acc: 0.9301\n",
      "Epoch 8/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2358 - acc: 0.9305\n",
      "Epoch 9/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2252 - acc: 0.9350\n",
      "Epoch 10/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2157 - acc: 0.9375\n",
      "Epoch 11/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2070 - acc: 0.9407\n",
      "Epoch 12/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1991 - acc: 0.9423\n",
      "Epoch 13/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1925 - acc: 0.9439\n",
      "Epoch 14/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1848 - acc: 0.9463\n",
      "Epoch 15/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1772 - acc: 0.9480\n",
      "Epoch 16/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1728 - acc: 0.9491\n",
      "Epoch 17/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1677 - acc: 0.9511\n",
      "Epoch 18/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1624 - acc: 0.9515\n",
      "Epoch 19/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1586 - acc: 0.9534\n",
      "Epoch 20/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1534 - acc: 0.9545\n",
      "Epoch 21/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1501 - acc: 0.9555\n",
      "Epoch 22/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1450 - acc: 0.9575\n",
      "Epoch 23/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1411 - acc: 0.9578\n",
      "Epoch 24/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1386 - acc: 0.9587\n",
      "Epoch 25/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1334 - acc: 0.9607\n",
      "Epoch 26/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1308 - acc: 0.9608\n",
      "Epoch 27/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1278 - acc: 0.9619\n",
      "Epoch 28/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1256 - acc: 0.9626\n",
      "Epoch 29/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1231 - acc: 0.9629\n",
      "Epoch 30/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1198 - acc: 0.9641\n",
      "Epoch 31/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1164 - acc: 0.9653\n",
      "Epoch 32/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1148 - acc: 0.9665\n",
      "Epoch 33/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1109 - acc: 0.9672\n",
      "Epoch 34/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1099 - acc: 0.9675\n",
      "Epoch 35/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1069 - acc: 0.9684\n",
      "Epoch 36/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1054 - acc: 0.9682\n",
      "Epoch 37/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1033 - acc: 0.9694\n",
      "Epoch 38/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1008 - acc: 0.9700\n",
      "Epoch 39/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0982 - acc: 0.9711\n",
      "Epoch 40/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0972 - acc: 0.9709\n",
      "Epoch 41/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0938 - acc: 0.9717\n",
      "Epoch 42/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0932 - acc: 0.9718\n",
      "Epoch 43/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0899 - acc: 0.9736\n",
      "Epoch 44/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0885 - acc: 0.9735\n",
      "Epoch 45/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0872 - acc: 0.9741\n",
      "Epoch 46/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0849 - acc: 0.9742\n",
      "Epoch 47/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0834 - acc: 0.9749\n",
      "Epoch 48/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0814 - acc: 0.9758\n",
      "Epoch 49/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0811 - acc: 0.9755\n",
      "Epoch 50/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0790 - acc: 0.9761\n",
      "Epoch 51/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0766 - acc: 0.9773\n",
      "Epoch 52/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0761 - acc: 0.9773\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0735 - acc: 0.9786\n",
      "Epoch 54/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0723 - acc: 0.9783\n",
      "Epoch 55/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0716 - acc: 0.9795\n",
      "Epoch 56/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0701 - acc: 0.9788\n",
      "Epoch 57/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0684 - acc: 0.9798\n",
      "Epoch 58/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0675 - acc: 0.9801\n",
      "Epoch 59/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0673 - acc: 0.9806\n",
      "Epoch 60/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0639 - acc: 0.9810\n",
      "Epoch 61/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0628 - acc: 0.9817\n",
      "Epoch 62/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0628 - acc: 0.9821\n",
      "Epoch 63/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0610 - acc: 0.9824\n",
      "Epoch 64/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0595 - acc: 0.9829\n",
      "Epoch 65/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0586 - acc: 0.9829\n",
      "Epoch 66/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0576 - acc: 0.9836\n",
      "Epoch 67/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0570 - acc: 0.9829\n",
      "Epoch 68/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0545 - acc: 0.9847\n",
      "Epoch 69/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0546 - acc: 0.9842\n",
      "Epoch 70/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0537 - acc: 0.9841\n",
      "Epoch 71/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0526 - acc: 0.9848\n",
      "Epoch 72/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0518 - acc: 0.9854\n",
      "Epoch 73/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0500 - acc: 0.9852\n",
      "Epoch 74/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0496 - acc: 0.9859\n",
      "Epoch 75/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0488 - acc: 0.9859\n",
      "Epoch 76/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0476 - acc: 0.9868\n",
      "Epoch 77/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0468 - acc: 0.9870\n",
      "Epoch 78/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0462 - acc: 0.9870\n",
      "Epoch 79/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0447 - acc: 0.9875\n",
      "Epoch 80/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0448 - acc: 0.9871\n",
      "Epoch 81/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0422 - acc: 0.9884\n",
      "Epoch 82/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0418 - acc: 0.9884\n",
      "Epoch 83/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0414 - acc: 0.9886\n",
      "Epoch 84/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0416 - acc: 0.9885\n",
      "Epoch 85/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0398 - acc: 0.9895\n",
      "Epoch 86/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0383 - acc: 0.9894\n",
      "Epoch 87/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0378 - acc: 0.9899\n",
      "Epoch 88/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0376 - acc: 0.9897\n",
      "Epoch 89/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0368 - acc: 0.9900\n",
      "Epoch 90/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0366 - acc: 0.9899\n",
      "Epoch 91/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0353 - acc: 0.9901\n",
      "Epoch 92/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0340 - acc: 0.9910\n",
      "Epoch 93/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0332 - acc: 0.9912\n",
      "Epoch 94/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0333 - acc: 0.9912\n",
      "Epoch 95/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0326 - acc: 0.9916\n",
      "Epoch 96/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0322 - acc: 0.9911\n",
      "Epoch 97/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0311 - acc: 0.9924\n",
      "Epoch 98/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0304 - acc: 0.9921\n",
      "Epoch 99/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0301 - acc: 0.9924\n",
      "Epoch 100/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0287 - acc: 0.9931\n",
      "30000/30000 [==============================] - 0s 14us/step\n",
      "10000/10000 [==============================] - 0s 14us/step\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "k = 2  #For 10-fold cross validation\n",
    "\n",
    "model_file_name = 'bestModel_global.json'\n",
    "weights_file_name = 'bestModel_global.h5'\n",
    "\n",
    "for dataset in test_sets.keys():\n",
    "    for alphaValue in alpha_folders:\n",
    "        \n",
    "        results_key = dataset + \"_\" +  alphaValue\n",
    "        \n",
    "        evaluations_cv = np.zeros(k)\n",
    "        evaluations_test = np.zeros(k)\n",
    "        \n",
    "        model_location = best_model_folder + '/' + dataset + '/' + alphaValue + '/' + model_file_name\n",
    "        \n",
    "        if weights_file_name != \"\":\n",
    "            weights_location = best_model_folder + '/' + dataset + '/' + alphaValue + '/' + weights_file_name\n",
    "        \n",
    "        dhandler, data_scaler, problem_type = test_sets[dataset]\n",
    "\n",
    "        #model = load_model(model_location, weights_location, problem_type)   \n",
    "        \n",
    "        data_handler = dhandler(data_scaler=data_scaler)\n",
    "        data_handler.load_data(verbose = 1, )\n",
    "        data_handler.print_data()\n",
    "        \n",
    "        folds = list(KFold(n_splits=k, shuffle=True).split(data_handler.X_train))\n",
    "        \n",
    "        print('Validation on model:' + model_location)\n",
    "        \n",
    "        for j, (train_idx, val_idx) in enumerate(folds):\n",
    "\n",
    "            print('\\nExperiment on Fold ', j)\n",
    "            \n",
    "            K.clear_session()  #Clear the previous tensorflow graph \n",
    "\n",
    "            X_train_cv = data_handler.X_train[train_idx]\n",
    "            y_train_cv = data_handler.y_train[train_idx]\n",
    "            X_valid_cv = data_handler.X_train[val_idx]\n",
    "            y_valid_cv = data_handler.y_train[val_idx]\n",
    "\n",
    "            model = load_model(model_location, \"\", problem_type)\n",
    "            model.summary()\n",
    "\n",
    "            model.fit(X_train_cv, y_train_cv, batch_size=512, epochs=100, verbose=1)\n",
    "\n",
    "            evaluation_cv = model.evaluate(X_valid_cv, y_valid_cv)\n",
    "            evaluation_test = model.evaluate(data_handler.X_test, data_handler.y_test)\n",
    "\n",
    "            evaluations_cv[j] = evaluation_cv[1]\n",
    "            evaluations_test[j] = evaluation_test[1]\n",
    "            \n",
    "        results[results_key] = (evaluations_cv, evaluations_test)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats for: \n",
      "cifar10_alpha0.6\n",
      "\n",
      "CrossVal stats: \n",
      "[0.47508 0.4686 ]\n",
      "DescribeResult(nobs=2, minmax=(0.4686, 0.47508), mean=0.47184000000000004, variance=2.0995199999999907e-05, skewness=-2.5682023229530742e-14, kurtosis=-2.0)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=2, minmax=(0.473, 0.4747), mean=0.47385, variance=1.4450000000000592e-06, skewness=0.0, kurtosis=-2.0)\n",
      "\n",
      "Stats for: \n",
      "cifar10_alpha0.8\n",
      "\n",
      "CrossVal stats: \n",
      "[0.4906  0.48684]\n",
      "DescribeResult(nobs=2, minmax=(0.48684, 0.4906), mean=0.48872, variance=7.068799999999946e-06, skewness=0.0, kurtosis=-2.0)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=2, minmax=(0.493, 0.4948), mean=0.4939, variance=1.620000000000043e-06, skewness=0.0, kurtosis=-2.0)\n",
      "\n",
      "Stats for: \n",
      "cifar10_alpha1\n",
      "\n",
      "CrossVal stats: \n",
      "[0.48828 0.49932]\n",
      "DescribeResult(nobs=2, minmax=(0.48828, 0.49932), mean=0.4938, variance=6.094079999999994e-05, skewness=-1.5029220755522348e-14, kurtosis=-2.0)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=2, minmax=(0.49, 0.4945), mean=0.49224999999999997, variance=1.0125000000000019e-05, skewness=3.703590561554286e-14, kurtosis=-2.0)\n",
      "\n",
      "Stats for: \n",
      "cmapss_alpha0.6\n",
      "\n",
      "CrossVal stats: \n",
      "[235.12583778 392.56169975]\n",
      "DescribeResult(nobs=2, minmax=(235.12583777715156, 392.561699751008), mean=313.84376876407975, variance=12393.025317725589, skewness=1.073993480313371e-15, kurtosis=-2.0)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=2, minmax=(242.10990646362305, 327.59099212646487), mean=284.850449295044, variance=3653.508003049051, skewness=-9.319016043607603e-16, kurtosis=-2.0)\n",
      "\n",
      "Stats for: \n",
      "cmapss_alpha0.8\n",
      "\n",
      "CrossVal stats: \n",
      "[311.30665702 248.43025499]\n",
      "DescribeResult(nobs=2, minmax=(248.43025498549753, 311.3066570186573), mean=279.86845600207744, variance=1976.7209663177687, skewness=-2.7514078213875624e-15, kurtosis=-2.0)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=2, minmax=(252.31254943847657, 289.46053787231443), mean=270.8865436553955, variance=689.986522340276, skewness=2.3418992077426783e-15, kurtosis=-2.0)\n",
      "\n",
      "Stats for: \n",
      "cmapss_alpha1\n",
      "\n",
      "CrossVal stats: \n",
      "[272.15742718 253.74019229]\n",
      "DescribeResult(nobs=2, minmax=(253.74019229196287, 272.15742717557123), mean=262.94880973376706, variance=169.5972703790003, skewness=-4.658830082337029e-15, kurtosis=-1.9999999999999998)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=2, minmax=(298.47339370727536, 346.2955499267578), mean=322.38447181701656, variance=1143.479312740292, skewness=3.59249736943299e-15, kurtosis=-2.0)\n",
      "\n",
      "Stats for: \n",
      "mnist_alpha0.6\n",
      "\n",
      "CrossVal stats: \n",
      "[0.9669     0.96196667]\n",
      "DescribeResult(nobs=2, minmax=(0.9619666666666666, 0.9669), mean=0.9644333333333333, variance=1.2168888888888947e-05, skewness=6.757085620972629e-14, kurtosis=-1.9999999999999998)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=2, minmax=(0.9672, 0.9674), mean=0.9673, variance=2.0000000000017798e-08, skewness=-1.6653674124534759e-12, kurtosis=-2.0)\n",
      "\n",
      "Stats for: \n",
      "mnist_alpha0.8\n",
      "\n",
      "CrossVal stats: \n",
      "[0.94756667 0.95013333]\n",
      "DescribeResult(nobs=2, minmax=(0.9475666666666667, 0.9501333333333334), mean=0.94885, variance=3.293888888889018e-06, skewness=1.2983532041346708e-13, kurtosis=-2.0)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=2, minmax=(0.9521, 0.9548), mean=0.9534499999999999, variance=3.6450000000000964e-06, skewness=1.233017282543559e-13, kurtosis=-2.0)\n",
      "\n",
      "Stats for: \n",
      "mnist_alpha1\n",
      "\n",
      "CrossVal stats: \n",
      "[0.94836667 0.95316667]\n",
      "DescribeResult(nobs=2, minmax=(0.9483666666666667, 0.9531666666666667), mean=0.9507666666666668, variance=1.1520000000000127e-05, skewness=-6.935057363635296e-14, kurtosis=-1.9999999999999998)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=2, minmax=(0.9533, 0.9544), mean=0.9538500000000001, variance=6.049999999999889e-07, skewness=-3.0281273739028837e-13, kurtosis=-2.0)\n"
     ]
    }
   ],
   "source": [
    "for key in results.keys():\n",
    "    \n",
    "    print(\"\\nStats for: \")\n",
    "    print(key)\n",
    "    evaluations_cv, evaluations_test = results[key]\n",
    "    \n",
    "    print(\"\\nCrossVal stats: \")\n",
    "    print(evaluations_cv)\n",
    "    print(stats.describe(evaluations_cv))\n",
    "    \n",
    "    print(\"\\nTest stats: \")\n",
    "    print(stats.describe(evaluations_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
