{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Best Models\n",
    "\n",
    "Test notebook to generate the statistics of the different models found with AMS. First load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import stats\n",
    "\n",
    "#sys.path.append('/Users/davidlaredorazo/Documents/University_of_California/Research/Projects')\n",
    "sys.path.append('/media/controlslab/DATA/Projects')\n",
    "\n",
    "import ann_framework.aux_functions as aux_functions\n",
    "\n",
    "import automatic_model_selection\n",
    "from automatic_model_selection import Configuration\n",
    "from ann_encoding_rules import Layers\n",
    "import fetch_to_keras\n",
    "#from CMAPSAuxFunctions import TrainValTensorBoard\n",
    "\n",
    "#Tunable model\n",
    "from ann_framework.tunable_model.tunable_model import SequenceTunableModelRegression, SequenceTunableModelClassification\n",
    "\n",
    "#Data handlers\n",
    "from ann_framework.data_handlers.data_handler_CMAPSS import CMAPSSDataHandler\n",
    "from ann_framework.data_handlers.data_handler_MNIST import MNISTDataHandler\n",
    "from ann_framework.data_handlers.data_handler_CIFAR10 import CIFAR10DataHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given a model, get the compiled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model(model, problem_type, optimizer_params=[]):\n",
    "    \"\"\"Obtain a keras compiled model\"\"\"\n",
    "    \n",
    "    #Shared parameters for the models\n",
    "    optimizer = Adam(lr=0.001, beta_1=0.5)\n",
    "    \n",
    "    if problem_type == 1:\n",
    "        lossFunction = \"mean_squared_error\"\n",
    "        metrics = [\"mse\"]\n",
    "    elif problem_type == 2:\n",
    "        lossFunction = \"categorical_crossentropy\"\n",
    "        metrics = [\"accuracy\"]\n",
    "    else:\n",
    "        print(\"Problem type not defined\")\n",
    "        model = None\n",
    "        return\n",
    "    \n",
    "    #Create and compile the models\n",
    "    model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_tunable_model(model_genotype, problem_type, input_shape, data_handler, model_number):\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    model = fetch_to_keras.decode_genotype(model_genotype, problem_type, input_shape, 1)\n",
    "    \n",
    "    model = get_compiled_model(model, problem_type, optimizer_params=[])\n",
    "    \n",
    "    if problem_type == 1:\n",
    "        tModel = SequenceTunableModelRegression('ModelReg_SN_'+str(model_number), model, lib_type='keras', data_handler=data_handler)\n",
    "    else:\n",
    "        tModel = SequenceTunableModelClassification('ModelClass_SN_'+str(model_number), model, lib_type='keras', data_handler=data_handler)\n",
    "        \n",
    "    return tModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cmaps data handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmapss_dhandler(data_scaler=None):\n",
    "\n",
    "    #Selected as per CNN paper\n",
    "    features = ['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', 'BPR', \n",
    "    'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "    selected_indices = np.array([2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21])\n",
    "    selected_features = list(features[i] for i in selected_indices-1)\n",
    "    data_folder = '../CMAPSSData'\n",
    "\n",
    "    window_size = 24\n",
    "    window_stride = 1\n",
    "    max_rul = 129\n",
    "\n",
    "    dhandler_cmapss = CMAPSSDataHandler(data_folder, 1, selected_features,\n",
    "                                       max_rul, window_size, window_stride, data_scaler=data_scaler)\n",
    "\n",
    "    input_shape = (len(selected_features)*window_size, )\n",
    "\n",
    "    return dhandler_cmapss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_file, weights_file=\"\", problem_type=1):\n",
    "    \n",
    "    p_type = \"\"\n",
    "    \n",
    "    # load json and create model\n",
    "    json_file = open(model_file, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    print(\"Loaded model from disk\") \n",
    "        \n",
    "    #Load weights if specified\n",
    "    if weights_file != \"\":\n",
    "        # load weights into new model\n",
    "        loaded_model.load_weights(weights_file)\n",
    "        print(\"Loaded weights from disk\") \n",
    "    else:\n",
    "        print(\"Model needs training\")\n",
    "        \n",
    "    optimizer = Adam(lr=0.001, beta_1=0.5)\n",
    "    \n",
    "    if problem_type == 1:\n",
    "        p_type = \"regression\"\n",
    "        lossFunction = \"mean_squared_error\"\n",
    "        metrics = [\"mse\"]\n",
    "    elif problem_type == 2:\n",
    "        p_type = \"classification\"\n",
    "        lossFunction = \"categorical_crossentropy\"\n",
    "        metrics = [\"accuracy\"]\n",
    "    else:\n",
    "        print(\"Problem type not defined\")\n",
    "        model = None\n",
    "        return\n",
    "    \n",
    "    #Create and compile the models\n",
    "    loaded_model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    print(\"Created model for \" + p_type + \" with loss function \" + lossFunction)\n",
    "\n",
    "    return loaded_model\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load each of the models and test them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_folder = 'best_models'\n",
    "\"\"\"\n",
    "test_sets = {'cifar10':(CIFAR10DataHandler, None, 2), \n",
    "             'cmapss':(cmaps_dhandler, MinMaxScaler(feature_range=(-1, 1)), 1), \n",
    "             'mnist':(MNISTDataHandler, None, 2)}\n",
    "\"\"\"\n",
    "\n",
    "test_sets = {'cmapss':(cmapss_dhandler, MinMaxScaler(feature_range=(-1, 1)), 1)}\n",
    "#alpha_folders = ['alpha0.6', 'alpha0.8', 'alpha1']\n",
    "#alpha_folders = ['alpha0.5']\n",
    "alpha_values = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "#alpha_values = [0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for yulin/alpha0.2/bestModel_global.json\n",
      "Loading data for dataset 1 with window_size of 24, stride of 1 and maxRUL of 129. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(18331, 336)\n",
      "(18331, 1)\n",
      "Testing data (X, y)\n",
      "(100, 336)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.63253012 -0.18639634 -0.38048616 ... -0.33333333  0.33333333\n",
      "   0.31289699]\n",
      " [-0.43373494 -0.09396119 -0.29473329 ... -0.16666667  0.25581395\n",
      "   0.47638774]\n",
      " [-0.31325301 -0.26095487 -0.25894666 ...  0.          0.11627907\n",
      "   0.43800055]\n",
      " [-0.31325301 -0.48768258 -0.33760972 ... -0.16666667  0.31782946\n",
      "   0.52720243]\n",
      " [-0.30120482 -0.48506649 -0.19074949 ... -0.66666667  0.34883721\n",
      "   0.07677437]]\n",
      "[[129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]]\n",
      "Testing data (X, y)\n",
      "[[-0.19879518 -0.5705254  -0.37069548 ... -0.16666667  0.03875969\n",
      "   0.27312897]\n",
      " [-0.21686747 -0.30237628 -0.12086428 ... -0.5         0.03875969\n",
      "   0.01518917]\n",
      " [-0.04216867 -0.1942446  -0.0209318  ...  0.16666667  0.2248062\n",
      "   0.04888152]\n",
      " [-0.22891566 -0.01722259 -0.13673194 ...  0.16666667 -0.31782946\n",
      "   0.004971  ]\n",
      " [-0.11445783 -0.11968607  0.03511141 ...  0.         -0.05426357\n",
      "   0.42916321]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n",
      "Validation on model:best_models/cmapss/yulin/alpha0.2/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 168)               56616     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 872)               147368    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 873       \n",
      "=================================================================\n",
      "Total params: 204,857\n",
      "Trainable params: 204,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14664/14664 [==============================] - 1s 39us/step - loss: 2985.2615 - mean_squared_error: 2985.2615\n",
      "Epoch 2/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 464.7724 - mean_squared_error: 464.7724\n",
      "Epoch 3/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 350.3326 - mean_squared_error: 350.3326\n",
      "Epoch 4/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 297.9144 - mean_squared_error: 297.9144\n",
      "Epoch 5/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 276.4584 - mean_squared_error: 276.4584\n",
      "Epoch 6/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 262.2748 - mean_squared_error: 262.2748\n",
      "Epoch 7/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 252.3595 - mean_squared_error: 252.3595\n",
      "Epoch 8/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 248.3245 - mean_squared_error: 248.3245\n",
      "Epoch 9/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 244.7846 - mean_squared_error: 244.7846\n",
      "Epoch 10/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 246.3523 - mean_squared_error: 246.3523\n",
      "Epoch 11/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 241.1840 - mean_squared_error: 241.1840\n",
      "Epoch 12/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 244.0977 - mean_squared_error: 244.0977\n",
      "Epoch 13/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 238.5702 - mean_squared_error: 238.5702\n",
      "Epoch 14/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 238.5376 - mean_squared_error: 238.5376\n",
      "Epoch 15/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 241.1933 - mean_squared_error: 241.1933\n",
      "Epoch 16/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 236.0912 - mean_squared_error: 236.0912\n",
      "Epoch 17/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 238.1197 - mean_squared_error: 238.1197\n",
      "Epoch 18/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 240.1735 - mean_squared_error: 240.1735\n",
      "Epoch 19/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 231.3845 - mean_squared_error: 231.3845\n",
      "Epoch 20/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 240.2137 - mean_squared_error: 240.2137\n",
      "Epoch 21/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 229.8224 - mean_squared_error: 229.8224\n",
      "Epoch 22/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 226.5875 - mean_squared_error: 226.5875\n",
      "Epoch 23/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 235.2776 - mean_squared_error: 235.2776\n",
      "Epoch 24/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 235.1067 - mean_squared_error: 235.1067\n",
      "Epoch 25/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 225.8889 - mean_squared_error: 225.8889\n",
      "Epoch 26/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 231.6123 - mean_squared_error: 231.6123\n",
      "Epoch 27/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 232.8254 - mean_squared_error: 232.8254\n",
      "Epoch 28/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 228.4618 - mean_squared_error: 228.4618\n",
      "Epoch 29/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 226.5544 - mean_squared_error: 226.5544\n",
      "Epoch 30/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 226.7418 - mean_squared_error: 226.7418\n",
      "Epoch 31/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 227.8830 - mean_squared_error: 227.8830\n",
      "Epoch 32/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 219.0743 - mean_squared_error: 219.0743\n",
      "Epoch 33/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 230.3457 - mean_squared_error: 230.3457\n",
      "Epoch 34/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 222.5525 - mean_squared_error: 222.5525\n",
      "Epoch 35/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 223.2431 - mean_squared_error: 223.2431\n",
      "Epoch 36/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 213.4020 - mean_squared_error: 213.4020\n",
      "Epoch 37/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 221.6859 - mean_squared_error: 221.6859\n",
      "Epoch 38/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 218.4243 - mean_squared_error: 218.4243\n",
      "Epoch 39/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 210.3348 - mean_squared_error: 210.3348\n",
      "Epoch 40/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 212.1950 - mean_squared_error: 212.1950\n",
      "Epoch 41/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 216.0700 - mean_squared_error: 216.0700\n",
      "Epoch 42/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 211.8804 - mean_squared_error: 211.8804\n",
      "Epoch 43/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 215.3983 - mean_squared_error: 215.3983\n",
      "Epoch 44/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 212.1761 - mean_squared_error: 212.1761\n",
      "Epoch 45/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 205.4126 - mean_squared_error: 205.4126\n",
      "Epoch 46/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 216.2309 - mean_squared_error: 216.2309\n",
      "Epoch 47/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 202.0870 - mean_squared_error: 202.0870\n",
      "Epoch 48/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 207.3078 - mean_squared_error: 207.3078\n",
      "Epoch 49/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 208.4036 - mean_squared_error: 208.4036\n",
      "Epoch 50/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 213.4089 - mean_squared_error: 213.4089\n",
      "Epoch 51/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 200.9308 - mean_squared_error: 200.9308\n",
      "Epoch 52/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 207.2032 - mean_squared_error: 207.2032\n",
      "Epoch 53/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 196.5069 - mean_squared_error: 196.5069\n",
      "Epoch 54/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 203.1393 - mean_squared_error: 203.1393\n",
      "Epoch 55/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 198.5525 - mean_squared_error: 198.5525\n",
      "Epoch 56/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 194.4273 - mean_squared_error: 194.4273\n",
      "Epoch 57/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 196.6889 - mean_squared_error: 196.6889\n",
      "Epoch 58/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 212.2815 - mean_squared_error: 212.2815\n",
      "Epoch 59/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 188.8851 - mean_squared_error: 188.8851\n",
      "Epoch 60/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 183.4864 - mean_squared_error: 183.4864\n",
      "Epoch 61/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 186.4960 - mean_squared_error: 186.4960\n",
      "Epoch 62/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 190.5530 - mean_squared_error: 190.5530\n",
      "Epoch 63/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 192.0747 - mean_squared_error: 192.0747\n",
      "Epoch 64/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 183.2163 - mean_squared_error: 183.2163\n",
      "Epoch 65/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 183.4000 - mean_squared_error: 183.4000\n",
      "Epoch 66/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 193.1213 - mean_squared_error: 193.1213\n",
      "Epoch 67/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 184.8748 - mean_squared_error: 184.8748\n",
      "Epoch 68/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 193.5091 - mean_squared_error: 193.5091\n",
      "Epoch 69/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 177.2083 - mean_squared_error: 177.2083\n",
      "Epoch 70/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 177.6734 - mean_squared_error: 177.6734\n",
      "Epoch 71/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 183.0740 - mean_squared_error: 183.0740\n",
      "Epoch 72/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 177.4223 - mean_squared_error: 177.4223\n",
      "Epoch 73/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 176.3740 - mean_squared_error: 176.3740\n",
      "Epoch 74/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 173.8777 - mean_squared_error: 173.8777\n",
      "Epoch 75/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 171.0448 - mean_squared_error: 171.0448\n",
      "Epoch 76/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 184.0199 - mean_squared_error: 184.0199\n",
      "Epoch 77/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 177.9522 - mean_squared_error: 177.9522\n",
      "Epoch 78/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 172.3489 - mean_squared_error: 172.3489\n",
      "Epoch 79/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 167.8515 - mean_squared_error: 167.8515\n",
      "Epoch 80/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 160.2926 - mean_squared_error: 160.2926\n",
      "Epoch 81/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 172.6121 - mean_squared_error: 172.6121\n",
      "Epoch 82/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 160.9963 - mean_squared_error: 160.9963\n",
      "Epoch 83/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 166.2685 - mean_squared_error: 166.2685\n",
      "Epoch 84/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 175.0691 - mean_squared_error: 175.0691\n",
      "Epoch 85/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 156.6637 - mean_squared_error: 156.6637\n",
      "Epoch 86/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 173.0051 - mean_squared_error: 173.0051\n",
      "Epoch 87/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 155.2449 - mean_squared_error: 155.2449\n",
      "Epoch 88/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 162.2763 - mean_squared_error: 162.2763\n",
      "Epoch 89/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 156.6658 - mean_squared_error: 156.6658\n",
      "Epoch 90/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 162.8005 - mean_squared_error: 162.8005\n",
      "Epoch 91/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 166.8986 - mean_squared_error: 166.8986\n",
      "Epoch 92/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 182.7273 - mean_squared_error: 182.7273\n",
      "Epoch 93/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 154.5040 - mean_squared_error: 154.5040\n",
      "Epoch 94/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 151.7233 - mean_squared_error: 151.7233\n",
      "Epoch 95/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 154.3370 - mean_squared_error: 154.3370\n",
      "Epoch 96/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 158.1129 - mean_squared_error: 158.1129\n",
      "Epoch 97/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 161.0694 - mean_squared_error: 161.0694\n",
      "Epoch 98/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 153.2828 - mean_squared_error: 153.2828\n",
      "Epoch 99/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 144.6668 - mean_squared_error: 144.6668\n",
      "Epoch 100/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 149.3641 - mean_squared_error: 149.3641\n",
      "3667/3667 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 19us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 168)               56616     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 872)               147368    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 873       \n",
      "=================================================================\n",
      "Total params: 204,857\n",
      "Trainable params: 204,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 10us/step - loss: 3001.5668 - mean_squared_error: 3001.5668\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 464.7122 - mean_squared_error: 464.7122\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 366.0264 - mean_squared_error: 366.0264\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 305.5791 - mean_squared_error: 305.5791\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 281.9212 - mean_squared_error: 281.9212\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 268.5126 - mean_squared_error: 268.5126\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 253.5755 - mean_squared_error: 253.5755\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 249.1824 - mean_squared_error: 249.1824\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 246.5865 - mean_squared_error: 246.5865\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 247.3250 - mean_squared_error: 247.3250\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.0814 - mean_squared_error: 242.0814\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 241.4747 - mean_squared_error: 241.4747\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.5817 - mean_squared_error: 233.5817\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.7131 - mean_squared_error: 234.7131\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 237.8782 - mean_squared_error: 237.8782\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.9340 - mean_squared_error: 233.9340\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.7368 - mean_squared_error: 228.7368\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.7056 - mean_squared_error: 230.7056\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 240.2914 - mean_squared_error: 240.2914\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.5301 - mean_squared_error: 222.5301\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.6373 - mean_squared_error: 226.6373\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.1236 - mean_squared_error: 221.1236\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.4696 - mean_squared_error: 227.4696\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.7163 - mean_squared_error: 226.7163\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.6100 - mean_squared_error: 225.6100\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.1714 - mean_squared_error: 219.1714\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.6394 - mean_squared_error: 212.6394\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.5807 - mean_squared_error: 216.5807\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.3929 - mean_squared_error: 215.3929\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.2067 - mean_squared_error: 210.2067\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.7076 - mean_squared_error: 220.7076\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.7046 - mean_squared_error: 215.7046\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.5018 - mean_squared_error: 209.5018\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.0344 - mean_squared_error: 206.0344\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.1382 - mean_squared_error: 213.1382\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.8845 - mean_squared_error: 204.8845\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.5561 - mean_squared_error: 208.5561\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.1300 - mean_squared_error: 210.1300\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.8996 - mean_squared_error: 198.8996\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.6314 - mean_squared_error: 197.6314\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.2527 - mean_squared_error: 206.2527\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.2340 - mean_squared_error: 207.2340\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.7310 - mean_squared_error: 197.7310\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.3451 - mean_squared_error: 205.3451\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.3684 - mean_squared_error: 200.3684\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.9096 - mean_squared_error: 192.9096\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.2203 - mean_squared_error: 198.2203\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.1379 - mean_squared_error: 190.1379\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.3657 - mean_squared_error: 187.3657\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.2735 - mean_squared_error: 202.2735\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.0906 - mean_squared_error: 188.0906\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.7616 - mean_squared_error: 190.7616\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.0004 - mean_squared_error: 186.0004\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.6098 - mean_squared_error: 193.6098\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.8055 - mean_squared_error: 188.8055\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.4472 - mean_squared_error: 183.4472\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.8014 - mean_squared_error: 186.8014\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.0825 - mean_squared_error: 183.0825\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.2909 - mean_squared_error: 197.2909\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.3980 - mean_squared_error: 176.3980\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.5167 - mean_squared_error: 181.5167\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.9925 - mean_squared_error: 178.9925\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.4838 - mean_squared_error: 195.4838\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.2712 - mean_squared_error: 174.2712\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.3868 - mean_squared_error: 179.3868\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.3626 - mean_squared_error: 177.3626\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.6510 - mean_squared_error: 181.6510\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.3584 - mean_squared_error: 173.3584\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.1749 - mean_squared_error: 170.1749\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.4696 - mean_squared_error: 171.4696\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.7120 - mean_squared_error: 170.7120\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.6261 - mean_squared_error: 183.6261\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.5337 - mean_squared_error: 170.5337\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.4940 - mean_squared_error: 168.4940\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.1385 - mean_squared_error: 168.1385\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.4025 - mean_squared_error: 162.4025\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.5412 - mean_squared_error: 158.5412\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.5561 - mean_squared_error: 169.5561\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.1327 - mean_squared_error: 165.1327\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.4448 - mean_squared_error: 159.4448\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.0762 - mean_squared_error: 162.0762\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.9500 - mean_squared_error: 165.9500\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.8842 - mean_squared_error: 160.8842\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.3038 - mean_squared_error: 170.3038\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.2422 - mean_squared_error: 166.2422\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.1165 - mean_squared_error: 159.1165\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.2090 - mean_squared_error: 158.2090\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 151.9780 - mean_squared_error: 151.9780\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.1335 - mean_squared_error: 158.1335\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 163.8830 - mean_squared_error: 163.8830\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.1116 - mean_squared_error: 157.1116\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 149.4621 - mean_squared_error: 149.4621\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 151.1021 - mean_squared_error: 151.1021\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 153.4370 - mean_squared_error: 153.4370\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.9261 - mean_squared_error: 154.9261\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 147.9247 - mean_squared_error: 147.9247\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 147.8806 - mean_squared_error: 147.8806\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.0340 - mean_squared_error: 159.0340\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 149.6434 - mean_squared_error: 149.6434\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 142.4057 - mean_squared_error: 142.4057\n",
      "3666/3666 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 18us/step\n",
      "\n",
      "Experiment on Fold  2\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 168)               56616     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 872)               147368    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 873       \n",
      "=================================================================\n",
      "Total params: 204,857\n",
      "Trainable params: 204,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 11us/step - loss: 2929.6622 - mean_squared_error: 2929.6622\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 473.8355 - mean_squared_error: 473.8355\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 362.3162 - mean_squared_error: 362.3162\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 303.2833 - mean_squared_error: 303.2833\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 275.2010 - mean_squared_error: 275.2010\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 268.0382 - mean_squared_error: 268.0382\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 253.2729 - mean_squared_error: 253.2729\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 247.5743 - mean_squared_error: 247.5743\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 246.7546 - mean_squared_error: 246.7546\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.3491 - mean_squared_error: 242.3491\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 235.5489 - mean_squared_error: 235.5489\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.4453 - mean_squared_error: 233.4453\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 244.9734 - mean_squared_error: 244.9734\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.4284 - mean_squared_error: 228.4284\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.5774 - mean_squared_error: 234.5774\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.4276 - mean_squared_error: 229.4276\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.5063 - mean_squared_error: 230.5063\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.1558 - mean_squared_error: 227.1558\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.2074 - mean_squared_error: 228.2074\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.9657 - mean_squared_error: 226.9657\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.1775 - mean_squared_error: 219.1775\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.9760 - mean_squared_error: 223.9760\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.6820 - mean_squared_error: 217.6820\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.4379 - mean_squared_error: 221.4379\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.6848 - mean_squared_error: 212.6848\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.0906 - mean_squared_error: 219.0906\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.2494 - mean_squared_error: 214.2494\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.8712 - mean_squared_error: 214.8712\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.5827 - mean_squared_error: 207.5827\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.3857 - mean_squared_error: 210.3857\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.1888 - mean_squared_error: 204.1888\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.0266 - mean_squared_error: 202.0266\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.6036 - mean_squared_error: 218.6036\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.7533 - mean_squared_error: 201.7533\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.9238 - mean_squared_error: 203.9238\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.4386 - mean_squared_error: 197.4386\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.4008 - mean_squared_error: 207.4008\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.3542 - mean_squared_error: 195.3542\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.5706 - mean_squared_error: 203.5706\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.2427 - mean_squared_error: 196.2427\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.3873 - mean_squared_error: 189.3873\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.9176 - mean_squared_error: 209.9176\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.0057 - mean_squared_error: 190.0057\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.4821 - mean_squared_error: 187.4821\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.0782 - mean_squared_error: 196.0782\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.2194 - mean_squared_error: 192.2194\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.3305 - mean_squared_error: 190.3305\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.5039 - mean_squared_error: 182.5039\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.0267 - mean_squared_error: 194.0267\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.1135 - mean_squared_error: 192.1135\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.6588 - mean_squared_error: 184.6588\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.2089 - mean_squared_error: 192.2089\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.9658 - mean_squared_error: 180.9658\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.6241 - mean_squared_error: 181.6241\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.7817 - mean_squared_error: 188.7817\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.4766 - mean_squared_error: 183.4766\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.7255 - mean_squared_error: 175.7255\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.7113 - mean_squared_error: 186.7113\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.6234 - mean_squared_error: 177.6234\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.0009 - mean_squared_error: 181.0009\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.3191 - mean_squared_error: 174.3191\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.0100 - mean_squared_error: 171.0100\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.8197 - mean_squared_error: 175.8197\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.3558 - mean_squared_error: 176.3558\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.2145 - mean_squared_error: 180.2145\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.1656 - mean_squared_error: 169.1656\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.2999 - mean_squared_error: 165.2999\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.7480 - mean_squared_error: 173.7480\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.9137 - mean_squared_error: 160.9137\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.4509 - mean_squared_error: 168.4509\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.9526 - mean_squared_error: 178.9526\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.1036 - mean_squared_error: 166.1036\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 167.9764 - mean_squared_error: 167.9764\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.5759 - mean_squared_error: 165.5759\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.7376 - mean_squared_error: 176.7376\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.3622 - mean_squared_error: 164.3622\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.1999 - mean_squared_error: 157.1999\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.2966 - mean_squared_error: 156.2966\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.1216 - mean_squared_error: 172.1216\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.7655 - mean_squared_error: 158.7655\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 153.5617 - mean_squared_error: 153.5617\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.7735 - mean_squared_error: 158.7735\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 151.1011 - mean_squared_error: 151.1011\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.6298 - mean_squared_error: 162.6298\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.2648 - mean_squared_error: 169.2648\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.2057 - mean_squared_error: 159.2057\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 151.4789 - mean_squared_error: 151.4789\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 155.3005 - mean_squared_error: 155.3005\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 153.1552 - mean_squared_error: 153.1552\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 146.6080 - mean_squared_error: 146.6080\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.0848 - mean_squared_error: 154.0848\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 146.8019 - mean_squared_error: 146.8019\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 146.7891 - mean_squared_error: 146.7891\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 146.9046 - mean_squared_error: 146.9046\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 146.2134 - mean_squared_error: 146.2134\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 136.8584 - mean_squared_error: 136.8584\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 152.1054 - mean_squared_error: 152.1054\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 144.9758 - mean_squared_error: 144.9758\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 145.4618 - mean_squared_error: 145.4618\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 140.9852 - mean_squared_error: 140.9852\n",
      "3666/3666 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 18us/step\n",
      "\n",
      "Experiment on Fold  3\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 168)               56616     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 872)               147368    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 873       \n",
      "=================================================================\n",
      "Total params: 204,857\n",
      "Trainable params: 204,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 15us/step - loss: 2882.3414 - mean_squared_error: 2882.3414\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 459.1280 - mean_squared_error: 459.1280\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 353.2621 - mean_squared_error: 353.2621\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 298.0061 - mean_squared_error: 298.0061\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 276.9815 - mean_squared_error: 276.9815\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 263.6885 - mean_squared_error: 263.6885\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 251.9202 - mean_squared_error: 251.9202\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 252.3341 - mean_squared_error: 252.3341\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 244.9401 - mean_squared_error: 244.9401\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.3097 - mean_squared_error: 238.3097\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.8330 - mean_squared_error: 238.8330\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.5689 - mean_squared_error: 242.5689\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 248.0477 - mean_squared_error: 248.0477\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 235.1389 - mean_squared_error: 235.1389\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 243.9855 - mean_squared_error: 243.9855\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 235.7996 - mean_squared_error: 235.7996\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.6942 - mean_squared_error: 228.6942\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.2296 - mean_squared_error: 232.2296\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.7635 - mean_squared_error: 230.7635\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.3815 - mean_squared_error: 234.3815\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.4662 - mean_squared_error: 230.4662\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.2620 - mean_squared_error: 234.2620\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.5732 - mean_squared_error: 222.5732\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.0351 - mean_squared_error: 227.0351\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.0333 - mean_squared_error: 224.0333\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.3914 - mean_squared_error: 228.3914\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.5121 - mean_squared_error: 218.5121\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.4679 - mean_squared_error: 221.4679\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.6450 - mean_squared_error: 221.6450\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.1358 - mean_squared_error: 219.1358\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.0920 - mean_squared_error: 216.0920\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.5495 - mean_squared_error: 213.5495\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.1708 - mean_squared_error: 226.1708\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.8390 - mean_squared_error: 212.8390\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.8793 - mean_squared_error: 209.8793\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.2569 - mean_squared_error: 211.2569\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.9551 - mean_squared_error: 219.9551\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.9769 - mean_squared_error: 211.9769\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.3169 - mean_squared_error: 221.3169\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.2006 - mean_squared_error: 216.2006\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.4925 - mean_squared_error: 210.4925\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.9396 - mean_squared_error: 203.9396\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.0692 - mean_squared_error: 206.0692\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.9240 - mean_squared_error: 205.9240\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.8460 - mean_squared_error: 198.8460\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.3389 - mean_squared_error: 205.3389\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.1982 - mean_squared_error: 203.1982\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.3987 - mean_squared_error: 198.3987\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.5528 - mean_squared_error: 199.5528\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.8586 - mean_squared_error: 196.8586\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.2865 - mean_squared_error: 196.2865\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.9790 - mean_squared_error: 200.9790\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.5660 - mean_squared_error: 197.5660\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.9198 - mean_squared_error: 198.9198\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.0239 - mean_squared_error: 187.0239\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.7284 - mean_squared_error: 195.7284\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.8915 - mean_squared_error: 183.8915\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.4823 - mean_squared_error: 185.4823\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.6332 - mean_squared_error: 191.6332\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.0006 - mean_squared_error: 181.0006\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.3243 - mean_squared_error: 177.3243\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.3948 - mean_squared_error: 191.3948\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.8404 - mean_squared_error: 186.8404\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.3882 - mean_squared_error: 177.3882\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.9642 - mean_squared_error: 180.9642\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.6015 - mean_squared_error: 176.6015\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.2846 - mean_squared_error: 187.2846\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.5718 - mean_squared_error: 184.5718\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.4297 - mean_squared_error: 172.4297\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.2613 - mean_squared_error: 173.2613\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.7672 - mean_squared_error: 168.7672\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.8206 - mean_squared_error: 183.8206\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.9629 - mean_squared_error: 170.9629\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.8585 - mean_squared_error: 174.8585\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.6838 - mean_squared_error: 174.6838\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.0353 - mean_squared_error: 166.0353\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.2041 - mean_squared_error: 164.2041\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 161.2402 - mean_squared_error: 161.2402\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.1849 - mean_squared_error: 160.1849\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.5785 - mean_squared_error: 174.5785\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.2369 - mean_squared_error: 165.2369\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.9140 - mean_squared_error: 169.9140\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.0669 - mean_squared_error: 166.0669\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 152.4074 - mean_squared_error: 152.4074\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 161.8355 - mean_squared_error: 161.8355\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 161.4617 - mean_squared_error: 161.4617\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.1410 - mean_squared_error: 160.1410\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.1200 - mean_squared_error: 157.1200\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.7281 - mean_squared_error: 156.7281\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.3984 - mean_squared_error: 156.3984\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.9833 - mean_squared_error: 157.9833\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.5774 - mean_squared_error: 160.5774\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 148.2806 - mean_squared_error: 148.2806\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 150.2224 - mean_squared_error: 150.2224\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.9224 - mean_squared_error: 180.9224\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.2379 - mean_squared_error: 156.2379\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 148.9956 - mean_squared_error: 148.9956\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 149.0184 - mean_squared_error: 149.0184\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 145.8345 - mean_squared_error: 145.8345\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.1102 - mean_squared_error: 154.1102\n",
      "3666/3666 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 19us/step\n",
      "\n",
      "Experiment on Fold  4\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 168)               56616     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 872)               147368    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 873       \n",
      "=================================================================\n",
      "Total params: 204,857\n",
      "Trainable params: 204,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 11us/step - loss: 2881.5116 - mean_squared_error: 2881.5116\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 460.9347 - mean_squared_error: 460.9347\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 352.3112 - mean_squared_error: 352.3112\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 295.3029 - mean_squared_error: 295.3029\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 271.5759 - mean_squared_error: 271.5759\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 262.8244 - mean_squared_error: 262.8244\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 253.3782 - mean_squared_error: 253.3782\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 251.4012 - mean_squared_error: 251.4012\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 249.5230 - mean_squared_error: 249.5230\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 243.9134 - mean_squared_error: 243.9134\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 245.0509 - mean_squared_error: 245.0509\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.8005 - mean_squared_error: 242.8005\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.1742 - mean_squared_error: 236.1742\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 241.8826 - mean_squared_error: 241.8826\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.5590 - mean_squared_error: 232.5590\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.4239 - mean_squared_error: 236.4239\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.8395 - mean_squared_error: 233.8395\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 235.7464 - mean_squared_error: 235.7464\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.9133 - mean_squared_error: 238.9133\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 235.0662 - mean_squared_error: 235.0662\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.3336 - mean_squared_error: 230.3336\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.8006 - mean_squared_error: 224.8006\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.3891 - mean_squared_error: 229.3891\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.3324 - mean_squared_error: 232.3324\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.8116 - mean_squared_error: 232.8116\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.2509 - mean_squared_error: 221.2509\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.6338 - mean_squared_error: 227.6338\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.9925 - mean_squared_error: 219.9925\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.1732 - mean_squared_error: 229.1732\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.5849 - mean_squared_error: 220.5849\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.9951 - mean_squared_error: 220.9951\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.2463 - mean_squared_error: 220.2463\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.3597 - mean_squared_error: 218.3597\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.4414 - mean_squared_error: 223.4414\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.0077 - mean_squared_error: 222.0077\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.4235 - mean_squared_error: 225.4235\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.4445 - mean_squared_error: 214.4445\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.6649 - mean_squared_error: 215.6649\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.1515 - mean_squared_error: 210.1515\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.9012 - mean_squared_error: 214.9012\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.7828 - mean_squared_error: 222.7828\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.2795 - mean_squared_error: 209.2795\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.5180 - mean_squared_error: 211.5180\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.4799 - mean_squared_error: 208.4799\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.6298 - mean_squared_error: 205.6298\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.4696 - mean_squared_error: 216.4696\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.9202 - mean_squared_error: 204.9202\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.7224 - mean_squared_error: 212.7224\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.7031 - mean_squared_error: 204.7031\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.8496 - mean_squared_error: 202.8496\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.0030 - mean_squared_error: 196.0030\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.0663 - mean_squared_error: 203.0663\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.5490 - mean_squared_error: 200.5490\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.7246 - mean_squared_error: 198.7246\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.7555 - mean_squared_error: 205.7555\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.7475 - mean_squared_error: 207.7475\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.9038 - mean_squared_error: 198.9038\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.9670 - mean_squared_error: 191.9670\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.1490 - mean_squared_error: 206.1490\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.9750 - mean_squared_error: 198.9750\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.8444 - mean_squared_error: 194.8444\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.9943 - mean_squared_error: 198.9943\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.0076 - mean_squared_error: 201.0076\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.6953 - mean_squared_error: 187.6953\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.4891 - mean_squared_error: 202.4891\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.3845 - mean_squared_error: 192.3845\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.8040 - mean_squared_error: 197.8040\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.4102 - mean_squared_error: 191.4102\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.3113 - mean_squared_error: 191.3113\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.9196 - mean_squared_error: 190.9196\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.2594 - mean_squared_error: 193.2594\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.9130 - mean_squared_error: 184.9130\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.6368 - mean_squared_error: 182.6368\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.0820 - mean_squared_error: 188.0820\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.9457 - mean_squared_error: 190.9457\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.7372 - mean_squared_error: 185.7372\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.8748 - mean_squared_error: 182.8748\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.1170 - mean_squared_error: 193.1170\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.0363 - mean_squared_error: 179.0363\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.7113 - mean_squared_error: 176.7113\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.2762 - mean_squared_error: 187.2762\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.3534 - mean_squared_error: 177.3534\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.9621 - mean_squared_error: 176.9621\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.3447 - mean_squared_error: 172.3447\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.5118 - mean_squared_error: 185.5118\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.9527 - mean_squared_error: 190.9527\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.1034 - mean_squared_error: 179.1034\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.3739 - mean_squared_error: 178.3739\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.5752 - mean_squared_error: 173.5752\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.0371 - mean_squared_error: 169.0371\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.9913 - mean_squared_error: 166.9913\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.1036 - mean_squared_error: 176.1036\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.0825 - mean_squared_error: 169.0825\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.7839 - mean_squared_error: 174.7839\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 167.7791 - mean_squared_error: 167.7791\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.4187 - mean_squared_error: 160.4187\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.5718 - mean_squared_error: 165.5718\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.2388 - mean_squared_error: 169.2388\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.5409 - mean_squared_error: 172.5409\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.4945 - mean_squared_error: 169.4945\n",
      "3666/3666 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 19us/step\n",
      "Testing for yulin/alpha0.3/bestModel_global.json\n",
      "Loading data for dataset 1 with window_size of 24, stride of 1 and maxRUL of 129. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(18331, 336)\n",
      "(18331, 1)\n",
      "Testing data (X, y)\n",
      "(100, 336)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.63253012 -0.18639634 -0.38048616 ... -0.33333333  0.33333333\n",
      "   0.31289699]\n",
      " [-0.43373494 -0.09396119 -0.29473329 ... -0.16666667  0.25581395\n",
      "   0.47638774]\n",
      " [-0.31325301 -0.26095487 -0.25894666 ...  0.          0.11627907\n",
      "   0.43800055]\n",
      " [-0.31325301 -0.48768258 -0.33760972 ... -0.16666667  0.31782946\n",
      "   0.52720243]\n",
      " [-0.30120482 -0.48506649 -0.19074949 ... -0.66666667  0.34883721\n",
      "   0.07677437]]\n",
      "[[129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]]\n",
      "Testing data (X, y)\n",
      "[[-0.19879518 -0.5705254  -0.37069548 ... -0.16666667  0.03875969\n",
      "   0.27312897]\n",
      " [-0.21686747 -0.30237628 -0.12086428 ... -0.5         0.03875969\n",
      "   0.01518917]\n",
      " [-0.04216867 -0.1942446  -0.0209318  ...  0.16666667  0.2248062\n",
      "   0.04888152]\n",
      " [-0.22891566 -0.01722259 -0.13673194 ...  0.16666667 -0.31782946\n",
      "   0.004971  ]\n",
      " [-0.11445783 -0.11968607  0.03511141 ...  0.         -0.05426357\n",
      "   0.42916321]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n",
      "Validation on model:best_models/cmapss/yulin/alpha0.3/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 128)               43136     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 616)               79464     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 616)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 617       \n",
      "=================================================================\n",
      "Total params: 123,217\n",
      "Trainable params: 123,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14664/14664 [==============================] - 0s 12us/step - loss: 3274.6505 - mean_squared_error: 3274.6505\n",
      "Epoch 2/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 507.6676 - mean_squared_error: 507.6676\n",
      "Epoch 3/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 381.7894 - mean_squared_error: 381.7894\n",
      "Epoch 4/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 318.9718 - mean_squared_error: 318.9718\n",
      "Epoch 5/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 289.0722 - mean_squared_error: 289.0722\n",
      "Epoch 6/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 273.4628 - mean_squared_error: 273.4628\n",
      "Epoch 7/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 265.5644 - mean_squared_error: 265.5644\n",
      "Epoch 8/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 260.0474 - mean_squared_error: 260.0474\n",
      "Epoch 9/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 248.2931 - mean_squared_error: 248.2931\n",
      "Epoch 10/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 249.7767 - mean_squared_error: 249.7767\n",
      "Epoch 11/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 249.4174 - mean_squared_error: 249.4174\n",
      "Epoch 12/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 243.7449 - mean_squared_error: 243.7449\n",
      "Epoch 13/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 249.0446 - mean_squared_error: 249.0446\n",
      "Epoch 14/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 239.8490 - mean_squared_error: 239.8490\n",
      "Epoch 15/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 241.2087 - mean_squared_error: 241.2087\n",
      "Epoch 16/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 239.5606 - mean_squared_error: 239.5606\n",
      "Epoch 17/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 237.6841 - mean_squared_error: 237.6841\n",
      "Epoch 18/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 239.5357 - mean_squared_error: 239.5357\n",
      "Epoch 19/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 239.9562 - mean_squared_error: 239.9562\n",
      "Epoch 20/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 234.3793 - mean_squared_error: 234.3793\n",
      "Epoch 21/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 227.4530 - mean_squared_error: 227.4530\n",
      "Epoch 22/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 240.4554 - mean_squared_error: 240.4554\n",
      "Epoch 23/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 229.8320 - mean_squared_error: 229.8320\n",
      "Epoch 24/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 229.2867 - mean_squared_error: 229.2867\n",
      "Epoch 25/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 223.5201 - mean_squared_error: 223.5201\n",
      "Epoch 26/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 234.4319 - mean_squared_error: 234.4319\n",
      "Epoch 27/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 231.0717 - mean_squared_error: 231.0717\n",
      "Epoch 28/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 222.7629 - mean_squared_error: 222.7629\n",
      "Epoch 29/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 221.9497 - mean_squared_error: 221.9497\n",
      "Epoch 30/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 215.4397 - mean_squared_error: 215.4397\n",
      "Epoch 31/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 219.0254 - mean_squared_error: 219.0254\n",
      "Epoch 32/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 218.8088 - mean_squared_error: 218.8088\n",
      "Epoch 33/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 222.7768 - mean_squared_error: 222.7768\n",
      "Epoch 34/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 214.3322 - mean_squared_error: 214.3322\n",
      "Epoch 35/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 213.5820 - mean_squared_error: 213.5820\n",
      "Epoch 36/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 217.6842 - mean_squared_error: 217.6842\n",
      "Epoch 37/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 215.8372 - mean_squared_error: 215.8372\n",
      "Epoch 38/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 208.3476 - mean_squared_error: 208.3476\n",
      "Epoch 39/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 213.7428 - mean_squared_error: 213.7428\n",
      "Epoch 40/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 208.6912 - mean_squared_error: 208.6912\n",
      "Epoch 41/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 213.2703 - mean_squared_error: 213.2703\n",
      "Epoch 42/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 204.4011 - mean_squared_error: 204.4011\n",
      "Epoch 43/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 208.6848 - mean_squared_error: 208.6848\n",
      "Epoch 44/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 202.0148 - mean_squared_error: 202.0148\n",
      "Epoch 45/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 210.3100 - mean_squared_error: 210.3100\n",
      "Epoch 46/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 210.3042 - mean_squared_error: 210.3042\n",
      "Epoch 47/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 205.1484 - mean_squared_error: 205.1484\n",
      "Epoch 48/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 197.2385 - mean_squared_error: 197.2385\n",
      "Epoch 49/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 201.7154 - mean_squared_error: 201.7154\n",
      "Epoch 50/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 198.8066 - mean_squared_error: 198.8066\n",
      "Epoch 51/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 200.4656 - mean_squared_error: 200.4656\n",
      "Epoch 52/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 196.5670 - mean_squared_error: 196.5670\n",
      "Epoch 53/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 201.3479 - mean_squared_error: 201.3479\n",
      "Epoch 54/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 194.9798 - mean_squared_error: 194.9798\n",
      "Epoch 55/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 199.9816 - mean_squared_error: 199.9816\n",
      "Epoch 56/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 191.1510 - mean_squared_error: 191.1510\n",
      "Epoch 57/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 204.7949 - mean_squared_error: 204.7949\n",
      "Epoch 58/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 191.0730 - mean_squared_error: 191.0730\n",
      "Epoch 59/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 187.3091 - mean_squared_error: 187.3091\n",
      "Epoch 60/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 191.7476 - mean_squared_error: 191.7476\n",
      "Epoch 61/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 192.6260 - mean_squared_error: 192.6260\n",
      "Epoch 62/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 188.7107 - mean_squared_error: 188.7107\n",
      "Epoch 63/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 183.3426 - mean_squared_error: 183.3426\n",
      "Epoch 64/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 198.9242 - mean_squared_error: 198.9242\n",
      "Epoch 65/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 194.4515 - mean_squared_error: 194.4515\n",
      "Epoch 66/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 198.4928 - mean_squared_error: 198.4928\n",
      "Epoch 67/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 182.0098 - mean_squared_error: 182.0098\n",
      "Epoch 68/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 180.2232 - mean_squared_error: 180.2232\n",
      "Epoch 69/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 194.0727 - mean_squared_error: 194.0727\n",
      "Epoch 70/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 192.5494 - mean_squared_error: 192.5494\n",
      "Epoch 71/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 177.9611 - mean_squared_error: 177.9611\n",
      "Epoch 72/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 178.2946 - mean_squared_error: 178.2946\n",
      "Epoch 73/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 179.3026 - mean_squared_error: 179.3026\n",
      "Epoch 74/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 181.2622 - mean_squared_error: 181.2622\n",
      "Epoch 75/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 194.3763 - mean_squared_error: 194.3763\n",
      "Epoch 76/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 171.7023 - mean_squared_error: 171.7023\n",
      "Epoch 77/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 187.5941 - mean_squared_error: 187.5941\n",
      "Epoch 78/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 177.8350 - mean_squared_error: 177.8350\n",
      "Epoch 79/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 183.8337 - mean_squared_error: 183.8337\n",
      "Epoch 80/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 174.7817 - mean_squared_error: 174.7817\n",
      "Epoch 81/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 174.2992 - mean_squared_error: 174.2992\n",
      "Epoch 82/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 180.9064 - mean_squared_error: 180.9064\n",
      "Epoch 83/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 176.9038 - mean_squared_error: 176.9038\n",
      "Epoch 84/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 168.6359 - mean_squared_error: 168.6359\n",
      "Epoch 85/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 168.7299 - mean_squared_error: 168.7299\n",
      "Epoch 86/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 168.8506 - mean_squared_error: 168.8506\n",
      "Epoch 87/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 172.7236 - mean_squared_error: 172.7236\n",
      "Epoch 88/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 176.8190 - mean_squared_error: 176.8190\n",
      "Epoch 89/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 169.5043 - mean_squared_error: 169.5043\n",
      "Epoch 90/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 170.2638 - mean_squared_error: 170.2638\n",
      "Epoch 91/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 174.0883 - mean_squared_error: 174.0883\n",
      "Epoch 92/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 169.6127 - mean_squared_error: 169.6127\n",
      "Epoch 93/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 167.5956 - mean_squared_error: 167.5956\n",
      "Epoch 94/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 169.4391 - mean_squared_error: 169.4391\n",
      "Epoch 95/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 161.5197 - mean_squared_error: 161.5197\n",
      "Epoch 96/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 165.1269 - mean_squared_error: 165.1269\n",
      "Epoch 97/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 162.7746 - mean_squared_error: 162.7746\n",
      "Epoch 98/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 167.9068 - mean_squared_error: 167.9068\n",
      "Epoch 99/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 161.0301 - mean_squared_error: 161.0301\n",
      "Epoch 100/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 167.9164 - mean_squared_error: 167.9164\n",
      "3667/3667 [==============================] - 0s 17us/step\n",
      "100/100 [==============================] - 0s 26us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 128)               43136     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 616)               79464     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 616)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 617       \n",
      "=================================================================\n",
      "Total params: 123,217\n",
      "Trainable params: 123,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 12us/step - loss: 3661.8277 - mean_squared_error: 3661.8277\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 494.6536 - mean_squared_error: 494.6536\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 378.5769 - mean_squared_error: 378.5769\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 320.2431 - mean_squared_error: 320.2431\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 290.2482 - mean_squared_error: 290.2482\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 271.5488 - mean_squared_error: 271.5488\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 268.3250 - mean_squared_error: 268.3250\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 257.0116 - mean_squared_error: 257.0116\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 258.2165 - mean_squared_error: 258.2165\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 254.4453 - mean_squared_error: 254.4453\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 248.4811 - mean_squared_error: 248.4811\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 248.2406 - mean_squared_error: 248.2406\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 249.2553 - mean_squared_error: 249.2553\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 244.8727 - mean_squared_error: 244.8727\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 239.9368 - mean_squared_error: 239.9368\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 246.4915 - mean_squared_error: 246.4915\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 240.5472 - mean_squared_error: 240.5472\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 240.7047 - mean_squared_error: 240.7047\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.0799 - mean_squared_error: 238.0799\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 235.4892 - mean_squared_error: 235.4892\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 240.8209 - mean_squared_error: 240.8209\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 237.7093 - mean_squared_error: 237.7093\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 241.4293 - mean_squared_error: 241.4293\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.4715 - mean_squared_error: 231.4715\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.6376 - mean_squared_error: 231.6376\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.4860 - mean_squared_error: 226.4860\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 235.1401 - mean_squared_error: 235.1401\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.1885 - mean_squared_error: 230.1885\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 235.5054 - mean_squared_error: 235.5054\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.9302 - mean_squared_error: 231.9302\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.6815 - mean_squared_error: 223.6815\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.9973 - mean_squared_error: 229.9973\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.5114 - mean_squared_error: 224.5114\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.9387 - mean_squared_error: 223.9387\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.0669 - mean_squared_error: 219.0669\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.5986 - mean_squared_error: 224.5986\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.7671 - mean_squared_error: 215.7671\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.0804 - mean_squared_error: 217.0804\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.5765 - mean_squared_error: 220.5765\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.0980 - mean_squared_error: 212.0980\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.9834 - mean_squared_error: 225.9834\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.5903 - mean_squared_error: 220.5903\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.6845 - mean_squared_error: 214.6845\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.0611 - mean_squared_error: 217.0611\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.8607 - mean_squared_error: 209.8607\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.5395 - mean_squared_error: 219.5395\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.4059 - mean_squared_error: 206.4059\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.8107 - mean_squared_error: 209.8107\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.8639 - mean_squared_error: 214.8639\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.7517 - mean_squared_error: 212.7517\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.4680 - mean_squared_error: 208.4680\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.7064 - mean_squared_error: 205.7064\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.5628 - mean_squared_error: 206.5628\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.7341 - mean_squared_error: 199.7341\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.3725 - mean_squared_error: 221.3725\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.5607 - mean_squared_error: 203.5607\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.2978 - mean_squared_error: 197.2978\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.9066 - mean_squared_error: 195.9066\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.9410 - mean_squared_error: 202.9410\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.8301 - mean_squared_error: 200.8301\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.3930 - mean_squared_error: 202.3930\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.0700 - mean_squared_error: 194.0700\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.3999 - mean_squared_error: 198.3999\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.1038 - mean_squared_error: 198.1038\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.3518 - mean_squared_error: 195.3518\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.5532 - mean_squared_error: 195.5532\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.5437 - mean_squared_error: 197.5437\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.3448 - mean_squared_error: 192.3448\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.2698 - mean_squared_error: 199.2698\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.9627 - mean_squared_error: 198.9627\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.0947 - mean_squared_error: 207.0947\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.1357 - mean_squared_error: 194.1357\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.6810 - mean_squared_error: 191.6810\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.2040 - mean_squared_error: 187.2040\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.7689 - mean_squared_error: 199.7689\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.6561 - mean_squared_error: 192.6561\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.0032 - mean_squared_error: 194.0032\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.4615 - mean_squared_error: 187.4615\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.5442 - mean_squared_error: 190.5442\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.4288 - mean_squared_error: 188.4288\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.3212 - mean_squared_error: 185.3212\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.9725 - mean_squared_error: 189.9725\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.9053 - mean_squared_error: 182.9053\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.9901 - mean_squared_error: 184.9901\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.9282 - mean_squared_error: 182.9282\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.2988 - mean_squared_error: 184.2988\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.9603 - mean_squared_error: 180.9603\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.4902 - mean_squared_error: 184.4902\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.9464 - mean_squared_error: 179.9464\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.2981 - mean_squared_error: 179.2981\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.0372 - mean_squared_error: 180.0372\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.6815 - mean_squared_error: 188.6815\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.2002 - mean_squared_error: 180.2002\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.7707 - mean_squared_error: 179.7707\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.9220 - mean_squared_error: 181.9220\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.6128 - mean_squared_error: 183.6128\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.2026 - mean_squared_error: 178.2026\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.1146 - mean_squared_error: 170.1146\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.7956 - mean_squared_error: 173.7956\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.1676 - mean_squared_error: 179.1676\n",
      "3666/3666 [==============================] - 0s 17us/step\n",
      "100/100 [==============================] - 0s 18us/step\n",
      "\n",
      "Experiment on Fold  2\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 128)               43136     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 616)               79464     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 616)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 617       \n",
      "=================================================================\n",
      "Total params: 123,217\n",
      "Trainable params: 123,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 12us/step - loss: 3463.9074 - mean_squared_error: 3463.9074\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 512.6361 - mean_squared_error: 512.6361\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 399.8528 - mean_squared_error: 399.8528\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 329.0282 - mean_squared_error: 329.0282\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 297.3934 - mean_squared_error: 297.3934\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 275.8445 - mean_squared_error: 275.8445\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 267.6216 - mean_squared_error: 267.6216\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 267.1424 - mean_squared_error: 267.1424\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 256.1928 - mean_squared_error: 256.1928\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 250.9779 - mean_squared_error: 250.9779\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 251.8856 - mean_squared_error: 251.8856\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 244.8095 - mean_squared_error: 244.8095\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 249.1632 - mean_squared_error: 249.1632\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 244.0918 - mean_squared_error: 244.0918\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.4421 - mean_squared_error: 242.4421\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.3551 - mean_squared_error: 242.3551\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.8481 - mean_squared_error: 242.8481\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 239.8928 - mean_squared_error: 239.8928\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.5864 - mean_squared_error: 236.5864\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.4043 - mean_squared_error: 236.4043\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 240.5625 - mean_squared_error: 240.5625\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.0664 - mean_squared_error: 233.0664\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.2187 - mean_squared_error: 234.2187\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.9069 - mean_squared_error: 227.9069\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.9532 - mean_squared_error: 229.9532\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.2406 - mean_squared_error: 232.2406\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.5209 - mean_squared_error: 230.5209\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.6639 - mean_squared_error: 230.6639\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.8115 - mean_squared_error: 225.8115\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.7776 - mean_squared_error: 222.7776\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.3898 - mean_squared_error: 225.3898\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.1373 - mean_squared_error: 220.1373\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.8646 - mean_squared_error: 221.8646\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.9517 - mean_squared_error: 219.9517\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.9779 - mean_squared_error: 216.9779\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.5184 - mean_squared_error: 225.5184\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.2765 - mean_squared_error: 220.2765\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.1261 - mean_squared_error: 215.1261\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.0888 - mean_squared_error: 216.0888\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.0270 - mean_squared_error: 213.0270\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.3375 - mean_squared_error: 209.3375\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.4906 - mean_squared_error: 219.4906\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.9755 - mean_squared_error: 214.9755\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.5127 - mean_squared_error: 208.5127\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.8717 - mean_squared_error: 206.8717\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.6845 - mean_squared_error: 205.6845\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.1936 - mean_squared_error: 207.1936\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.9713 - mean_squared_error: 207.9713\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.5478 - mean_squared_error: 203.5478\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.8773 - mean_squared_error: 202.8773\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.6230 - mean_squared_error: 201.6230\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.7269 - mean_squared_error: 202.7269\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.6202 - mean_squared_error: 208.6202\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.0402 - mean_squared_error: 198.0402\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.6595 - mean_squared_error: 198.6595\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.1105 - mean_squared_error: 198.1105\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.2189 - mean_squared_error: 200.2189\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.2778 - mean_squared_error: 193.2778\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.7212 - mean_squared_error: 192.7212\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.8397 - mean_squared_error: 204.8397\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.9306 - mean_squared_error: 194.9306\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.9155 - mean_squared_error: 194.9155\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.3452 - mean_squared_error: 191.3452\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.2172 - mean_squared_error: 189.2172\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.8730 - mean_squared_error: 192.8730\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.9706 - mean_squared_error: 187.9706\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.3198 - mean_squared_error: 188.3198\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.6846 - mean_squared_error: 184.6846\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.3872 - mean_squared_error: 207.3872\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.3190 - mean_squared_error: 180.3190\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.7436 - mean_squared_error: 183.7436\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.4231 - mean_squared_error: 180.4231\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.6041 - mean_squared_error: 185.6041\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.1010 - mean_squared_error: 181.1010\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.7754 - mean_squared_error: 180.7754\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.1307 - mean_squared_error: 179.1307\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.2480 - mean_squared_error: 183.2480\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.2879 - mean_squared_error: 182.2879\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.5856 - mean_squared_error: 172.5856\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.8507 - mean_squared_error: 181.8507\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.8794 - mean_squared_error: 178.8794\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.7178 - mean_squared_error: 175.7178\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.7198 - mean_squared_error: 175.7198\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.7463 - mean_squared_error: 173.7463\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.2114 - mean_squared_error: 174.2114\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.3550 - mean_squared_error: 179.3550\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.1006 - mean_squared_error: 171.1006\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.7425 - mean_squared_error: 176.7425\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.8640 - mean_squared_error: 166.8640\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.9884 - mean_squared_error: 169.9884\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.3232 - mean_squared_error: 173.3232\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.9988 - mean_squared_error: 168.9988\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.0652 - mean_squared_error: 168.0652\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.8699 - mean_squared_error: 166.8699\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.4096 - mean_squared_error: 179.4096\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.7779 - mean_squared_error: 162.7779\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.3593 - mean_squared_error: 170.3593\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.8023 - mean_squared_error: 165.8023\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.3560 - mean_squared_error: 165.3560\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.1897 - mean_squared_error: 164.1897\n",
      "3666/3666 [==============================] - 0s 17us/step\n",
      "100/100 [==============================] - 0s 21us/step\n",
      "\n",
      "Experiment on Fold  3\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 128)               43136     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 616)               79464     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 616)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 617       \n",
      "=================================================================\n",
      "Total params: 123,217\n",
      "Trainable params: 123,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 12us/step - loss: 3412.6182 - mean_squared_error: 3412.6182\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 533.6912 - mean_squared_error: 533.6912\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 412.5121 - mean_squared_error: 412.5121\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 344.2649 - mean_squared_error: 344.2649\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 302.0587 - mean_squared_error: 302.0587\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 280.1546 - mean_squared_error: 280.1546\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 269.3001 - mean_squared_error: 269.3001\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 261.6228 - mean_squared_error: 261.6228\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 255.6740 - mean_squared_error: 255.6740\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 252.9038 - mean_squared_error: 252.9038\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 251.3944 - mean_squared_error: 251.3944\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 248.9115 - mean_squared_error: 248.9115\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 246.7431 - mean_squared_error: 246.7431\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 244.3813 - mean_squared_error: 244.3813\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 243.2956 - mean_squared_error: 243.2956\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 240.7613 - mean_squared_error: 240.7613\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 244.6471 - mean_squared_error: 244.6471\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 240.2739 - mean_squared_error: 240.2739\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 237.2684 - mean_squared_error: 237.2684\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.5324 - mean_squared_error: 236.5324\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.5336 - mean_squared_error: 233.5336\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.1128 - mean_squared_error: 234.1128\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 244.2896 - mean_squared_error: 244.2896\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.9519 - mean_squared_error: 234.9519\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.5674 - mean_squared_error: 230.5674\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.2681 - mean_squared_error: 236.2681\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.6676 - mean_squared_error: 226.6676\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.9294 - mean_squared_error: 232.9294\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.3198 - mean_squared_error: 223.3198\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.4016 - mean_squared_error: 226.4016\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.2675 - mean_squared_error: 226.2675\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.7992 - mean_squared_error: 220.7992\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.5706 - mean_squared_error: 227.5706\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.0546 - mean_squared_error: 222.0546\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.2540 - mean_squared_error: 220.2540\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.1381 - mean_squared_error: 221.1381\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.9276 - mean_squared_error: 219.9276\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.4643 - mean_squared_error: 213.4643\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.1810 - mean_squared_error: 214.1810\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.9889 - mean_squared_error: 211.9889\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.9041 - mean_squared_error: 213.9041\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.9176 - mean_squared_error: 211.9176\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.4135 - mean_squared_error: 216.4135\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.5056 - mean_squared_error: 217.5056\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.3347 - mean_squared_error: 205.3347\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.1237 - mean_squared_error: 208.1237\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.5973 - mean_squared_error: 214.5973\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.3930 - mean_squared_error: 210.3930\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.2354 - mean_squared_error: 209.2354\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.1441 - mean_squared_error: 202.1441\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.3156 - mean_squared_error: 205.3156\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.3556 - mean_squared_error: 211.3556\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.5926 - mean_squared_error: 208.5926\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.9678 - mean_squared_error: 199.9678\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.5199 - mean_squared_error: 196.5199\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.3881 - mean_squared_error: 203.3881\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.9388 - mean_squared_error: 197.9388\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.0401 - mean_squared_error: 197.0401\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.5393 - mean_squared_error: 200.5393\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.3374 - mean_squared_error: 195.3374\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.1852 - mean_squared_error: 199.1852\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.8785 - mean_squared_error: 198.8785\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.0657 - mean_squared_error: 202.0657\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.0000 - mean_squared_error: 198.0000\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.7364 - mean_squared_error: 192.7364\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.2708 - mean_squared_error: 195.2708\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.4933 - mean_squared_error: 188.4933\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.9830 - mean_squared_error: 192.9830\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.3724 - mean_squared_error: 193.3724\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.1368 - mean_squared_error: 190.1368\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.7693 - mean_squared_error: 191.7693\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.2634 - mean_squared_error: 190.2634\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.2235 - mean_squared_error: 184.2235\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.0180 - mean_squared_error: 185.0180\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.1345 - mean_squared_error: 185.1345\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.6329 - mean_squared_error: 186.6329\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.1146 - mean_squared_error: 188.1146\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.5385 - mean_squared_error: 178.5385\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.3354 - mean_squared_error: 186.3354\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.2422 - mean_squared_error: 177.2422\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.0134 - mean_squared_error: 179.0134\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.5215 - mean_squared_error: 178.5215\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.6357 - mean_squared_error: 173.6357\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.4850 - mean_squared_error: 180.4850\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.6544 - mean_squared_error: 176.6544\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.3236 - mean_squared_error: 178.3236\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.5758 - mean_squared_error: 177.5758\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.6297 - mean_squared_error: 171.6297\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.9091 - mean_squared_error: 174.9091\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.9472 - mean_squared_error: 178.9472\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.0756 - mean_squared_error: 175.0756\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.3248 - mean_squared_error: 185.3248\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.9536 - mean_squared_error: 173.9536\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.4564 - mean_squared_error: 177.4564\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.0067 - mean_squared_error: 170.0067\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.7385 - mean_squared_error: 166.7385\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 167.6553 - mean_squared_error: 167.6553\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.3416 - mean_squared_error: 165.3416\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.6207 - mean_squared_error: 164.6207\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.4352 - mean_squared_error: 165.4352\n",
      "3666/3666 [==============================] - 0s 17us/step\n",
      "100/100 [==============================] - 0s 19us/step\n",
      "\n",
      "Experiment on Fold  4\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 128)               43136     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 616)               79464     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 616)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 617       \n",
      "=================================================================\n",
      "Total params: 123,217\n",
      "Trainable params: 123,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 12us/step - loss: 3327.6114 - mean_squared_error: 3327.6114\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 514.3757 - mean_squared_error: 514.3757\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 399.8932 - mean_squared_error: 399.8932\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 324.2946 - mean_squared_error: 324.2946\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 289.1942 - mean_squared_error: 289.1942\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 271.5561 - mean_squared_error: 271.5561\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 267.4483 - mean_squared_error: 267.4483\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 252.1180 - mean_squared_error: 252.1180\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 250.6982 - mean_squared_error: 250.6982\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 246.9856 - mean_squared_error: 246.9856\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 248.9882 - mean_squared_error: 248.9882\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 248.6592 - mean_squared_error: 248.6592\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 241.5533 - mean_squared_error: 241.5533\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.2269 - mean_squared_error: 238.2269\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 243.2813 - mean_squared_error: 243.2813\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.8829 - mean_squared_error: 242.8829\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.6528 - mean_squared_error: 238.6528\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.5804 - mean_squared_error: 236.5804\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.7504 - mean_squared_error: 234.7504\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.0310 - mean_squared_error: 233.0310\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 235.4428 - mean_squared_error: 235.4428\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.2381 - mean_squared_error: 234.2381\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.1519 - mean_squared_error: 232.1519\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.4306 - mean_squared_error: 231.4306\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.3206 - mean_squared_error: 231.3206\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.5221 - mean_squared_error: 233.5221\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.2528 - mean_squared_error: 226.2528\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.0185 - mean_squared_error: 234.0185\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.7544 - mean_squared_error: 227.7544\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.0235 - mean_squared_error: 227.0235\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.4902 - mean_squared_error: 221.4902\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.8725 - mean_squared_error: 221.8725\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.3035 - mean_squared_error: 222.3035\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.6635 - mean_squared_error: 225.6635\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.9399 - mean_squared_error: 219.9399\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.6013 - mean_squared_error: 219.6013\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.0899 - mean_squared_error: 221.0899\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.8300 - mean_squared_error: 219.8300\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.5562 - mean_squared_error: 216.5562\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.6189 - mean_squared_error: 214.6189\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.9003 - mean_squared_error: 221.9003\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.3674 - mean_squared_error: 214.3674\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.5465 - mean_squared_error: 210.5465\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.8068 - mean_squared_error: 214.8068\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.8898 - mean_squared_error: 206.8898\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.5119 - mean_squared_error: 204.5119\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.8626 - mean_squared_error: 219.8626\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.1878 - mean_squared_error: 207.1878\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.8273 - mean_squared_error: 206.8273\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.8863 - mean_squared_error: 204.8863\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.9586 - mean_squared_error: 207.9586\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.0291 - mean_squared_error: 202.0291\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.4393 - mean_squared_error: 203.4393\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.7651 - mean_squared_error: 204.7651\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.3217 - mean_squared_error: 201.3217\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.1611 - mean_squared_error: 200.1611\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.0073 - mean_squared_error: 196.0073\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.3936 - mean_squared_error: 201.3936\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.5775 - mean_squared_error: 195.5775\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.5701 - mean_squared_error: 195.5701\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.8225 - mean_squared_error: 197.8225\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.9295 - mean_squared_error: 193.9295\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.6937 - mean_squared_error: 197.6937\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.5101 - mean_squared_error: 190.5101\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.1192 - mean_squared_error: 186.1192\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.3147 - mean_squared_error: 196.3147\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.9700 - mean_squared_error: 189.9700\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.7898 - mean_squared_error: 189.7898\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.4336 - mean_squared_error: 188.4336\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.7214 - mean_squared_error: 186.7214\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.7947 - mean_squared_error: 192.7947\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.4525 - mean_squared_error: 183.4525\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.9618 - mean_squared_error: 185.9618\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.8889 - mean_squared_error: 191.8889\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.1189 - mean_squared_error: 182.1189\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.0933 - mean_squared_error: 179.0933\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.6410 - mean_squared_error: 185.6410\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.1168 - mean_squared_error: 178.1168\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.0002 - mean_squared_error: 179.0002\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.3737 - mean_squared_error: 177.3737\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.5362 - mean_squared_error: 181.5362\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.0240 - mean_squared_error: 182.0240\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.5936 - mean_squared_error: 175.5936\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.6024 - mean_squared_error: 178.6024\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.2047 - mean_squared_error: 181.2047\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.9513 - mean_squared_error: 176.9513\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.3635 - mean_squared_error: 185.3635\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.8373 - mean_squared_error: 175.8373\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.1274 - mean_squared_error: 170.1274\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.7735 - mean_squared_error: 172.7735\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.7888 - mean_squared_error: 170.7888\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.7598 - mean_squared_error: 168.7598\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.4980 - mean_squared_error: 176.4980\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.2104 - mean_squared_error: 168.2104\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.0101 - mean_squared_error: 175.0101\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.2395 - mean_squared_error: 168.2395\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 167.0935 - mean_squared_error: 167.0935\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 167.0627 - mean_squared_error: 167.0627\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.8353 - mean_squared_error: 171.8353\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.8259 - mean_squared_error: 172.8259\n",
      "3666/3666 [==============================] - 0s 17us/step\n",
      "100/100 [==============================] - 0s 21us/step\n",
      "Testing for yulin/alpha0.4/bestModel_global.json\n",
      "Loading data for dataset 1 with window_size of 24, stride of 1 and maxRUL of 129. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(18331, 336)\n",
      "(18331, 1)\n",
      "Testing data (X, y)\n",
      "(100, 336)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.63253012 -0.18639634 -0.38048616 ... -0.33333333  0.33333333\n",
      "   0.31289699]\n",
      " [-0.43373494 -0.09396119 -0.29473329 ... -0.16666667  0.25581395\n",
      "   0.47638774]\n",
      " [-0.31325301 -0.26095487 -0.25894666 ...  0.          0.11627907\n",
      "   0.43800055]\n",
      " [-0.31325301 -0.48768258 -0.33760972 ... -0.16666667  0.31782946\n",
      "   0.52720243]\n",
      " [-0.30120482 -0.48506649 -0.19074949 ... -0.66666667  0.34883721\n",
      "   0.07677437]]\n",
      "[[129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]]\n",
      "Testing data (X, y)\n",
      "[[-0.19879518 -0.5705254  -0.37069548 ... -0.16666667  0.03875969\n",
      "   0.27312897]\n",
      " [-0.21686747 -0.30237628 -0.12086428 ... -0.5         0.03875969\n",
      "   0.01518917]\n",
      " [-0.04216867 -0.1942446  -0.0209318  ...  0.16666667  0.2248062\n",
      "   0.04888152]\n",
      " [-0.22891566 -0.01722259 -0.13673194 ...  0.16666667 -0.31782946\n",
      "   0.004971  ]\n",
      " [-0.11445783 -0.11968607  0.03511141 ...  0.         -0.05426357\n",
      "   0.42916321]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n",
      "Validation on model:best_models/cmapss/yulin/alpha0.4/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 696)               234552    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 472)               328984    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 473       \n",
      "=================================================================\n",
      "Total params: 564,009\n",
      "Trainable params: 564,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14664/14664 [==============================] - 0s 11us/step - loss: 2172.9693 - mean_squared_error: 2172.9693\n",
      "Epoch 2/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 369.9071 - mean_squared_error: 369.9071\n",
      "Epoch 3/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 297.4259 - mean_squared_error: 297.4259\n",
      "Epoch 4/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 269.2931 - mean_squared_error: 269.2931\n",
      "Epoch 5/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 250.6587 - mean_squared_error: 250.6587\n",
      "Epoch 6/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 252.0810 - mean_squared_error: 252.0810\n",
      "Epoch 7/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 248.0217 - mean_squared_error: 248.0217\n",
      "Epoch 8/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 243.8706 - mean_squared_error: 243.8706\n",
      "Epoch 9/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 245.5797 - mean_squared_error: 245.5797\n",
      "Epoch 10/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 230.9286 - mean_squared_error: 230.9286\n",
      "Epoch 11/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 253.7419 - mean_squared_error: 253.7419\n",
      "Epoch 12/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 232.6565 - mean_squared_error: 232.6565\n",
      "Epoch 13/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 227.4254 - mean_squared_error: 227.4254\n",
      "Epoch 14/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 239.4009 - mean_squared_error: 239.4009\n",
      "Epoch 15/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 225.0047 - mean_squared_error: 225.0047\n",
      "Epoch 16/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 227.6180 - mean_squared_error: 227.6180\n",
      "Epoch 17/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 230.0892 - mean_squared_error: 230.0892\n",
      "Epoch 18/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 225.7021 - mean_squared_error: 225.7021\n",
      "Epoch 19/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 228.0307 - mean_squared_error: 228.0307\n",
      "Epoch 20/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 217.0589 - mean_squared_error: 217.0589\n",
      "Epoch 21/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 222.6143 - mean_squared_error: 222.6143\n",
      "Epoch 22/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 221.5683 - mean_squared_error: 221.5683\n",
      "Epoch 23/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 216.0739 - mean_squared_error: 216.0739\n",
      "Epoch 24/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 234.6748 - mean_squared_error: 234.6748\n",
      "Epoch 25/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 206.6548 - mean_squared_error: 206.6548\n",
      "Epoch 26/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 201.8852 - mean_squared_error: 201.8852\n",
      "Epoch 27/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 205.6897 - mean_squared_error: 205.6897\n",
      "Epoch 28/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 212.6780 - mean_squared_error: 212.6780\n",
      "Epoch 29/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 198.7134 - mean_squared_error: 198.7134\n",
      "Epoch 30/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 201.8977 - mean_squared_error: 201.8977\n",
      "Epoch 31/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 200.2347 - mean_squared_error: 200.2347\n",
      "Epoch 32/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 198.9557 - mean_squared_error: 198.9557\n",
      "Epoch 33/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 192.4305 - mean_squared_error: 192.4305\n",
      "Epoch 34/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 212.8354 - mean_squared_error: 212.8354\n",
      "Epoch 35/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 193.0352 - mean_squared_error: 193.0352\n",
      "Epoch 36/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 193.0951 - mean_squared_error: 193.0951\n",
      "Epoch 37/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 198.5183 - mean_squared_error: 198.5183\n",
      "Epoch 38/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 182.4320 - mean_squared_error: 182.4320\n",
      "Epoch 39/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 197.0691 - mean_squared_error: 197.0691\n",
      "Epoch 40/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 184.7074 - mean_squared_error: 184.7074\n",
      "Epoch 41/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 178.5452 - mean_squared_error: 178.5452\n",
      "Epoch 42/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 188.5308 - mean_squared_error: 188.5308\n",
      "Epoch 43/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 184.2082 - mean_squared_error: 184.2082\n",
      "Epoch 44/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 180.7109 - mean_squared_error: 180.7109\n",
      "Epoch 45/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 172.3181 - mean_squared_error: 172.3181\n",
      "Epoch 46/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 176.1055 - mean_squared_error: 176.1055\n",
      "Epoch 47/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 185.0695 - mean_squared_error: 185.0695\n",
      "Epoch 48/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 176.1971 - mean_squared_error: 176.1971\n",
      "Epoch 49/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 164.6693 - mean_squared_error: 164.6693\n",
      "Epoch 50/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 173.5087 - mean_squared_error: 173.5087\n",
      "Epoch 51/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 161.9418 - mean_squared_error: 161.9418\n",
      "Epoch 52/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 169.0468 - mean_squared_error: 169.0468\n",
      "Epoch 53/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 163.9241 - mean_squared_error: 163.9241\n",
      "Epoch 54/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 156.7711 - mean_squared_error: 156.7711\n",
      "Epoch 55/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 156.5784 - mean_squared_error: 156.5784\n",
      "Epoch 56/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 163.9621 - mean_squared_error: 163.9621\n",
      "Epoch 57/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 160.7667 - mean_squared_error: 160.7667\n",
      "Epoch 58/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 151.0236 - mean_squared_error: 151.0236\n",
      "Epoch 59/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 159.1366 - mean_squared_error: 159.1366\n",
      "Epoch 60/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 150.5283 - mean_squared_error: 150.5283\n",
      "Epoch 61/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 151.8021 - mean_squared_error: 151.8021\n",
      "Epoch 62/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 150.0249 - mean_squared_error: 150.0249\n",
      "Epoch 63/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 160.1718 - mean_squared_error: 160.1718\n",
      "Epoch 64/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 157.9793 - mean_squared_error: 157.9793\n",
      "Epoch 65/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 134.7049 - mean_squared_error: 134.7049\n",
      "Epoch 66/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 145.8795 - mean_squared_error: 145.8795\n",
      "Epoch 67/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 141.9732 - mean_squared_error: 141.9732\n",
      "Epoch 68/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 133.3653 - mean_squared_error: 133.3653\n",
      "Epoch 69/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 135.1459 - mean_squared_error: 135.1459\n",
      "Epoch 70/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 133.4217 - mean_squared_error: 133.4217\n",
      "Epoch 71/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 123.2140 - mean_squared_error: 123.2140\n",
      "Epoch 72/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 146.2722 - mean_squared_error: 146.2722\n",
      "Epoch 73/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 126.9940 - mean_squared_error: 126.9940\n",
      "Epoch 74/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 122.0952 - mean_squared_error: 122.0952\n",
      "Epoch 75/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 126.3105 - mean_squared_error: 126.3105\n",
      "Epoch 76/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 126.3456 - mean_squared_error: 126.3456\n",
      "Epoch 77/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 120.9875 - mean_squared_error: 120.9875\n",
      "Epoch 78/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 132.3695 - mean_squared_error: 132.3695\n",
      "Epoch 79/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 114.2670 - mean_squared_error: 114.2670\n",
      "Epoch 80/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 107.7771 - mean_squared_error: 107.7771\n",
      "Epoch 81/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 128.9782 - mean_squared_error: 128.9782\n",
      "Epoch 82/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 133.9215 - mean_squared_error: 133.9215\n",
      "Epoch 83/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 118.2074 - mean_squared_error: 118.2074\n",
      "Epoch 84/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 101.7245 - mean_squared_error: 101.7245\n",
      "Epoch 85/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 96.3425 - mean_squared_error: 96.3425\n",
      "Epoch 86/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 116.4706 - mean_squared_error: 116.4706\n",
      "Epoch 87/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 123.7594 - mean_squared_error: 123.7594\n",
      "Epoch 88/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 95.2663 - mean_squared_error: 95.2663\n",
      "Epoch 89/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 105.0358 - mean_squared_error: 105.0358\n",
      "Epoch 90/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 102.9008 - mean_squared_error: 102.9008\n",
      "Epoch 91/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 100.9267 - mean_squared_error: 100.9267\n",
      "Epoch 92/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 95.7914 - mean_squared_error: 95.7914\n",
      "Epoch 93/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 108.8653 - mean_squared_error: 108.8653\n",
      "Epoch 94/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 107.7780 - mean_squared_error: 107.7780\n",
      "Epoch 95/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 93.0912 - mean_squared_error: 93.0912\n",
      "Epoch 96/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 90.4650 - mean_squared_error: 90.4650\n",
      "Epoch 97/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 99.1015 - mean_squared_error: 99.1015\n",
      "Epoch 98/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 109.4187 - mean_squared_error: 109.4187\n",
      "Epoch 99/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 82.6650 - mean_squared_error: 82.6650\n",
      "Epoch 100/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 90.6327 - mean_squared_error: 90.6327\n",
      "3667/3667 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 19us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 696)               234552    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 472)               328984    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 473       \n",
      "=================================================================\n",
      "Total params: 564,009\n",
      "Trainable params: 564,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 11us/step - loss: 2275.6114 - mean_squared_error: 2275.6114\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 377.3828 - mean_squared_error: 377.3828\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 303.1813 - mean_squared_error: 303.1813\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 273.8926 - mean_squared_error: 273.8926\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 268.0850 - mean_squared_error: 268.0850\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 249.5345 - mean_squared_error: 249.5345\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 260.9505 - mean_squared_error: 260.9505\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 245.0379 - mean_squared_error: 245.0379\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 243.7082 - mean_squared_error: 243.7082\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.7478 - mean_squared_error: 236.7478\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.8582 - mean_squared_error: 236.8582\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 237.7172 - mean_squared_error: 237.7172\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 250.0941 - mean_squared_error: 250.0941\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.3297 - mean_squared_error: 234.3297\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.3855 - mean_squared_error: 236.3855\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 235.3964 - mean_squared_error: 235.3964\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.4987 - mean_squared_error: 224.4987\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.8628 - mean_squared_error: 227.8628\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.6102 - mean_squared_error: 226.6102\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.5148 - mean_squared_error: 223.5148\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.3011 - mean_squared_error: 231.3011\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.0933 - mean_squared_error: 221.0933\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.0265 - mean_squared_error: 211.0265\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.5123 - mean_squared_error: 220.5123\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.5264 - mean_squared_error: 226.5264\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.0625 - mean_squared_error: 223.0625\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.5916 - mean_squared_error: 201.5916\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.3404 - mean_squared_error: 209.3404\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.2290 - mean_squared_error: 214.2290\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.5374 - mean_squared_error: 197.5374\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.2545 - mean_squared_error: 206.2545\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.9089 - mean_squared_error: 196.9089\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.1577 - mean_squared_error: 209.1577\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.4564 - mean_squared_error: 204.4564\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.2553 - mean_squared_error: 210.2553\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.0232 - mean_squared_error: 196.0232\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.7727 - mean_squared_error: 201.7727\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.8194 - mean_squared_error: 189.8194\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.9209 - mean_squared_error: 192.9209\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.4995 - mean_squared_error: 191.4995\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.1893 - mean_squared_error: 188.1893\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.5210 - mean_squared_error: 194.5210\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.1232 - mean_squared_error: 202.1232\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.8725 - mean_squared_error: 181.8725\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.5536 - mean_squared_error: 180.5536\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.1902 - mean_squared_error: 190.1902\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.5259 - mean_squared_error: 177.5259\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.1038 - mean_squared_error: 187.1038\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.0979 - mean_squared_error: 165.0979\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.1549 - mean_squared_error: 176.1549\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.0066 - mean_squared_error: 182.0066\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.0749 - mean_squared_error: 164.0749\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.9646 - mean_squared_error: 162.9646\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.1440 - mean_squared_error: 179.1440\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.1302 - mean_squared_error: 168.1302\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.5376 - mean_squared_error: 159.5376\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 167.1382 - mean_squared_error: 167.1382\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.4942 - mean_squared_error: 169.4942\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.7872 - mean_squared_error: 164.7872\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.0107 - mean_squared_error: 159.0107\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 167.6791 - mean_squared_error: 167.6791\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.9285 - mean_squared_error: 169.9285\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 148.7569 - mean_squared_error: 148.7569\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 151.8063 - mean_squared_error: 151.8063\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.8138 - mean_squared_error: 170.8138\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 146.6314 - mean_squared_error: 146.6314\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.8088 - mean_squared_error: 156.8088\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 137.0353 - mean_squared_error: 137.0353\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 148.4188 - mean_squared_error: 148.4188\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 150.1840 - mean_squared_error: 150.1840\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 138.2945 - mean_squared_error: 138.2945\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 146.5682 - mean_squared_error: 146.5682\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 133.5511 - mean_squared_error: 133.5511\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 128.6177 - mean_squared_error: 128.6177\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 131.4030 - mean_squared_error: 131.4030\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 145.8913 - mean_squared_error: 145.8913\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 128.3513 - mean_squared_error: 128.3513\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 128.1370 - mean_squared_error: 128.1370\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 129.1317 - mean_squared_error: 129.1317\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 126.3130 - mean_squared_error: 126.3130\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 117.1550 - mean_squared_error: 117.1550\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 125.6703 - mean_squared_error: 125.6703\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 132.1868 - mean_squared_error: 132.1868\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 114.3154 - mean_squared_error: 114.3154\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 117.6885 - mean_squared_error: 117.6885\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 129.8670 - mean_squared_error: 129.8670\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 115.5040 - mean_squared_error: 115.5040\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 101.1275 - mean_squared_error: 101.1275\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 115.3617 - mean_squared_error: 115.3617\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 108.4870 - mean_squared_error: 108.4870\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 107.4950 - mean_squared_error: 107.4950\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 105.8095 - mean_squared_error: 105.8095\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 111.1854 - mean_squared_error: 111.1854\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 102.4814 - mean_squared_error: 102.4814\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 103.6397 - mean_squared_error: 103.6397\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 96.9942 - mean_squared_error: 96.9942\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 111.2726 - mean_squared_error: 111.2726\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 96.0109 - mean_squared_error: 96.0109\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 93.8419 - mean_squared_error: 93.8419\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 100.4646 - mean_squared_error: 100.4646\n",
      "3666/3666 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 17us/step\n",
      "\n",
      "Experiment on Fold  2\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 696)               234552    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 472)               328984    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 473       \n",
      "=================================================================\n",
      "Total params: 564,009\n",
      "Trainable params: 564,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 11us/step - loss: 2285.2931 - mean_squared_error: 2285.2931\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 392.9795 - mean_squared_error: 392.9795\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 313.3102 - mean_squared_error: 313.3102\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 275.2278 - mean_squared_error: 275.2278\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 272.8199 - mean_squared_error: 272.8199\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 253.5419 - mean_squared_error: 253.5419\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 245.7226 - mean_squared_error: 245.7226\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 255.9423 - mean_squared_error: 255.9423\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 247.1381 - mean_squared_error: 247.1381\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 252.9792 - mean_squared_error: 252.9792\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.4143 - mean_squared_error: 238.4143\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 250.4514 - mean_squared_error: 250.4514\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 237.0102 - mean_squared_error: 237.0102\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 240.0382 - mean_squared_error: 240.0382\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.3790 - mean_squared_error: 233.3790\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.1143 - mean_squared_error: 228.1143\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 243.4710 - mean_squared_error: 243.4710\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.4538 - mean_squared_error: 230.4538\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.1178 - mean_squared_error: 232.1178\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.2366 - mean_squared_error: 232.2366\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.5219 - mean_squared_error: 226.5219\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.7081 - mean_squared_error: 231.7081\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.0370 - mean_squared_error: 225.0370\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.7211 - mean_squared_error: 219.7211\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.4393 - mean_squared_error: 226.4393\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.6787 - mean_squared_error: 217.6787\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.1243 - mean_squared_error: 217.1243\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.8851 - mean_squared_error: 226.8851\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.5390 - mean_squared_error: 214.5390\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.1516 - mean_squared_error: 219.1516\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.3296 - mean_squared_error: 204.3296\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.0902 - mean_squared_error: 227.0902\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.1798 - mean_squared_error: 204.1798\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.7957 - mean_squared_error: 209.7957\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.4596 - mean_squared_error: 206.4596\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.9727 - mean_squared_error: 203.9727\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.9872 - mean_squared_error: 213.9872\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.4430 - mean_squared_error: 205.4430\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.9247 - mean_squared_error: 203.9247\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.6771 - mean_squared_error: 198.6771\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.2115 - mean_squared_error: 190.2115\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.3598 - mean_squared_error: 197.3598\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.0103 - mean_squared_error: 214.0103\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.3367 - mean_squared_error: 192.3367\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.5637 - mean_squared_error: 186.5637\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.8957 - mean_squared_error: 189.8957\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.5742 - mean_squared_error: 189.5742\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.6908 - mean_squared_error: 183.6908\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.6042 - mean_squared_error: 190.6042\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.4780 - mean_squared_error: 178.4780\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.7421 - mean_squared_error: 185.7421\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.9133 - mean_squared_error: 187.9133\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.9900 - mean_squared_error: 187.9900\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.7243 - mean_squared_error: 185.7243\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.7013 - mean_squared_error: 171.7013\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 167.6758 - mean_squared_error: 167.6758\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.8907 - mean_squared_error: 175.8907\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.6844 - mean_squared_error: 175.6844\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.4363 - mean_squared_error: 169.4363\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.8522 - mean_squared_error: 164.8522\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.6167 - mean_squared_error: 168.6167\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.0502 - mean_squared_error: 174.0502\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 150.6682 - mean_squared_error: 150.6682\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.2493 - mean_squared_error: 175.2493\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 153.8313 - mean_squared_error: 153.8313\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 151.7640 - mean_squared_error: 151.7640\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.7161 - mean_squared_error: 166.7161\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.6286 - mean_squared_error: 165.6286\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 149.9185 - mean_squared_error: 149.9185\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.4111 - mean_squared_error: 154.4111\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 147.7311 - mean_squared_error: 147.7311\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 152.4280 - mean_squared_error: 152.4280\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 141.1924 - mean_squared_error: 141.1924\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 143.7312 - mean_squared_error: 143.7312\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 150.7931 - mean_squared_error: 150.7931\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 139.8261 - mean_squared_error: 139.8261\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 152.2208 - mean_squared_error: 152.2208\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 129.3237 - mean_squared_error: 129.3237\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 142.7265 - mean_squared_error: 142.7265\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 128.7314 - mean_squared_error: 128.7314\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 137.5984 - mean_squared_error: 137.5984\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 130.0071 - mean_squared_error: 130.0071\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 123.0497 - mean_squared_error: 123.0497\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 117.5045 - mean_squared_error: 117.5045\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 138.6658 - mean_squared_error: 138.6658\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 127.1435 - mean_squared_error: 127.1435\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 123.7381 - mean_squared_error: 123.7381\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 125.0690 - mean_squared_error: 125.0690\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 113.6069 - mean_squared_error: 113.6069\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 120.4215 - mean_squared_error: 120.4215\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 118.7170 - mean_squared_error: 118.7170\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 115.2420 - mean_squared_error: 115.2420\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 119.9957 - mean_squared_error: 119.9957\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 120.0402 - mean_squared_error: 120.0402\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 111.5366 - mean_squared_error: 111.5366\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 104.3175 - mean_squared_error: 104.3175\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 98.2604 - mean_squared_error: 98.2604\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 92.4223 - mean_squared_error: 92.4223\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 107.3716 - mean_squared_error: 107.3716\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 96.0660 - mean_squared_error: 96.0660\n",
      "3666/3666 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 28us/step\n",
      "\n",
      "Experiment on Fold  3\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 696)               234552    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 472)               328984    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 473       \n",
      "=================================================================\n",
      "Total params: 564,009\n",
      "Trainable params: 564,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 11us/step - loss: 2164.2218 - mean_squared_error: 2164.2218\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 392.4484 - mean_squared_error: 392.4484\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 300.1771 - mean_squared_error: 300.1771\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 270.3823 - mean_squared_error: 270.3823\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 254.6069 - mean_squared_error: 254.6069\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 255.4383 - mean_squared_error: 255.4383\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 249.4166 - mean_squared_error: 249.4166\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 241.3170 - mean_squared_error: 241.3170\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 247.2668 - mean_squared_error: 247.2668\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 244.9219 - mean_squared_error: 244.9219\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 234.8726 - mean_squared_error: 234.8726\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 243.4926 - mean_squared_error: 243.4926\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.8630 - mean_squared_error: 231.8630\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.4615 - mean_squared_error: 238.4615\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.7170 - mean_squared_error: 226.7170\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.5342 - mean_squared_error: 231.5342\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 235.5907 - mean_squared_error: 235.5907\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.2688 - mean_squared_error: 229.2688\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.9689 - mean_squared_error: 219.9689\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.6923 - mean_squared_error: 224.6923\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.7447 - mean_squared_error: 232.7447\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.7360 - mean_squared_error: 222.7360\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.2081 - mean_squared_error: 232.2081\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.9784 - mean_squared_error: 209.9784\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.4855 - mean_squared_error: 223.4855\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.1825 - mean_squared_error: 215.1825\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 206.3772 - mean_squared_error: 206.3772\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.8695 - mean_squared_error: 212.8695\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.3106 - mean_squared_error: 215.3106\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.8115 - mean_squared_error: 209.8115\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.5452 - mean_squared_error: 207.5452\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.5516 - mean_squared_error: 214.5516\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.1660 - mean_squared_error: 200.1660\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.0053 - mean_squared_error: 199.0053\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.7538 - mean_squared_error: 206.7538\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.9328 - mean_squared_error: 194.9328\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.8477 - mean_squared_error: 190.8477\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.1898 - mean_squared_error: 202.1898\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.7460 - mean_squared_error: 203.7460\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 195.7950 - mean_squared_error: 195.7950\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.2683 - mean_squared_error: 195.2683\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.5357 - mean_squared_error: 186.5357\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.7228 - mean_squared_error: 187.7228\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 177.5673 - mean_squared_error: 177.5673\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.3850 - mean_squared_error: 192.3850\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.5150 - mean_squared_error: 188.5150\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.8646 - mean_squared_error: 189.8646\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.4910 - mean_squared_error: 180.4910\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.2964 - mean_squared_error: 172.2964\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 174.6107 - mean_squared_error: 174.6107\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.1006 - mean_squared_error: 186.1006\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.0514 - mean_squared_error: 178.0514\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.5154 - mean_squared_error: 171.5154\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.6315 - mean_squared_error: 176.6315\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.0976 - mean_squared_error: 175.0976\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.5040 - mean_squared_error: 173.5040\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 163.1977 - mean_squared_error: 163.1977\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.9128 - mean_squared_error: 157.9128\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.7793 - mean_squared_error: 160.7793\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.0444 - mean_squared_error: 173.0444\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.0933 - mean_squared_error: 158.0933\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 157.5131 - mean_squared_error: 157.5131\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.5667 - mean_squared_error: 158.5667\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.8684 - mean_squared_error: 157.8684\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 152.2399 - mean_squared_error: 152.2399\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 145.1732 - mean_squared_error: 145.1732\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 149.2667 - mean_squared_error: 149.2667\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 149.7401 - mean_squared_error: 149.7401\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 152.7436 - mean_squared_error: 152.7436\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 160.5338 - mean_squared_error: 160.5338\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 152.5064 - mean_squared_error: 152.5064\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 147.0283 - mean_squared_error: 147.0283\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 139.0493 - mean_squared_error: 139.0493\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 143.5521 - mean_squared_error: 143.5521\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 131.6240 - mean_squared_error: 131.6240\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 154.0781 - mean_squared_error: 154.0781\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 126.8172 - mean_squared_error: 126.8172\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 132.2926 - mean_squared_error: 132.2926\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 144.8423 - mean_squared_error: 144.8423\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 131.2396 - mean_squared_error: 131.2396\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 126.4978 - mean_squared_error: 126.4978\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 119.8273 - mean_squared_error: 119.8273\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 131.9773 - mean_squared_error: 131.9773\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 122.6485 - mean_squared_error: 122.6485\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 125.7880 - mean_squared_error: 125.7880\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 117.2100 - mean_squared_error: 117.2100\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 116.9056 - mean_squared_error: 116.9056\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 118.5731 - mean_squared_error: 118.5731\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 120.4020 - mean_squared_error: 120.4020\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 112.3678 - mean_squared_error: 112.3678\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 112.0461 - mean_squared_error: 112.0461\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 116.3867 - mean_squared_error: 116.3867\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 109.4747 - mean_squared_error: 109.4747\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 117.2991 - mean_squared_error: 117.2991\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 110.6905 - mean_squared_error: 110.6905\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 107.9967 - mean_squared_error: 107.9967\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 116.3144 - mean_squared_error: 116.3144\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 96.5184 - mean_squared_error: 96.5184\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 118.0282 - mean_squared_error: 118.0282\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 93.3468 - mean_squared_error: 93.3468\n",
      "3666/3666 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 17us/step\n",
      "\n",
      "Experiment on Fold  4\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 696)               234552    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 472)               328984    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 473       \n",
      "=================================================================\n",
      "Total params: 564,009\n",
      "Trainable params: 564,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 12us/step - loss: 2167.9249 - mean_squared_error: 2167.9249\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 387.5232 - mean_squared_error: 387.5232\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 305.6111 - mean_squared_error: 305.6111\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 282.2438 - mean_squared_error: 282.2438\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 261.1989 - mean_squared_error: 261.1989\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 261.4906 - mean_squared_error: 261.4906\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 247.2343 - mean_squared_error: 247.2343\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 252.9497 - mean_squared_error: 252.9497\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 237.3861 - mean_squared_error: 237.3861\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 245.0236 - mean_squared_error: 245.0236\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 257.6939 - mean_squared_error: 257.6939\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 241.4777 - mean_squared_error: 241.4777\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 239.1678 - mean_squared_error: 239.1678\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.6067 - mean_squared_error: 236.6067\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.5783 - mean_squared_error: 233.5783\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 246.9156 - mean_squared_error: 246.9156\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.1818 - mean_squared_error: 223.1818\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.8219 - mean_squared_error: 242.8219\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.9371 - mean_squared_error: 223.9371\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.7891 - mean_squared_error: 234.7891\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.2692 - mean_squared_error: 223.2692\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.8195 - mean_squared_error: 218.8195\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.9661 - mean_squared_error: 224.9661\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.7058 - mean_squared_error: 220.7058\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.7598 - mean_squared_error: 225.7598\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.7154 - mean_squared_error: 213.7154\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.4098 - mean_squared_error: 226.4098\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.5148 - mean_squared_error: 203.5148\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.9738 - mean_squared_error: 214.9738\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.6405 - mean_squared_error: 223.6405\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.4406 - mean_squared_error: 207.4406\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.4665 - mean_squared_error: 214.4665\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.6517 - mean_squared_error: 205.6517\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.3983 - mean_squared_error: 203.3983\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.3674 - mean_squared_error: 201.3674\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.2516 - mean_squared_error: 202.2516\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.4804 - mean_squared_error: 202.4804\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.0263 - mean_squared_error: 187.0263\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.5823 - mean_squared_error: 204.5823\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.3673 - mean_squared_error: 192.3673\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.5485 - mean_squared_error: 184.5485\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 193.2405 - mean_squared_error: 193.2405\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.6314 - mean_squared_error: 201.6314\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.1134 - mean_squared_error: 184.1134\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.8047 - mean_squared_error: 180.8047\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.4793 - mean_squared_error: 176.4793\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.5362 - mean_squared_error: 183.5362\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.6702 - mean_squared_error: 185.6702\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 167.5981 - mean_squared_error: 167.5981\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.8980 - mean_squared_error: 180.8980\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.7131 - mean_squared_error: 177.7131\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.3100 - mean_squared_error: 185.3100\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.9061 - mean_squared_error: 165.9061\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.7911 - mean_squared_error: 172.7911\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.7030 - mean_squared_error: 169.7030\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.6002 - mean_squared_error: 170.6002\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 163.0079 - mean_squared_error: 163.0079\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.9273 - mean_squared_error: 156.9273\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.9114 - mean_squared_error: 158.9114\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.7738 - mean_squared_error: 180.7738\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.3324 - mean_squared_error: 156.3324\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.0951 - mean_squared_error: 160.0951\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.4634 - mean_squared_error: 168.4634\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 160.2264 - mean_squared_error: 160.2264\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 144.3696 - mean_squared_error: 144.3696\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 142.7548 - mean_squared_error: 142.7548\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.2960 - mean_squared_error: 154.2960\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 141.9855 - mean_squared_error: 141.9855\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 147.1785 - mean_squared_error: 147.1785\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 151.9931 - mean_squared_error: 151.9931\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 139.4055 - mean_squared_error: 139.4055\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 132.4276 - mean_squared_error: 132.4276\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 140.5044 - mean_squared_error: 140.5044\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 139.6055 - mean_squared_error: 139.6055\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 135.8365 - mean_squared_error: 135.8365\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 135.5783 - mean_squared_error: 135.5783\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 131.5383 - mean_squared_error: 131.5383\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 133.3404 - mean_squared_error: 133.3404\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 139.5851 - mean_squared_error: 139.5851\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 127.4476 - mean_squared_error: 127.4476\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 124.0278 - mean_squared_error: 124.0278\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 134.1989 - mean_squared_error: 134.1989\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 118.0776 - mean_squared_error: 118.0776\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 128.3513 - mean_squared_error: 128.3513\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 115.5692 - mean_squared_error: 115.5692\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 112.2460 - mean_squared_error: 112.2460\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 111.8988 - mean_squared_error: 111.8988\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 109.0006 - mean_squared_error: 109.0006\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 113.4219 - mean_squared_error: 113.4219\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 116.9863 - mean_squared_error: 116.9863\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 112.1689 - mean_squared_error: 112.1689\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 112.8527 - mean_squared_error: 112.8527\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 116.2133 - mean_squared_error: 116.2133\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 92.9503 - mean_squared_error: 92.9503\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 94.9561 - mean_squared_error: 94.9561\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 109.1074 - mean_squared_error: 109.1074\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 97.9708 - mean_squared_error: 97.9708\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 112.6007 - mean_squared_error: 112.6007\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 101.4378 - mean_squared_error: 101.4378\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 89.0997 - mean_squared_error: 89.0997\n",
      "3666/3666 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 17us/step\n",
      "Testing for yulin/alpha0.5/bestModel_global.json\n",
      "Loading data for dataset 1 with window_size of 24, stride of 1 and maxRUL of 129. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(18331, 336)\n",
      "(18331, 1)\n",
      "Testing data (X, y)\n",
      "(100, 336)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.63253012 -0.18639634 -0.38048616 ... -0.33333333  0.33333333\n",
      "   0.31289699]\n",
      " [-0.43373494 -0.09396119 -0.29473329 ... -0.16666667  0.25581395\n",
      "   0.47638774]\n",
      " [-0.31325301 -0.26095487 -0.25894666 ...  0.          0.11627907\n",
      "   0.43800055]\n",
      " [-0.31325301 -0.48768258 -0.33760972 ... -0.16666667  0.31782946\n",
      "   0.52720243]\n",
      " [-0.30120482 -0.48506649 -0.19074949 ... -0.66666667  0.34883721\n",
      "   0.07677437]]\n",
      "[[129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]]\n",
      "Testing data (X, y)\n",
      "[[-0.19879518 -0.5705254  -0.37069548 ... -0.16666667  0.03875969\n",
      "   0.27312897]\n",
      " [-0.21686747 -0.30237628 -0.12086428 ... -0.5         0.03875969\n",
      "   0.01518917]\n",
      " [-0.04216867 -0.1942446  -0.0209318  ...  0.16666667  0.2248062\n",
      "   0.04888152]\n",
      " [-0.22891566 -0.01722259 -0.13673194 ...  0.16666667 -0.31782946\n",
      "   0.004971  ]\n",
      " [-0.11445783 -0.11968607  0.03511141 ...  0.         -0.05426357\n",
      "   0.42916321]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n",
      "Validation on model:best_models/cmapss/yulin/alpha0.5/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 936)               315432    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 937       \n",
      "=================================================================\n",
      "Total params: 316,369\n",
      "Trainable params: 316,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14664/14664 [==============================] - 0s 9us/step - loss: 3988.1150 - mean_squared_error: 3988.1150\n",
      "Epoch 2/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 707.4768 - mean_squared_error: 707.4768\n",
      "Epoch 3/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 530.7087 - mean_squared_error: 530.7087\n",
      "Epoch 4/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 462.8425 - mean_squared_error: 462.8425\n",
      "Epoch 5/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 414.0852 - mean_squared_error: 414.0852\n",
      "Epoch 6/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 368.3723 - mean_squared_error: 368.3723\n",
      "Epoch 7/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 333.4935 - mean_squared_error: 333.4935\n",
      "Epoch 8/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 310.1792 - mean_squared_error: 310.1792\n",
      "Epoch 9/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 294.6019 - mean_squared_error: 294.6019\n",
      "Epoch 10/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 284.6629 - mean_squared_error: 284.6629\n",
      "Epoch 11/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 273.2424 - mean_squared_error: 273.2424\n",
      "Epoch 12/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 265.9691 - mean_squared_error: 265.9691\n",
      "Epoch 13/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 260.0285 - mean_squared_error: 260.0285\n",
      "Epoch 14/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 255.2966 - mean_squared_error: 255.2966\n",
      "Epoch 15/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 250.8269 - mean_squared_error: 250.8269\n",
      "Epoch 16/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 247.3982 - mean_squared_error: 247.3982\n",
      "Epoch 17/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 244.9228 - mean_squared_error: 244.9228\n",
      "Epoch 18/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 244.1637 - mean_squared_error: 244.1637\n",
      "Epoch 19/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 240.1869 - mean_squared_error: 240.1869\n",
      "Epoch 20/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 239.3429 - mean_squared_error: 239.3429\n",
      "Epoch 21/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 236.6528 - mean_squared_error: 236.6528\n",
      "Epoch 22/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 235.9102 - mean_squared_error: 235.9102\n",
      "Epoch 23/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 234.7850 - mean_squared_error: 234.7850\n",
      "Epoch 24/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 232.6895 - mean_squared_error: 232.6895\n",
      "Epoch 25/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 230.7969 - mean_squared_error: 230.7969\n",
      "Epoch 26/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 231.6836 - mean_squared_error: 231.6836\n",
      "Epoch 27/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 228.8092 - mean_squared_error: 228.8092\n",
      "Epoch 28/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 227.6601 - mean_squared_error: 227.6601\n",
      "Epoch 29/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 225.6908 - mean_squared_error: 225.6908\n",
      "Epoch 30/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 225.1835 - mean_squared_error: 225.1835\n",
      "Epoch 31/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 222.8273 - mean_squared_error: 222.8273\n",
      "Epoch 32/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 225.4548 - mean_squared_error: 225.4548\n",
      "Epoch 33/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 222.1197 - mean_squared_error: 222.1197\n",
      "Epoch 34/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 220.2437 - mean_squared_error: 220.2437\n",
      "Epoch 35/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 223.1960 - mean_squared_error: 223.1960\n",
      "Epoch 36/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 218.7808 - mean_squared_error: 218.7808\n",
      "Epoch 37/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 217.0517 - mean_squared_error: 217.0517\n",
      "Epoch 38/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 214.3915 - mean_squared_error: 214.3915\n",
      "Epoch 39/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 216.7897 - mean_squared_error: 216.7897\n",
      "Epoch 40/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 214.2091 - mean_squared_error: 214.2091\n",
      "Epoch 41/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 213.3491 - mean_squared_error: 213.3491\n",
      "Epoch 42/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 212.3951 - mean_squared_error: 212.3951\n",
      "Epoch 43/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 210.5366 - mean_squared_error: 210.5366\n",
      "Epoch 44/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 209.4177 - mean_squared_error: 209.4177\n",
      "Epoch 45/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 210.3323 - mean_squared_error: 210.3323\n",
      "Epoch 46/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 209.9931 - mean_squared_error: 209.9931\n",
      "Epoch 47/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 209.8084 - mean_squared_error: 209.8084\n",
      "Epoch 48/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 206.9986 - mean_squared_error: 206.9986\n",
      "Epoch 49/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 207.5773 - mean_squared_error: 207.5773\n",
      "Epoch 50/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 205.2714 - mean_squared_error: 205.2714\n",
      "Epoch 51/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 205.3599 - mean_squared_error: 205.3599\n",
      "Epoch 52/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 208.1471 - mean_squared_error: 208.1471\n",
      "Epoch 53/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 204.8476 - mean_squared_error: 204.8476\n",
      "Epoch 54/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 205.2038 - mean_squared_error: 205.2038\n",
      "Epoch 55/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 204.0267 - mean_squared_error: 204.0267\n",
      "Epoch 56/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 202.1466 - mean_squared_error: 202.1466\n",
      "Epoch 57/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 202.1565 - mean_squared_error: 202.1565\n",
      "Epoch 58/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 202.2125 - mean_squared_error: 202.2125\n",
      "Epoch 59/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 199.4440 - mean_squared_error: 199.4440\n",
      "Epoch 60/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 197.7926 - mean_squared_error: 197.7926\n",
      "Epoch 61/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 198.4794 - mean_squared_error: 198.4794\n",
      "Epoch 62/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 199.6713 - mean_squared_error: 199.6713\n",
      "Epoch 63/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 199.9777 - mean_squared_error: 199.9777\n",
      "Epoch 64/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 196.5100 - mean_squared_error: 196.5100\n",
      "Epoch 65/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 197.3579 - mean_squared_error: 197.3579\n",
      "Epoch 66/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 198.0707 - mean_squared_error: 198.0707\n",
      "Epoch 67/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 194.4205 - mean_squared_error: 194.4205\n",
      "Epoch 68/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 192.7623 - mean_squared_error: 192.7623\n",
      "Epoch 69/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 194.1156 - mean_squared_error: 194.1156\n",
      "Epoch 70/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 194.9231 - mean_squared_error: 194.9231\n",
      "Epoch 71/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 191.7629 - mean_squared_error: 191.7629\n",
      "Epoch 72/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 190.5036 - mean_squared_error: 190.5036\n",
      "Epoch 73/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 190.2695 - mean_squared_error: 190.2695\n",
      "Epoch 74/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 189.3467 - mean_squared_error: 189.3467\n",
      "Epoch 75/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 193.3527 - mean_squared_error: 193.3527\n",
      "Epoch 76/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 188.2544 - mean_squared_error: 188.2544\n",
      "Epoch 77/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 192.4139 - mean_squared_error: 192.4139\n",
      "Epoch 78/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 186.6599 - mean_squared_error: 186.6599\n",
      "Epoch 79/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 187.3793 - mean_squared_error: 187.3793\n",
      "Epoch 80/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 186.3658 - mean_squared_error: 186.3658\n",
      "Epoch 81/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 185.6980 - mean_squared_error: 185.6980\n",
      "Epoch 82/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 185.7658 - mean_squared_error: 185.7658\n",
      "Epoch 83/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 186.1623 - mean_squared_error: 186.1623\n",
      "Epoch 84/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 185.6783 - mean_squared_error: 185.6783\n",
      "Epoch 85/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 188.4243 - mean_squared_error: 188.4243\n",
      "Epoch 86/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 184.4515 - mean_squared_error: 184.4515\n",
      "Epoch 87/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 184.0810 - mean_squared_error: 184.0810\n",
      "Epoch 88/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 186.9258 - mean_squared_error: 186.9258\n",
      "Epoch 89/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 182.0665 - mean_squared_error: 182.0665\n",
      "Epoch 90/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 183.6023 - mean_squared_error: 183.6023\n",
      "Epoch 91/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 182.3753 - mean_squared_error: 182.3753\n",
      "Epoch 92/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 182.7080 - mean_squared_error: 182.7080\n",
      "Epoch 93/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 183.5645 - mean_squared_error: 183.5645\n",
      "Epoch 94/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 177.5733 - mean_squared_error: 177.5733\n",
      "Epoch 95/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 178.1358 - mean_squared_error: 178.1358\n",
      "Epoch 96/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 178.7110 - mean_squared_error: 178.7110\n",
      "Epoch 97/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 178.3384 - mean_squared_error: 178.3384\n",
      "Epoch 98/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 177.3221 - mean_squared_error: 177.3221\n",
      "Epoch 99/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 179.2515 - mean_squared_error: 179.2515\n",
      "Epoch 100/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 175.0256 - mean_squared_error: 175.0256\n",
      "3667/3667 [==============================] - 0s 14us/step\n",
      "100/100 [==============================] - 0s 17us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 936)               315432    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 937       \n",
      "=================================================================\n",
      "Total params: 316,369\n",
      "Trainable params: 316,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 9us/step - loss: 3835.1729 - mean_squared_error: 3835.1729\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 702.2134 - mean_squared_error: 702.2134\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 527.4480 - mean_squared_error: 527.4480\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 466.1137 - mean_squared_error: 466.1137\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 423.7361 - mean_squared_error: 423.7361\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 384.7564 - mean_squared_error: 384.7564\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 351.0951 - mean_squared_error: 351.0951\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 326.1146 - mean_squared_error: 326.1146\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 308.0034 - mean_squared_error: 308.0034\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 294.4841 - mean_squared_error: 294.4841\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 285.2030 - mean_squared_error: 285.2030\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 276.7080 - mean_squared_error: 276.7080\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 270.6375 - mean_squared_error: 270.6375\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 264.4186 - mean_squared_error: 264.4186\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 260.8811 - mean_squared_error: 260.8811\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 257.5590 - mean_squared_error: 257.5590\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 254.3569 - mean_squared_error: 254.3569\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 252.4695 - mean_squared_error: 252.4695\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 251.0349 - mean_squared_error: 251.0349\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 248.1632 - mean_squared_error: 248.1632\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 245.8266 - mean_squared_error: 245.8266\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 246.0727 - mean_squared_error: 246.0727\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 244.2549 - mean_squared_error: 244.2549\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 240.5519 - mean_squared_error: 240.5519\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 240.0775 - mean_squared_error: 240.0775\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.1316 - mean_squared_error: 238.1316\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 237.0993 - mean_squared_error: 237.0993\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.6712 - mean_squared_error: 234.6712\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.3356 - mean_squared_error: 233.3356\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.4666 - mean_squared_error: 232.4666\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.7709 - mean_squared_error: 230.7709\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.3680 - mean_squared_error: 230.3680\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.2454 - mean_squared_error: 229.2454\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.7209 - mean_squared_error: 225.7209\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.5857 - mean_squared_error: 224.5857\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.1921 - mean_squared_error: 229.1921\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.6674 - mean_squared_error: 223.6674\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.7645 - mean_squared_error: 221.7645\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.4796 - mean_squared_error: 223.4796\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.3280 - mean_squared_error: 221.3280\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.4509 - mean_squared_error: 218.4509\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.9387 - mean_squared_error: 218.9387\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.6323 - mean_squared_error: 220.6323\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.5092 - mean_squared_error: 216.5092\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.5433 - mean_squared_error: 215.5433\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.8314 - mean_squared_error: 213.8314\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.3076 - mean_squared_error: 215.3076\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.4696 - mean_squared_error: 214.4696\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.3189 - mean_squared_error: 212.3189\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.8261 - mean_squared_error: 215.8261\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.3937 - mean_squared_error: 214.3937\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.6266 - mean_squared_error: 211.6266\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.5154 - mean_squared_error: 209.5154\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.3666 - mean_squared_error: 208.3666\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.6771 - mean_squared_error: 206.6771\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.1068 - mean_squared_error: 208.1068\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.3251 - mean_squared_error: 205.3251\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.2477 - mean_squared_error: 204.2477\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.5788 - mean_squared_error: 204.5788\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.0988 - mean_squared_error: 205.0988\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.2575 - mean_squared_error: 203.2575\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.1105 - mean_squared_error: 208.1105\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.3129 - mean_squared_error: 204.3129\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.7856 - mean_squared_error: 204.7856\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.5747 - mean_squared_error: 200.5747\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.3931 - mean_squared_error: 200.3931\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.1565 - mean_squared_error: 199.1565\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.1106 - mean_squared_error: 199.1106\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.7556 - mean_squared_error: 198.7556\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.1682 - mean_squared_error: 199.1682\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.6155 - mean_squared_error: 202.6155\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.2707 - mean_squared_error: 196.2707\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.5648 - mean_squared_error: 195.5648\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.8074 - mean_squared_error: 195.8074\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.0245 - mean_squared_error: 197.0245\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.6361 - mean_squared_error: 197.6361\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.7706 - mean_squared_error: 195.7706\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.4341 - mean_squared_error: 192.4341\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.5861 - mean_squared_error: 193.5861\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.2093 - mean_squared_error: 193.2093\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.6502 - mean_squared_error: 192.6502\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.2690 - mean_squared_error: 190.2690\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.0065 - mean_squared_error: 192.0065\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.7778 - mean_squared_error: 188.7778\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.4660 - mean_squared_error: 195.4660\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.8589 - mean_squared_error: 187.8589\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.7121 - mean_squared_error: 190.7121\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.7939 - mean_squared_error: 188.7939\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.0761 - mean_squared_error: 187.0761\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.1717 - mean_squared_error: 186.1717\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.4701 - mean_squared_error: 188.4701\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.8179 - mean_squared_error: 184.8179\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.1440 - mean_squared_error: 185.1440\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.0095 - mean_squared_error: 187.0095\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.6569 - mean_squared_error: 183.6569\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.1978 - mean_squared_error: 182.1978\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.2162 - mean_squared_error: 186.2162\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.9332 - mean_squared_error: 181.9332\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.1545 - mean_squared_error: 183.1545\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.9369 - mean_squared_error: 179.9369\n",
      "3666/3666 [==============================] - 0s 14us/step\n",
      "100/100 [==============================] - 0s 19us/step\n",
      "\n",
      "Experiment on Fold  2\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 936)               315432    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 937       \n",
      "=================================================================\n",
      "Total params: 316,369\n",
      "Trainable params: 316,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 9us/step - loss: 3936.8172 - mean_squared_error: 3936.8172\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 700.3667 - mean_squared_error: 700.3667\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 524.2293 - mean_squared_error: 524.2293\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 460.9981 - mean_squared_error: 460.9981\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 413.8659 - mean_squared_error: 413.8659\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 373.5415 - mean_squared_error: 373.5415\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 342.1177 - mean_squared_error: 342.1177\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 318.4060 - mean_squared_error: 318.4060\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 302.1411 - mean_squared_error: 302.1411\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 289.5719 - mean_squared_error: 289.5719\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 279.9004 - mean_squared_error: 279.9004\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 272.1921 - mean_squared_error: 272.1921\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 266.6600 - mean_squared_error: 266.6600\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 262.5099 - mean_squared_error: 262.5099\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 257.9146 - mean_squared_error: 257.9146\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 254.5618 - mean_squared_error: 254.5618\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 251.0900 - mean_squared_error: 251.0900\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 250.0521 - mean_squared_error: 250.0521\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 246.9262 - mean_squared_error: 246.9262\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 244.8494 - mean_squared_error: 244.8494\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 243.4028 - mean_squared_error: 243.4028\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 243.0931 - mean_squared_error: 243.0931\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 240.8154 - mean_squared_error: 240.8154\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 239.6528 - mean_squared_error: 239.6528\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.1212 - mean_squared_error: 238.1212\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.7080 - mean_squared_error: 236.7080\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.9442 - mean_squared_error: 234.9442\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.7786 - mean_squared_error: 233.7786\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.4329 - mean_squared_error: 232.4329\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.5674 - mean_squared_error: 230.5674\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.5465 - mean_squared_error: 228.5465\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.2944 - mean_squared_error: 227.2944\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.9946 - mean_squared_error: 226.9946\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.9666 - mean_squared_error: 224.9666\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.9364 - mean_squared_error: 223.9364\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.1702 - mean_squared_error: 226.1702\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.7626 - mean_squared_error: 220.7626\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.3266 - mean_squared_error: 221.3266\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.0422 - mean_squared_error: 219.0422\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.2655 - mean_squared_error: 217.2655\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.7063 - mean_squared_error: 217.7063\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.1152 - mean_squared_error: 219.1152\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.6598 - mean_squared_error: 214.6598\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.8226 - mean_squared_error: 214.8226\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.3805 - mean_squared_error: 213.3805\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.3960 - mean_squared_error: 213.3960\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.9992 - mean_squared_error: 210.9992\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.7304 - mean_squared_error: 209.7304\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.8954 - mean_squared_error: 209.8954\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.4335 - mean_squared_error: 209.4335\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.4651 - mean_squared_error: 208.4651\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.0852 - mean_squared_error: 209.0852\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.0330 - mean_squared_error: 206.0330\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.0261 - mean_squared_error: 206.0261\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.6740 - mean_squared_error: 204.6740\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.9233 - mean_squared_error: 205.9233\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.9663 - mean_squared_error: 202.9663\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.1981 - mean_squared_error: 204.1981\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.6585 - mean_squared_error: 205.6585\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.6585 - mean_squared_error: 201.6585\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.6293 - mean_squared_error: 200.6293\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.0729 - mean_squared_error: 203.0729\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.8769 - mean_squared_error: 199.8769\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.3397 - mean_squared_error: 198.3397\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.9033 - mean_squared_error: 199.9033\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.1517 - mean_squared_error: 200.1517\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.6853 - mean_squared_error: 197.6853\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.0174 - mean_squared_error: 196.0174\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.7314 - mean_squared_error: 199.7314\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.8616 - mean_squared_error: 195.8616\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.5539 - mean_squared_error: 195.5539\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.1580 - mean_squared_error: 196.1580\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.9726 - mean_squared_error: 192.9726\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.7709 - mean_squared_error: 192.7709\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.4046 - mean_squared_error: 191.4046\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.1551 - mean_squared_error: 192.1551\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.5940 - mean_squared_error: 190.5940\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.9445 - mean_squared_error: 189.9445\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.9717 - mean_squared_error: 191.9717\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.8770 - mean_squared_error: 191.8770\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.0239 - mean_squared_error: 187.0239\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.9162 - mean_squared_error: 190.9162\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.5101 - mean_squared_error: 191.5101\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.4990 - mean_squared_error: 185.4990\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.1161 - mean_squared_error: 189.1161\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.4531 - mean_squared_error: 188.4531\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.7984 - mean_squared_error: 188.7984\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.7934 - mean_squared_error: 184.7934\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.3603 - mean_squared_error: 182.3603\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.9367 - mean_squared_error: 183.9367\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.8560 - mean_squared_error: 186.8560\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.8974 - mean_squared_error: 182.8974\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.7331 - mean_squared_error: 182.7331\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.0850 - mean_squared_error: 184.0850\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.3763 - mean_squared_error: 179.3763\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.4976 - mean_squared_error: 180.4976\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.8156 - mean_squared_error: 178.8156\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.5755 - mean_squared_error: 182.5755\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.5134 - mean_squared_error: 177.5134\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.3755 - mean_squared_error: 179.3755\n",
      "3666/3666 [==============================] - 0s 14us/step\n",
      "100/100 [==============================] - 0s 20us/step\n",
      "\n",
      "Experiment on Fold  3\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 936)               315432    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 937       \n",
      "=================================================================\n",
      "Total params: 316,369\n",
      "Trainable params: 316,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 9us/step - loss: 3931.9848 - mean_squared_error: 3931.9848\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 696.6911 - mean_squared_error: 696.6911\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 526.4848 - mean_squared_error: 526.4848\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 462.6569 - mean_squared_error: 462.6569\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 420.3638 - mean_squared_error: 420.3638\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 382.4822 - mean_squared_error: 382.4822\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 346.7814 - mean_squared_error: 346.7814\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 322.6441 - mean_squared_error: 322.6441\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 302.6163 - mean_squared_error: 302.6163\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 290.7690 - mean_squared_error: 290.7690\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 279.7912 - mean_squared_error: 279.7912\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 271.9007 - mean_squared_error: 271.9007\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 264.7725 - mean_squared_error: 264.7725\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 259.9143 - mean_squared_error: 259.9143\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 254.2992 - mean_squared_error: 254.2992\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 253.0449 - mean_squared_error: 253.0449\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 248.8629 - mean_squared_error: 248.8629\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 246.2366 - mean_squared_error: 246.2366\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 243.3891 - mean_squared_error: 243.3891\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 244.5769 - mean_squared_error: 244.5769\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 239.6548 - mean_squared_error: 239.6548\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.2897 - mean_squared_error: 238.2897\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 237.1247 - mean_squared_error: 237.1247\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 235.3817 - mean_squared_error: 235.3817\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.4765 - mean_squared_error: 233.4765\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.1283 - mean_squared_error: 234.1283\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.3843 - mean_squared_error: 230.3843\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.0150 - mean_squared_error: 229.0150\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.4413 - mean_squared_error: 228.4413\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.1782 - mean_squared_error: 226.1782\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.8371 - mean_squared_error: 225.8371\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.8678 - mean_squared_error: 222.8678\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.3201 - mean_squared_error: 223.3201\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.2345 - mean_squared_error: 221.2345\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.5515 - mean_squared_error: 218.5515\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.8962 - mean_squared_error: 221.8962\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.3517 - mean_squared_error: 218.3517\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.5332 - mean_squared_error: 215.5332\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.5843 - mean_squared_error: 215.5843\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.4674 - mean_squared_error: 215.4674\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.3473 - mean_squared_error: 216.3473\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.2470 - mean_squared_error: 212.2470\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.2023 - mean_squared_error: 214.2023\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.4348 - mean_squared_error: 210.4348\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.1712 - mean_squared_error: 212.1712\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.3515 - mean_squared_error: 209.3515\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.9805 - mean_squared_error: 206.9805\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.6948 - mean_squared_error: 208.6948\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.8588 - mean_squared_error: 209.8588\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.4719 - mean_squared_error: 207.4719\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.4277 - mean_squared_error: 205.4277\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.3267 - mean_squared_error: 207.3267\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.7443 - mean_squared_error: 204.7443\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.9986 - mean_squared_error: 202.9986\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.7742 - mean_squared_error: 202.7742\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.9454 - mean_squared_error: 202.9454\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.5123 - mean_squared_error: 200.5123\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.0318 - mean_squared_error: 201.0318\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.6826 - mean_squared_error: 200.6826\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.4700 - mean_squared_error: 198.4700\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.2597 - mean_squared_error: 199.2597\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.2567 - mean_squared_error: 197.2567\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.9466 - mean_squared_error: 197.9466\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.6142 - mean_squared_error: 198.6142\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.4805 - mean_squared_error: 197.4805\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.2522 - mean_squared_error: 197.2522\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.4321 - mean_squared_error: 192.4321\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.3172 - mean_squared_error: 194.3172\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.7512 - mean_squared_error: 194.7512\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.8164 - mean_squared_error: 196.8164\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.8413 - mean_squared_error: 191.8413\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.3694 - mean_squared_error: 190.3694\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.6518 - mean_squared_error: 194.6518\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.3376 - mean_squared_error: 193.3376\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.3521 - mean_squared_error: 193.3521\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.7227 - mean_squared_error: 189.7227\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.7081 - mean_squared_error: 187.7081\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.5110 - mean_squared_error: 189.5110\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.9099 - mean_squared_error: 190.9099\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.7015 - mean_squared_error: 185.7015\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.1125 - mean_squared_error: 187.1125\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.6121 - mean_squared_error: 184.6121\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.6359 - mean_squared_error: 186.6359\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.6503 - mean_squared_error: 184.6503\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.1458 - mean_squared_error: 184.1458\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.2152 - mean_squared_error: 181.2152\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.4023 - mean_squared_error: 182.4023\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.4352 - mean_squared_error: 180.4352\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.5088 - mean_squared_error: 181.5088\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.6676 - mean_squared_error: 179.6676\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.7093 - mean_squared_error: 179.7093\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.9393 - mean_squared_error: 177.9393\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.6311 - mean_squared_error: 180.6311\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.9150 - mean_squared_error: 175.9150\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.1236 - mean_squared_error: 178.1236\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.6402 - mean_squared_error: 175.6402\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.1514 - mean_squared_error: 180.1514\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.0109 - mean_squared_error: 173.0109\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.5658 - mean_squared_error: 172.5658\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.6624 - mean_squared_error: 173.6624\n",
      "3666/3666 [==============================] - 0s 14us/step\n",
      "100/100 [==============================] - 0s 18us/step\n",
      "\n",
      "Experiment on Fold  4\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 936)               315432    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 937       \n",
      "=================================================================\n",
      "Total params: 316,369\n",
      "Trainable params: 316,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 9us/step - loss: 3890.7427 - mean_squared_error: 3890.7427\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 693.5261 - mean_squared_error: 693.5261\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 520.1100 - mean_squared_error: 520.1100\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 455.9586 - mean_squared_error: 455.9586\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 407.6835 - mean_squared_error: 407.6835\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 366.9276 - mean_squared_error: 366.9276\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 337.1470 - mean_squared_error: 337.1470\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 313.8531 - mean_squared_error: 313.8531\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 299.2123 - mean_squared_error: 299.2123\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 289.0060 - mean_squared_error: 289.0060\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 280.8526 - mean_squared_error: 280.8526\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 273.3033 - mean_squared_error: 273.3033\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 267.8972 - mean_squared_error: 267.8972\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 262.5733 - mean_squared_error: 262.5733\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 260.0837 - mean_squared_error: 260.0837\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 257.6429 - mean_squared_error: 257.6429\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 253.4916 - mean_squared_error: 253.4916\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 250.5711 - mean_squared_error: 250.5711\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 249.2323 - mean_squared_error: 249.2323\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 248.2484 - mean_squared_error: 248.2484\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 245.4252 - mean_squared_error: 245.4252\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 244.7327 - mean_squared_error: 244.7327\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.0858 - mean_squared_error: 242.0858\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 241.8330 - mean_squared_error: 241.8330\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 239.7345 - mean_squared_error: 239.7345\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.5538 - mean_squared_error: 238.5538\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.6184 - mean_squared_error: 238.6184\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.4020 - mean_squared_error: 234.4020\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.4844 - mean_squared_error: 234.4844\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.7013 - mean_squared_error: 232.7013\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.4759 - mean_squared_error: 232.4759\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.4474 - mean_squared_error: 229.4474\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.7554 - mean_squared_error: 230.7554\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.6546 - mean_squared_error: 231.6546\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.4084 - mean_squared_error: 227.4084\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.3991 - mean_squared_error: 225.3991\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.5183 - mean_squared_error: 224.5183\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.4613 - mean_squared_error: 223.4613\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.9581 - mean_squared_error: 221.9581\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.1271 - mean_squared_error: 221.1271\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.7981 - mean_squared_error: 221.7981\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.2620 - mean_squared_error: 220.2620\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.6803 - mean_squared_error: 217.6803\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.4269 - mean_squared_error: 217.4269\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.4027 - mean_squared_error: 217.4027\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.0050 - mean_squared_error: 216.0050\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.7719 - mean_squared_error: 213.7719\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.8397 - mean_squared_error: 213.8397\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.8684 - mean_squared_error: 212.8684\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.3914 - mean_squared_error: 211.3914\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.9309 - mean_squared_error: 211.9309\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.3068 - mean_squared_error: 209.3068\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.6321 - mean_squared_error: 210.6321\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.4426 - mean_squared_error: 211.4426\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.1822 - mean_squared_error: 208.1822\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.6356 - mean_squared_error: 208.6356\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.1179 - mean_squared_error: 207.1179\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.2271 - mean_squared_error: 205.2271\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.7830 - mean_squared_error: 203.7830\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.1222 - mean_squared_error: 205.1222\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.3166 - mean_squared_error: 204.3166\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.7133 - mean_squared_error: 202.7133\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.9545 - mean_squared_error: 201.9545\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.1993 - mean_squared_error: 203.1993\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.6920 - mean_squared_error: 200.6920\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.3267 - mean_squared_error: 199.3267\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.3852 - mean_squared_error: 201.3852\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.7699 - mean_squared_error: 197.7699\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.3890 - mean_squared_error: 196.3890\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.6753 - mean_squared_error: 197.6753\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.3944 - mean_squared_error: 197.3944\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.5108 - mean_squared_error: 196.5108\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.2100 - mean_squared_error: 195.2100\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.3607 - mean_squared_error: 194.3607\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.4833 - mean_squared_error: 192.4833\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.9179 - mean_squared_error: 193.9179\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.5574 - mean_squared_error: 191.5574\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.1577 - mean_squared_error: 200.1577\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.4656 - mean_squared_error: 192.4656\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.1324 - mean_squared_error: 192.1324\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.6435 - mean_squared_error: 190.6435\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.9790 - mean_squared_error: 188.9790\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.2532 - mean_squared_error: 189.2532\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.6986 - mean_squared_error: 187.6986\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.8297 - mean_squared_error: 186.8297\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.8503 - mean_squared_error: 189.8503\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.9657 - mean_squared_error: 185.9657\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.8438 - mean_squared_error: 185.8438\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.5770 - mean_squared_error: 184.5770\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.9837 - mean_squared_error: 182.9837\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.1751 - mean_squared_error: 182.1751\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.0644 - mean_squared_error: 182.0644\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.3837 - mean_squared_error: 180.3837\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.2146 - mean_squared_error: 182.2146\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.0896 - mean_squared_error: 181.0896\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.1613 - mean_squared_error: 179.1613\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.7781 - mean_squared_error: 177.7781\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.1481 - mean_squared_error: 181.1481\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.0926 - mean_squared_error: 176.0926\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.6077 - mean_squared_error: 177.6077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3666/3666 [==============================] - 0s 14us/step\n",
      "100/100 [==============================] - 0s 19us/step\n",
      "Testing for yulin/alpha0.6/bestModel_global.json\n",
      "Loading data for dataset 1 with window_size of 24, stride of 1 and maxRUL of 129. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(18331, 336)\n",
      "(18331, 1)\n",
      "Testing data (X, y)\n",
      "(100, 336)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.63253012 -0.18639634 -0.38048616 ... -0.33333333  0.33333333\n",
      "   0.31289699]\n",
      " [-0.43373494 -0.09396119 -0.29473329 ... -0.16666667  0.25581395\n",
      "   0.47638774]\n",
      " [-0.31325301 -0.26095487 -0.25894666 ...  0.          0.11627907\n",
      "   0.43800055]\n",
      " [-0.31325301 -0.48768258 -0.33760972 ... -0.16666667  0.31782946\n",
      "   0.52720243]\n",
      " [-0.30120482 -0.48506649 -0.19074949 ... -0.66666667  0.34883721\n",
      "   0.07677437]]\n",
      "[[129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]]\n",
      "Testing data (X, y)\n",
      "[[-0.19879518 -0.5705254  -0.37069548 ... -0.16666667  0.03875969\n",
      "   0.27312897]\n",
      " [-0.21686747 -0.30237628 -0.12086428 ... -0.5         0.03875969\n",
      "   0.01518917]\n",
      " [-0.04216867 -0.1942446  -0.0209318  ...  0.16666667  0.2248062\n",
      "   0.04888152]\n",
      " [-0.22891566 -0.01722259 -0.13673194 ...  0.16666667 -0.31782946\n",
      "   0.004971  ]\n",
      " [-0.11445783 -0.11968607  0.03511141 ...  0.         -0.05426357\n",
      "   0.42916321]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n",
      "Validation on model:best_models/cmapss/yulin/alpha0.6/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 184)               62008     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 184)               34040     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 185       \n",
      "=================================================================\n",
      "Total params: 96,233\n",
      "Trainable params: 96,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14664/14664 [==============================] - 0s 10us/step - loss: 4141.7093 - mean_squared_error: 4141.7093\n",
      "Epoch 2/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 568.1798 - mean_squared_error: 568.1798\n",
      "Epoch 3/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 429.1160 - mean_squared_error: 429.1160\n",
      "Epoch 4/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 339.4507 - mean_squared_error: 339.4507\n",
      "Epoch 5/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 292.5733 - mean_squared_error: 292.5733\n",
      "Epoch 6/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 270.3442 - mean_squared_error: 270.3442\n",
      "Epoch 7/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 257.0613 - mean_squared_error: 257.0613\n",
      "Epoch 8/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 247.7386 - mean_squared_error: 247.7386\n",
      "Epoch 9/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 242.3382 - mean_squared_error: 242.3382\n",
      "Epoch 10/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 246.1202 - mean_squared_error: 246.1202\n",
      "Epoch 11/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 239.6905 - mean_squared_error: 239.6905\n",
      "Epoch 12/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 237.8983 - mean_squared_error: 237.8983\n",
      "Epoch 13/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 235.8144 - mean_squared_error: 235.8144\n",
      "Epoch 14/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 234.5996 - mean_squared_error: 234.5996\n",
      "Epoch 15/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 231.4636 - mean_squared_error: 231.4636\n",
      "Epoch 16/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 233.9192 - mean_squared_error: 233.9192\n",
      "Epoch 17/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 230.7948 - mean_squared_error: 230.7948\n",
      "Epoch 18/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 230.8292 - mean_squared_error: 230.8292\n",
      "Epoch 19/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 233.0314 - mean_squared_error: 233.0314\n",
      "Epoch 20/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 227.3287 - mean_squared_error: 227.3287\n",
      "Epoch 21/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 229.4198 - mean_squared_error: 229.4198\n",
      "Epoch 22/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 222.5412 - mean_squared_error: 222.5412\n",
      "Epoch 23/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 224.2819 - mean_squared_error: 224.2819\n",
      "Epoch 24/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 228.7217 - mean_squared_error: 228.7217\n",
      "Epoch 25/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 223.1247 - mean_squared_error: 223.1247\n",
      "Epoch 26/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 223.1503 - mean_squared_error: 223.1503\n",
      "Epoch 27/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 223.9677 - mean_squared_error: 223.9677\n",
      "Epoch 28/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 222.5370 - mean_squared_error: 222.5370\n",
      "Epoch 29/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 219.2522 - mean_squared_error: 219.2522\n",
      "Epoch 30/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 216.6303 - mean_squared_error: 216.6303\n",
      "Epoch 31/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 212.6754 - mean_squared_error: 212.6754\n",
      "Epoch 32/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 221.1235 - mean_squared_error: 221.1235\n",
      "Epoch 33/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 210.0360 - mean_squared_error: 210.0360\n",
      "Epoch 34/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 210.2199 - mean_squared_error: 210.2199\n",
      "Epoch 35/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 211.4744 - mean_squared_error: 211.4744\n",
      "Epoch 36/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 207.6366 - mean_squared_error: 207.6366\n",
      "Epoch 37/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 205.9669 - mean_squared_error: 205.9669\n",
      "Epoch 38/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 204.5482 - mean_squared_error: 204.5482\n",
      "Epoch 39/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 207.7775 - mean_squared_error: 207.7775\n",
      "Epoch 40/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 207.8997 - mean_squared_error: 207.8997\n",
      "Epoch 41/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 209.8771 - mean_squared_error: 209.8771\n",
      "Epoch 42/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 200.6117 - mean_squared_error: 200.6117\n",
      "Epoch 43/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 209.8967 - mean_squared_error: 209.8967\n",
      "Epoch 44/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 196.5859 - mean_squared_error: 196.5859\n",
      "Epoch 45/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 196.1930 - mean_squared_error: 196.1930\n",
      "Epoch 46/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 197.1504 - mean_squared_error: 197.1504\n",
      "Epoch 47/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 195.5248 - mean_squared_error: 195.5248\n",
      "Epoch 48/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 207.2629 - mean_squared_error: 207.2629\n",
      "Epoch 49/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 200.2029 - mean_squared_error: 200.2029\n",
      "Epoch 50/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 188.2568 - mean_squared_error: 188.2568\n",
      "Epoch 51/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 187.5091 - mean_squared_error: 187.5091\n",
      "Epoch 52/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 191.3694 - mean_squared_error: 191.3694\n",
      "Epoch 53/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 190.5082 - mean_squared_error: 190.5082\n",
      "Epoch 54/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 186.6535 - mean_squared_error: 186.6535\n",
      "Epoch 55/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 185.1842 - mean_squared_error: 185.1842\n",
      "Epoch 56/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 182.7529 - mean_squared_error: 182.7529\n",
      "Epoch 57/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 181.2963 - mean_squared_error: 181.2963\n",
      "Epoch 58/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 185.9929 - mean_squared_error: 185.9929\n",
      "Epoch 59/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 193.0708 - mean_squared_error: 193.0708\n",
      "Epoch 60/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 176.7587 - mean_squared_error: 176.7587\n",
      "Epoch 61/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 190.1795 - mean_squared_error: 190.1795\n",
      "Epoch 62/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 175.8327 - mean_squared_error: 175.8327\n",
      "Epoch 63/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 183.5841 - mean_squared_error: 183.5841\n",
      "Epoch 64/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 181.7186 - mean_squared_error: 181.7186\n",
      "Epoch 65/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 185.9365 - mean_squared_error: 185.9365\n",
      "Epoch 66/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 174.5603 - mean_squared_error: 174.5603\n",
      "Epoch 67/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 178.8427 - mean_squared_error: 178.8427\n",
      "Epoch 68/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 180.5105 - mean_squared_error: 180.5105\n",
      "Epoch 69/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 169.2142 - mean_squared_error: 169.2142\n",
      "Epoch 70/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 173.9676 - mean_squared_error: 173.9676\n",
      "Epoch 71/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 169.5853 - mean_squared_error: 169.5853\n",
      "Epoch 72/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 171.4353 - mean_squared_error: 171.4353\n",
      "Epoch 73/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 172.2234 - mean_squared_error: 172.2234\n",
      "Epoch 74/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 168.7635 - mean_squared_error: 168.7635\n",
      "Epoch 75/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 171.7245 - mean_squared_error: 171.7245\n",
      "Epoch 76/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 167.3499 - mean_squared_error: 167.3499\n",
      "Epoch 77/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 160.8598 - mean_squared_error: 160.8598\n",
      "Epoch 78/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 169.7110 - mean_squared_error: 169.7110\n",
      "Epoch 79/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 165.2465 - mean_squared_error: 165.2465\n",
      "Epoch 80/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 165.7345 - mean_squared_error: 165.7345\n",
      "Epoch 81/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 165.6018 - mean_squared_error: 165.6018\n",
      "Epoch 82/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 168.6514 - mean_squared_error: 168.6514\n",
      "Epoch 83/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 160.6550 - mean_squared_error: 160.6550\n",
      "Epoch 84/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 166.0128 - mean_squared_error: 166.0128\n",
      "Epoch 85/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 161.4004 - mean_squared_error: 161.4004\n",
      "Epoch 86/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 159.8882 - mean_squared_error: 159.8882\n",
      "Epoch 87/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 157.9218 - mean_squared_error: 157.9218\n",
      "Epoch 88/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 157.3743 - mean_squared_error: 157.3743\n",
      "Epoch 89/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 163.8759 - mean_squared_error: 163.8759\n",
      "Epoch 90/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 153.3109 - mean_squared_error: 153.3109\n",
      "Epoch 91/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 164.1268 - mean_squared_error: 164.1268\n",
      "Epoch 92/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 152.1388 - mean_squared_error: 152.1388\n",
      "Epoch 93/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 154.4952 - mean_squared_error: 154.4952\n",
      "Epoch 94/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 151.3891 - mean_squared_error: 151.3891\n",
      "Epoch 95/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 150.4265 - mean_squared_error: 150.4265\n",
      "Epoch 96/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 155.3608 - mean_squared_error: 155.3608\n",
      "Epoch 97/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 148.5741 - mean_squared_error: 148.5741\n",
      "Epoch 98/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 149.7648 - mean_squared_error: 149.7648\n",
      "Epoch 99/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 149.9846 - mean_squared_error: 149.9846\n",
      "Epoch 100/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 161.7304 - mean_squared_error: 161.7304\n",
      "3667/3667 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 19us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 184)               62008     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 184)               34040     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 185       \n",
      "=================================================================\n",
      "Total params: 96,233\n",
      "Trainable params: 96,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 11us/step - loss: 4064.2177 - mean_squared_error: 4064.2177\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 557.1756 - mean_squared_error: 557.1756\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 415.6785 - mean_squared_error: 415.6785\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 323.4551 - mean_squared_error: 323.4551\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 280.6176 - mean_squared_error: 280.6176\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 261.3348 - mean_squared_error: 261.3348\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 249.9910 - mean_squared_error: 249.9910\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.5200 - mean_squared_error: 242.5200\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.5024 - mean_squared_error: 238.5024\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.9344 - mean_squared_error: 233.9344\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.0236 - mean_squared_error: 233.0236\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.5714 - mean_squared_error: 231.5714\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.8222 - mean_squared_error: 229.8222\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.2554 - mean_squared_error: 227.2554\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.0753 - mean_squared_error: 228.0753\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.8507 - mean_squared_error: 227.8507\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.3317 - mean_squared_error: 226.3317\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.1181 - mean_squared_error: 225.1181\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.6524 - mean_squared_error: 222.6524\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.9205 - mean_squared_error: 221.9205\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.1027 - mean_squared_error: 218.1027\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.3165 - mean_squared_error: 218.3165\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.7195 - mean_squared_error: 219.7195\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.4868 - mean_squared_error: 217.4868\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.4780 - mean_squared_error: 217.4780\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.2421 - mean_squared_error: 216.2421\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.8649 - mean_squared_error: 213.8649\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.1567 - mean_squared_error: 213.1567\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.7964 - mean_squared_error: 209.7964\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.9497 - mean_squared_error: 207.9497\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.5461 - mean_squared_error: 208.5461\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.1961 - mean_squared_error: 207.1961\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.8921 - mean_squared_error: 204.8921\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.4581 - mean_squared_error: 206.4581\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.2785 - mean_squared_error: 202.2785\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.7508 - mean_squared_error: 205.7508\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.2015 - mean_squared_error: 203.2015\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.9984 - mean_squared_error: 204.9984\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.1032 - mean_squared_error: 203.1032\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.9725 - mean_squared_error: 202.9725\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.7096 - mean_squared_error: 197.7096\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.2608 - mean_squared_error: 202.2608\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.1209 - mean_squared_error: 198.1209\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.6200 - mean_squared_error: 198.6200\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.6993 - mean_squared_error: 199.6993\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.6045 - mean_squared_error: 197.6045\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.8024 - mean_squared_error: 194.8024\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.5907 - mean_squared_error: 195.5907\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.3199 - mean_squared_error: 196.3199\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.8847 - mean_squared_error: 188.8847\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.2891 - mean_squared_error: 187.2891\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.0206 - mean_squared_error: 190.0206\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.3628 - mean_squared_error: 186.3628\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.7138 - mean_squared_error: 187.7138\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.0328 - mean_squared_error: 182.0328\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.9579 - mean_squared_error: 189.9579\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.4266 - mean_squared_error: 197.4266\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.5411 - mean_squared_error: 179.5411\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.0564 - mean_squared_error: 187.0564\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.4330 - mean_squared_error: 184.4330\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.0116 - mean_squared_error: 186.0116\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.6332 - mean_squared_error: 178.6332\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.6441 - mean_squared_error: 175.6441\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.1637 - mean_squared_error: 181.1637\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.3609 - mean_squared_error: 173.3609\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.0739 - mean_squared_error: 176.0739\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.1578 - mean_squared_error: 179.1578\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.8081 - mean_squared_error: 176.8081\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.0577 - mean_squared_error: 177.0577\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.0108 - mean_squared_error: 169.0108\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.8017 - mean_squared_error: 177.8017\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.4059 - mean_squared_error: 174.4059\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.4548 - mean_squared_error: 165.4548\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.8811 - mean_squared_error: 164.8811\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 167.9147 - mean_squared_error: 167.9147\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.0803 - mean_squared_error: 170.0803\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.1079 - mean_squared_error: 166.1079\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.4409 - mean_squared_error: 166.4409\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.6265 - mean_squared_error: 166.6265\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.8982 - mean_squared_error: 164.8982\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.5911 - mean_squared_error: 170.5911\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.8005 - mean_squared_error: 162.8005\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.9467 - mean_squared_error: 160.9467\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.7337 - mean_squared_error: 156.7337\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.8687 - mean_squared_error: 170.8687\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.3852 - mean_squared_error: 159.3852\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 151.9494 - mean_squared_error: 151.9494\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.7168 - mean_squared_error: 156.7168\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 153.3548 - mean_squared_error: 153.3548\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 152.1730 - mean_squared_error: 152.1730\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.2003 - mean_squared_error: 156.2003\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 148.9520 - mean_squared_error: 148.9520\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 144.6980 - mean_squared_error: 144.6980\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.4007 - mean_squared_error: 154.4007\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 150.6273 - mean_squared_error: 150.6273\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 148.3352 - mean_squared_error: 148.3352\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 153.1267 - mean_squared_error: 153.1267\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.4963 - mean_squared_error: 154.4963\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 139.9833 - mean_squared_error: 139.9833\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 138.9101 - mean_squared_error: 138.9101\n",
      "3666/3666 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 19us/step\n",
      "\n",
      "Experiment on Fold  2\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 184)               62008     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 184)               34040     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 185       \n",
      "=================================================================\n",
      "Total params: 96,233\n",
      "Trainable params: 96,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 10us/step - loss: 3614.3229 - mean_squared_error: 3614.3229\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 532.8861 - mean_squared_error: 532.8861\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 391.1059 - mean_squared_error: 391.1059\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 312.1350 - mean_squared_error: 312.1350\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 278.0625 - mean_squared_error: 278.0625\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 263.3926 - mean_squared_error: 263.3926\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 251.4717 - mean_squared_error: 251.4717\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 247.2528 - mean_squared_error: 247.2528\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 241.4934 - mean_squared_error: 241.4934\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 239.1933 - mean_squared_error: 239.1933\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.7141 - mean_squared_error: 233.7141\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.5002 - mean_squared_error: 231.5002\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.6703 - mean_squared_error: 231.6703\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.3518 - mean_squared_error: 230.3518\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.6316 - mean_squared_error: 229.6316\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.2453 - mean_squared_error: 227.2453\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.7828 - mean_squared_error: 228.7828\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.9629 - mean_squared_error: 228.9629\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.9554 - mean_squared_error: 225.9554\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.2330 - mean_squared_error: 222.2330\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.0031 - mean_squared_error: 227.0031\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.9017 - mean_squared_error: 223.9017\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.9239 - mean_squared_error: 218.9239\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.8641 - mean_squared_error: 223.8641\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.2970 - mean_squared_error: 220.2970\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.1518 - mean_squared_error: 220.1518\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.6996 - mean_squared_error: 216.6996\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.7605 - mean_squared_error: 216.7605\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.3150 - mean_squared_error: 217.3150\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.4089 - mean_squared_error: 214.4089\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.5487 - mean_squared_error: 211.5487\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.0216 - mean_squared_error: 212.0216\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.4306 - mean_squared_error: 213.4306\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.4355 - mean_squared_error: 208.4355\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.6907 - mean_squared_error: 205.6907\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.5543 - mean_squared_error: 209.5543\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.2961 - mean_squared_error: 206.2961\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.5764 - mean_squared_error: 204.5764\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.7173 - mean_squared_error: 203.7173\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.8788 - mean_squared_error: 199.8788\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.1149 - mean_squared_error: 205.1149\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.3913 - mean_squared_error: 202.3913\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.5748 - mean_squared_error: 199.5748\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.9513 - mean_squared_error: 202.9513\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.8496 - mean_squared_error: 196.8496\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.2010 - mean_squared_error: 197.2010\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.2847 - mean_squared_error: 196.2847\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.9785 - mean_squared_error: 191.9785\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.6990 - mean_squared_error: 192.6990\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.0450 - mean_squared_error: 190.0450\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.5942 - mean_squared_error: 189.5942\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.1057 - mean_squared_error: 186.1057\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.1676 - mean_squared_error: 190.1676\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.9663 - mean_squared_error: 184.9663\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.6923 - mean_squared_error: 185.6923\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.4465 - mean_squared_error: 188.4465\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.5848 - mean_squared_error: 186.5848\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.9462 - mean_squared_error: 181.9462\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.6556 - mean_squared_error: 177.6556\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.0511 - mean_squared_error: 183.0511\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.3382 - mean_squared_error: 183.3382\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.3841 - mean_squared_error: 183.3841\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.8185 - mean_squared_error: 176.8185\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.5587 - mean_squared_error: 184.5587\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.8534 - mean_squared_error: 173.8534\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.6363 - mean_squared_error: 177.6363\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.1542 - mean_squared_error: 179.1542\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.0125 - mean_squared_error: 170.0125\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.0971 - mean_squared_error: 170.0971\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.2315 - mean_squared_error: 170.2315\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.7797 - mean_squared_error: 171.7797\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.8292 - mean_squared_error: 173.8292\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.4519 - mean_squared_error: 171.4519\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.5685 - mean_squared_error: 170.5685\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.1671 - mean_squared_error: 166.1671\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.6454 - mean_squared_error: 165.6454\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.5699 - mean_squared_error: 172.5699\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.1896 - mean_squared_error: 174.1896\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.8906 - mean_squared_error: 164.8906\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.2524 - mean_squared_error: 162.2524\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.8959 - mean_squared_error: 164.8959\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 163.8943 - mean_squared_error: 163.8943\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.7647 - mean_squared_error: 157.7647\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.1080 - mean_squared_error: 158.1080\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 153.9355 - mean_squared_error: 153.9355\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.4362 - mean_squared_error: 154.4362\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.9219 - mean_squared_error: 166.9219\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 155.6522 - mean_squared_error: 155.6522\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.3415 - mean_squared_error: 154.3415\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.2882 - mean_squared_error: 158.2882\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.9819 - mean_squared_error: 157.9819\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.8684 - mean_squared_error: 154.8684\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 149.2168 - mean_squared_error: 149.2168\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.9684 - mean_squared_error: 154.9684\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.8270 - mean_squared_error: 158.8270\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 147.6522 - mean_squared_error: 147.6522\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 149.5116 - mean_squared_error: 149.5116\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 148.2635 - mean_squared_error: 148.2635\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 145.5754 - mean_squared_error: 145.5754\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 147.4427 - mean_squared_error: 147.4427\n",
      "3666/3666 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 20us/step\n",
      "\n",
      "Experiment on Fold  3\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 184)               62008     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 184)               34040     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 185       \n",
      "=================================================================\n",
      "Total params: 96,233\n",
      "Trainable params: 96,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 10us/step - loss: 4018.9876 - mean_squared_error: 4018.9876\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 550.2483 - mean_squared_error: 550.2483\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 417.4692 - mean_squared_error: 417.4692\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 334.3995 - mean_squared_error: 334.3995\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 289.3375 - mean_squared_error: 289.3375\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 269.3569 - mean_squared_error: 269.3569\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 255.8951 - mean_squared_error: 255.8951\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 246.2282 - mean_squared_error: 246.2282\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 240.5474 - mean_squared_error: 240.5474\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.6232 - mean_squared_error: 236.6232\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.9194 - mean_squared_error: 234.9194\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.2675 - mean_squared_error: 233.2675\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.4392 - mean_squared_error: 231.4392\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.4132 - mean_squared_error: 229.4132\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.9720 - mean_squared_error: 227.9720\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.6837 - mean_squared_error: 226.6837\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.9576 - mean_squared_error: 221.9576\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.9431 - mean_squared_error: 225.9431\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.1428 - mean_squared_error: 219.1428\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.8786 - mean_squared_error: 218.8786\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.6952 - mean_squared_error: 223.6952\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.4263 - mean_squared_error: 225.4263\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.8783 - mean_squared_error: 214.8783\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.9368 - mean_squared_error: 217.9368\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.2685 - mean_squared_error: 214.2685\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.4882 - mean_squared_error: 212.4882\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.3006 - mean_squared_error: 226.3006\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.5829 - mean_squared_error: 209.5829\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.4689 - mean_squared_error: 213.4689\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.8318 - mean_squared_error: 213.8318\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.3805 - mean_squared_error: 208.3805\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.7813 - mean_squared_error: 207.7813\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.0533 - mean_squared_error: 207.0533\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.8213 - mean_squared_error: 205.8213\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.3376 - mean_squared_error: 200.3376\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.6068 - mean_squared_error: 200.6068\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.2414 - mean_squared_error: 201.2414\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.7444 - mean_squared_error: 199.7444\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.5387 - mean_squared_error: 209.5387\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.2504 - mean_squared_error: 200.2504\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.1047 - mean_squared_error: 198.1047\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.1625 - mean_squared_error: 200.1625\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.3893 - mean_squared_error: 194.3893\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.3644 - mean_squared_error: 194.3644\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.7045 - mean_squared_error: 194.7045\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.7737 - mean_squared_error: 198.7737\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.1139 - mean_squared_error: 192.1139\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.7003 - mean_squared_error: 197.7003\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.7008 - mean_squared_error: 193.7008\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.0486 - mean_squared_error: 188.0486\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.3776 - mean_squared_error: 192.3776\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.1547 - mean_squared_error: 192.1547\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.2076 - mean_squared_error: 188.2076\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.1745 - mean_squared_error: 192.1745\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.9914 - mean_squared_error: 181.9914\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.2619 - mean_squared_error: 195.2619\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.5722 - mean_squared_error: 190.5722\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.7978 - mean_squared_error: 185.7978\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.3429 - mean_squared_error: 179.3429\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.0124 - mean_squared_error: 183.0124\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.0947 - mean_squared_error: 184.0947\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.3479 - mean_squared_error: 176.3479\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.8119 - mean_squared_error: 170.8119\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.7316 - mean_squared_error: 199.7316\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.7065 - mean_squared_error: 175.7065\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.5348 - mean_squared_error: 169.5348\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.6098 - mean_squared_error: 178.6098\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.5239 - mean_squared_error: 169.5239\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.8792 - mean_squared_error: 170.8792\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.1266 - mean_squared_error: 172.1266\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.8211 - mean_squared_error: 171.8211\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.7153 - mean_squared_error: 175.7153\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.5062 - mean_squared_error: 168.5062\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.3992 - mean_squared_error: 169.3992\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.8690 - mean_squared_error: 173.8690\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.2680 - mean_squared_error: 171.2680\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 163.2982 - mean_squared_error: 163.2982\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.7492 - mean_squared_error: 169.7492\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.5071 - mean_squared_error: 166.5071\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.0240 - mean_squared_error: 165.0240\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.6012 - mean_squared_error: 160.6012\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.8234 - mean_squared_error: 157.8234\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 163.9002 - mean_squared_error: 163.9002\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 161.2362 - mean_squared_error: 161.2362\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.1154 - mean_squared_error: 160.1154\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.1034 - mean_squared_error: 162.1034\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 167.4979 - mean_squared_error: 167.4979\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 153.3204 - mean_squared_error: 153.3204\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 151.3754 - mean_squared_error: 151.3754\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.2573 - mean_squared_error: 157.2573\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.6171 - mean_squared_error: 154.6171\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 152.7162 - mean_squared_error: 152.7162\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 149.2402 - mean_squared_error: 149.2402\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 146.2579 - mean_squared_error: 146.2579\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 153.8874 - mean_squared_error: 153.8874\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 155.2370 - mean_squared_error: 155.2370\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 153.3352 - mean_squared_error: 153.3352\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 151.3951 - mean_squared_error: 151.3951\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 145.8134 - mean_squared_error: 145.8134\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 147.9934 - mean_squared_error: 147.9934\n",
      "3666/3666 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 18us/step\n",
      "\n",
      "Experiment on Fold  4\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 184)               62008     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 184)               34040     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 185       \n",
      "=================================================================\n",
      "Total params: 96,233\n",
      "Trainable params: 96,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 11us/step - loss: 4111.2002 - mean_squared_error: 4111.2002\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 562.5941 - mean_squared_error: 562.5941\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 427.1971 - mean_squared_error: 427.1971\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 336.1642 - mean_squared_error: 336.1642\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 289.7720 - mean_squared_error: 289.7720\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 265.9629 - mean_squared_error: 265.9629\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 255.4711 - mean_squared_error: 255.4711\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 245.1633 - mean_squared_error: 245.1633\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 241.7134 - mean_squared_error: 241.7134\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.5706 - mean_squared_error: 236.5706\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.3501 - mean_squared_error: 236.3501\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.8534 - mean_squared_error: 234.8534\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.4765 - mean_squared_error: 233.4765\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 237.8251 - mean_squared_error: 237.8251\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.7911 - mean_squared_error: 230.7911\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.9658 - mean_squared_error: 229.9658\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.0415 - mean_squared_error: 227.0415\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.4278 - mean_squared_error: 230.4278\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.5197 - mean_squared_error: 228.5197\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.1095 - mean_squared_error: 224.1095\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.1382 - mean_squared_error: 226.1382\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.7748 - mean_squared_error: 220.7748\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.9300 - mean_squared_error: 222.9300\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.7294 - mean_squared_error: 221.7294\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.9182 - mean_squared_error: 218.9182\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.4704 - mean_squared_error: 220.4704\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.4113 - mean_squared_error: 218.4113\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.6533 - mean_squared_error: 216.6533\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.0460 - mean_squared_error: 212.0460\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.2604 - mean_squared_error: 218.2604\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.6585 - mean_squared_error: 213.6585\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.2410 - mean_squared_error: 208.2410\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.4037 - mean_squared_error: 213.4037\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.2009 - mean_squared_error: 210.2009\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.9384 - mean_squared_error: 201.9384\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.9459 - mean_squared_error: 207.9459\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.0700 - mean_squared_error: 202.0700\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.6984 - mean_squared_error: 201.6984\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.6572 - mean_squared_error: 201.6572\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.8471 - mean_squared_error: 203.8471\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.6504 - mean_squared_error: 199.6504\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.3214 - mean_squared_error: 201.3214\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.2215 - mean_squared_error: 195.2215\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.2075 - mean_squared_error: 196.2075\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.5251 - mean_squared_error: 196.5251\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.3547 - mean_squared_error: 192.3547\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.8609 - mean_squared_error: 188.8609\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.3848 - mean_squared_error: 191.3848\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.0695 - mean_squared_error: 190.0695\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.3352 - mean_squared_error: 187.3352\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.8449 - mean_squared_error: 185.8449\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.1018 - mean_squared_error: 180.1018\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.7760 - mean_squared_error: 179.7760\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.7103 - mean_squared_error: 180.7103\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.8618 - mean_squared_error: 187.8618\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.1568 - mean_squared_error: 185.1568\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.5643 - mean_squared_error: 177.5643\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.0057 - mean_squared_error: 178.0057\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.7548 - mean_squared_error: 181.7548\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.1870 - mean_squared_error: 175.1870\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.6142 - mean_squared_error: 173.6142\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.8434 - mean_squared_error: 174.8434\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.9333 - mean_squared_error: 168.9333\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.7426 - mean_squared_error: 168.7426\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.2190 - mean_squared_error: 171.2190\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.9317 - mean_squared_error: 164.9317\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.5689 - mean_squared_error: 169.5689\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.9453 - mean_squared_error: 178.9453\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 163.7150 - mean_squared_error: 163.7150\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 161.7665 - mean_squared_error: 161.7665\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.2187 - mean_squared_error: 164.2187\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.7792 - mean_squared_error: 165.7792\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.5157 - mean_squared_error: 159.5157\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 167.0946 - mean_squared_error: 167.0946\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.8832 - mean_squared_error: 157.8832\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.4151 - mean_squared_error: 156.4151\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 151.8221 - mean_squared_error: 151.8221\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.4159 - mean_squared_error: 157.4159\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.0272 - mean_squared_error: 162.0272\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.5528 - mean_squared_error: 154.5528\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 153.5589 - mean_squared_error: 153.5589\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 148.7840 - mean_squared_error: 148.7840\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 155.7568 - mean_squared_error: 155.7568\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.6028 - mean_squared_error: 154.6028\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.9475 - mean_squared_error: 160.9475\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 141.3408 - mean_squared_error: 141.3408\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 151.3324 - mean_squared_error: 151.3324\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 143.3914 - mean_squared_error: 143.3914\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 146.5794 - mean_squared_error: 146.5794\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 146.4230 - mean_squared_error: 146.4230\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 143.0511 - mean_squared_error: 143.0511\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 143.5304 - mean_squared_error: 143.5304\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 137.1293 - mean_squared_error: 137.1293\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 135.4052 - mean_squared_error: 135.4052\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 145.7227 - mean_squared_error: 145.7227\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 133.3606 - mean_squared_error: 133.3606\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 141.6478 - mean_squared_error: 141.6478\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 131.5395 - mean_squared_error: 131.5395\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 142.4040 - mean_squared_error: 142.4040\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 129.4635 - mean_squared_error: 129.4635\n",
      "3666/3666 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 24us/step\n",
      "Testing for yulin/alpha0.7/bestModel_global.json\n",
      "Loading data for dataset 1 with window_size of 24, stride of 1 and maxRUL of 129. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(18331, 336)\n",
      "(18331, 1)\n",
      "Testing data (X, y)\n",
      "(100, 336)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.63253012 -0.18639634 -0.38048616 ... -0.33333333  0.33333333\n",
      "   0.31289699]\n",
      " [-0.43373494 -0.09396119 -0.29473329 ... -0.16666667  0.25581395\n",
      "   0.47638774]\n",
      " [-0.31325301 -0.26095487 -0.25894666 ...  0.          0.11627907\n",
      "   0.43800055]\n",
      " [-0.31325301 -0.48768258 -0.33760972 ... -0.16666667  0.31782946\n",
      "   0.52720243]\n",
      " [-0.30120482 -0.48506649 -0.19074949 ... -0.66666667  0.34883721\n",
      "   0.07677437]]\n",
      "[[129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]]\n",
      "Testing data (X, y)\n",
      "[[-0.19879518 -0.5705254  -0.37069548 ... -0.16666667  0.03875969\n",
      "   0.27312897]\n",
      " [-0.21686747 -0.30237628 -0.12086428 ... -0.5         0.03875969\n",
      "   0.01518917]\n",
      " [-0.04216867 -0.1942446  -0.0209318  ...  0.16666667  0.2248062\n",
      "   0.04888152]\n",
      " [-0.22891566 -0.01722259 -0.13673194 ...  0.16666667 -0.31782946\n",
      "   0.004971  ]\n",
      " [-0.11445783 -0.11968607  0.03511141 ...  0.         -0.05426357\n",
      "   0.42916321]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n",
      "Validation on model:best_models/cmapss/yulin/alpha0.7/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 104)               35048     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 104)               10920     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 105       \n",
      "=================================================================\n",
      "Total params: 46,073\n",
      "Trainable params: 46,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14664/14664 [==============================] - 0s 10us/step - loss: 5336.0718 - mean_squared_error: 5336.0718\n",
      "Epoch 2/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 654.4483 - mean_squared_error: 654.4483\n",
      "Epoch 3/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 509.8706 - mean_squared_error: 509.8706\n",
      "Epoch 4/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 429.6300 - mean_squared_error: 429.6300\n",
      "Epoch 5/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 359.2261 - mean_squared_error: 359.2261\n",
      "Epoch 6/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 309.6388 - mean_squared_error: 309.6388\n",
      "Epoch 7/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 283.1947 - mean_squared_error: 283.1947\n",
      "Epoch 8/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 269.0584 - mean_squared_error: 269.0584\n",
      "Epoch 9/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 256.6497 - mean_squared_error: 256.6497\n",
      "Epoch 10/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 247.5032 - mean_squared_error: 247.5032\n",
      "Epoch 11/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 241.5103 - mean_squared_error: 241.5103\n",
      "Epoch 12/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 238.5764 - mean_squared_error: 238.5764\n",
      "Epoch 13/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 236.0992 - mean_squared_error: 236.0992\n",
      "Epoch 14/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 231.6570 - mean_squared_error: 231.6570\n",
      "Epoch 15/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 229.5687 - mean_squared_error: 229.5687\n",
      "Epoch 16/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 228.2302 - mean_squared_error: 228.2302\n",
      "Epoch 17/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 226.9862 - mean_squared_error: 226.9862\n",
      "Epoch 18/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 224.8711 - mean_squared_error: 224.8711\n",
      "Epoch 19/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 225.4219 - mean_squared_error: 225.4219\n",
      "Epoch 20/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 223.7039 - mean_squared_error: 223.7039\n",
      "Epoch 21/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 225.0318 - mean_squared_error: 225.0318\n",
      "Epoch 22/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 221.7409 - mean_squared_error: 221.7409\n",
      "Epoch 23/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 220.8277 - mean_squared_error: 220.8277\n",
      "Epoch 24/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 220.0769 - mean_squared_error: 220.0769\n",
      "Epoch 25/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 219.3121 - mean_squared_error: 219.3121\n",
      "Epoch 26/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 218.2999 - mean_squared_error: 218.2999\n",
      "Epoch 27/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 217.0067 - mean_squared_error: 217.0067\n",
      "Epoch 28/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 217.9801 - mean_squared_error: 217.9801\n",
      "Epoch 29/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 215.7156 - mean_squared_error: 215.7156\n",
      "Epoch 30/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 216.6052 - mean_squared_error: 216.6052\n",
      "Epoch 31/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 212.3608 - mean_squared_error: 212.3608\n",
      "Epoch 32/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 212.4621 - mean_squared_error: 212.4621\n",
      "Epoch 33/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 211.9043 - mean_squared_error: 211.9043\n",
      "Epoch 34/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 211.3652 - mean_squared_error: 211.3652\n",
      "Epoch 35/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 209.0261 - mean_squared_error: 209.0261\n",
      "Epoch 36/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 206.9299 - mean_squared_error: 206.9299\n",
      "Epoch 37/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 211.3853 - mean_squared_error: 211.3853\n",
      "Epoch 38/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 208.0165 - mean_squared_error: 208.0165\n",
      "Epoch 39/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 204.3037 - mean_squared_error: 204.3037\n",
      "Epoch 40/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 207.0363 - mean_squared_error: 207.0363\n",
      "Epoch 41/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 205.2280 - mean_squared_error: 205.2280\n",
      "Epoch 42/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 200.7612 - mean_squared_error: 200.7612\n",
      "Epoch 43/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 203.2395 - mean_squared_error: 203.2395\n",
      "Epoch 44/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 202.0497 - mean_squared_error: 202.0497\n",
      "Epoch 45/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 197.6855 - mean_squared_error: 197.6855\n",
      "Epoch 46/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 198.5696 - mean_squared_error: 198.5696\n",
      "Epoch 47/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 198.4535 - mean_squared_error: 198.4535\n",
      "Epoch 48/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 195.4878 - mean_squared_error: 195.4878\n",
      "Epoch 49/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 193.7976 - mean_squared_error: 193.7976\n",
      "Epoch 50/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 196.6835 - mean_squared_error: 196.6835\n",
      "Epoch 51/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 196.8426 - mean_squared_error: 196.8426\n",
      "Epoch 52/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 194.0930 - mean_squared_error: 194.0930\n",
      "Epoch 53/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 194.6457 - mean_squared_error: 194.6457\n",
      "Epoch 54/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 188.8507 - mean_squared_error: 188.8507\n",
      "Epoch 55/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 192.7023 - mean_squared_error: 192.7023\n",
      "Epoch 56/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 188.6944 - mean_squared_error: 188.6944\n",
      "Epoch 57/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 191.0145 - mean_squared_error: 191.0145\n",
      "Epoch 58/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 186.1345 - mean_squared_error: 186.1345\n",
      "Epoch 59/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 192.2013 - mean_squared_error: 192.2013\n",
      "Epoch 60/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 184.5583 - mean_squared_error: 184.5583\n",
      "Epoch 61/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 183.7378 - mean_squared_error: 183.7378\n",
      "Epoch 62/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 185.9856 - mean_squared_error: 185.9856\n",
      "Epoch 63/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 181.0964 - mean_squared_error: 181.0964\n",
      "Epoch 64/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 180.9410 - mean_squared_error: 180.9410\n",
      "Epoch 65/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 181.8370 - mean_squared_error: 181.8370\n",
      "Epoch 66/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 181.1219 - mean_squared_error: 181.1219\n",
      "Epoch 67/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 180.2997 - mean_squared_error: 180.2997\n",
      "Epoch 68/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 176.6945 - mean_squared_error: 176.6945\n",
      "Epoch 69/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 176.2913 - mean_squared_error: 176.2913\n",
      "Epoch 70/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 176.6151 - mean_squared_error: 176.6151\n",
      "Epoch 71/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 178.3000 - mean_squared_error: 178.3000\n",
      "Epoch 72/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 175.6484 - mean_squared_error: 175.6484\n",
      "Epoch 73/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 174.3593 - mean_squared_error: 174.3593\n",
      "Epoch 74/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 168.8234 - mean_squared_error: 168.8234\n",
      "Epoch 75/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 172.0285 - mean_squared_error: 172.0285\n",
      "Epoch 76/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 170.0390 - mean_squared_error: 170.0390\n",
      "Epoch 77/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 171.8244 - mean_squared_error: 171.8244\n",
      "Epoch 78/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 171.3827 - mean_squared_error: 171.3827\n",
      "Epoch 79/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 171.1392 - mean_squared_error: 171.1392\n",
      "Epoch 80/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 170.3875 - mean_squared_error: 170.3875\n",
      "Epoch 81/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 166.8144 - mean_squared_error: 166.8144\n",
      "Epoch 82/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 164.3256 - mean_squared_error: 164.3256\n",
      "Epoch 83/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 167.5478 - mean_squared_error: 167.5478\n",
      "Epoch 84/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 165.4421 - mean_squared_error: 165.4421\n",
      "Epoch 85/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 161.6707 - mean_squared_error: 161.6707\n",
      "Epoch 86/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 169.7721 - mean_squared_error: 169.7721\n",
      "Epoch 87/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 165.4588 - mean_squared_error: 165.4588\n",
      "Epoch 88/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 161.7178 - mean_squared_error: 161.7178\n",
      "Epoch 89/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 156.4395 - mean_squared_error: 156.4395\n",
      "Epoch 90/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 161.1070 - mean_squared_error: 161.1070\n",
      "Epoch 91/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 156.1301 - mean_squared_error: 156.1301\n",
      "Epoch 92/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 156.2634 - mean_squared_error: 156.2634\n",
      "Epoch 93/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 159.6438 - mean_squared_error: 159.6438\n",
      "Epoch 94/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 158.9263 - mean_squared_error: 158.9263\n",
      "Epoch 95/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 155.2882 - mean_squared_error: 155.2882\n",
      "Epoch 96/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 157.9359 - mean_squared_error: 157.9359\n",
      "Epoch 97/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 153.7116 - mean_squared_error: 153.7116\n",
      "Epoch 98/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 155.1185 - mean_squared_error: 155.1185\n",
      "Epoch 99/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 156.0311 - mean_squared_error: 156.0311\n",
      "Epoch 100/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 154.8872 - mean_squared_error: 154.8872\n",
      "3667/3667 [==============================] - 0s 16us/step\n",
      "100/100 [==============================] - 0s 21us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 104)               35048     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 104)               10920     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 105       \n",
      "=================================================================\n",
      "Total params: 46,073\n",
      "Trainable params: 46,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 10us/step - loss: 5632.4028 - mean_squared_error: 5632.4028\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 723.9605 - mean_squared_error: 723.9605\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 557.3381 - mean_squared_error: 557.3381\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 448.3915 - mean_squared_error: 448.3915\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 362.7967 - mean_squared_error: 362.7967\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 303.1629 - mean_squared_error: 303.1629\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 274.4209 - mean_squared_error: 274.4209\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 260.8246 - mean_squared_error: 260.8246\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 250.2002 - mean_squared_error: 250.2002\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 245.8836 - mean_squared_error: 245.8836\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 240.7665 - mean_squared_error: 240.7665\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.1121 - mean_squared_error: 236.1121\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.7522 - mean_squared_error: 234.7522\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.1848 - mean_squared_error: 231.1848\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.1463 - mean_squared_error: 229.1463\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.7352 - mean_squared_error: 228.7352\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.5555 - mean_squared_error: 226.5555\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.6752 - mean_squared_error: 226.6752\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.7741 - mean_squared_error: 225.7741\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.8169 - mean_squared_error: 222.8169\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.7500 - mean_squared_error: 224.7500\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.1124 - mean_squared_error: 222.1124\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.0579 - mean_squared_error: 223.0579\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.4839 - mean_squared_error: 219.4839\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.0353 - mean_squared_error: 221.0353\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.7523 - mean_squared_error: 218.7523\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.8768 - mean_squared_error: 217.8768\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.8084 - mean_squared_error: 218.8084\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.1448 - mean_squared_error: 217.1448\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.1342 - mean_squared_error: 216.1342\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.9934 - mean_squared_error: 217.9934\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.1534 - mean_squared_error: 216.1534\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.9519 - mean_squared_error: 212.9519\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.8553 - mean_squared_error: 212.8553\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.2196 - mean_squared_error: 216.2196\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.6528 - mean_squared_error: 210.6528\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.8894 - mean_squared_error: 211.8894\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.4531 - mean_squared_error: 212.4531\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.3542 - mean_squared_error: 209.3542\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.0477 - mean_squared_error: 212.0477\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.7534 - mean_squared_error: 207.7534\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.0881 - mean_squared_error: 207.0881\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.5534 - mean_squared_error: 207.5534\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.6909 - mean_squared_error: 206.6909\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.9951 - mean_squared_error: 204.9951\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.6108 - mean_squared_error: 204.6108\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.5093 - mean_squared_error: 203.5093\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.3002 - mean_squared_error: 202.3002\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.1313 - mean_squared_error: 200.1313\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.3370 - mean_squared_error: 201.3370\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.6484 - mean_squared_error: 197.6484\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.7365 - mean_squared_error: 200.7365\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.5780 - mean_squared_error: 194.5780\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.7078 - mean_squared_error: 192.7078\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.0184 - mean_squared_error: 192.0184\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.0824 - mean_squared_error: 194.0824\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.2580 - mean_squared_error: 193.2580\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.7152 - mean_squared_error: 190.7152\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.2397 - mean_squared_error: 195.2397\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.4075 - mean_squared_error: 191.4075\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.4442 - mean_squared_error: 192.4442\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.1176 - mean_squared_error: 191.1176\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.5855 - mean_squared_error: 190.5855\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.1244 - mean_squared_error: 184.1244\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.6768 - mean_squared_error: 184.6768\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.5295 - mean_squared_error: 187.5295\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.0188 - mean_squared_error: 185.0188\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.2598 - mean_squared_error: 187.2598\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.6104 - mean_squared_error: 182.6104\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.4176 - mean_squared_error: 184.4176\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.0972 - mean_squared_error: 181.0972\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.1009 - mean_squared_error: 184.1009\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.5911 - mean_squared_error: 184.5911\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.5438 - mean_squared_error: 182.5438\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.6327 - mean_squared_error: 181.6327\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.8459 - mean_squared_error: 177.8459\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.3170 - mean_squared_error: 176.3170\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.1938 - mean_squared_error: 181.1938\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.7563 - mean_squared_error: 175.7563\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.6405 - mean_squared_error: 174.6405\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.4142 - mean_squared_error: 171.4142\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.1205 - mean_squared_error: 173.1205\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.4830 - mean_squared_error: 173.4830\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.9409 - mean_squared_error: 173.9409\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.0033 - mean_squared_error: 174.0033\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.3935 - mean_squared_error: 169.3935\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.2947 - mean_squared_error: 175.2947\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.1766 - mean_squared_error: 172.1766\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.4563 - mean_squared_error: 168.4563\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.9861 - mean_squared_error: 166.9861\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.3120 - mean_squared_error: 166.3120\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.3740 - mean_squared_error: 169.3740\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.5002 - mean_squared_error: 164.5002\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.4582 - mean_squared_error: 169.4582\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 167.1748 - mean_squared_error: 167.1748\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 163.9312 - mean_squared_error: 163.9312\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.5880 - mean_squared_error: 165.5880\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.4056 - mean_squared_error: 162.4056\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.5152 - mean_squared_error: 159.5152\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.5989 - mean_squared_error: 164.5989\n",
      "3666/3666 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 21us/step\n",
      "\n",
      "Experiment on Fold  2\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 104)               35048     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 104)               10920     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 105       \n",
      "=================================================================\n",
      "Total params: 46,073\n",
      "Trainable params: 46,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 10us/step - loss: 5009.0531 - mean_squared_error: 5009.0531\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 653.7368 - mean_squared_error: 653.7368\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 491.0286 - mean_squared_error: 491.0286\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 393.4232 - mean_squared_error: 393.4232\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 321.3078 - mean_squared_error: 321.3078\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 287.4790 - mean_squared_error: 287.4790\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 270.3100 - mean_squared_error: 270.3100\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 256.5624 - mean_squared_error: 256.5624\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 251.3026 - mean_squared_error: 251.3026\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 244.1749 - mean_squared_error: 244.1749\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.4905 - mean_squared_error: 242.4905\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 240.2585 - mean_squared_error: 240.2585\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 237.9011 - mean_squared_error: 237.9011\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 235.8867 - mean_squared_error: 235.8867\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 235.8735 - mean_squared_error: 235.8735\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.6558 - mean_squared_error: 231.6558\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.0276 - mean_squared_error: 231.0276\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.7315 - mean_squared_error: 228.7315\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.8971 - mean_squared_error: 227.8971\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.8702 - mean_squared_error: 226.8702\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.1493 - mean_squared_error: 225.1493\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.8766 - mean_squared_error: 224.8766\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.2327 - mean_squared_error: 224.2327\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.0569 - mean_squared_error: 222.0569\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.6132 - mean_squared_error: 221.6132\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.1356 - mean_squared_error: 221.1356\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.4298 - mean_squared_error: 218.4298\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.4944 - mean_squared_error: 219.4944\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.0841 - mean_squared_error: 218.0841\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.8559 - mean_squared_error: 217.8559\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.6332 - mean_squared_error: 216.6332\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.3750 - mean_squared_error: 219.3750\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.6681 - mean_squared_error: 216.6681\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.4081 - mean_squared_error: 211.4081\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.2172 - mean_squared_error: 214.2172\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.7573 - mean_squared_error: 209.7573\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.5421 - mean_squared_error: 214.5421\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.1909 - mean_squared_error: 209.1909\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.4868 - mean_squared_error: 210.4868\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.8047 - mean_squared_error: 207.8047\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.0269 - mean_squared_error: 207.0269\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.1673 - mean_squared_error: 207.1673\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.4726 - mean_squared_error: 204.4726\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.7177 - mean_squared_error: 205.7177\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.6987 - mean_squared_error: 204.6987\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.2054 - mean_squared_error: 204.2054\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.0278 - mean_squared_error: 208.0278\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.0247 - mean_squared_error: 205.0247\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.5411 - mean_squared_error: 204.5411\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.9943 - mean_squared_error: 199.9943\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.6559 - mean_squared_error: 200.6559\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.8073 - mean_squared_error: 196.8073\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.2260 - mean_squared_error: 198.2260\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.1398 - mean_squared_error: 195.1398\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.4333 - mean_squared_error: 195.4333\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.8970 - mean_squared_error: 196.8970\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.0207 - mean_squared_error: 193.0207\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.8699 - mean_squared_error: 198.8699\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.7067 - mean_squared_error: 188.7067\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.9874 - mean_squared_error: 199.9874\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.8394 - mean_squared_error: 200.8394\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.3943 - mean_squared_error: 187.3943\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.0724 - mean_squared_error: 186.0724\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.7940 - mean_squared_error: 185.7940\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.6927 - mean_squared_error: 184.6927\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.3838 - mean_squared_error: 186.3838\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.0390 - mean_squared_error: 185.0390\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.9108 - mean_squared_error: 179.9108\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.5921 - mean_squared_error: 180.5921\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.0727 - mean_squared_error: 183.0727\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.9973 - mean_squared_error: 177.9973\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.6262 - mean_squared_error: 180.6262\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.9873 - mean_squared_error: 173.9873\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.3936 - mean_squared_error: 184.3936\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.4052 - mean_squared_error: 173.4052\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.0958 - mean_squared_error: 169.0958\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.4891 - mean_squared_error: 177.4891\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.1209 - mean_squared_error: 170.1209\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.0430 - mean_squared_error: 169.0430\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.8559 - mean_squared_error: 176.8559\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.4817 - mean_squared_error: 168.4817\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 167.1525 - mean_squared_error: 167.1525\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.8389 - mean_squared_error: 166.8389\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.0508 - mean_squared_error: 162.0508\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.3388 - mean_squared_error: 162.3388\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.6900 - mean_squared_error: 159.6900\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.3514 - mean_squared_error: 160.3514\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 161.6490 - mean_squared_error: 161.6490\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.7567 - mean_squared_error: 165.7567\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.4565 - mean_squared_error: 158.4565\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.5130 - mean_squared_error: 154.5130\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.7664 - mean_squared_error: 154.7664\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 153.5218 - mean_squared_error: 153.5218\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 152.1163 - mean_squared_error: 152.1163\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.0324 - mean_squared_error: 159.0324\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 153.2976 - mean_squared_error: 153.2976\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.5625 - mean_squared_error: 154.5625\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 148.9715 - mean_squared_error: 148.9715\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.7856 - mean_squared_error: 157.7856\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 149.6362 - mean_squared_error: 149.6362\n",
      "3666/3666 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 18us/step\n",
      "\n",
      "Experiment on Fold  3\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 104)               35048     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 104)               10920     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 105       \n",
      "=================================================================\n",
      "Total params: 46,073\n",
      "Trainable params: 46,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 10us/step - loss: 5003.1530 - mean_squared_error: 5003.1530\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 667.9706 - mean_squared_error: 667.9706\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 517.1137 - mean_squared_error: 517.1137\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 423.7726 - mean_squared_error: 423.7726\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 351.6843 - mean_squared_error: 351.6843\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 301.3850 - mean_squared_error: 301.3850\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 276.8910 - mean_squared_error: 276.8910\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 266.4294 - mean_squared_error: 266.4294\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 254.5931 - mean_squared_error: 254.5931\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 249.4691 - mean_squared_error: 249.4691\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.5815 - mean_squared_error: 242.5815\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.3864 - mean_squared_error: 238.3864\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.2347 - mean_squared_error: 238.2347\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.9185 - mean_squared_error: 232.9185\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.7864 - mean_squared_error: 231.7864\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.1801 - mean_squared_error: 228.1801\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.1574 - mean_squared_error: 228.1574\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.7075 - mean_squared_error: 225.7075\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.9519 - mean_squared_error: 224.9519\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.5920 - mean_squared_error: 227.5920\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.2382 - mean_squared_error: 222.2382\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.1708 - mean_squared_error: 222.1708\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.6304 - mean_squared_error: 222.6304\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.2371 - mean_squared_error: 222.2371\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.3807 - mean_squared_error: 221.3807\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.7562 - mean_squared_error: 217.7562\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.5283 - mean_squared_error: 217.5283\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.4626 - mean_squared_error: 216.4626\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.3794 - mean_squared_error: 218.3794\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.0473 - mean_squared_error: 216.0473\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.5831 - mean_squared_error: 213.5831\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.5880 - mean_squared_error: 215.5880\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.0805 - mean_squared_error: 213.0805\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.3890 - mean_squared_error: 213.3890\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.3306 - mean_squared_error: 212.3306\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.6368 - mean_squared_error: 209.6368\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.7501 - mean_squared_error: 209.7501\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.2982 - mean_squared_error: 209.2982\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.9452 - mean_squared_error: 206.9452\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.8783 - mean_squared_error: 205.8783\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.3763 - mean_squared_error: 209.3763\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.0771 - mean_squared_error: 206.0771\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.0233 - mean_squared_error: 207.0233\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.9408 - mean_squared_error: 203.9408\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.1091 - mean_squared_error: 204.1091\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.4162 - mean_squared_error: 206.4162\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.9960 - mean_squared_error: 202.9960\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.5678 - mean_squared_error: 202.5678\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.7669 - mean_squared_error: 201.7669\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.8650 - mean_squared_error: 200.8650\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.5763 - mean_squared_error: 200.5763\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.0089 - mean_squared_error: 202.0089\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.9274 - mean_squared_error: 200.9274\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.2797 - mean_squared_error: 200.2797\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.1474 - mean_squared_error: 197.1474\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.7849 - mean_squared_error: 199.7849\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.9559 - mean_squared_error: 197.9559\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.0740 - mean_squared_error: 198.0740\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.5770 - mean_squared_error: 194.5770\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.3521 - mean_squared_error: 195.3521\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.4758 - mean_squared_error: 189.4758\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.8996 - mean_squared_error: 191.8996\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.3992 - mean_squared_error: 191.3992\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.3607 - mean_squared_error: 191.3607\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.5331 - mean_squared_error: 197.5331\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.9046 - mean_squared_error: 185.9046\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.6984 - mean_squared_error: 188.6984\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.9753 - mean_squared_error: 188.9753\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.1028 - mean_squared_error: 192.1028\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.9334 - mean_squared_error: 186.9334\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.4666 - mean_squared_error: 189.4666\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.3924 - mean_squared_error: 183.3924\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.1223 - mean_squared_error: 182.1223\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.4555 - mean_squared_error: 182.4555\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.0182 - mean_squared_error: 181.0182\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.6928 - mean_squared_error: 183.6928\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.3103 - mean_squared_error: 184.3103\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.7511 - mean_squared_error: 182.7511\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.7613 - mean_squared_error: 178.7613\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.4301 - mean_squared_error: 179.4301\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.8604 - mean_squared_error: 178.8604\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.7874 - mean_squared_error: 178.7874\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.8239 - mean_squared_error: 175.8239\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.5638 - mean_squared_error: 176.5638\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.3578 - mean_squared_error: 178.3578\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.9315 - mean_squared_error: 169.9315\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.8081 - mean_squared_error: 178.8081\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.3892 - mean_squared_error: 170.3892\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.4623 - mean_squared_error: 173.4623\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.4541 - mean_squared_error: 169.4541\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.7473 - mean_squared_error: 168.7473\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.6625 - mean_squared_error: 165.6625\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.6674 - mean_squared_error: 166.6674\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.0700 - mean_squared_error: 166.0700\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.2185 - mean_squared_error: 165.2185\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.4780 - mean_squared_error: 164.4780\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.6782 - mean_squared_error: 162.6782\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 163.7426 - mean_squared_error: 163.7426\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.4926 - mean_squared_error: 158.4926\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.8646 - mean_squared_error: 159.8646\n",
      "3666/3666 [==============================] - 0s 16us/step\n",
      "100/100 [==============================] - 0s 19us/step\n",
      "\n",
      "Experiment on Fold  4\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 104)               35048     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 104)               10920     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 105       \n",
      "=================================================================\n",
      "Total params: 46,073\n",
      "Trainable params: 46,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 10us/step - loss: 5392.0219 - mean_squared_error: 5392.0219\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 653.8569 - mean_squared_error: 653.8569\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 492.4831 - mean_squared_error: 492.4831\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 400.5547 - mean_squared_error: 400.5547\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 327.9538 - mean_squared_error: 327.9538\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 286.4576 - mean_squared_error: 286.4576\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 266.4120 - mean_squared_error: 266.4120\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 255.5304 - mean_squared_error: 255.5304\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 247.8616 - mean_squared_error: 247.8616\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 241.2036 - mean_squared_error: 241.2036\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 240.4616 - mean_squared_error: 240.4616\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.7344 - mean_squared_error: 234.7344\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.8668 - mean_squared_error: 234.8668\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.1172 - mean_squared_error: 232.1172\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.8213 - mean_squared_error: 230.8213\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.9678 - mean_squared_error: 229.9678\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.6580 - mean_squared_error: 226.6580\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.8559 - mean_squared_error: 229.8559\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.9247 - mean_squared_error: 224.9247\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.7736 - mean_squared_error: 224.7736\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.2860 - mean_squared_error: 226.2860\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.4202 - mean_squared_error: 220.4202\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.8959 - mean_squared_error: 219.8959\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.8691 - mean_squared_error: 219.8691\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.3971 - mean_squared_error: 220.3971\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.4108 - mean_squared_error: 219.4108\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.1748 - mean_squared_error: 217.1748\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.1004 - mean_squared_error: 214.1004\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.4111 - mean_squared_error: 212.4111\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.8829 - mean_squared_error: 211.8829\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.9880 - mean_squared_error: 212.9880\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.1119 - mean_squared_error: 213.1119\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.3094 - mean_squared_error: 209.3094\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.7281 - mean_squared_error: 207.7281\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.8457 - mean_squared_error: 203.8457\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.3133 - mean_squared_error: 205.3133\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.0548 - mean_squared_error: 204.0548\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.6136 - mean_squared_error: 202.6136\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.9594 - mean_squared_error: 201.9594\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.3257 - mean_squared_error: 201.3257\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.2475 - mean_squared_error: 200.2475\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.3352 - mean_squared_error: 199.3352\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.8245 - mean_squared_error: 195.8245\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.8157 - mean_squared_error: 198.8157\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.4832 - mean_squared_error: 194.4832\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.7180 - mean_squared_error: 191.7180\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.6473 - mean_squared_error: 195.6473\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.4028 - mean_squared_error: 191.4028\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.5489 - mean_squared_error: 190.5489\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.6116 - mean_squared_error: 190.6116\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.5252 - mean_squared_error: 188.5252\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.7897 - mean_squared_error: 187.7897\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.3438 - mean_squared_error: 187.3438\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.1521 - mean_squared_error: 183.1521\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.1317 - mean_squared_error: 190.1317\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.5394 - mean_squared_error: 183.5394\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.4606 - mean_squared_error: 182.4606\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.0745 - mean_squared_error: 180.0745\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.1938 - mean_squared_error: 178.1938\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.6694 - mean_squared_error: 180.6694\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.5718 - mean_squared_error: 180.5718\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.2958 - mean_squared_error: 178.2958\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.8401 - mean_squared_error: 180.8401\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.7033 - mean_squared_error: 173.7033\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.6756 - mean_squared_error: 171.6756\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.3252 - mean_squared_error: 172.3252\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.1285 - mean_squared_error: 171.1285\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.0596 - mean_squared_error: 173.0596\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.6262 - mean_squared_error: 175.6262\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.1832 - mean_squared_error: 170.1832\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 167.0516 - mean_squared_error: 167.0516\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.5377 - mean_squared_error: 169.5377\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.0224 - mean_squared_error: 169.0224\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.5042 - mean_squared_error: 162.5042\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.6644 - mean_squared_error: 165.6644\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.6382 - mean_squared_error: 170.6382\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.2668 - mean_squared_error: 165.2668\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.1884 - mean_squared_error: 165.1884\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.9153 - mean_squared_error: 158.9153\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.4174 - mean_squared_error: 159.4174\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 161.9085 - mean_squared_error: 161.9085\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.7493 - mean_squared_error: 160.7493\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.8406 - mean_squared_error: 158.8406\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.9304 - mean_squared_error: 159.9304\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.0207 - mean_squared_error: 157.0207\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.2850 - mean_squared_error: 156.2850\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.1751 - mean_squared_error: 154.1751\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.1159 - mean_squared_error: 157.1159\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 152.0931 - mean_squared_error: 152.0931\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 151.3377 - mean_squared_error: 151.3377\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.7735 - mean_squared_error: 154.7735\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 150.6872 - mean_squared_error: 150.6872\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.5426 - mean_squared_error: 158.5426\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 155.9354 - mean_squared_error: 155.9354\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 146.1773 - mean_squared_error: 146.1773\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 147.2793 - mean_squared_error: 147.2793\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 151.9877 - mean_squared_error: 151.9877\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 145.0428 - mean_squared_error: 145.0428\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 146.8241 - mean_squared_error: 146.8241\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 142.1176 - mean_squared_error: 142.1176\n",
      "3666/3666 [==============================] - 0s 16us/step\n",
      "100/100 [==============================] - 0s 20us/step\n",
      "Testing for yulin/alpha0.8/bestModel_global.json\n",
      "Loading data for dataset 1 with window_size of 24, stride of 1 and maxRUL of 129. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(18331, 336)\n",
      "(18331, 1)\n",
      "Testing data (X, y)\n",
      "(100, 336)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.63253012 -0.18639634 -0.38048616 ... -0.33333333  0.33333333\n",
      "   0.31289699]\n",
      " [-0.43373494 -0.09396119 -0.29473329 ... -0.16666667  0.25581395\n",
      "   0.47638774]\n",
      " [-0.31325301 -0.26095487 -0.25894666 ...  0.          0.11627907\n",
      "   0.43800055]\n",
      " [-0.31325301 -0.48768258 -0.33760972 ... -0.16666667  0.31782946\n",
      "   0.52720243]\n",
      " [-0.30120482 -0.48506649 -0.19074949 ... -0.66666667  0.34883721\n",
      "   0.07677437]]\n",
      "[[129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]]\n",
      "Testing data (X, y)\n",
      "[[-0.19879518 -0.5705254  -0.37069548 ... -0.16666667  0.03875969\n",
      "   0.27312897]\n",
      " [-0.21686747 -0.30237628 -0.12086428 ... -0.5         0.03875969\n",
      "   0.01518917]\n",
      " [-0.04216867 -0.1942446  -0.0209318  ...  0.16666667  0.2248062\n",
      "   0.04888152]\n",
      " [-0.22891566 -0.01722259 -0.13673194 ...  0.16666667 -0.31782946\n",
      "   0.004971  ]\n",
      " [-0.11445783 -0.11968607  0.03511141 ...  0.         -0.05426357\n",
      "   0.42916321]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n",
      "Validation on model:best_models/cmapss/yulin/alpha0.8/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 24)                8088      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 320)               8000      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 321       \n",
      "=================================================================\n",
      "Total params: 17,009\n",
      "Trainable params: 17,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14664/14664 [==============================] - 0s 14us/step - loss: 6236.4036 - mean_squared_error: 6236.4036\n",
      "Epoch 2/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 729.8156 - mean_squared_error: 729.8156\n",
      "Epoch 3/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 550.8966 - mean_squared_error: 550.8966\n",
      "Epoch 4/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 434.4164 - mean_squared_error: 434.4164\n",
      "Epoch 5/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 356.7358 - mean_squared_error: 356.7358\n",
      "Epoch 6/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 319.8227 - mean_squared_error: 319.8227\n",
      "Epoch 7/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 306.8006 - mean_squared_error: 306.8006\n",
      "Epoch 8/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 291.0087 - mean_squared_error: 291.0087\n",
      "Epoch 9/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 285.0471 - mean_squared_error: 285.0471\n",
      "Epoch 10/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 282.9972 - mean_squared_error: 282.9972\n",
      "Epoch 11/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 276.2694 - mean_squared_error: 276.2694\n",
      "Epoch 12/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 278.8958 - mean_squared_error: 278.8958\n",
      "Epoch 13/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 272.3930 - mean_squared_error: 272.3930\n",
      "Epoch 14/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 271.6863 - mean_squared_error: 271.6863\n",
      "Epoch 15/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 271.8701 - mean_squared_error: 271.8701\n",
      "Epoch 16/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 264.8666 - mean_squared_error: 264.8666\n",
      "Epoch 17/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 266.8072 - mean_squared_error: 266.8072\n",
      "Epoch 18/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 267.9904 - mean_squared_error: 267.9904\n",
      "Epoch 19/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 265.5185 - mean_squared_error: 265.5185\n",
      "Epoch 20/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 261.7547 - mean_squared_error: 261.7547\n",
      "Epoch 21/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 263.2359 - mean_squared_error: 263.2359\n",
      "Epoch 22/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 261.8978 - mean_squared_error: 261.8978\n",
      "Epoch 23/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 254.8913 - mean_squared_error: 254.8913\n",
      "Epoch 24/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 253.2409 - mean_squared_error: 253.2409\n",
      "Epoch 25/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 254.0609 - mean_squared_error: 254.0609\n",
      "Epoch 26/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 256.1020 - mean_squared_error: 256.1020\n",
      "Epoch 27/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 251.0821 - mean_squared_error: 251.0821\n",
      "Epoch 28/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 250.2872 - mean_squared_error: 250.2872\n",
      "Epoch 29/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 253.7445 - mean_squared_error: 253.7445\n",
      "Epoch 30/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 252.1474 - mean_squared_error: 252.1474\n",
      "Epoch 31/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 247.6049 - mean_squared_error: 247.6049\n",
      "Epoch 32/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 246.8240 - mean_squared_error: 246.8240\n",
      "Epoch 33/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 249.3850 - mean_squared_error: 249.3850\n",
      "Epoch 34/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 251.4755 - mean_squared_error: 251.4755\n",
      "Epoch 35/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 245.0972 - mean_squared_error: 245.0972\n",
      "Epoch 36/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 247.2588 - mean_squared_error: 247.2588\n",
      "Epoch 37/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 246.0835 - mean_squared_error: 246.0835\n",
      "Epoch 38/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 245.3422 - mean_squared_error: 245.3422\n",
      "Epoch 39/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 244.4462 - mean_squared_error: 244.4462\n",
      "Epoch 40/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 244.1655 - mean_squared_error: 244.1655\n",
      "Epoch 41/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 243.0364 - mean_squared_error: 243.0364\n",
      "Epoch 42/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 242.1232 - mean_squared_error: 242.1232\n",
      "Epoch 43/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 240.4299 - mean_squared_error: 240.4299\n",
      "Epoch 44/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 241.6403 - mean_squared_error: 241.6403\n",
      "Epoch 45/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 236.1853 - mean_squared_error: 236.1853\n",
      "Epoch 46/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 240.0132 - mean_squared_error: 240.0132\n",
      "Epoch 47/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 239.6888 - mean_squared_error: 239.6888\n",
      "Epoch 48/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 238.1794 - mean_squared_error: 238.1794\n",
      "Epoch 49/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 244.1916 - mean_squared_error: 244.1916\n",
      "Epoch 50/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 240.6067 - mean_squared_error: 240.6067\n",
      "Epoch 51/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 236.8181 - mean_squared_error: 236.8181\n",
      "Epoch 52/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 234.0756 - mean_squared_error: 234.0756\n",
      "Epoch 53/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 238.0936 - mean_squared_error: 238.0936\n",
      "Epoch 54/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 237.3819 - mean_squared_error: 237.3819\n",
      "Epoch 55/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 232.7731 - mean_squared_error: 232.7731\n",
      "Epoch 56/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 236.6987 - mean_squared_error: 236.6987\n",
      "Epoch 57/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 229.6408 - mean_squared_error: 229.6408\n",
      "Epoch 58/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 235.3994 - mean_squared_error: 235.3994\n",
      "Epoch 59/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 230.9972 - mean_squared_error: 230.9972\n",
      "Epoch 60/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 231.3679 - mean_squared_error: 231.3679\n",
      "Epoch 61/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 232.9968 - mean_squared_error: 232.9968\n",
      "Epoch 62/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 235.8453 - mean_squared_error: 235.8453\n",
      "Epoch 63/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 232.3808 - mean_squared_error: 232.3808\n",
      "Epoch 64/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 228.4600 - mean_squared_error: 228.4600\n",
      "Epoch 65/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 235.1427 - mean_squared_error: 235.1427\n",
      "Epoch 66/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 231.7300 - mean_squared_error: 231.7300\n",
      "Epoch 67/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 232.4092 - mean_squared_error: 232.4092\n",
      "Epoch 68/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 231.5833 - mean_squared_error: 231.5833\n",
      "Epoch 69/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 230.5258 - mean_squared_error: 230.5258\n",
      "Epoch 70/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 227.8318 - mean_squared_error: 227.8318\n",
      "Epoch 71/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 225.7315 - mean_squared_error: 225.7315\n",
      "Epoch 72/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 232.1730 - mean_squared_error: 232.1730\n",
      "Epoch 73/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 227.9798 - mean_squared_error: 227.9798\n",
      "Epoch 74/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 227.5076 - mean_squared_error: 227.5076\n",
      "Epoch 75/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 224.2754 - mean_squared_error: 224.2754\n",
      "Epoch 76/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 225.5936 - mean_squared_error: 225.5936\n",
      "Epoch 77/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 225.7574 - mean_squared_error: 225.7574\n",
      "Epoch 78/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 228.0099 - mean_squared_error: 228.0099\n",
      "Epoch 79/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 222.9241 - mean_squared_error: 222.9241\n",
      "Epoch 80/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 228.5746 - mean_squared_error: 228.5746\n",
      "Epoch 81/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 223.3786 - mean_squared_error: 223.3786\n",
      "Epoch 82/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 220.5864 - mean_squared_error: 220.5864\n",
      "Epoch 83/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 225.6434 - mean_squared_error: 225.6434\n",
      "Epoch 84/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 223.6519 - mean_squared_error: 223.6519\n",
      "Epoch 85/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 224.6362 - mean_squared_error: 224.6362\n",
      "Epoch 86/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 222.1715 - mean_squared_error: 222.1715\n",
      "Epoch 87/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 223.4802 - mean_squared_error: 223.4802\n",
      "Epoch 88/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 218.3741 - mean_squared_error: 218.3741\n",
      "Epoch 89/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 221.4834 - mean_squared_error: 221.4834\n",
      "Epoch 90/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 219.3204 - mean_squared_error: 219.3204\n",
      "Epoch 91/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 219.8932 - mean_squared_error: 219.8932\n",
      "Epoch 92/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 222.2531 - mean_squared_error: 222.2531\n",
      "Epoch 93/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 215.3897 - mean_squared_error: 215.3897\n",
      "Epoch 94/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 217.7444 - mean_squared_error: 217.7444\n",
      "Epoch 95/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 218.9764 - mean_squared_error: 218.9764\n",
      "Epoch 96/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 223.9997 - mean_squared_error: 223.9997\n",
      "Epoch 97/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 218.3990 - mean_squared_error: 218.3990\n",
      "Epoch 98/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 217.6303 - mean_squared_error: 217.6303\n",
      "Epoch 99/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 214.5061 - mean_squared_error: 214.5061\n",
      "Epoch 100/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 222.6434 - mean_squared_error: 222.6434\n",
      "3667/3667 [==============================] - 0s 18us/step\n",
      "100/100 [==============================] - 0s 21us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 24)                8088      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 320)               8000      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 321       \n",
      "=================================================================\n",
      "Total params: 17,009\n",
      "Trainable params: 17,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 13us/step - loss: 6793.0691 - mean_squared_error: 6793.0691\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 805.1012 - mean_squared_error: 805.1012\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 523.9572 - mean_squared_error: 523.9572\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 419.8062 - mean_squared_error: 419.8062\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 357.0835 - mean_squared_error: 357.0835\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 322.1260 - mean_squared_error: 322.1260\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 309.6401 - mean_squared_error: 309.6401\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 4us/step - loss: 301.6345 - mean_squared_error: 301.6345\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 294.1775 - mean_squared_error: 294.1775\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 291.3829 - mean_squared_error: 291.3829\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 283.8161 - mean_squared_error: 283.8161\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 287.9149 - mean_squared_error: 287.9149\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 282.1916 - mean_squared_error: 282.1916\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 283.9086 - mean_squared_error: 283.9086\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 281.7192 - mean_squared_error: 281.7192\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 275.4030 - mean_squared_error: 275.4030\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 278.4247 - mean_squared_error: 278.4247\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 274.4087 - mean_squared_error: 274.4087\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 277.8724 - mean_squared_error: 277.8724\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 273.0159 - mean_squared_error: 273.0159\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 270.3925 - mean_squared_error: 270.3925\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 271.3348 - mean_squared_error: 271.3348\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 269.7834 - mean_squared_error: 269.7834\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 268.6525 - mean_squared_error: 268.6525\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 268.7340 - mean_squared_error: 268.7340\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 265.3741 - mean_squared_error: 265.3741\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 272.4674 - mean_squared_error: 272.4674\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 268.5440 - mean_squared_error: 268.5440\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 266.4202 - mean_squared_error: 266.4202\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 265.3164 - mean_squared_error: 265.3164\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 263.1214 - mean_squared_error: 263.1214\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 264.5538 - mean_squared_error: 264.5538\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 261.3635 - mean_squared_error: 261.3635\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 263.9497 - mean_squared_error: 263.9497\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 257.3001 - mean_squared_error: 257.3001\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 262.1234 - mean_squared_error: 262.1234\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 259.5632 - mean_squared_error: 259.5632\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 261.1232 - mean_squared_error: 261.1232\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 253.6001 - mean_squared_error: 253.6001\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 259.8350 - mean_squared_error: 259.8350\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 260.0176 - mean_squared_error: 260.0176\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.5924 - mean_squared_error: 255.5924\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.6823 - mean_squared_error: 255.6823\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 258.2263 - mean_squared_error: 258.2263\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 254.5907 - mean_squared_error: 254.5907\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.1796 - mean_squared_error: 255.1796\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 261.8185 - mean_squared_error: 261.8185\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.4042 - mean_squared_error: 255.4042\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 249.9332 - mean_squared_error: 249.9332\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.1711 - mean_squared_error: 255.1711\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 246.7905 - mean_squared_error: 246.7905\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.3136 - mean_squared_error: 250.3136\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 249.1601 - mean_squared_error: 249.1601\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.9475 - mean_squared_error: 250.9475\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 252.5534 - mean_squared_error: 252.5534\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 248.0158 - mean_squared_error: 248.0158\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 249.7223 - mean_squared_error: 249.7223\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 243.9056 - mean_squared_error: 243.9056\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 247.1866 - mean_squared_error: 247.1866\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 244.6684 - mean_squared_error: 244.6684\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 241.7172 - mean_squared_error: 241.7172\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 248.0184 - mean_squared_error: 248.0184\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 241.1825 - mean_squared_error: 241.1825\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 246.6916 - mean_squared_error: 246.6916\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 242.6587 - mean_squared_error: 242.6587\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 243.9247 - mean_squared_error: 243.9247\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 240.1849 - mean_squared_error: 240.1849\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 239.5810 - mean_squared_error: 239.5810\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 236.0187 - mean_squared_error: 236.0187\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 239.7204 - mean_squared_error: 239.7204\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 237.0728 - mean_squared_error: 237.0728\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 233.7733 - mean_squared_error: 233.7733\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 239.6682 - mean_squared_error: 239.6682\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 237.6879 - mean_squared_error: 237.6879\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 234.0308 - mean_squared_error: 234.0308\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 238.8744 - mean_squared_error: 238.8744\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 234.6743 - mean_squared_error: 234.6743\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 236.1523 - mean_squared_error: 236.1523\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 228.1860 - mean_squared_error: 228.1860\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 229.5489 - mean_squared_error: 229.5489\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 228.6931 - mean_squared_error: 228.6931\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 233.0203 - mean_squared_error: 233.0203\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 227.8598 - mean_squared_error: 227.8598\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 231.0345 - mean_squared_error: 231.0345\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 231.3415 - mean_squared_error: 231.3415\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 231.9561 - mean_squared_error: 231.9561\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 229.6181 - mean_squared_error: 229.6181\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 222.8522 - mean_squared_error: 222.8522\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 226.1176 - mean_squared_error: 226.1176\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 221.6454 - mean_squared_error: 221.6454\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 223.3778 - mean_squared_error: 223.3778\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 221.0893 - mean_squared_error: 221.0893\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 226.3831 - mean_squared_error: 226.3831\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 217.7685 - mean_squared_error: 217.7685\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 221.5779 - mean_squared_error: 221.5779\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 224.2809 - mean_squared_error: 224.2809\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 225.5486 - mean_squared_error: 225.5486\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 219.8454 - mean_squared_error: 219.8454\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 217.4459 - mean_squared_error: 217.4459\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 214.5439 - mean_squared_error: 214.5439\n",
      "3666/3666 [==============================] - 0s 18us/step\n",
      "100/100 [==============================] - 0s 20us/step\n",
      "\n",
      "Experiment on Fold  2\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 24)                8088      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 320)               8000      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 321       \n",
      "=================================================================\n",
      "Total params: 17,009\n",
      "Trainable params: 17,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 14us/step - loss: 6430.5427 - mean_squared_error: 6430.5427\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 752.5071 - mean_squared_error: 752.5071\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 529.2617 - mean_squared_error: 529.2617\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 407.7692 - mean_squared_error: 407.7692\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 340.0323 - mean_squared_error: 340.0323\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 321.7076 - mean_squared_error: 321.7076\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 306.3101 - mean_squared_error: 306.3101\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 293.2835 - mean_squared_error: 293.2835\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 292.9406 - mean_squared_error: 292.9406\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 291.5148 - mean_squared_error: 291.5148\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 285.0625 - mean_squared_error: 285.0625\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 280.6801 - mean_squared_error: 280.6801\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 280.5453 - mean_squared_error: 280.5453\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 282.2750 - mean_squared_error: 282.2750\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 279.6452 - mean_squared_error: 279.6452\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 277.5543 - mean_squared_error: 277.5543\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 273.3012 - mean_squared_error: 273.3012\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 272.1676 - mean_squared_error: 272.1676\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 273.4790 - mean_squared_error: 273.4790\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 271.6961 - mean_squared_error: 271.6961\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 272.7515 - mean_squared_error: 272.7515\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 270.9282 - mean_squared_error: 270.9282\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 269.3989 - mean_squared_error: 269.3989\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 268.9388 - mean_squared_error: 268.9388\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 262.3455 - mean_squared_error: 262.3455\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 270.3873 - mean_squared_error: 270.3873\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 269.0996 - mean_squared_error: 269.0996\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 266.1831 - mean_squared_error: 266.1831\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 265.3398 - mean_squared_error: 265.3398\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 268.5218 - mean_squared_error: 268.5218\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 265.5000 - mean_squared_error: 265.5000\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 264.6600 - mean_squared_error: 264.6600\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 264.5354 - mean_squared_error: 264.5354\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 4us/step - loss: 263.3127 - mean_squared_error: 263.3127\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 261.7055 - mean_squared_error: 261.7055\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 260.7125 - mean_squared_error: 260.7125\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 264.3984 - mean_squared_error: 264.3984\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 259.9634 - mean_squared_error: 259.9634\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 258.9121 - mean_squared_error: 258.9121\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 265.1111 - mean_squared_error: 265.1111\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 260.3578 - mean_squared_error: 260.3578\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 265.5536 - mean_squared_error: 265.5536\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 261.0493 - mean_squared_error: 261.0493\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.8815 - mean_squared_error: 255.8815\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 257.6753 - mean_squared_error: 257.6753\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 261.2928 - mean_squared_error: 261.2928\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 256.5953 - mean_squared_error: 256.5953\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 258.4001 - mean_squared_error: 258.4001\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 254.5520 - mean_squared_error: 254.5520\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 260.2794 - mean_squared_error: 260.2794\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 257.5814 - mean_squared_error: 257.5814\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.8938 - mean_squared_error: 255.8938\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.0963 - mean_squared_error: 255.0963\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 257.3046 - mean_squared_error: 257.3046\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 261.4902 - mean_squared_error: 261.4902\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 253.7059 - mean_squared_error: 253.7059\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 258.8483 - mean_squared_error: 258.8483\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.1425 - mean_squared_error: 255.1425\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 252.2750 - mean_squared_error: 252.2750\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 252.3336 - mean_squared_error: 252.3336\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 254.4085 - mean_squared_error: 254.4085\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 247.7616 - mean_squared_error: 247.7616\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 249.5081 - mean_squared_error: 249.5081\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 247.9703 - mean_squared_error: 247.9703\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 249.5008 - mean_squared_error: 249.5008\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.3106 - mean_squared_error: 255.3106\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 251.3871 - mean_squared_error: 251.3871\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 247.5472 - mean_squared_error: 247.5472\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 245.5308 - mean_squared_error: 245.5308\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 254.9946 - mean_squared_error: 254.9946\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 251.1985 - mean_squared_error: 251.1985\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 246.5102 - mean_squared_error: 246.5102\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 251.7348 - mean_squared_error: 251.7348\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 253.9448 - mean_squared_error: 253.9448\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 247.0705 - mean_squared_error: 247.0705\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 251.9978 - mean_squared_error: 251.9978\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 242.8930 - mean_squared_error: 242.8930\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 246.7734 - mean_squared_error: 246.7734\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 246.4196 - mean_squared_error: 246.4196\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 243.7829 - mean_squared_error: 243.7829\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 248.8395 - mean_squared_error: 248.8395\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 244.9177 - mean_squared_error: 244.9177\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 243.4786 - mean_squared_error: 243.4786\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 247.9051 - mean_squared_error: 247.9051\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 240.5763 - mean_squared_error: 240.5763\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 245.8904 - mean_squared_error: 245.8904\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 242.3052 - mean_squared_error: 242.3052\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 242.8911 - mean_squared_error: 242.8911\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 239.7950 - mean_squared_error: 239.7950\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 240.7541 - mean_squared_error: 240.7541\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 240.4701 - mean_squared_error: 240.4701\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 239.4336 - mean_squared_error: 239.4336\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 241.5753 - mean_squared_error: 241.5753\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 243.0398 - mean_squared_error: 243.0398\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 235.5051 - mean_squared_error: 235.5051\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 240.9481 - mean_squared_error: 240.9481\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 235.7305 - mean_squared_error: 235.7305\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 233.6864 - mean_squared_error: 233.6864\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 234.8195 - mean_squared_error: 234.8195\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 238.3917 - mean_squared_error: 238.3917\n",
      "3666/3666 [==============================] - 0s 18us/step\n",
      "100/100 [==============================] - 0s 22us/step\n",
      "\n",
      "Experiment on Fold  3\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 24)                8088      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 320)               8000      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 321       \n",
      "=================================================================\n",
      "Total params: 17,009\n",
      "Trainable params: 17,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 13us/step - loss: 6177.3487 - mean_squared_error: 6177.3487\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 734.2623 - mean_squared_error: 734.2623\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 554.3513 - mean_squared_error: 554.3513\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 423.7022 - mean_squared_error: 423.7022\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 356.6862 - mean_squared_error: 356.6862\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 322.7475 - mean_squared_error: 322.7475\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 308.6356 - mean_squared_error: 308.6356\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 295.4002 - mean_squared_error: 295.4002\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 288.8207 - mean_squared_error: 288.8207\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 287.1386 - mean_squared_error: 287.1386\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 276.6558 - mean_squared_error: 276.6558\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 276.6263 - mean_squared_error: 276.6263\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 275.7520 - mean_squared_error: 275.7520\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 272.2844 - mean_squared_error: 272.2844\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 270.7743 - mean_squared_error: 270.7743\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 266.0293 - mean_squared_error: 266.0293\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 268.5952 - mean_squared_error: 268.5952\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 265.0065 - mean_squared_error: 265.0065\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 262.6784 - mean_squared_error: 262.6784\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 260.1112 - mean_squared_error: 260.1112\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 264.4788 - mean_squared_error: 264.4788\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 259.8030 - mean_squared_error: 259.8030\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 259.1522 - mean_squared_error: 259.1522\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 256.4966 - mean_squared_error: 256.4966\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 259.2850 - mean_squared_error: 259.2850\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 257.0400 - mean_squared_error: 257.0400\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 253.0224 - mean_squared_error: 253.0224\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.2619 - mean_squared_error: 250.2619\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 251.1365 - mean_squared_error: 251.1365\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 253.9541 - mean_squared_error: 253.9541\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 252.4738 - mean_squared_error: 252.4738\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 248.3854 - mean_squared_error: 248.3854\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 249.6319 - mean_squared_error: 249.6319\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 244.4867 - mean_squared_error: 244.4867\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 243.6682 - mean_squared_error: 243.6682\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 242.2964 - mean_squared_error: 242.2964\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 246.1674 - mean_squared_error: 246.1674\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 241.1685 - mean_squared_error: 241.1685\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 244.3632 - mean_squared_error: 244.3632\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 238.9369 - mean_squared_error: 238.9369\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 239.9304 - mean_squared_error: 239.9304\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 237.4410 - mean_squared_error: 237.4410\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 237.6265 - mean_squared_error: 237.6265\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 242.1619 - mean_squared_error: 242.1619\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 233.7289 - mean_squared_error: 233.7289\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 237.6821 - mean_squared_error: 237.6821\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 234.3808 - mean_squared_error: 234.3808\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 235.5743 - mean_squared_error: 235.5743\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 233.9678 - mean_squared_error: 233.9678\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 230.9501 - mean_squared_error: 230.9501\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 235.1831 - mean_squared_error: 235.1831\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 232.5725 - mean_squared_error: 232.5725\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 229.6032 - mean_squared_error: 229.6032\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 229.2551 - mean_squared_error: 229.2551\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 226.8587 - mean_squared_error: 226.8587\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 224.1452 - mean_squared_error: 224.1452\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 224.9906 - mean_squared_error: 224.9906\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 227.3514 - mean_squared_error: 227.3514\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 226.0081 - mean_squared_error: 226.0081\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 225.6720 - mean_squared_error: 225.6720\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 226.1815 - mean_squared_error: 226.1815\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 225.8510 - mean_squared_error: 225.8510\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 222.9292 - mean_squared_error: 222.9292\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 225.8419 - mean_squared_error: 225.8419\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 225.0324 - mean_squared_error: 225.0324\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 225.2430 - mean_squared_error: 225.2430\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 224.1223 - mean_squared_error: 224.1223\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 224.5637 - mean_squared_error: 224.5637\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 223.5442 - mean_squared_error: 223.5442\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 220.7184 - mean_squared_error: 220.7184\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 218.1195 - mean_squared_error: 218.1195\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 216.9964 - mean_squared_error: 216.9964\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 219.5576 - mean_squared_error: 219.5576\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 216.8948 - mean_squared_error: 216.8948\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 215.9269 - mean_squared_error: 215.9269\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 226.2266 - mean_squared_error: 226.2266\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 215.7652 - mean_squared_error: 215.7652\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 216.8046 - mean_squared_error: 216.8046\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 214.5799 - mean_squared_error: 214.5799\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 212.0992 - mean_squared_error: 212.0992\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 213.9058 - mean_squared_error: 213.9058\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 214.6942 - mean_squared_error: 214.6942\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 218.4535 - mean_squared_error: 218.4535\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 210.2907 - mean_squared_error: 210.2907\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 214.7329 - mean_squared_error: 214.7329\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 210.8298 - mean_squared_error: 210.8298\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 213.5272 - mean_squared_error: 213.5272\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 212.7576 - mean_squared_error: 212.7576\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 208.3768 - mean_squared_error: 208.3768\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 211.4749 - mean_squared_error: 211.4749\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 209.5677 - mean_squared_error: 209.5677\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 211.9029 - mean_squared_error: 211.9029\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 207.7714 - mean_squared_error: 207.7714\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 207.9670 - mean_squared_error: 207.9670\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 214.2591 - mean_squared_error: 214.2591\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 207.1522 - mean_squared_error: 207.1522\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 206.9142 - mean_squared_error: 206.9142\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 205.4881 - mean_squared_error: 205.4881\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 212.5451 - mean_squared_error: 212.5451\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 204.7441 - mean_squared_error: 204.7441\n",
      "3666/3666 [==============================] - 0s 18us/step\n",
      "100/100 [==============================] - 0s 19us/step\n",
      "\n",
      "Experiment on Fold  4\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 24)                8088      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 320)               8000      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 321       \n",
      "=================================================================\n",
      "Total params: 17,009\n",
      "Trainable params: 17,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 14us/step - loss: 6280.1823 - mean_squared_error: 6280.1823\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 752.2557 - mean_squared_error: 752.2557\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 563.2235 - mean_squared_error: 563.2235\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 413.0092 - mean_squared_error: 413.0092\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 339.2371 - mean_squared_error: 339.2371\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 309.0826 - mean_squared_error: 309.0826\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 299.4265 - mean_squared_error: 299.4265\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 289.4627 - mean_squared_error: 289.4627\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 286.3127 - mean_squared_error: 286.3127\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 283.9729 - mean_squared_error: 283.9729\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 286.7359 - mean_squared_error: 286.7359\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 280.0912 - mean_squared_error: 280.0912\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 277.7599 - mean_squared_error: 277.7599\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 271.7859 - mean_squared_error: 271.7859\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 280.2372 - mean_squared_error: 280.2372\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 268.6042 - mean_squared_error: 268.6042\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 269.8932 - mean_squared_error: 269.8932\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 272.0306 - mean_squared_error: 272.0306\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 266.1099 - mean_squared_error: 266.1099\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 270.6375 - mean_squared_error: 270.6375\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 271.9166 - mean_squared_error: 271.9166\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 266.7272 - mean_squared_error: 266.7272\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 265.5447 - mean_squared_error: 265.5447\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 266.9713 - mean_squared_error: 266.9713\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 269.7844 - mean_squared_error: 269.7844\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 262.7566 - mean_squared_error: 262.7566\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 4us/step - loss: 262.4803 - mean_squared_error: 262.4803\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 259.9248 - mean_squared_error: 259.9248\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 258.5864 - mean_squared_error: 258.5864\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 260.3434 - mean_squared_error: 260.3434\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 258.6595 - mean_squared_error: 258.6595\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 264.6229 - mean_squared_error: 264.6229\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 258.2296 - mean_squared_error: 258.2296\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 257.3562 - mean_squared_error: 257.3562\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 261.0300 - mean_squared_error: 261.0300\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 263.4209 - mean_squared_error: 263.4209\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 259.9373 - mean_squared_error: 259.9373\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 259.0480 - mean_squared_error: 259.0480\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 258.6571 - mean_squared_error: 258.6571\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.9859 - mean_squared_error: 255.9859\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 252.3156 - mean_squared_error: 252.3156\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 254.1513 - mean_squared_error: 254.1513\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.0601 - mean_squared_error: 250.0601\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 253.7652 - mean_squared_error: 253.7652\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 256.8780 - mean_squared_error: 256.8780\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 249.0192 - mean_squared_error: 249.0192\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.6229 - mean_squared_error: 255.6229\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 251.2083 - mean_squared_error: 251.2083\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 251.1100 - mean_squared_error: 251.1100\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 248.0896 - mean_squared_error: 248.0896\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.3965 - mean_squared_error: 250.3965\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 248.4773 - mean_squared_error: 248.4773\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.4472 - mean_squared_error: 250.4472\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 248.2508 - mean_squared_error: 248.2508\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 244.8459 - mean_squared_error: 244.8459\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 245.5495 - mean_squared_error: 245.5495\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 248.2319 - mean_squared_error: 248.2319\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 243.7620 - mean_squared_error: 243.7620\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 246.7577 - mean_squared_error: 246.7577\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.0486 - mean_squared_error: 250.0486\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 239.9861 - mean_squared_error: 239.9861\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 240.6633 - mean_squared_error: 240.6633\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 241.6557 - mean_squared_error: 241.6557\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 244.4169 - mean_squared_error: 244.4169\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 240.3354 - mean_squared_error: 240.3354\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 243.9973 - mean_squared_error: 243.9973\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 246.7109 - mean_squared_error: 246.7109\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 237.2815 - mean_squared_error: 237.2815\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 244.3807 - mean_squared_error: 244.3807\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 235.7731 - mean_squared_error: 235.7731\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 240.5798 - mean_squared_error: 240.5798\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 234.8891 - mean_squared_error: 234.8891\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 236.1663 - mean_squared_error: 236.1663\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 236.7274 - mean_squared_error: 236.7274\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 234.7481 - mean_squared_error: 234.7481\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 232.5366 - mean_squared_error: 232.5366\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 238.0647 - mean_squared_error: 238.0647\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 233.5631 - mean_squared_error: 233.5631\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 233.6923 - mean_squared_error: 233.6923\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 229.9375 - mean_squared_error: 229.9375\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 230.9484 - mean_squared_error: 230.9484\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 229.8279 - mean_squared_error: 229.8279\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 228.3435 - mean_squared_error: 228.3435\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 228.1395 - mean_squared_error: 228.1395\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 229.7077 - mean_squared_error: 229.7077\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 229.4785 - mean_squared_error: 229.4785\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 228.9716 - mean_squared_error: 228.9716\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 232.7310 - mean_squared_error: 232.7310\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 228.2509 - mean_squared_error: 228.2509\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 225.9778 - mean_squared_error: 225.9778\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 228.9701 - mean_squared_error: 228.9701\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 222.3491 - mean_squared_error: 222.3491\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 223.5673 - mean_squared_error: 223.5673\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 225.7260 - mean_squared_error: 225.7260\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 222.0047 - mean_squared_error: 222.0047\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 222.9866 - mean_squared_error: 222.9866\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 223.6848 - mean_squared_error: 223.6848\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 219.9693 - mean_squared_error: 219.9693\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 222.1178 - mean_squared_error: 222.1178\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 224.0384 - mean_squared_error: 224.0384\n",
      "3666/3666 [==============================] - 0s 18us/step\n",
      "100/100 [==============================] - 0s 22us/step\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "k = 5  #For 10-fold cross validation\n",
    "\n",
    "for dataset in test_sets.keys():\n",
    "    for alphaValue in alpha_values:\n",
    "        \n",
    "        model_file_name = 'yulin/alpha{}/bestModel_global.json'.format(alphaValue)\n",
    "        weights_file_name = 'yulin/alpha{}/bestModel_global.h5'.format(alphaValue)\n",
    "        trainable_count = 0\n",
    "        \n",
    "        print(\"Testing for \"+model_file_name)\n",
    "        \n",
    "        results_key = dataset + \"_\" +  str(alphaValue)\n",
    "        \n",
    "        evaluations_cv = np.zeros(k)\n",
    "        evaluations_test = np.zeros(k)\n",
    "        \n",
    "        model_location = best_model_folder + '/' + dataset + '/' + model_file_name\n",
    "        \n",
    "        if weights_file_name != \"\":\n",
    "            weights_location = best_model_folder + '/' + dataset + '/' + weights_file_name\n",
    "        \n",
    "        dhandler, data_scaler, problem_type = test_sets[dataset]\n",
    "\n",
    "        #model = load_model(model_location, weights_location, problem_type)   \n",
    "        \n",
    "        data_handler = dhandler(data_scaler=data_scaler)\n",
    "        data_handler.load_data(verbose = 1, unroll=True)\n",
    "        data_handler.print_data()\n",
    "        \n",
    "        folds = list(KFold(n_splits=k, shuffle=True).split(data_handler.X_train))\n",
    "        \n",
    "        print('Validation on model:' + model_location)\n",
    "        \n",
    "        for j, (train_idx, val_idx) in enumerate(folds):\n",
    "\n",
    "            print('\\nExperiment on Fold ', j)\n",
    "            \n",
    "            K.clear_session()  #Clear the previous tensorflow graph \n",
    "\n",
    "            X_train_cv = data_handler.X_train[train_idx]\n",
    "            y_train_cv = data_handler.y_train[train_idx]\n",
    "            X_valid_cv = data_handler.X_train[val_idx]\n",
    "            y_valid_cv = data_handler.y_train[val_idx]\n",
    "\n",
    "            model = load_model(model_location, \"\", problem_type)\n",
    "            model.summary()\n",
    "            trainable_count = int(np.sum([K.count_params(p) for p in set(model.trainable_weights)]))\n",
    "\n",
    "            model.fit(X_train_cv, y_train_cv, batch_size=512, epochs=100, verbose=1)\n",
    "\n",
    "            evaluation_cv = model.evaluate(X_valid_cv, y_valid_cv)\n",
    "            evaluation_test = model.evaluate(data_handler.X_test, data_handler.y_test)\n",
    "\n",
    "            evaluations_cv[j] = evaluation_cv[1]\n",
    "            evaluations_test[j] = evaluation_test[1]\n",
    "            \n",
    "        results[results_key] = (evaluations_cv, evaluations_test, trainable_count)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats for: \n",
      "cmapss_0.2\n",
      "\n",
      "Model size: 204857\n",
      "\n",
      "CrossVal stats: \n",
      "[217.64832284 229.93248357 223.70135494 213.83678092 229.40168542]\n",
      "DescribeResult(nobs=5, minmax=(213.83678092477885, 229.9324835711207), mean=222.90412553912273, variance=50.52296905228123, skewness=-0.2091074027773435, kurtosis=-1.5620402112080323)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=5, minmax=(237.07466735839844, 267.63153198242185), mean=250.62655822753905, variance=168.12863200548176, skewness=0.1220242745306639, kurtosis=-1.43317394381513)\n",
      "\n",
      "Stats for: \n",
      "cmapss_0.3\n",
      "\n",
      "Model size: 123217\n",
      "\n",
      "CrossVal stats: \n",
      "[227.88341476 210.09389648 209.54530212 237.57312073 219.26007216]\n",
      "DescribeResult(nobs=5, minmax=(209.54530211686438, 237.57312073319972), mean=220.87116125039606, variance=143.7868197373457, skewness=0.37206860948754394, kurtosis=-1.334525493521017)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=5, minmax=(232.46487670898438, 269.30808898925784), mean=246.28016296386718, variance=203.83261259166224, skewness=0.8497381596463058, kurtosis=-0.5614722515057209)\n",
      "\n",
      "Stats for: \n",
      "cmapss_0.4\n",
      "\n",
      "Model size: 564009\n",
      "\n",
      "CrossVal stats: \n",
      "[230.1176495  224.31424175 226.74939513 232.43198667 229.40650691]\n",
      "DescribeResult(nobs=5, minmax=(224.31424174956527, 232.4319866740242), mean=228.6039559910906, variance=9.857554797338933, skewness=-0.22790843624307044, kurtosis=-1.1641674209101154)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=5, minmax=(234.21787658691406, 278.8021856689453), mean=261.92399240112303, variance=299.164591198378, skewness=-0.8295275188619387, kurtosis=-0.618309312897154)\n",
      "\n",
      "Stats for: \n",
      "cmapss_0.5\n",
      "\n",
      "Model size: 316369\n",
      "\n",
      "CrossVal stats: \n",
      "[224.97420719 203.33008304 261.09311145 222.61568957 206.58247724]\n",
      "DescribeResult(nobs=5, minmax=(203.33008304477323, 261.09311144506745), mean=223.7191136989044, variance=527.246348008607, skewness=0.8934083107229492, kurtosis=-0.5154636890152582)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=5, minmax=(243.6519973754883, 294.28219116210937), mean=256.49552905273435, variance=452.10202818529365, skewness=1.4508729282464214, kurtosis=0.18606111125501856)\n",
      "\n",
      "Stats for: \n",
      "cmapss_0.6\n",
      "\n",
      "Model size: 96233\n",
      "\n",
      "CrossVal stats: \n",
      "[212.42313516 229.52352356 245.58735373 232.32010708 214.08141151]\n",
      "DescribeResult(nobs=5, minmax=(212.42313515876663, 245.58735373289417), mean=226.78710620954152, variance=189.82743193566637, skewness=0.19450861406297687, kurtosis=-1.312809911785987)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=5, minmax=(233.91781677246092, 274.07925506591795), mean=254.24083712768552, variance=208.74833030275275, skewness=-0.05870333142493479, kurtosis=-0.6632150610249128)\n",
      "\n",
      "Stats for: \n",
      "cmapss_0.7\n",
      "\n",
      "Model size: 46073\n",
      "\n",
      "CrossVal stats: \n",
      "[227.80720761 232.01190715 219.56904863 240.20316164 238.24999171]\n",
      "DescribeResult(nobs=5, minmax=(219.56904863023524, 240.20316164440231), mean=231.56826334772137, variance=69.38261911058827, skewness=-0.405594832080217, kurtosis=-1.1509887122227829)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=5, minmax=(256.2549206542969, 311.9249493408203), mean=277.8392038879395, variance=422.9267246469299, skewness=0.9382953432594042, kurtosis=-0.25904903819322334)\n",
      "\n",
      "Stats for: \n",
      "cmapss_0.8\n",
      "\n",
      "Model size: 17009\n",
      "\n",
      "CrossVal stats: \n",
      "[220.88443311 217.3353689  227.44927984 220.91864388 247.07782891]\n",
      "DescribeResult(nobs=5, minmax=(217.33536890407632, 247.07782890623668), mean=226.73311092694448, variance=142.6882654862636, skewness=1.1798250738980844, kurtosis=-0.21522989588573038)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=5, minmax=(250.31609436035157, 263.2602490234375), mean=257.4331490097046, variance=38.03765944580174, skewness=-0.30704692586234705, kurtosis=-1.7636606531879127)\n"
     ]
    }
   ],
   "source": [
    "model_sizes = []\n",
    "cv_errors = []\n",
    "test_errors = []\n",
    "alphas = []\n",
    "\n",
    "for key in results.keys():\n",
    "    \n",
    "    print(\"\\nStats for: \")\n",
    "    print(key)\n",
    "    evaluations_cv, evaluations_test, model_size = results[key]\n",
    "    \n",
    "    \n",
    "    print(\"\\nModel size: %d\"%model_size)\n",
    "    \n",
    "    print(\"\\nCrossVal stats: \")\n",
    "    print(evaluations_cv)\n",
    "    cv_stats = stats.describe(evaluations_cv)\n",
    "    print(cv_stats)\n",
    "    \n",
    "    print(\"\\nTest stats: \")\n",
    "    test_stats = stats.describe(evaluations_test)\n",
    "    print(test_stats)\n",
    "    \n",
    "    model_sizes.append(model_size)\n",
    "    cv_errors.append(cv_stats[2])\n",
    "    test_errors.append(test_stats[2])\n",
    "    key_alphas = key.split('_')\n",
    "    alphas.append(key_alphas[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8']\n"
     ]
    }
   ],
   "source": [
    "print(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\nmean_02 = 0.9761666666666666\\nmean_03 = 0.9737166666666667\\nmean_04 = 0.9705999999999999\\nmean_05 = 0.9716666666666667\\nmean_06 = 0.9648333333333332\\nmean_07 = 0.9593166666666665\\nmean_08 = 0.9150166666666667\\nsize = [1516, 26506, 38170, 47722, 47722, 63370, 101706]\\nerror = [1-mean_08, 1-mean_07, 1-mean_06, 1-mean_05, 1-mean_04, 1-mean_03, 1-mean_02]\\nplt.scatter(size, error)\\nplt.xlabel('Model Size')\\nplt.ylabel('Error')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mean_02 = 0.9761666666666666\n",
    "mean_03 = 0.9737166666666667\n",
    "mean_04 = 0.9705999999999999\n",
    "mean_05 = 0.9716666666666667\n",
    "mean_06 = 0.9648333333333332\n",
    "mean_07 = 0.9593166666666665\n",
    "mean_08 = 0.9150166666666667\n",
    "size = [1516, 26506, 38170, 47722, 47722, 63370, 101706]\n",
    "error = [1-mean_08, 1-mean_07, 1-mean_06, 1-mean_05, 1-mean_04, 1-mean_03, 1-mean_02]\n",
    "plt.scatter(size, error)\n",
    "plt.xlabel('Model Size')\n",
    "plt.ylabel('Error')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "mean_1 = 234\n",
    "mean_2 = 227\n",
    "mean_3 = 235\n",
    "mean_4 = 285\n",
    "mean_5 = 223\n",
    "mean_6 = 275\n",
    "mean_7 = 276\n",
    "size = [17009, 46073, 123217, 204857, 316369, 498657, 564009]\n",
    "error = [mean_1, mean_2, mean_3, mean_4, mean_5, mean_6, mean_7]\n",
    "'''\n",
    "\n",
    "np_sizes = np.array(model_sizes)\n",
    "np_cv_errors = np.array(np.sqrt(cv_errors))\n",
    "np_test_errors = np.array(np.sqrt(test_errors))\n",
    "np_alphas = np.array(alphas)\n",
    "colors = ['b', 'c', 'y', 'm', 'r', 'g', 'k']\n",
    "n1 = plt.scatter(np_sizes[0], np_cv_errors[0], color = colors[0], label = 'alpha='+np_alphas[0])\n",
    "n2 = plt.scatter(np_sizes[1], np_cv_errors[1], color = colors[1], label = 'alpha='+np_alphas[1])\n",
    "n3 = plt.scatter(np_sizes[2], np_cv_errors[2], color = colors[2], label = 'alpha='+np_alphas[2])\n",
    "n4 = plt.scatter(np_sizes[3], np_cv_errors[3], color = colors[3], label = 'alpha='+np_alphas[3])\n",
    "n5 = plt.scatter(np_sizes[4], np_cv_errors[4], color = colors[4], label = 'alpha='+np_alphas[4])\n",
    "n6 = plt.scatter(np_sizes[5], np_cv_errors[5], color = colors[5], label = 'alpha='+np_alphas[5])si \n",
    "n7 = plt.scatter(np_sizes[6], np_cv_errors[6], color = colors[6], label = 'alpha='+np_alphas[6])\n",
    "plt.legend(bbox_to_anchor=(1.05, 1),loc=2)\n",
    "plt.xlabel('Model Size')\n",
    "plt.ylabel('Error')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
