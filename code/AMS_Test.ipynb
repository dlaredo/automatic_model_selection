{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic model selection\n",
    "\n",
    "Test notebook for automatic model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "\n",
    "#sys.path.append('/Users/davidlaredorazo/Documents/University_of_California/Research/Projects')\n",
    "sys.path.append('/media/controlslab/DATA/Projects')\n",
    "\n",
    "import ann_framework.aux_functions as aux_functions\n",
    "\n",
    "import automatic_model_selection\n",
    "from automatic_model_selection import Configuration\n",
    "from ann_encoding_rules import Layers\n",
    "import fetch_to_keras\n",
    "#from CMAPSAuxFunctions import TrainValTensorBoard\n",
    "\n",
    "#Tunable model\n",
    "from ann_framework.tunable_model.tunable_model import SequenceTunableModelRegression, SequenceTunableModelClassification\n",
    "\n",
    "#Data handlers\n",
    "from ann_framework.data_handlers.data_handler_CMAPSS import CMAPSSDataHandler\n",
    "from ann_framework.data_handlers.data_handler_MNIST import MNISTDataHandler\n",
    "from ann_framework.data_handlers.data_handler_CIFAR10 import CIFAR10DataHandler\n",
    "\n",
    "learningRate_scheduler = LearningRateScheduler(aux_functions.step_decay)\n",
    "\n",
    "size_scaler = 0.5\n",
    "\n",
    "#Use same configuration for all experiments, just change some of the parameters\n",
    "\n",
    "#Define some random paramaters for the creation of the configuration, this will change for each test model\n",
    "architecture_type = Layers.FullyConnected\n",
    "problem_type = 2  #1 for regression, 2 for classification\n",
    "output_shape = 10 #If regression applies, number of classes\n",
    "input_shape = (784,)\n",
    "\n",
    "config = Configuration(architecture_type, problem_type, input_shape, output_shape, pop_size=5, \n",
    "                       tournament_size=3, max_similar=3, epochs=5, cross_val=0.2, size_scaler=size_scaler,\n",
    "                       max_generations=2, binary_selection=True, mutation_ratio=0.8, \n",
    "                       similarity_threshold=0.2, more_layers_prob=0.4, verbose_individuals=True, \n",
    "                       show_model=False, verbose_training=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given a model, get the compiled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model(model, problem_type, optimizer_params=[]):\n",
    "    \"\"\"Obtain a keras compiled model\"\"\"\n",
    "    \n",
    "    #Shared parameters for the models\n",
    "    optimizer = Adam(lr=0.01, beta_1=0.5)\n",
    "    \n",
    "    if problem_type == 1:\n",
    "        lossFunction = \"mean_squared_error\"\n",
    "        metrics = [\"mse\"]\n",
    "    elif problem_type == 2:\n",
    "        lossFunction = \"categorical_crossentropy\"\n",
    "        metrics = [\"accuracy\"]\n",
    "    else:\n",
    "        print(\"Problem type not defined\")\n",
    "        model = None\n",
    "        return\n",
    "    \n",
    "    #Create and compile the models\n",
    "    model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_tunable_model(model_genotype, problem_type, input_shape, data_handler, model_number):\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    model = fetch_to_keras.decode_genotype(model_genotype, problem_type, input_shape, 1)\n",
    "    \n",
    "    model = get_compiled_model(model, problem_type, optimizer_params=[])\n",
    "    \n",
    "    if problem_type == 1:\n",
    "        tModel = SequenceTunableModelRegression('ModelReg_SN_'+str(model_number), model, lib_type='keras', data_handler=data_handler)\n",
    "    else:\n",
    "        tModel = SequenceTunableModelClassification('ModelClass_SN_'+str(model_number), model, lib_type='keras', data_handler=data_handler)\n",
    "        \n",
    "    return tModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cmaps data handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmaps_dhandler():\n",
    "\n",
    "    #Selected as per CNN paper\n",
    "    features = ['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', 'BPR', \n",
    "    'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "    selected_indices = np.array([2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21])\n",
    "    selected_features = list(features[i] for i in selected_indices-1)\n",
    "    data_folder = '../CMAPSSData'\n",
    "\n",
    "    window_size = 24\n",
    "    window_stride = 1\n",
    "    max_rul = 129\n",
    "\n",
    "    dHandler_cmaps = CMAPSSDataHandler(data_folder, 1, selected_features, max_rul, window_size, window_stride)\n",
    "\n",
    "    input_shape = (len(selected_features)*window_size, )\n",
    "\n",
    "    return dHandler_cmaps, input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to save top models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_models(best_models_list, global_best_model_index, saveto, input_shape, data_handler, \n",
    "                     problem_type=1, data_scaler=None, train_epochs=100, metrics=[], round=0):\n",
    "    \n",
    "    n_models = len(best_models_list)\n",
    "    \n",
    "    for ind_model, i in zip(best_models_list, range(n_models)):\n",
    "        \n",
    "        tModel = create_tunable_model(ind_model.stringModel, problem_type, input_shape, data_handler, i)\n",
    "        kmodel = tModel.model\n",
    "        model_json = kmodel.to_json()\n",
    "        \n",
    "        #Save model's architecture\n",
    "        string_append = str(i) if i != global_best_model_index else 'global'\n",
    "        with open(saveto+\"bestModel_\"+string_append+\".json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "            \n",
    "    #Train the global best, model has to be recompiled\n",
    "    ind_model = best_models_list[global_best_model_index]\n",
    "    tModel = create_tunable_model(ind_model.stringModel, problem_type, input_shape, data_handler, n_models)\n",
    "    \n",
    "    print(tModel.model.summary())\n",
    "    print(tModel.data_handler)\n",
    "    \n",
    "    if tModel.data_handler.data_scaler != None:\n",
    "        print(\"Using data handler scaler\")\n",
    "    elif tModel.data_scaler != None:\n",
    "        print(\"Using tModel scaler (Overriding data handler scaler)\")\n",
    "    else:\n",
    "        print(\"No data scaling used\")\n",
    "    \n",
    "    if data_scaler != None:\n",
    "        tModel.data_handler.data_scaler = None\n",
    "        tModel.data_scaler = data_scaler\n",
    "        \n",
    "    tModel.load_data(unroll=True, verbose=1, cross_validation_ratio=0)\n",
    "    tModel.print_data()\n",
    "    tModel.epochs = train_epochs\n",
    "\n",
    "    tModel.train_model(verbose=1)\n",
    "    \n",
    "    tModel.evaluate_model(metrics, round=round)\n",
    "    \n",
    "    kmodel = tModel.model\n",
    "            \n",
    "    # serialize weights to HDF5\n",
    "    kmodel.save_weights(saveto+\"bestModel_global.h5\")\n",
    "    \n",
    "    print(\"Saved models for dataset 1 to disk\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get global best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recompute_globals_fitness(best_models, size_scaler, problem_type):\n",
    "    \"\"\"It is necessary to recompute the fiteness of global models since they have differnt normalization factors\"\"\"\n",
    "\n",
    "    automatic_model_selection.print_best(best_models)\n",
    "    normalize_scores(best_models)\n",
    "    automatic_model_selection.print_best(best_models)\n",
    "    \n",
    "    compute_fitness(best_models, size_scaler, problem_type)\n",
    "    automatic_model_selection.print_best(best_models)\n",
    "\n",
    "\n",
    "def normalize_scores(best_models):\n",
    "    \n",
    "    pop_size = len(best_models)\n",
    "    raw_scores = np.zeros((pop_size,))\n",
    "    \n",
    "    for i in range(pop_size):\n",
    "        model = best_models[i]\n",
    "        raw_scores[i] = model.raw_score\n",
    "        \n",
    "    normalization_factor = np.linalg.norm(raw_scores)\n",
    "    normalized_scores = raw_scores/normalization_factor\n",
    "    \n",
    "    for i in range(pop_size):\n",
    "        model = best_models[i]\n",
    "        model.normalized_score = raw_scores[i]\n",
    "    \n",
    "    \n",
    "def compute_fitness(best_models, size_scaler, problem_type):\n",
    "    \n",
    "    pop_size = len(best_models)\n",
    "    \n",
    "    for i in range(pop_size):\n",
    "    \n",
    "        scaled_score = best_models[i].normalized_score\n",
    "\n",
    "        #For classification estimate the error which is between 0 and 1                                                                                                                   \n",
    "        if problem_type == 2:\n",
    "            metric_score = (1 - scaled_score)*10 #Multiply by 10 to have a better scaling. I still need to find an appropriate scaling                                                \n",
    "        else:\n",
    "            metric_score = scaled_score*10 #Multiply by 10 to have a better scaling. I still need to find an appropiate scaling                                                       \n",
    "    \n",
    "        metric_scaler = 1-size_scaler\n",
    "        print(\"metric_scaler %f\"%metric_scaler)\n",
    "        print(\"size scaler %f\"%size_scaler)\n",
    "    \n",
    "        #Scalarization of multiobjective version of the fitness function                                                                                                                  \n",
    "        best_models[i].fitness = metric_scaler*metric_score + size_scaler*size_score\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_test(dhandler_mnist, size_scaler=0.5, total_experiments=3):\n",
    "\n",
    "    \"\"\"Input can be of 3 types, ANN (1), CNN (2) or RNN (3)\"\"\"\n",
    "    architecture_type = Layers.FullyConnected\n",
    "    problem_type = 2  #1 for regression, 2 for classification\n",
    "    output_shape = 10 #If regression applies, number of classes\n",
    "    input_shape = (784,)\n",
    "\n",
    "    \"\"\"\n",
    "    pop_size = 5\n",
    "    tournament_size = 3\n",
    "    max_similar = 3\n",
    "    total_experiments = 5\n",
    "    count_experiments = 0\n",
    "    unroll = True\n",
    "    \"\"\"\n",
    "    #total_experiments = 1\n",
    "    count_experiments = 0\n",
    "    unroll = True\n",
    "\n",
    "    global_best_list = []\n",
    "    global_best = None\n",
    "    global_best_index = 0\n",
    "    experiment_times = np.zeros((total_experiments,1))\n",
    "\n",
    "    scaler = None\n",
    "\n",
    "    t = datetime.datetime.now()\n",
    "\n",
    "    logging.basicConfig(filename='logs/nn_evolution_mnist_' + t.strftime('%m%d%Y%H%M%S') + '.log', level=logging.INFO, \n",
    "                            format='%(levelname)s:%(threadName)s:%(message)s', datefmt='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "    #mnist datahandler\n",
    "    #dHandler_mnist = MNISTDataHandler()\n",
    "\n",
    "    config.architecture_type = architecture_type\n",
    "    config.problem_type = problem_type\n",
    "    config.input_shape = input_shape\n",
    "    config.output_shape = output_shape\n",
    "    config.size_scaler = size_scaler\n",
    "\n",
    "    \"\"\"\n",
    "    config = Configuration(architecture_type, problem_type, input_shape, output_shape, pop_size, \n",
    "                           tournament_size, max_similar, epochs=20, cross_val=0.2, size_scaler=size_scaler,\n",
    "                           max_generations=10, binary_selection=True, mutation_ratio=0.4, \n",
    "                           similarity_threshold=0.2, more_layers_prob=0.8)\n",
    "    \"\"\"\n",
    "\n",
    "    while count_experiments < total_experiments:\n",
    "        print(\"Launching experiment {}\".format(count_experiments+1))\n",
    "        logging.info(\"Launching experiment {}\".format(count_experiments+1))\n",
    "\n",
    "\n",
    "        start = time.time()\n",
    "        best = automatic_model_selection.run_experiment(config, dHandler_mnist, count_experiments + 1, unroll=unroll,\n",
    "                                                        learningRate_scheduler=learningRate_scheduler, \n",
    "                                                        tModel_scaler=scaler)\n",
    "        end = time.time()\n",
    "        elapsed_time = (end-start)/60\n",
    "        experiment_times[count_experiments] = elapsed_time\n",
    "        print(\"Experiment time: {} minutes\".format(elapsed_time))\n",
    "        logging.info(\"Experiment time: {} minutes\".format(elapsed_time))\n",
    "\n",
    "\n",
    "        best.individual_label = count_experiments\n",
    "\n",
    "        global_best_list.append(best)\n",
    "        \n",
    "        \"\"\"\n",
    "        if global_best == None:\n",
    "            global_best = best\n",
    "        else:\n",
    "            if best.fitness < global_best.fitness:\n",
    "                global_best = best\n",
    "                global_best_index = count_experiments\n",
    "        \"\"\"\n",
    "\n",
    "        count_experiments =  count_experiments + 1\n",
    "    \n",
    "    recompute_globals_fitness(global_best_list, config.size_scaler, config.problem_type)\n",
    "    \n",
    "    total_experiment_time = experiment_times.sum()\n",
    "\n",
    "    print(\"Global best list\\n\")\n",
    "    logging.info(\"Global best list\\n\")\n",
    "    automatic_model_selection.print_best(global_best_list)\n",
    "\n",
    "    print(\"Global best is\\n\")\n",
    "    print(global_best)\n",
    "    logging.info(\"Global best is\\n\")\n",
    "    logging.info(global_best)\n",
    "\n",
    "    print(\"Global time {}\".format(experiment_times.sum()))\n",
    "    logging.info(\"Global time {}\".format(experiment_times.sum()))\n",
    "    \n",
    "    return global_best_list, global_best_index, total_experiment_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar_test(dHandler_cifar, size_scaler=0.5, total_experiments=3):\n",
    "\n",
    "    \"\"\"Input can be of 3 types, ANN (1), CNN (2) or RNN (3)\"\"\"\n",
    "    architecture_type = Layers.FullyConnected\n",
    "    problem_type = 2  #1 for regression, 2 for classification\n",
    "    output_shape = 10 #If regression applies, number of classes\n",
    "    input_shape = (3072,)\n",
    "    \"\"\"\n",
    "    pop_size = 5\n",
    "    tournament_size = 3\n",
    "    max_similar = 3\n",
    "    \"\"\"\n",
    "    total_experiments = 5\n",
    "    count_experiments = 0\n",
    "    unroll = True\n",
    "\n",
    "    global_best_list = []\n",
    "    global_best = None\n",
    "    global_best_index = 0\n",
    "\n",
    "    scaler = None\n",
    "\n",
    "    t = datetime.datetime.now()\n",
    "\n",
    "    logging.basicConfig(filename='logs/nn_evolution_cifar10_' + t.strftime('%m%d%Y%H%M%S') + '.log', level=logging.INFO, \n",
    "                            format='%(levelname)s:%(threadName)s:%(message)s', datefmt='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "    #mnist datahandler\n",
    "    #dHandler_cifar = CIFAR10DataHandler()\n",
    "\n",
    "    \"\"\"\n",
    "    config = Configuration(architecture_type, problem_type, input_shape, output_shape, pop_size, tournament_size, max_similar, \n",
    "                           epochs=5, cross_val=0.2, size_scaler=size_scaler, max_generations=10, binary_selection=True, \n",
    "                           mutation_ratio=0.4, similarity_threshold=0.2, more_layers_prob=0.8)\n",
    "    \"\"\"\n",
    "\n",
    "    config.architecture_type = architecture_type\n",
    "    config.problem_type = problem_type\n",
    "    config.input_shape = input_shape\n",
    "    config.output_shape = output_shape\n",
    "\n",
    "    while count_experiments < total_experiments:\n",
    "        print(\"Launching experiment {}\".format(count_experiments+1))\n",
    "        logging.info(\"Launching experiment {}\".format(count_experiments+1))\n",
    "\n",
    "        best = automatic_model_selection.run_experiment(config, dHandler_cifar, count_experiments + 1, unroll=unroll,\n",
    "                                                        learningRate_scheduler=learningRate_scheduler, \n",
    "                                                        tModel_scaler=scaler, verbose_data=0)\n",
    "\n",
    "        best.individual_label = count_experiments\n",
    "\n",
    "        global_best_list.append(best)\n",
    "\n",
    "        if global_best == None:\n",
    "            global_best = best\n",
    "        else:\n",
    "            if best.fitness < global_best.fitness:\n",
    "                global_best = best\n",
    "                global_best_index = count_experiments\n",
    "\n",
    "        count_experiments =  count_experiments + 1\n",
    "        \n",
    "    total_experiment_time = experiment_times.sum()\n",
    "\n",
    "    print(\"Global best list\\n\")\n",
    "    logging.info(\"Global best list\\n\")\n",
    "    automatic_model_selection.print_best(global_best_list)\n",
    "\n",
    "    print(\"Global best is\\n\")\n",
    "    print(global_best)\n",
    "    logging.info(\"Global best is\\n\")\n",
    "    logging.info(global_best)\n",
    "    \n",
    "    return global_best_list, global_best_index, total_experiment_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test on CMAPSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmapss_test(dhandler_cmaps, input_shape, size_scaler=0.5, total_experiments=3):\n",
    "\n",
    "    \"\"\"Input can be of 3 types, ANN (1), CNN (2) or RNN (3)\"\"\"\n",
    "    architecture_type = Layers.FullyConnected\n",
    "    problem_type = 1  #1 for regression, 2 for classification\n",
    "    output_shape = 1 #If regression applies, number of classes\n",
    "    input_shape = None\n",
    "\n",
    "    \"\"\"\n",
    "    pop_size = 5\n",
    "    tournament_size = 3\n",
    "    max_similar = 3\n",
    "    \"\"\"\n",
    "    total_experiments = 5\n",
    "    count_experiments = 0\n",
    "    unroll = True\n",
    "\n",
    "    global_best_list = []\n",
    "    global_best = None\n",
    "    global_best_index = 0\n",
    "    experiment_times = np.zeros((total_experiments,1))\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "    t = datetime.datetime.now()\n",
    "\n",
    "    logging.basicConfig(filename='logs/nn_evolution_cmaps_' + t.strftime('%m%d%Y%H%M%S') + '.log', level=logging.INFO, \n",
    "                            format='%(levelname)s:%(threadName)s:%(message)s', datefmt='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "    #cmaps datahandler\n",
    "    #dhandler_cmaps, input_shape = cmaps_dhandler()\n",
    "\n",
    "    \"\"\"\n",
    "    config = Configuration(architecture_type, problem_type, input_shape, output_shape, pop_size, tournament_size, \n",
    "                           max_similar, epochs=5, cross_val=0.2, size_scaler=size_scaler, max_generations=10, \n",
    "                           binary_selection=True, mutation_ratio=0.4, similarity_threshold=0.2, more_layers_prob=0.8)\n",
    "    \"\"\"\n",
    "\n",
    "    config.architecture_type = architecture_type\n",
    "    config.problem_type = problem_type\n",
    "    config.input_shape = input_shape\n",
    "    config.output_shape = output_shape\n",
    "\n",
    "    while count_experiments < total_experiments:\n",
    "        print(\"Launching experiment {}\".format(count_experiments+1))\n",
    "        logging.info(\"Launching experiment {}\".format(count_experiments+1))\n",
    "\n",
    "        start = time.time()\n",
    "        best = automatic_model_selection.run_experiment(config, dhandler_cmaps, count_experiments + 1, unroll=unroll,\n",
    "                                                        learningRate_scheduler=learningRate_scheduler, \n",
    "                                                        tModel_scaler=scaler)\n",
    "        end = time.time()\n",
    "        elapsed_time = (end-start)/60\n",
    "        experiment_times[count_experiments] = elapsed_time\n",
    "        print(\"Experiment time: {} minutes\".format(elapsed_time))\n",
    "        logging.info(\"Experiment time: {} minutes\".format(elapsed_time))\n",
    "\n",
    "        best.individual_label = count_experiments\n",
    "\n",
    "        global_best_list.append(best)\n",
    "\n",
    "        if global_best == None:\n",
    "            global_best = best\n",
    "        else:\n",
    "            if best.fitness < global_best.fitness:\n",
    "                global_best = best\n",
    "                global_best_index = count_experiments\n",
    "\n",
    "        count_experiments =  count_experiments + 1\n",
    "        \n",
    "    total_experiment_time = experiment_times.sum()\n",
    "\n",
    "    print(\"Global best list\\n\")\n",
    "    logging.info(\"Global best list\\n\")\n",
    "    automatic_model_selection.print_best(global_best_list)\n",
    "\n",
    "    print(\"Global best is\\n\")\n",
    "    print(global_best)\n",
    "    logging.info(\"Global best is\\n\")\n",
    "    logging.info(global_best)\n",
    "\n",
    "    print(\"Global time {}\".format(total_experiment_time))\n",
    "    logging.info(\"Global time {}\".format(total_experiment_time))\n",
    "    \n",
    "    return global_best_list, global_best_index, total_experiment_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for alpha=0.2\n",
      "Launching experiment 1\n",
      "\n",
      "Generation 1\n",
      "launch new\n",
      "True\n",
      "gen similar\n",
      "False\n",
      "Loading data for the first time\n",
      "Reloading data due to parameter change\n",
      "Loading data. Cross-Validation ratio 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with cv\n",
      "12000/12000 [==============================] - 0s 27us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 20us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 1s 45us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 39us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 24us/step\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 0 score/normalized score/size/fitness 0.94975/0.94975/923394/1.5950403402051827\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 1 score/normalized score/size/fitness 0.9510833333333333/0.9510833333333333/657402/1.55484640724529\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 2 score/normalized score/size/fitness 0.9605/0.9605/1636466/1.5587566598670608\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 3 score/normalized score/size/fitness 0.9248333333333333/0.9248333333333333/1493490/1.8361452948783388\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 4 score/normalized score/size/fitness 0.9341666666666667/0.9341666666666667/908354/1.7182838363708834\n",
      "\n",
      "Generating offsprings\n",
      "Applying Mutation\n",
      "Launch new generation?: True\n",
      "\n",
      "Generation 2\n",
      "launch new\n",
      "True\n",
      "gen similar\n",
      "False\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 10us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 13us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 29us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 41us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 13us/step\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 0 score/normalized score/size/fitness 0.942/0.942/298930/1.5591342376648865\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 1 score/normalized score/size/fitness 0.9560833333333333/0.9560833333333333/347802/1.4596491821226498\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 2 score/normalized score/size/fitness 0.9725833333333334/0.9725833333333334/1057938/1.4242304668731667\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 3 score/normalized score/size/fitness 0.9638333333333333/0.9638333333333333/1481634/1.5235029740619954\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 4 score/normalized score/size/fitness 0.9589166666666666/0.9589166666666666/350898/1.4377280899598317\n",
      "\n",
      "Generating offsprings\n",
      "Applying Mutation\n",
      "Launch new generation?: True\n",
      "Experiment 1 finished\n",
      "Experiment time: 1.4787036895751953 minutes\n",
      "Launching experiment 2\n",
      "\n",
      "Generation 1\n",
      "launch new\n",
      "True\n",
      "gen similar\n",
      "False\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 11us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 11us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 17us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 28us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 12us/step\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 0 score/normalized score/size/fitness 0.9688333333333333/0.9688333333333333/295034/1.3432977365289662\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 1 score/normalized score/size/fitness 0.9398333333333333/0.9398333333333333/337090/1.5868593135076015\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 2 score/normalized score/size/fitness 0.972/0.972/554106/1.372701952945686\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 3 score/normalized score/size/fitness 0.9135/0.9135/904690/1.883329715841041\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 4 score/normalized score/size/fitness 0.96925/0.96925/256634/1.3279866246662593\n",
      "\n",
      "Generating offsprings\n",
      "Applying Mutation\n",
      "Launch new generation?: True\n",
      "\n",
      "Generation 2\n",
      "launch new\n",
      "True\n",
      "gen similar\n",
      "False\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 11us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 12us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 11us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 11us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 15us/step\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 0 score/normalized score/size/fitness 0.9380833333333334/0.9380833333333334/337090/1.6008593135076008\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 1 score/normalized score/size/fitness 0.971/0.971/346730/1.340065894958175\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 2 score/normalized score/size/fitness 0.9456666666666667/0.9456666666666667/337090/1.5401926468409346\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 3 score/normalized score/size/fitness 0.9646666666666667/0.9646666666666667/337090/1.3881926468409345\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 4 score/normalized score/size/fitness 0.97/0.97/271882/1.32691378080684\n",
      "\n",
      "Generating offsprings\n",
      "Applying Mutation\n",
      "Launch new generation?: True\n",
      "Experiment 2 finished\n",
      "Experiment time: 0.737374218304952 minutes\n",
      "Launching experiment 3\n",
      "\n",
      "Generation 1\n",
      "launch new\n",
      "True\n",
      "gen similar\n",
      "False\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 28us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 9us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 16us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 32us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 1s 45us/step\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 0 score/normalized score/size/fitness 0.9299166666666666/0.9299166666666666/1049674/1.7649045264806549\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 1 score/normalized score/size/fitness 0.9380833333333334/0.9380833333333334/216250/1.562224083563519\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 2 score/normalized score/size/fitness 0.9663333333333334/0.9663333333333334/288738/1.3615129018846426\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 3 score/normalized score/size/fitness 0.9740833333333333/0.9740833333333333/1265090/1.4277514384357008\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 4 score/normalized score/size/fitness 0.9354166666666667/0.9354166666666667/1817074/1.7685376521282734\n",
      "\n",
      "Generating offsprings\n",
      "Applying Mutation\n",
      "Launch new generation?: True\n",
      "\n",
      "Generation 2\n",
      "launch new\n",
      "True\n",
      "gen similar\n",
      "False\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 9us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 35us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 21us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 13us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 19us/step\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 0 score/normalized score/size/fitness 0.9165833333333333/0.9165833333333333/216250/1.7342240835635196\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 1 score/normalized score/size/fitness 0.9743333333333334/0.9743333333333334/1469642/1.4387968002829683\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 2 score/normalized score/size/fitness 0.9675833333333334/0.9675833333333334/641314/1.4207049392370967\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 3 score/normalized score/size/fitness 0.9566666666666667/0.9566666666666667/235042/1.420880239121014\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 4 score/normalized score/size/fitness 0.97225/0.97225/646946/1.3841808561337405\n",
      "\n",
      "Generating offsprings\n",
      "Applying Mutation\n",
      "Launch new generation?: True\n",
      "Experiment 3 finished\n",
      "Experiment time: 1.318633508682251 minutes\n",
      "Launching experiment 4\n",
      "\n",
      "Generation 1\n",
      "launch new\n",
      "True\n",
      "gen similar\n",
      "False\n",
      "Using previously loaded data\n",
      "training with cv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000/12000 [==============================] - 0s 18us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 10us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 29us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 27us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 10us/step\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 0 score/normalized score/size/fitness 0.92475/0.92475/582730/1.7551337109518033\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 1 score/normalized score/size/fitness 0.95725/0.95725/96498/1.3384542466079132\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 2 score/normalized score/size/fitness 0.9308333333333333/0.9308333333333333/1121098/1.7632544558523284\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 3 score/normalized score/size/fitness 0.9308333333333333/0.9308333333333333/1085834/1.7604992983838994\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 4 score/normalized score/size/fitness 0.92/0.92/228970/1.7119670964679774\n",
      "\n",
      "Generating offsprings\n",
      "Applying Mutation\n",
      "Launch new generation?: True\n",
      "\n",
      "Generation 2\n",
      "launch new\n",
      "True\n",
      "gen similar\n",
      "False\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 9us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 12us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 14us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 12us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 26us/step\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 0 score/normalized score/size/fitness 0.9218333333333333/0.9218333333333333/228970/1.6973004298013115\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 1 score/normalized score/size/fitness 0.9274166666666667/0.9274166666666667/312202/1.679497585470355\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 2 score/normalized score/size/fitness 0.93375/0.93375/460506/1.66274018507793\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 3 score/normalized score/size/fitness 0.9283333333333333/0.9283333333333333/312202/1.6721642521370217\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 4 score/normalized score/size/fitness 0.9374166666666667/0.9374166666666667/864842/1.6880698881596294\n",
      "\n",
      "Generating offsprings\n",
      "Applying Mutation\n",
      "Launch new generation?: True\n",
      "Experiment 4 finished\n",
      "Experiment time: 0.9048760056495666 minutes\n",
      "Launching experiment 5\n",
      "\n",
      "Generation 1\n",
      "launch new\n",
      "True\n",
      "gen similar\n",
      "False\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 11us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 10us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 12us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 26us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 14us/step\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 0 score/normalized score/size/fitness 0.95325/0.95325/262786/1.4579911496979514\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 1 score/normalized score/size/fitness 0.9599166666666666/0.9599166666666666/78194/1.299085587204763\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 2 score/normalized score/size/fitness 0.96025/0.96025/368682/1.4314052732318119\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 3 score/normalized score/size/fitness 0.9595833333333333/0.9595833333333333/1052570/1.5278190075704305\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 4 score/normalized score/size/fitness 0.9060833333333334/0.9060833333333334/186306/1.8052359221769165\n",
      "\n",
      "Generating offsprings\n",
      "Applying Mutation\n",
      "Launch new generation?: True\n",
      "\n",
      "Generation 2\n",
      "launch new\n",
      "True\n",
      "gen similar\n",
      "False\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 8us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 9us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 12us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 8us/step\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "12000/12000 [==============================] - 0s 15us/step\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 0 score/normalized score/size/fitness 0.951/0.951/62850/1.3518681098907168\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 1 score/normalized score/size/fitness 0.9481666666666667/0.9481666666666667/89050/1.4045446679956488\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 2 score/normalized score/size/fitness 0.9293333333333333/0.9293333333333333/314442/1.6647192629479763\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 3 score/normalized score/size/fitness 0.9535/0.9535/133570/1.3974209596729614\n",
      "metric_scaler 0.800000\n",
      "size scaler 0.200000\n",
      "Individual 4 score/normalized score/size/fitness 0.96775/0.96775/448370/1.3882556027996287\n",
      "\n",
      "Generating offsprings\n",
      "Applying Mutation\n",
      "Launch new generation?: True\n",
      "Experiment 5 finished\n",
      "Experiment time: 0.6612612088521321 minutes\n",
      "\n",
      "\n",
      "String Model\n",
      "[[<Layers.FullyConnected: 1>, 1024, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 216, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 144, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 10, 3, 0, 0, 0, 0, 0]]\n",
      "<Individual(label = '0' fitness = '1.4242304668731667', raw_score = '0.9725833333333334', raw_size = '1057938)>\n",
      "Checksum vector: [   4. 1394.    9.    0.    0.    0.    0.    0.]\n",
      "\n",
      "\n",
      "String Model\n",
      "[[<Layers.FullyConnected: 1>, 152, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 152, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 216, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 424, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 10, 3, 0, 0, 0, 0, 0]]\n",
      "<Individual(label = '1' fitness = '1.32691378080684', raw_score = '0.97', raw_size = '271882)>\n",
      "Checksum vector: [  5. 954.  11.   0.   0.   0.   0.   0.]\n",
      "\n",
      "\n",
      "String Model\n",
      "[[<Layers.FullyConnected: 1>, 128, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 776, 2, 0, 0, 0, 0, 0], [<Layers.Dropout: 5>, 0, 0, 0, 0, 0, 0, 0.4], [<Layers.FullyConnected: 1>, 112, 2, 0, 0, 0, 0, 0], [<Layers.Dropout: 5>, 0, 0, 0, 0, 0, 0, 0.15], [<Layers.FullyConnected: 1>, 10, 3, 0, 0, 0, 0, 0]]\n",
      "<Individual(label = '2' fitness = '1.3615129018846426', raw_score = '0.9663333333333334', raw_size = '288738)>\n",
      "Checksum vector: [1.400e+01 1.026e+03 9.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 5.500e-01]\n",
      "\n",
      "\n",
      "String Model\n",
      "[[<Layers.FullyConnected: 1>, 56, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 784, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 10, 3, 0, 0, 0, 0, 0]]\n",
      "<Individual(label = '3' fitness = '1.3384542466079132', raw_score = '0.95725', raw_size = '96498)>\n",
      "Checksum vector: [  3. 850.   7.   0.   0.   0.   0.   0.]\n",
      "\n",
      "\n",
      "String Model\n",
      "[[<Layers.FullyConnected: 1>, 64, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 112, 2, 0, 0, 0, 0, 0], [<Layers.Dropout: 5>, 0, 0, 0, 0, 0, 0, 0.2], [<Layers.FullyConnected: 1>, 168, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 10, 3, 0, 0, 0, 0, 0]]\n",
      "<Individual(label = '4' fitness = '1.299085587204763', raw_score = '0.9599166666666666', raw_size = '78194)>\n",
      "Checksum vector: [9.00e+00 3.54e+02 9.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 2.00e-01]\n",
      "\n",
      "\n",
      "String Model\n",
      "[[<Layers.FullyConnected: 1>, 1024, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 216, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 144, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 10, 3, 0, 0, 0, 0, 0]]\n",
      "<Individual(label = '0' fitness = '1.4242304668731667', raw_score = '0.9725833333333334', raw_size = '1057938)>\n",
      "Checksum vector: [   4. 1394.    9.    0.    0.    0.    0.    0.]\n",
      "\n",
      "\n",
      "String Model\n",
      "[[<Layers.FullyConnected: 1>, 152, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 152, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 216, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 424, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 10, 3, 0, 0, 0, 0, 0]]\n",
      "<Individual(label = '1' fitness = '1.32691378080684', raw_score = '0.97', raw_size = '271882)>\n",
      "Checksum vector: [  5. 954.  11.   0.   0.   0.   0.   0.]\n",
      "\n",
      "\n",
      "String Model\n",
      "[[<Layers.FullyConnected: 1>, 128, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 776, 2, 0, 0, 0, 0, 0], [<Layers.Dropout: 5>, 0, 0, 0, 0, 0, 0, 0.4], [<Layers.FullyConnected: 1>, 112, 2, 0, 0, 0, 0, 0], [<Layers.Dropout: 5>, 0, 0, 0, 0, 0, 0, 0.15], [<Layers.FullyConnected: 1>, 10, 3, 0, 0, 0, 0, 0]]\n",
      "<Individual(label = '2' fitness = '1.3615129018846426', raw_score = '0.9663333333333334', raw_size = '288738)>\n",
      "Checksum vector: [1.400e+01 1.026e+03 9.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 5.500e-01]\n",
      "\n",
      "\n",
      "String Model\n",
      "[[<Layers.FullyConnected: 1>, 56, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 784, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 10, 3, 0, 0, 0, 0, 0]]\n",
      "<Individual(label = '3' fitness = '1.3384542466079132', raw_score = '0.95725', raw_size = '96498)>\n",
      "Checksum vector: [  3. 850.   7.   0.   0.   0.   0.   0.]\n",
      "\n",
      "\n",
      "String Model\n",
      "[[<Layers.FullyConnected: 1>, 64, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 112, 2, 0, 0, 0, 0, 0], [<Layers.Dropout: 5>, 0, 0, 0, 0, 0, 0, 0.2], [<Layers.FullyConnected: 1>, 168, 2, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 10, 3, 0, 0, 0, 0, 0]]\n",
      "<Individual(label = '4' fitness = '1.299085587204763', raw_score = '0.9599166666666666', raw_size = '78194)>\n",
      "Checksum vector: [9.00e+00 3.54e+02 9.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 2.00e-01]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "compute_fitness() missing 1 required positional argument: 'problem_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c8ee2c200fe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     global_best_list, global_best_index, total_experiment_time = mnist_test(dHandler_mnist, \n\u001b[1;32m     18\u001b[0m                                                                             \u001b[0msize_scaler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize_scaler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                                                                             total_experiments=experiments)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mavg_experiment_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_experiment_time\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mexperiments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-9bbb3708e29e>\u001b[0m in \u001b[0;36mmnist_test\u001b[0;34m(dhandler_mnist, size_scaler, total_experiments)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mcount_experiments\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mcount_experiments\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mrecompute_globals_fitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_best_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize_scaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtotal_experiment_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-5b1293b6dcb5>\u001b[0m in \u001b[0;36mrecompute_globals_fitness\u001b[0;34m(best_models, size_scaler, problem_type)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mautomatic_model_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcompute_fitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_scaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mautomatic_model_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: compute_fitness() missing 1 required positional argument: 'problem_type'"
     ]
    }
   ],
   "source": [
    "#alphas = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "alphas = [0.2]\n",
    "experiments = 5\n",
    "\n",
    "global_best_list = []\n",
    "global_best_index = 0\n",
    "total_experiment_time = []\n",
    "total_experiment_time = 0\n",
    "avg_experiment_time = 0\n",
    "\n",
    "dHandler_mnist = MNISTDataHandler()\n",
    "\n",
    "for size_scaler in alphas:\n",
    "\n",
    "    print(\"Running for alpha={}\".format(size_scaler))\n",
    "    \n",
    "    global_best_list, global_best_index, total_experiment_time = mnist_test(dHandler_mnist, \n",
    "                                                                            size_scaler=size_scaler, \n",
    "                                                                            total_experiments=experiments)\n",
    "    \n",
    "    avg_experiment_time = total_experiment_time/experiments\n",
    "    \n",
    "    print(\"Total experiment time {}\".format(total_experiment_time))\n",
    "    print(\"Avg experiment time {}\".format(avg_experiment_time))\n",
    "    \n",
    "    save_best_models(global_best_list, global_best_index, \n",
    "                     'best_models/mnist/scalarized/alpha{}/'.format(size_scaler), input_shape=input_shape, \n",
    "                     data_handler=dHandler_mnist, problem_type=problem_type, train_epochs=100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "dHandler_cifar = CIFAR10DataHandler()\n",
    "\n",
    "global_best_list, global_best_index = cifar_test(dHandler_cifar, size_scaler=size_scaler, total_experiments=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "dhandler_cmaps, input_shape = cmaps_dhandler()\n",
    "\n",
    "global_best_list, global_best_index = cmapss_test(dhandler_cmaps, input_shape, size_scaler=size_scaler, total_experiments=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "save_best_models(global_best_list, global_best_index, 'best_models/mnist/alpha{}/scalarized_version/'.format(size_scaler), \n",
    "                 input_shape=input_shape, data_handler=dHandler_mnist, problem_type=problem_type, train_epochs=100)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "save_best_models(global_best_list, global_best_index, 'best_models/cifar10/alpha{}/version2'.format(size_scaler), \n",
    "                 input_shape=input_shape, data_handler=dHandler_cifar, problem_type=problem_type, train_epochs=100)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "save_best_models(global_best_list, global_best_index, 'best_models/cmapss/alpha{}/'.format(size_scaler), \n",
    "                 input_shape=input_shape, data_handler=dhandler_cmaps, problem_type=problem_type, train_epochs=100, \n",
    "                 data_scaler=scaler, metrics=['rhs', 'rmse'], round=2)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
