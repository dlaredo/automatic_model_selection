{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic model selection\n",
    "\n",
    "Test notebook for automatic model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "\n",
    "#sys.path.append('/Users/davidlaredorazo/Documents/University_of_California/Research/Projects')\n",
    "sys.path.append('/media/controlslab/DATA/Projects')\n",
    "\n",
    "import ann_framework.aux_functions as aux_functions\n",
    "\n",
    "import automatic_model_selection\n",
    "from automatic_model_selection import Configuration\n",
    "from ann_encoding_rules import Layers\n",
    "import fetch_to_keras\n",
    "#from CMAPSAuxFunctions import TrainValTensorBoard\n",
    "\n",
    "#Tunable model\n",
    "from ann_framework.tunable_model.tunable_model import SequenceTunableModelRegression, SequenceTunableModelClassification\n",
    "\n",
    "#Data handlers\n",
    "from ann_framework.data_handlers.data_handler_CMAPSS import CMAPSSDataHandler\n",
    "from ann_framework.data_handlers.data_handler_MNIST import MNISTDataHandler\n",
    "from ann_framework.data_handlers.data_handler_CIFAR10 import CIFAR10DataHandler\n",
    "#from data_handler_MNIST import MNISTDataHandler\n",
    "#from data_handler_CMAPS import CMAPSDataHandler\n",
    "\n",
    "size_scaler = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given a model, get the compiled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model(model, problem_type, optimizer_params=[]):\n",
    "    \"\"\"Obtain a keras compiled model\"\"\"\n",
    "    \n",
    "    #Shared parameters for the models\n",
    "    optimizer = Adam(lr=0.001, beta_1=0.5)\n",
    "    \n",
    "    if problem_type == 1:\n",
    "        lossFunction = \"mean_squared_error\"\n",
    "        metrics = [\"mse\"]\n",
    "    elif problem_type == 2:\n",
    "        lossFunction = \"categorical_crossentropy\"\n",
    "        metrics = [\"accuracy\"]\n",
    "    else:\n",
    "        print(\"Problem type not defined\")\n",
    "        model = None\n",
    "        return\n",
    "    \n",
    "    #Create and compile the models\n",
    "    model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_tunable_model(model_genotype, problem_type, input_shape, data_handler, model_number):\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    model = fetch_to_keras.decode_genotype(model_genotype, problem_type, input_shape, 1)\n",
    "    \n",
    "    model = get_compiled_model(model, problem_type, optimizer_params=[])\n",
    "    \n",
    "    if problem_type == 1:\n",
    "        tModel = SequenceTunableModelRegression('ModelReg_SN_'+str(model_number), model, lib_type='keras', data_handler=data_handler)\n",
    "    else:\n",
    "        tModel = SequenceTunableModelClassification('ModelClass_SN_'+str(model_number), model, lib_type='keras', data_handler=data_handler)\n",
    "        \n",
    "    return tModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cmaps data handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmaps_dhandler():\n",
    "\n",
    "    #Selected as per CNN paper\n",
    "    features = ['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', 'BPR', \n",
    "    'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "    selected_indices = np.array([2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21])\n",
    "    selected_features = list(features[i] for i in selected_indices-1)\n",
    "    data_folder = '../CMAPSSData'\n",
    "\n",
    "    window_size = 25\n",
    "    window_stride = 1\n",
    "    max_rul = 130\n",
    "\n",
    "    dHandler_cmaps = CMAPSSDataHandler(data_folder, 1, selected_features, max_rul, window_size, window_stride)\n",
    "\n",
    "    input_shape = (len(selected_features)*window_size, )\n",
    "\n",
    "    return dHandler_cmaps, input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to save top models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_models(best_models_list, global_best_model_index, saveto, input_shape, data_handler, \n",
    "                     problem_type=1, data_scaler=None, train_epochs=100, metrics=[], round=0):\n",
    "    \n",
    "    n_models = len(best_models_list)\n",
    "    \n",
    "    for ind_model, i in zip(best_models_list, range(n_models)):\n",
    "        \n",
    "        tModel = create_tunable_model(ind_model.stringModel, problem_type, input_shape, data_handler, i)\n",
    "        kmodel = tModel.model\n",
    "        model_json = kmodel.to_json()\n",
    "        \n",
    "        #Save model's architecture\n",
    "        string_append = str(i) if i != global_best_model_index else 'global'\n",
    "        with open(saveto+\"bestModel_\"+string_append+\".json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "            \n",
    "    #Train the global best, model has to be recompiled\n",
    "    ind_model = best_models_list[global_best_model_index]\n",
    "    tModel = create_tunable_model(ind_model.stringModel, problem_type, input_shape, data_handler, n_models)\n",
    "    \n",
    "    print(tModel.model.summary())\n",
    "    print(tModel.data_handler)\n",
    "    \n",
    "    if tModel.data_handler.data_scaler != None:\n",
    "        print(\"Using data handler scaler\")\n",
    "    elif tModel.data_scaler != None:\n",
    "        print(\"Using tModel scaler (Overriding data handler scaler)\")\n",
    "    else:\n",
    "        print(\"No data scaling used\")\n",
    "    \n",
    "    if data_scaler != None:\n",
    "        tModel.data_handler.data_scaler = None\n",
    "        tModel.data_scaler = data_scaler\n",
    "        \n",
    "    tModel.load_data(unroll=True, verbose=1, cross_validation_ratio=0)\n",
    "    tModel.print_data()\n",
    "    tModel.epochs = train_epochs\n",
    "\n",
    "    tModel.train_model(verbose=1)\n",
    "    \n",
    "    tModel.evaluate_model(metrics, round=round)\n",
    "    \n",
    "    kmodel = tModel.model\n",
    "            \n",
    "    # serialize weights to HDF5\n",
    "    kmodel.save_weights(saveto+\"bestModel_global.h5\")\n",
    "    \n",
    "    print(\"Saved models for dataset 1 to disk\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching experiment 1\n",
      "\n",
      "Generation 1\n",
      "launch new\n",
      "True\n",
      "gen similar\n",
      "False\n",
      "Fetching model 0 to keras\n",
      "Evaluating model 0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 48)                37680     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 384)               18816     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 432)               166320    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 432)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 152)               65816     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 152)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 936)               143208    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 488)               457256    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 488)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 848)               414672    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 544)               461856    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 848)               462160    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 424)               359976    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                4250      \n",
      "=================================================================\n",
      "Total params: 2,592,010\n",
      "Trainable params: 2,592,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.7975 - acc: 0.2584 - val_loss: 1.5600 - val_acc: 0.3288\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 1s 10us/step - loss: 1.1434 - acc: 0.5072 - val_loss: 0.9704 - val_acc: 0.5882\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.7728 - acc: 0.6778 - val_loss: 0.6210 - val_acc: 0.7313\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.6493 - acc: 0.7291 - val_loss: 0.5870 - val_acc: 0.7595\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.5481 - acc: 0.7856 - val_loss: 0.3759 - val_acc: 0.8513\n",
      "12000/12000 [==============================] - 0s 19us/step\n",
      "Fetching model 1 to keras\n",
      "Evaluating model 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 904)               709640    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 904)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                9050      \n",
      "=================================================================\n",
      "Total params: 718,690\n",
      "Trainable params: 718,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 0s 8us/step - loss: 0.7727 - acc: 0.8054 - val_loss: 0.3942 - val_acc: 0.8948\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.3581 - acc: 0.9006 - val_loss: 0.3154 - val_acc: 0.9107\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.3047 - acc: 0.9132 - val_loss: 0.2809 - val_acc: 0.9183\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.2780 - acc: 0.9195 - val_loss: 0.2678 - val_acc: 0.9204\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.2581 - acc: 0.9254 - val_loss: 0.2481 - val_acc: 0.9271\n",
      "12000/12000 [==============================] - 0s 14us/step\n",
      "Fetching model 2 to keras\n",
      "Evaluating model 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 664)               521240    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 912)               606480    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 912)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 216)               197208    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2170      \n",
      "=================================================================\n",
      "Total params: 1,327,098\n",
      "Trainable params: 1,327,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3481 - acc: 0.8975 - val_loss: 0.1374 - val_acc: 0.9595\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.1103 - acc: 0.9670 - val_loss: 0.0973 - val_acc: 0.9706\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0734 - acc: 0.9770 - val_loss: 0.1021 - val_acc: 0.9690\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 0.0467 - acc: 0.9853 - val_loss: 0.0872 - val_acc: 0.9744\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 0.0311 - acc: 0.9906 - val_loss: 0.0823 - val_acc: 0.9760\n",
      "12000/12000 [==============================] - 0s 15us/step\n",
      "Fetching model 3 to keras\n",
      "Evaluating model 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 272)               213520    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 712)               194376    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1016)              724408    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1016)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 448)               455616    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 576)               258624    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 136)               78472     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1370      \n",
      "=================================================================\n",
      "Total params: 1,926,386\n",
      "Trainable params: 1,926,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 1s 15us/step - loss: 0.5435 - acc: 0.8251 - val_loss: 0.1606 - val_acc: 0.9508\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 0s 8us/step - loss: 0.1425 - acc: 0.9586 - val_loss: 0.1208 - val_acc: 0.9656\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 0s 8us/step - loss: 0.0952 - acc: 0.9723 - val_loss: 0.1265 - val_acc: 0.9639\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 0s 8us/step - loss: 0.0690 - acc: 0.9795 - val_loss: 0.0970 - val_acc: 0.9717\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 0s 8us/step - loss: 0.0506 - acc: 0.9850 - val_loss: 0.1062 - val_acc: 0.9731\n",
      "12000/12000 [==============================] - 0s 16us/step\n",
      "Fetching model 4 to keras\n",
      "Evaluating model 4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 104)               81640     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 104)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 872)               91560     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 872)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 792)               691416    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 336)               266448    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 232)               78184     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                2330      \n",
      "=================================================================\n",
      "Total params: 1,211,578\n",
      "Trainable params: 1,211,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.6181 - acc: 0.7973 - val_loss: 0.2331 - val_acc: 0.9279\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 0.2302 - acc: 0.9298 - val_loss: 0.1486 - val_acc: 0.9537\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 0.1700 - acc: 0.9482 - val_loss: 0.1266 - val_acc: 0.9615\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 0.1402 - acc: 0.9569 - val_loss: 0.1114 - val_acc: 0.9658\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 0.1202 - acc: 0.9634 - val_loss: 0.1008 - val_acc: 0.9690\n",
      "12000/12000 [==============================] - 0s 15us/step\n",
      "\n",
      "Generating offsprings\n",
      "Applying Mutation\n",
      "Launch new generation?: True\n",
      "\n",
      "Generation 2\n",
      "launch new\n",
      "True\n",
      "gen similar\n",
      "False\n",
      "Fetching model 0 to keras\n",
      "Evaluating model 0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 24)                18840     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1016)              25400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10170     \n",
      "=================================================================\n",
      "Total params: 54,410\n",
      "Trainable params: 54,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 0s 8us/step - loss: 0.6761 - acc: 0.8114 - val_loss: 0.3134 - val_acc: 0.9087\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.2720 - acc: 0.9210 - val_loss: 0.2460 - val_acc: 0.9297\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.2147 - acc: 0.9372 - val_loss: 0.2077 - val_acc: 0.9410\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1808 - acc: 0.9476 - val_loss: 0.1798 - val_acc: 0.9459\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.1556 - acc: 0.9545 - val_loss: 0.1658 - val_acc: 0.9517\n",
      "12000/12000 [==============================] - 0s 14us/step\n",
      "Fetching model 1 to keras\n",
      "Evaluating model 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 912)               715920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 912)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 216)               197208    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2170      \n",
      "=================================================================\n",
      "Total params: 915,298\n",
      "Trainable params: 915,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.3604 - acc: 0.8971 - val_loss: 0.1662 - val_acc: 0.9521\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1309 - acc: 0.9616 - val_loss: 0.1178 - val_acc: 0.9634\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0858 - acc: 0.9748 - val_loss: 0.0992 - val_acc: 0.9711\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0616 - acc: 0.9817 - val_loss: 0.0865 - val_acc: 0.9747\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0465 - acc: 0.9861 - val_loss: 0.0887 - val_acc: 0.9743\n",
      "12000/12000 [==============================] - 0s 14us/step\n",
      "Fetching model 2 to keras\n",
      "Evaluating model 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 408)               320280    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 216)               88344     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2170      \n",
      "=================================================================\n",
      "Total params: 410,794\n",
      "Trainable params: 410,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 0s 8us/step - loss: 1.0393 - acc: 0.7526 - val_loss: 0.4572 - val_acc: 0.8869\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.3678 - acc: 0.9017 - val_loss: 0.3133 - val_acc: 0.9118\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.2851 - acc: 0.9185 - val_loss: 0.2669 - val_acc: 0.9238\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.2451 - acc: 0.9291 - val_loss: 0.2380 - val_acc: 0.9310\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.2161 - acc: 0.9371 - val_loss: 0.2125 - val_acc: 0.9381\n",
      "12000/12000 [==============================] - 0s 13us/step\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Input can be of 3 types, ANN (1), CNN (2) or RNN (3)\"\"\"\n",
    "architecture_type = Layers.FullyConnected\n",
    "problem_type = 2  #1 for regression, 2 for classification\n",
    "output_shape = 10 #If regression applies, number of classes\n",
    "input_shape = (784,)\n",
    "pop_size = 5\n",
    "tournament_size = 3\n",
    "max_similar = 3\n",
    "total_experiments = 5\n",
    "count_experiments = 0\n",
    "unroll = True\n",
    "\n",
    "global_best_list = []\n",
    "global_best = None\n",
    "global_best_index = 0\n",
    "\n",
    "learningRate_scheduler = LearningRateScheduler(aux_functions.step_decay)\n",
    "\n",
    "scaler = None\n",
    "\n",
    "t = datetime.datetime.now()\n",
    "\n",
    "logging.basicConfig(filename='logs/nn_evolution_mnist_' + t.strftime('%m%d%Y%H%M%S') + '.log', level=logging.INFO, \n",
    "                        format='%(levelname)s:%(threadName)s:%(message)s', datefmt='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "#mnist datahandler\n",
    "dHandler_mnist = MNISTDataHandler()\n",
    "\n",
    "config = Configuration(architecture_type, problem_type, input_shape, output_shape, pop_size, \n",
    "                       tournament_size, max_similar, epochs=5, cross_val=0.2, size_scaler=size_scaler,\n",
    "                       max_generations=10, binary_selection=True, mutation_ratio=0.4, \n",
    "                       similarity_threshold=0.2, more_layers_prob=0.8)\n",
    "\n",
    "while count_experiments < total_experiments:\n",
    "    print(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    logging.info(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    \n",
    "    best = automatic_model_selection.run_experiment(config, dHandler_mnist, count_experiments + 1, unroll=unroll,\n",
    "                                                    learningRate_scheduler=learningRate_scheduler, \n",
    "                                                    tModel_scaler=scaler, verbose_data=0)\n",
    "\n",
    "    best.individual_label = count_experiments\n",
    "    \n",
    "    global_best_list.append(best)\n",
    "\n",
    "    if global_best == None:\n",
    "        global_best = best\n",
    "    else:\n",
    "        if best.fitness < global_best.fitness:\n",
    "            global_best = best\n",
    "            global_best_index = count_experiments\n",
    "\n",
    "    count_experiments =  count_experiments + 1\n",
    "\n",
    "print(\"Global best list\\n\")\n",
    "logging.info(\"Global best list\\n\")\n",
    "automatic_model_selection.print_best(global_best_list)\n",
    "\n",
    "print(\"Global best is\\n\")\n",
    "print(global_best)\n",
    "logging.info(\"Global best is\\n\")\n",
    "logging.info(global_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_best_models(global_best_list, global_best_index, 'best_models/mnist/alpha{}/'.format(size_scaler), \n",
    "                 input_shape=input_shape, data_handler=dHandler_mnist, problem_type=problem_type, train_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Input can be of 3 types, ANN (1), CNN (2) or RNN (3)\"\"\"\n",
    "architecture_type = Layers.FullyConnected\n",
    "problem_type = 2  #1 for regression, 2 for classification\n",
    "output_shape = 10 #If regression applies, number of classes\n",
    "input_shape = (3072,)\n",
    "pop_size = 5\n",
    "tournament_size = 3\n",
    "max_similar = 3\n",
    "total_experiments = 5\n",
    "count_experiments = 0\n",
    "unroll = True\n",
    "\n",
    "global_best_list = []\n",
    "global_best = None\n",
    "global_best_index = 0\n",
    "\n",
    "scaler = None\n",
    "\n",
    "t = datetime.datetime.now()\n",
    "\n",
    "logging.basicConfig(filename='logs/nn_evolution_cifar10_' + t.strftime('%m%d%Y%H%M%S') + '.log', level=logging.INFO, \n",
    "                        format='%(levelname)s:%(threadName)s:%(message)s', datefmt='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "#mnist datahandler\n",
    "dHandler_cifar = CIFAR10DataHandler()\n",
    "\n",
    "config = Configuration(architecture_type, problem_type, input_shape, output_shape, pop_size, tournament_size, max_similar, epochs=5, cross_val=0.2, size_scaler=0.4,\n",
    "                       max_generations=10, binary_selection=True, mutation_ratio=0.4, similarity_threshold=0.2, more_layers_prob=0.8)\n",
    "\n",
    "while count_experiments < total_experiments:\n",
    "    print(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    logging.info(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    \n",
    "    best = automatic_model_selection.run_experiment(config, dHandler_cifar, count_experiments + 1, unroll=unroll,\n",
    "                                                    learningRate_scheduler=learningRate_scheduler, \n",
    "                                                    tModel_scaler=scaler, verbose_data=0)\n",
    "    \n",
    "    best.individual_label = count_experiments\n",
    "\n",
    "    global_best_list.append(best)\n",
    "\n",
    "    if global_best == None:\n",
    "        global_best = best\n",
    "    else:\n",
    "        if best.fitness < global_best.fitness:\n",
    "            global_best = best\n",
    "            global_best_index = count_experiments\n",
    "\n",
    "    count_experiments =  count_experiments + 1\n",
    "\n",
    "print(\"Global best list\\n\")\n",
    "logging.info(\"Global best list\\n\")\n",
    "automatic_model_selection.print_best(global_best_list)\n",
    "\n",
    "print(\"Global best is\\n\")\n",
    "print(global_best)\n",
    "logging.info(\"Global best is\\n\")\n",
    "logging.info(global_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_best_models(global_best_list, global_best_index, 'best_models/cifar10/alpha{}/'.format(size_scaler), \n",
    "                 input_shape=input_shape, data_handler=dHandler_cifar, problem_type=problem_type, train_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test on CMAPSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Input can be of 3 types, ANN (1), CNN (2) or RNN (3)\"\"\"\n",
    "architecture_type = Layers.FullyConnected\n",
    "problem_type = 1  #1 for regression, 2 for classification\n",
    "output_shape = 1 #If regression applies, number of classes\n",
    "input_shape = None\n",
    "pop_size = 5\n",
    "tournament_size = 3\n",
    "max_similar = 3\n",
    "total_experiments = 5\n",
    "count_experiments = 0\n",
    "unroll = True\n",
    "\n",
    "global_best_list = []\n",
    "global_best = None\n",
    "global_best_index = 0\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "t = datetime.datetime.now()\n",
    "\n",
    "logging.basicConfig(filename='logs/nn_evolution_cmaps_' + t.strftime('%m%d%Y%H%M%S') + '.log', level=logging.INFO, \n",
    "                        format='%(levelname)s:%(threadName)s:%(message)s', datefmt='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "#cmaps datahandler\n",
    "dhandler_cmaps, input_shape = cmaps_dhandler()\n",
    "print(input_shape)\n",
    "\n",
    "#mnist datahandler\n",
    "#dHandler_mnist = MNISTDataHandler()\n",
    "\n",
    "config = Configuration(architecture_type, problem_type, input_shape, output_shape, pop_size, tournament_size, max_similar, epochs=5, cross_val=0.2, size_scaler=0.4,\n",
    "                       max_generations=10, binary_selection=True, mutation_ratio=0.4, similarity_threshold=0.2, more_layers_prob=0.8)\n",
    "\n",
    "while count_experiments < total_experiments:\n",
    "    print(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    logging.info(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    \n",
    "    best = automatic_model_selection.run_experiment(config, dhandler_cmaps, count_experiments + 1, unroll=unroll,\n",
    "                                                    learningRate_scheduler=learningRate_scheduler, \n",
    "                                                    tModel_scaler=scaler, verbose_data=0)\n",
    "    \n",
    "    best.individual_label = count_experiments\n",
    "\n",
    "    global_best_list.append(best)\n",
    "\n",
    "    if global_best == None:\n",
    "        global_best = best\n",
    "    else:\n",
    "        if best.fitness < global_best.fitness:\n",
    "            global_best = best\n",
    "            global_best_index = count_experiments\n",
    "\n",
    "    count_experiments =  count_experiments + 1\n",
    "\n",
    "print(\"Global best list\\n\")\n",
    "logging.info(\"Global best list\\n\")\n",
    "automatic_model_selection.print_best(global_best_list)\n",
    "\n",
    "print(\"Global best is\\n\")\n",
    "print(global_best)\n",
    "logging.info(\"Global best is\\n\")\n",
    "logging.info(global_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_best_models(global_best_list, global_best_index, 'best_models/cmapss/alpha{}/'.format(size_scaler), \n",
    "                 input_shape=input_shape, data_handler=dhandler_cmaps, problem_type=problem_type, train_epochs=100, \n",
    "                 data_scaler=scaler, metrics=['rhs', 'rmse'], round=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
