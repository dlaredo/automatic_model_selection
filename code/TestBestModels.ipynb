{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Best Models\n",
    "\n",
    "Test notebook to generate the statistics of the different models found with AMS. First load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import stats\n",
    "\n",
    "#sys.path.append('/Users/davidlaredorazo/Documents/University_of_California/Research/Projects')\n",
    "sys.path.append('/media/controlslab/DATA/Projects')\n",
    "\n",
    "import ann_framework.aux_functions as aux_functions\n",
    "\n",
    "import automatic_model_selection\n",
    "from automatic_model_selection import Configuration\n",
    "from ann_encoding_rules import Layers\n",
    "import fetch_to_keras\n",
    "#from CMAPSAuxFunctions import TrainValTensorBoard\n",
    "\n",
    "#Tunable model\n",
    "from ann_framework.tunable_model.tunable_model import SequenceTunableModelRegression, SequenceTunableModelClassification\n",
    "\n",
    "#Data handlers\n",
    "from ann_framework.data_handlers.data_handler_CMAPSS import CMAPSSDataHandler\n",
    "from ann_framework.data_handlers.data_handler_MNIST import MNISTDataHandler\n",
    "from ann_framework.data_handlers.data_handler_CIFAR10 import CIFAR10DataHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given a model, get the compiled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model(model, problem_type, optimizer_params=[]):\n",
    "    \"\"\"Obtain a keras compiled model\"\"\"\n",
    "    \n",
    "    #Shared parameters for the models\n",
    "    optimizer = Adam(lr=0.001, beta_1=0.5)\n",
    "    \n",
    "    if problem_type == 1:\n",
    "        lossFunction = \"mean_squared_error\"\n",
    "        metrics = [\"mse\"]\n",
    "    elif problem_type == 2:\n",
    "        lossFunction = \"categorical_crossentropy\"\n",
    "        metrics = [\"accuracy\"]\n",
    "    else:\n",
    "        print(\"Problem type not defined\")\n",
    "        model = None\n",
    "        return\n",
    "    \n",
    "    #Create and compile the models\n",
    "    model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_tunable_model(model_genotype, problem_type, input_shape, data_handler, model_number):\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    model = fetch_to_keras.decode_genotype(model_genotype, problem_type, input_shape, 1)\n",
    "    \n",
    "    model = get_compiled_model(model, problem_type, optimizer_params=[])\n",
    "    \n",
    "    if problem_type == 1:\n",
    "        tModel = SequenceTunableModelRegression('ModelReg_SN_'+str(model_number), model, lib_type='keras', data_handler=data_handler)\n",
    "    else:\n",
    "        tModel = SequenceTunableModelClassification('ModelClass_SN_'+str(model_number), model, lib_type='keras', data_handler=data_handler)\n",
    "        \n",
    "    return tModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cmaps data handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmapss_dhandler(data_scaler=None):\n",
    "\n",
    "    #Selected as per CNN paper\n",
    "    features = ['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', 'BPR', \n",
    "    'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "    selected_indices = np.array([2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21])\n",
    "    selected_features = list(features[i] for i in selected_indices-1)\n",
    "    data_folder = '../CMAPSSData'\n",
    "\n",
    "    window_size = 24\n",
    "    window_stride = 1\n",
    "    max_rul = 129\n",
    "\n",
    "    dhandler_cmapss = CMAPSSDataHandler(data_folder, 1, selected_features,\n",
    "                                       max_rul, window_size, window_stride, data_scaler=data_scaler)\n",
    "\n",
    "    input_shape = (len(selected_features)*window_size, )\n",
    "\n",
    "    return dhandler_cmapss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_file, weights_file=\"\", problem_type=1):\n",
    "    \n",
    "    p_type = \"\"\n",
    "    \n",
    "    # load json and create model\n",
    "    json_file = open(model_file, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    print(\"Loaded model from disk\") \n",
    "        \n",
    "    #Load weights if specified\n",
    "    if weights_file != \"\":\n",
    "        # load weights into new model\n",
    "        loaded_model.load_weights(weights_file)\n",
    "        print(\"Loaded weights from disk\") \n",
    "    else:\n",
    "        print(\"Model needs training\")\n",
    "        \n",
    "    optimizer = Adam(lr=0.001, beta_1=0.5)\n",
    "    \n",
    "    if problem_type == 1:\n",
    "        p_type = \"regression\"\n",
    "        lossFunction = \"mean_squared_error\"\n",
    "        metrics = [\"mse\"]\n",
    "    elif problem_type == 2:\n",
    "        p_type = \"classification\"\n",
    "        lossFunction = \"categorical_crossentropy\"\n",
    "        metrics = [\"accuracy\"]\n",
    "    else:\n",
    "        print(\"Problem type not defined\")\n",
    "        model = None\n",
    "        return\n",
    "    \n",
    "    #Create and compile the models\n",
    "    loaded_model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    print(\"Created model for \" + p_type + \" with loss function \" + lossFunction)\n",
    "\n",
    "    return loaded_model\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load each of the models and test them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_folder = 'best_models'\n",
    "\"\"\"\n",
    "test_sets = {'cifar10':(CIFAR10DataHandler, None, 2), \n",
    "             'cmapss':(cmaps_dhandler, MinMaxScaler(feature_range=(-1, 1)), 1), \n",
    "             'mnist':(MNISTDataHandler, None, 2)}\n",
    "\"\"\"\n",
    "\n",
    "test_sets = {'cmapss':(cmapss_dhandler, MinMaxScaler(feature_range=(-1, 1)), 1)}\n",
    "#test_sets = {'mnist':(MNISTDataHandler, None, 2)}\n",
    "#alpha_folders = ['alpha0.6', 'alpha0.8', 'alpha1']\n",
    "#alpha_folders = ['alpha0.5']\n",
    "#alpha_values = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "results = {}\n",
    "\n",
    "k = 5  #For 5-fold cross validation\n",
    "evaluations_cv = np.zeros(k)\n",
    "evaluations_test = np.zeros(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for yulin/alpha0.2/bestModel_global.json\n",
      "Loading data for dataset 1 with window_size of 24, stride of 1 and maxRUL of 129. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(18331, 336)\n",
      "(18331, 1)\n",
      "Testing data (X, y)\n",
      "(100, 336)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.63253012 -0.18639634 -0.38048616 ... -0.33333333  0.33333333\n",
      "   0.31289699]\n",
      " [-0.43373494 -0.09396119 -0.29473329 ... -0.16666667  0.25581395\n",
      "   0.47638774]\n",
      " [-0.31325301 -0.26095487 -0.25894666 ...  0.          0.11627907\n",
      "   0.43800055]\n",
      " [-0.31325301 -0.48768258 -0.33760972 ... -0.16666667  0.31782946\n",
      "   0.52720243]\n",
      " [-0.30120482 -0.48506649 -0.19074949 ... -0.66666667  0.34883721\n",
      "   0.07677437]]\n",
      "[[129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]]\n",
      "Testing data (X, y)\n",
      "[[-0.19879518 -0.5705254  -0.37069548 ... -0.16666667  0.03875969\n",
      "   0.27312897]\n",
      " [-0.21686747 -0.30237628 -0.12086428 ... -0.5         0.03875969\n",
      "   0.01518917]\n",
      " [-0.04216867 -0.1942446  -0.0209318  ...  0.16666667  0.2248062\n",
      "   0.04888152]\n",
      " [-0.22891566 -0.01722259 -0.13673194 ...  0.16666667 -0.31782946\n",
      "   0.004971  ]\n",
      " [-0.11445783 -0.11968607  0.03511141 ...  0.         -0.05426357\n",
      "   0.42916321]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n",
      "Validation on model:best_models/cmapss/yulin/alpha0.2/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 168)               56616     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 872)               147368    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 873       \n",
      "=================================================================\n",
      "Total params: 204,857\n",
      "Trainable params: 204,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14664/14664 [==============================] - 1s 37us/step - loss: 2894.6030 - mean_squared_error: 2894.6030\n",
      "Epoch 2/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 434.0389 - mean_squared_error: 434.0389\n",
      "Epoch 3/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 336.5986 - mean_squared_error: 336.5986\n",
      "Epoch 4/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 290.4659 - mean_squared_error: 290.4659\n",
      "Epoch 5/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 277.0789 - mean_squared_error: 277.0789\n",
      "Epoch 6/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 256.3321 - mean_squared_error: 256.3321\n",
      "Epoch 7/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 249.5888 - mean_squared_error: 249.5888\n",
      "Epoch 8/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 243.4661 - mean_squared_error: 243.4661\n",
      "Epoch 9/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 247.8803 - mean_squared_error: 247.8803\n",
      "Epoch 10/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 253.3998 - mean_squared_error: 253.3998\n",
      "Epoch 11/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 235.7679 - mean_squared_error: 235.7679\n",
      "Epoch 12/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 237.3801 - mean_squared_error: 237.3801\n",
      "Epoch 13/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 240.8198 - mean_squared_error: 240.8198\n",
      "Epoch 14/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 238.5414 - mean_squared_error: 238.5414\n",
      "Epoch 15/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 236.2693 - mean_squared_error: 236.2693\n",
      "Epoch 16/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 249.3268 - mean_squared_error: 249.3268\n",
      "Epoch 17/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 237.2490 - mean_squared_error: 237.2490\n",
      "Epoch 18/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 229.9960 - mean_squared_error: 229.9960\n",
      "Epoch 19/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 233.9321 - mean_squared_error: 233.9321\n",
      "Epoch 20/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 229.0524 - mean_squared_error: 229.0524\n",
      "Epoch 21/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 229.8992 - mean_squared_error: 229.8992\n",
      "Epoch 22/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 227.8632 - mean_squared_error: 227.8632\n",
      "Epoch 23/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 226.4640 - mean_squared_error: 226.4640\n",
      "Epoch 24/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 228.6551 - mean_squared_error: 228.6551\n",
      "Epoch 25/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 231.0331 - mean_squared_error: 231.0331\n",
      "Epoch 26/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 223.4435 - mean_squared_error: 223.4435\n",
      "Epoch 27/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 233.8544 - mean_squared_error: 233.8544\n",
      "Epoch 28/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 231.4452 - mean_squared_error: 231.4452\n",
      "Epoch 29/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 225.9483 - mean_squared_error: 225.9483\n",
      "Epoch 30/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 224.3044 - mean_squared_error: 224.3044\n",
      "Epoch 31/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 225.9642 - mean_squared_error: 225.9642\n",
      "Epoch 32/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 218.5182 - mean_squared_error: 218.5182\n",
      "Epoch 33/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 219.7351 - mean_squared_error: 219.7351\n",
      "Epoch 34/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 229.9020 - mean_squared_error: 229.9020\n",
      "Epoch 35/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 218.3844 - mean_squared_error: 218.3844\n",
      "Epoch 36/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 224.1134 - mean_squared_error: 224.1134\n",
      "Epoch 37/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 236.4363 - mean_squared_error: 236.4363\n",
      "Epoch 38/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 224.7183 - mean_squared_error: 224.7183\n",
      "Epoch 39/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 213.3007 - mean_squared_error: 213.3007\n",
      "Epoch 40/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 212.0949 - mean_squared_error: 212.0949\n",
      "Epoch 41/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 216.1262 - mean_squared_error: 216.1262\n",
      "Epoch 42/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 218.2178 - mean_squared_error: 218.2178\n",
      "Epoch 43/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 218.9385 - mean_squared_error: 218.9385\n",
      "Epoch 44/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 211.2101 - mean_squared_error: 211.2101\n",
      "Epoch 45/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 210.7707 - mean_squared_error: 210.7707\n",
      "Epoch 46/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 207.0468 - mean_squared_error: 207.0468\n",
      "Epoch 47/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 210.3471 - mean_squared_error: 210.3471\n",
      "Epoch 48/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 210.6424 - mean_squared_error: 210.6424\n",
      "Epoch 49/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 208.5402 - mean_squared_error: 208.5402\n",
      "Epoch 50/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 207.8020 - mean_squared_error: 207.8020\n",
      "Epoch 51/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 207.4405 - mean_squared_error: 207.4405\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14664/14664 [==============================] - 0s 3us/step - loss: 200.1436 - mean_squared_error: 200.1436\n",
      "Epoch 53/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 204.4706 - mean_squared_error: 204.4706\n",
      "Epoch 54/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 207.9080 - mean_squared_error: 207.9080\n",
      "Epoch 55/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 205.9071 - mean_squared_error: 205.9071\n",
      "Epoch 56/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 198.8483 - mean_squared_error: 198.8483\n",
      "Epoch 57/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 212.4190 - mean_squared_error: 212.4190\n",
      "Epoch 58/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 203.1515 - mean_squared_error: 203.1515\n",
      "Epoch 59/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 202.0407 - mean_squared_error: 202.0407\n",
      "Epoch 60/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 201.2846 - mean_squared_error: 201.2846\n",
      "Epoch 61/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 201.4785 - mean_squared_error: 201.4785\n",
      "Epoch 62/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 195.1744 - mean_squared_error: 195.1744\n",
      "Epoch 63/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 197.3037 - mean_squared_error: 197.3037\n",
      "Epoch 64/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 186.2458 - mean_squared_error: 186.2458\n",
      "Epoch 65/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 187.4285 - mean_squared_error: 187.4285\n",
      "Epoch 66/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 195.0361 - mean_squared_error: 195.0361\n",
      "Epoch 67/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 187.2483 - mean_squared_error: 187.2483\n",
      "Epoch 68/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 197.6951 - mean_squared_error: 197.6951\n",
      "Epoch 69/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 188.8267 - mean_squared_error: 188.8267\n",
      "Epoch 70/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 180.7075 - mean_squared_error: 180.7075\n",
      "Epoch 71/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 219.3441 - mean_squared_error: 219.3441\n",
      "Epoch 72/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 185.2103 - mean_squared_error: 185.2103\n",
      "Epoch 73/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 181.4079 - mean_squared_error: 181.4079\n",
      "Epoch 74/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 182.8736 - mean_squared_error: 182.8736\n",
      "Epoch 75/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 177.9399 - mean_squared_error: 177.9399\n",
      "Epoch 76/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 177.5182 - mean_squared_error: 177.5182\n",
      "Epoch 77/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 180.0314 - mean_squared_error: 180.0314\n",
      "Epoch 78/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 172.1351 - mean_squared_error: 172.1351\n",
      "Epoch 79/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 172.3135 - mean_squared_error: 172.3135\n",
      "Epoch 80/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 180.9569 - mean_squared_error: 180.9569\n",
      "Epoch 81/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 176.6204 - mean_squared_error: 176.6204\n",
      "Epoch 82/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 181.9777 - mean_squared_error: 181.9777\n",
      "Epoch 83/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 176.2876 - mean_squared_error: 176.2876\n",
      "Epoch 84/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 168.0016 - mean_squared_error: 168.0016\n",
      "Epoch 85/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 173.5354 - mean_squared_error: 173.5354\n",
      "Epoch 86/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 163.5142 - mean_squared_error: 163.5142\n",
      "Epoch 87/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 194.2966 - mean_squared_error: 194.2966\n",
      "Epoch 88/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 164.4429 - mean_squared_error: 164.4429\n",
      "Epoch 89/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 169.5065 - mean_squared_error: 169.5065\n",
      "Epoch 90/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 160.4689 - mean_squared_error: 160.4689\n",
      "Epoch 91/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 171.5228 - mean_squared_error: 171.5228\n",
      "Epoch 92/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 165.5613 - mean_squared_error: 165.5613\n",
      "Epoch 93/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 162.4222 - mean_squared_error: 162.4222\n",
      "Epoch 94/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 156.7054 - mean_squared_error: 156.7054\n",
      "Epoch 95/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 166.7728 - mean_squared_error: 166.7728\n",
      "Epoch 96/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 170.0607 - mean_squared_error: 170.0607\n",
      "Epoch 97/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 163.7487 - mean_squared_error: 163.7487\n",
      "Epoch 98/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 157.7315 - mean_squared_error: 157.7315\n",
      "Epoch 99/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 164.4720 - mean_squared_error: 164.4720\n",
      "Epoch 100/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 155.5224 - mean_squared_error: 155.5224\n",
      "3667/3667 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 20us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 168)               56616     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 872)               147368    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 873       \n",
      "=================================================================\n",
      "Total params: 204,857\n",
      "Trainable params: 204,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 11us/step - loss: 2996.3122 - mean_squared_error: 2996.3122\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 446.7853 - mean_squared_error: 446.7853\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 338.0903 - mean_squared_error: 338.0903\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 290.7550 - mean_squared_error: 290.7550\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 272.0450 - mean_squared_error: 272.0450\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 256.3880 - mean_squared_error: 256.3880\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 256.1741 - mean_squared_error: 256.1741\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 241.8231 - mean_squared_error: 241.8231\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.1328 - mean_squared_error: 242.1328\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.5368 - mean_squared_error: 242.5368\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.0609 - mean_squared_error: 238.0609\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.8898 - mean_squared_error: 234.8898\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 237.4788 - mean_squared_error: 237.4788\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.8196 - mean_squared_error: 238.8196\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.4135 - mean_squared_error: 233.4135\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 235.3252 - mean_squared_error: 235.3252\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.9366 - mean_squared_error: 228.9366\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.1452 - mean_squared_error: 236.1452\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.8681 - mean_squared_error: 226.8681\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.0961 - mean_squared_error: 227.0961\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.4044 - mean_squared_error: 230.4044\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.1452 - mean_squared_error: 225.1452\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.3556 - mean_squared_error: 223.3556\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.3188 - mean_squared_error: 228.3188\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.2737 - mean_squared_error: 229.2737\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.2752 - mean_squared_error: 223.2752\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.9369 - mean_squared_error: 229.9369\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.6272 - mean_squared_error: 220.6272\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.6583 - mean_squared_error: 225.6583\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.0359 - mean_squared_error: 216.0359\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.9575 - mean_squared_error: 225.9575\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.7489 - mean_squared_error: 215.7489\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.1321 - mean_squared_error: 224.1321\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.4368 - mean_squared_error: 218.4368\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.1723 - mean_squared_error: 219.1723\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.2017 - mean_squared_error: 217.2017\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.2375 - mean_squared_error: 219.2375\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.0203 - mean_squared_error: 210.0203\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.7958 - mean_squared_error: 209.7958\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.0468 - mean_squared_error: 214.0468\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.8145 - mean_squared_error: 208.8145\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.9503 - mean_squared_error: 216.9503\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.1638 - mean_squared_error: 215.1638\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.6430 - mean_squared_error: 205.6430\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.2249 - mean_squared_error: 205.2249\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.3970 - mean_squared_error: 205.3970\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.5976 - mean_squared_error: 211.5976\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.7658 - mean_squared_error: 204.7658\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.0628 - mean_squared_error: 208.0628\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.9909 - mean_squared_error: 210.9909\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.5067 - mean_squared_error: 200.5067\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.9828 - mean_squared_error: 193.9828\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.4696 - mean_squared_error: 200.4696\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.4169 - mean_squared_error: 201.4169\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.1339 - mean_squared_error: 196.1339\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.2391 - mean_squared_error: 200.2391\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.7657 - mean_squared_error: 191.7657\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.6409 - mean_squared_error: 199.6409\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.0134 - mean_squared_error: 193.0134\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.0363 - mean_squared_error: 192.0363\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.1389 - mean_squared_error: 193.1389\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.0373 - mean_squared_error: 195.0373\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.0967 - mean_squared_error: 195.0967\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.4873 - mean_squared_error: 189.4873\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.2958 - mean_squared_error: 193.2958\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.5800 - mean_squared_error: 189.5800\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.8885 - mean_squared_error: 202.8885\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.9748 - mean_squared_error: 189.9748\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.2594 - mean_squared_error: 178.2594\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.3558 - mean_squared_error: 183.3558\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.4456 - mean_squared_error: 185.4456\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.3231 - mean_squared_error: 183.3231\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.9609 - mean_squared_error: 172.9609\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.2311 - mean_squared_error: 184.2311\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.0061 - mean_squared_error: 177.0061\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.7296 - mean_squared_error: 175.7296\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.1218 - mean_squared_error: 189.1218\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.5844 - mean_squared_error: 184.5844\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.1030 - mean_squared_error: 176.1030\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.8273 - mean_squared_error: 171.8273\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.4482 - mean_squared_error: 173.4482\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.0755 - mean_squared_error: 174.0755\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.0029 - mean_squared_error: 174.0029\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.6190 - mean_squared_error: 168.6190\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.9834 - mean_squared_error: 181.9834\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.5892 - mean_squared_error: 170.5892\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 161.7732 - mean_squared_error: 161.7732\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.2930 - mean_squared_error: 168.2930\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 163.4871 - mean_squared_error: 163.4871\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.2967 - mean_squared_error: 168.2967\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.6176 - mean_squared_error: 160.6176\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.0251 - mean_squared_error: 158.0251\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.1477 - mean_squared_error: 164.1477\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.7881 - mean_squared_error: 162.7881\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.6577 - mean_squared_error: 157.6577\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.2221 - mean_squared_error: 171.2221\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.7940 - mean_squared_error: 165.7940\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 152.4082 - mean_squared_error: 152.4082\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.7072 - mean_squared_error: 165.7072\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 151.8210 - mean_squared_error: 151.8210\n",
      "3666/3666 [==============================] - 0s 16us/step\n",
      "100/100 [==============================] - 0s 19us/step\n",
      "\n",
      "Experiment on Fold  2\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 168)               56616     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 872)               147368    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 873       \n",
      "=================================================================\n",
      "Total params: 204,857\n",
      "Trainable params: 204,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 11us/step - loss: 2867.6905 - mean_squared_error: 2867.6905\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 468.2924 - mean_squared_error: 468.2924\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 357.6151 - mean_squared_error: 357.6151\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 295.3904 - mean_squared_error: 295.3904\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 273.7321 - mean_squared_error: 273.7321\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 264.1295 - mean_squared_error: 264.1295\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 259.3751 - mean_squared_error: 259.3751\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 247.6233 - mean_squared_error: 247.6233\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 244.1022 - mean_squared_error: 244.1022\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 241.0361 - mean_squared_error: 241.0361\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.4562 - mean_squared_error: 238.4562\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.2660 - mean_squared_error: 238.2660\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 232.4687 - mean_squared_error: 232.4687\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 237.3428 - mean_squared_error: 237.3428\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.2861 - mean_squared_error: 238.2861\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.1063 - mean_squared_error: 228.1063\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.7451 - mean_squared_error: 234.7451\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.7065 - mean_squared_error: 231.7065\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.6632 - mean_squared_error: 224.6632\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.9107 - mean_squared_error: 236.9107\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.2745 - mean_squared_error: 227.2745\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.5263 - mean_squared_error: 229.5263\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.1674 - mean_squared_error: 233.1674\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.2552 - mean_squared_error: 223.2552\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.9801 - mean_squared_error: 222.9801\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.3637 - mean_squared_error: 223.3637\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.5753 - mean_squared_error: 218.5753\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.5434 - mean_squared_error: 217.5434\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.1725 - mean_squared_error: 223.1725\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.8214 - mean_squared_error: 223.8214\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.7110 - mean_squared_error: 206.7110\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.9219 - mean_squared_error: 218.9219\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 216.1724 - mean_squared_error: 216.1724\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 213.4864 - mean_squared_error: 213.4864\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.0672 - mean_squared_error: 207.0672\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.1260 - mean_squared_error: 208.1260\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.1850 - mean_squared_error: 208.1850\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.7437 - mean_squared_error: 204.7437\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.0762 - mean_squared_error: 207.0762\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.0780 - mean_squared_error: 198.0780\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 207.1541 - mean_squared_error: 207.1541\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.3451 - mean_squared_error: 205.3451\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.7389 - mean_squared_error: 195.7389\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.0093 - mean_squared_error: 204.0093\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.9991 - mean_squared_error: 197.9991\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.0258 - mean_squared_error: 191.0258\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.4652 - mean_squared_error: 193.4652\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.1572 - mean_squared_error: 204.1572\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.6235 - mean_squared_error: 191.6235\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.1397 - mean_squared_error: 195.1397\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.9183 - mean_squared_error: 183.9183\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.3220 - mean_squared_error: 190.3220\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.0819 - mean_squared_error: 190.0819\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.7181 - mean_squared_error: 186.7181\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.0394 - mean_squared_error: 182.0394\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.2909 - mean_squared_error: 191.2909\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.7846 - mean_squared_error: 196.7846\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.2707 - mean_squared_error: 175.2707\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 181.6754 - mean_squared_error: 181.6754\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 185.6186 - mean_squared_error: 185.6186\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.5059 - mean_squared_error: 178.5059\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.3102 - mean_squared_error: 172.3102\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.6624 - mean_squared_error: 183.6624\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.4634 - mean_squared_error: 183.4634\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.9851 - mean_squared_error: 175.9851\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.5923 - mean_squared_error: 168.5923\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.5950 - mean_squared_error: 182.5950\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.8302 - mean_squared_error: 175.8302\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.8417 - mean_squared_error: 169.8417\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.6700 - mean_squared_error: 183.6700\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.2598 - mean_squared_error: 176.2598\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.8648 - mean_squared_error: 164.8648\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.0297 - mean_squared_error: 172.0297\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 161.0705 - mean_squared_error: 161.0705\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.5613 - mean_squared_error: 175.5613\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.8783 - mean_squared_error: 165.8783\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.3901 - mean_squared_error: 157.3901\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.6490 - mean_squared_error: 159.6490\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.5366 - mean_squared_error: 169.5366\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.5186 - mean_squared_error: 168.5186\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.9550 - mean_squared_error: 160.9550\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 161.6875 - mean_squared_error: 161.6875\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.5079 - mean_squared_error: 166.5079\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.6957 - mean_squared_error: 156.6957\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.9126 - mean_squared_error: 160.9126\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 151.4476 - mean_squared_error: 151.4476\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 163.4330 - mean_squared_error: 163.4330\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.2983 - mean_squared_error: 154.2983\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 163.1895 - mean_squared_error: 163.1895\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.4037 - mean_squared_error: 159.4037\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.8610 - mean_squared_error: 157.8610\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.3231 - mean_squared_error: 160.3231\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.9731 - mean_squared_error: 159.9731\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 143.9842 - mean_squared_error: 143.9842\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 147.2780 - mean_squared_error: 147.2780\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 155.1648 - mean_squared_error: 155.1648\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 155.2616 - mean_squared_error: 155.2616\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 145.2833 - mean_squared_error: 145.2833\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 151.7236 - mean_squared_error: 151.7236\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 151.6362 - mean_squared_error: 151.6362\n",
      "3666/3666 [==============================] - 0s 16us/step\n",
      "100/100 [==============================] - 0s 21us/step\n",
      "\n",
      "Experiment on Fold  3\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 168)               56616     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 872)               147368    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 873       \n",
      "=================================================================\n",
      "Total params: 204,857\n",
      "Trainable params: 204,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 15us/step - loss: 3089.4892 - mean_squared_error: 3089.4892\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 457.3376 - mean_squared_error: 457.3376\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 352.7950 - mean_squared_error: 352.7950\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 297.9681 - mean_squared_error: 297.9681\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 274.5042 - mean_squared_error: 274.5042\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 264.7631 - mean_squared_error: 264.7631\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 258.7356 - mean_squared_error: 258.7356\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 249.9519 - mean_squared_error: 249.9519\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 244.5035 - mean_squared_error: 244.5035\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 244.9521 - mean_squared_error: 244.9521\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 239.7816 - mean_squared_error: 239.7816\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 243.8061 - mean_squared_error: 243.8061\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 235.5631 - mean_squared_error: 235.5631\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.7435 - mean_squared_error: 236.7435\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 239.1420 - mean_squared_error: 239.1420\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.1651 - mean_squared_error: 231.1651\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.4995 - mean_squared_error: 231.4995\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.4493 - mean_squared_error: 227.4493\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.3962 - mean_squared_error: 226.3962\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.4245 - mean_squared_error: 229.4245\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.5228 - mean_squared_error: 225.5228\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.7891 - mean_squared_error: 220.7891\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.7675 - mean_squared_error: 220.7675\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.8301 - mean_squared_error: 228.8301\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.7008 - mean_squared_error: 221.7008\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.9452 - mean_squared_error: 219.9452\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.7276 - mean_squared_error: 218.7276\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.5539 - mean_squared_error: 220.5539\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.2034 - mean_squared_error: 214.2034\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.0122 - mean_squared_error: 217.0122\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.8132 - mean_squared_error: 210.8132\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.8177 - mean_squared_error: 216.8177\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.4598 - mean_squared_error: 202.4598\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.2112 - mean_squared_error: 227.2112\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.8995 - mean_squared_error: 210.8995\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.2862 - mean_squared_error: 201.2862\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.3076 - mean_squared_error: 207.3076\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.5593 - mean_squared_error: 200.5593\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.4361 - mean_squared_error: 208.4361\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.8911 - mean_squared_error: 203.8911\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.7076 - mean_squared_error: 205.7076\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.2436 - mean_squared_error: 198.2436\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.6665 - mean_squared_error: 200.6665\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.2733 - mean_squared_error: 201.2733\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.5318 - mean_squared_error: 204.5318\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.0390 - mean_squared_error: 197.0390\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.6069 - mean_squared_error: 199.6069\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.7407 - mean_squared_error: 193.7407\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.4569 - mean_squared_error: 191.4569\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.4937 - mean_squared_error: 194.4937\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.5004 - mean_squared_error: 191.5004\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.6571 - mean_squared_error: 187.6571\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.6432 - mean_squared_error: 195.6432\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.2208 - mean_squared_error: 192.2208\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.3304 - mean_squared_error: 181.3304\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.3898 - mean_squared_error: 180.3898\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.2470 - mean_squared_error: 187.2470\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.0379 - mean_squared_error: 187.0379\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.5253 - mean_squared_error: 178.5253\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.8042 - mean_squared_error: 183.8042\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.6370 - mean_squared_error: 183.6370\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.2480 - mean_squared_error: 177.2480\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.8483 - mean_squared_error: 174.8483\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.0516 - mean_squared_error: 185.0516\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.7348 - mean_squared_error: 177.7348\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.0612 - mean_squared_error: 177.0612\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.7030 - mean_squared_error: 168.7030\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.3632 - mean_squared_error: 177.3632\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.0452 - mean_squared_error: 169.0452\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 167.5712 - mean_squared_error: 167.5712\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.4985 - mean_squared_error: 176.4985\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.3679 - mean_squared_error: 165.3679\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.7893 - mean_squared_error: 176.7893\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 161.8598 - mean_squared_error: 161.8598\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.9680 - mean_squared_error: 170.9680\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.0096 - mean_squared_error: 164.0096\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.9558 - mean_squared_error: 165.9558\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.1314 - mean_squared_error: 180.1314\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.9327 - mean_squared_error: 156.9327\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.5900 - mean_squared_error: 159.5900\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.4528 - mean_squared_error: 157.4528\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.8694 - mean_squared_error: 160.8694\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.1271 - mean_squared_error: 158.1271\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.5524 - mean_squared_error: 165.5524\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 149.0222 - mean_squared_error: 149.0222\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 151.6579 - mean_squared_error: 151.6579\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 150.9851 - mean_squared_error: 150.9851\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 153.5962 - mean_squared_error: 153.5962\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.7952 - mean_squared_error: 157.7952\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 150.7018 - mean_squared_error: 150.7018\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 149.4942 - mean_squared_error: 149.4942\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 142.8763 - mean_squared_error: 142.8763\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 144.3279 - mean_squared_error: 144.3279\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.7966 - mean_squared_error: 194.7966\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 147.1752 - mean_squared_error: 147.1752\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 144.2584 - mean_squared_error: 144.2584\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 147.3463 - mean_squared_error: 147.3463\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 140.1253 - mean_squared_error: 140.1253\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 143.2304 - mean_squared_error: 143.2304\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 141.7839 - mean_squared_error: 141.7839\n",
      "3666/3666 [==============================] - 0s 16us/step\n",
      "100/100 [==============================] - 0s 17us/step\n",
      "\n",
      "Experiment on Fold  4\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 168)               56616     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 872)               147368    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 873       \n",
      "=================================================================\n",
      "Total params: 204,857\n",
      "Trainable params: 204,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 11us/step - loss: 2977.4809 - mean_squared_error: 2977.4809\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 460.1121 - mean_squared_error: 460.1121\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 353.2915 - mean_squared_error: 353.2915\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 301.6348 - mean_squared_error: 301.6348\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 282.0934 - mean_squared_error: 282.0934\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 263.7978 - mean_squared_error: 263.7978\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 256.6183 - mean_squared_error: 256.6183\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 249.7319 - mean_squared_error: 249.7319\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 246.9391 - mean_squared_error: 246.9391\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 248.3830 - mean_squared_error: 248.3830\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 244.8861 - mean_squared_error: 244.8861\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 240.7271 - mean_squared_error: 240.7271\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 243.9179 - mean_squared_error: 243.9179\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.7073 - mean_squared_error: 234.7073\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 240.7004 - mean_squared_error: 240.7004\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.8802 - mean_squared_error: 232.8802\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 237.5986 - mean_squared_error: 237.5986\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.6222 - mean_squared_error: 232.6222\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.0382 - mean_squared_error: 234.0382\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.5426 - mean_squared_error: 227.5426\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.3299 - mean_squared_error: 236.3299\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 239.4982 - mean_squared_error: 239.4982\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.3483 - mean_squared_error: 226.3483\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.4386 - mean_squared_error: 242.4386\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.9472 - mean_squared_error: 221.9472\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.3306 - mean_squared_error: 224.3306\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.6666 - mean_squared_error: 228.6666\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.5603 - mean_squared_error: 215.5603\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.1845 - mean_squared_error: 225.1845\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.0026 - mean_squared_error: 230.0026\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.2637 - mean_squared_error: 216.2637\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.7190 - mean_squared_error: 215.7190\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.6462 - mean_squared_error: 218.6462\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.5930 - mean_squared_error: 214.5930\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.7852 - mean_squared_error: 211.7852\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.0638 - mean_squared_error: 219.0638\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.8812 - mean_squared_error: 218.8812\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.2662 - mean_squared_error: 213.2662\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.9067 - mean_squared_error: 211.9067\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.2319 - mean_squared_error: 208.2319\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.3095 - mean_squared_error: 205.3095\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.9687 - mean_squared_error: 207.9687\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.7957 - mean_squared_error: 205.7957\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.9538 - mean_squared_error: 207.9538\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.2606 - mean_squared_error: 195.2606\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.0558 - mean_squared_error: 212.0558\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.8263 - mean_squared_error: 191.8263\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.5427 - mean_squared_error: 199.5427\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.2645 - mean_squared_error: 191.2645\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.1164 - mean_squared_error: 189.1164\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.5261 - mean_squared_error: 197.5261\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.2964 - mean_squared_error: 199.2964\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.2659 - mean_squared_error: 189.2659\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.6072 - mean_squared_error: 188.6072\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.4266 - mean_squared_error: 186.4266\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.5595 - mean_squared_error: 184.5595\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.6168 - mean_squared_error: 185.6168\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.5195 - mean_squared_error: 196.5195\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.3677 - mean_squared_error: 188.3677\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.5211 - mean_squared_error: 185.5211\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.2648 - mean_squared_error: 187.2648\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.8986 - mean_squared_error: 182.8986\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 187.3940 - mean_squared_error: 187.3940\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.5019 - mean_squared_error: 185.5019\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.9212 - mean_squared_error: 178.9212\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.7703 - mean_squared_error: 181.7703\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.6660 - mean_squared_error: 176.6660\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.6271 - mean_squared_error: 168.6271\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.6051 - mean_squared_error: 169.6051\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.0329 - mean_squared_error: 180.0329\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.0130 - mean_squared_error: 179.0130\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.5007 - mean_squared_error: 174.5007\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 169.3448 - mean_squared_error: 169.3448\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.1035 - mean_squared_error: 174.1035\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.5397 - mean_squared_error: 172.5397\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.8485 - mean_squared_error: 169.8485\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.7216 - mean_squared_error: 169.7216\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 161.4650 - mean_squared_error: 161.4650\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 167.1296 - mean_squared_error: 167.1296\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.1311 - mean_squared_error: 162.1311\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 161.0100 - mean_squared_error: 161.0100\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 163.5369 - mean_squared_error: 163.5369\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.3363 - mean_squared_error: 156.3363\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.3596 - mean_squared_error: 156.3596\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.4588 - mean_squared_error: 159.4588\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 274.9341 - mean_squared_error: 274.9341\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 163.7143 - mean_squared_error: 163.7143\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.0423 - mean_squared_error: 157.0423\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.5279 - mean_squared_error: 156.5279\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.6858 - mean_squared_error: 156.6858\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.2379 - mean_squared_error: 156.2379\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.8389 - mean_squared_error: 157.8389\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 151.6496 - mean_squared_error: 151.6496\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.6320 - mean_squared_error: 154.6320\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 150.2101 - mean_squared_error: 150.2101\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.8435 - mean_squared_error: 157.8435\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 148.7186 - mean_squared_error: 148.7186\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 143.8277 - mean_squared_error: 143.8277\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 144.0197 - mean_squared_error: 144.0197\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 140.1847 - mean_squared_error: 140.1847\n",
      "3666/3666 [==============================] - 0s 16us/step\n",
      "100/100 [==============================] - 0s 20us/step\n",
      "Testing for yulin/alpha0.3/bestModel_global.json\n",
      "Loading data for dataset 1 with window_size of 24, stride of 1 and maxRUL of 129. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(18331, 336)\n",
      "(18331, 1)\n",
      "Testing data (X, y)\n",
      "(100, 336)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.63253012 -0.18639634 -0.38048616 ... -0.33333333  0.33333333\n",
      "   0.31289699]\n",
      " [-0.43373494 -0.09396119 -0.29473329 ... -0.16666667  0.25581395\n",
      "   0.47638774]\n",
      " [-0.31325301 -0.26095487 -0.25894666 ...  0.          0.11627907\n",
      "   0.43800055]\n",
      " [-0.31325301 -0.48768258 -0.33760972 ... -0.16666667  0.31782946\n",
      "   0.52720243]\n",
      " [-0.30120482 -0.48506649 -0.19074949 ... -0.66666667  0.34883721\n",
      "   0.07677437]]\n",
      "[[129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]]\n",
      "Testing data (X, y)\n",
      "[[-0.19879518 -0.5705254  -0.37069548 ... -0.16666667  0.03875969\n",
      "   0.27312897]\n",
      " [-0.21686747 -0.30237628 -0.12086428 ... -0.5         0.03875969\n",
      "   0.01518917]\n",
      " [-0.04216867 -0.1942446  -0.0209318  ...  0.16666667  0.2248062\n",
      "   0.04888152]\n",
      " [-0.22891566 -0.01722259 -0.13673194 ...  0.16666667 -0.31782946\n",
      "   0.004971  ]\n",
      " [-0.11445783 -0.11968607  0.03511141 ...  0.         -0.05426357\n",
      "   0.42916321]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n",
      "Validation on model:best_models/cmapss/yulin/alpha0.3/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 128)               43136     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 616)               79464     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 616)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 617       \n",
      "=================================================================\n",
      "Total params: 123,217\n",
      "Trainable params: 123,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14664/14664 [==============================] - 0s 12us/step - loss: 3388.8690 - mean_squared_error: 3388.8690\n",
      "Epoch 2/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 511.1751 - mean_squared_error: 511.1751\n",
      "Epoch 3/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 385.3430 - mean_squared_error: 385.3430\n",
      "Epoch 4/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 313.9456 - mean_squared_error: 313.9456\n",
      "Epoch 5/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 279.7666 - mean_squared_error: 279.7666\n",
      "Epoch 6/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 272.7009 - mean_squared_error: 272.7009\n",
      "Epoch 7/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 256.6940 - mean_squared_error: 256.6940\n",
      "Epoch 8/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 255.4680 - mean_squared_error: 255.4680\n",
      "Epoch 9/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 255.3202 - mean_squared_error: 255.3202\n",
      "Epoch 10/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 250.6390 - mean_squared_error: 250.6390\n",
      "Epoch 11/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 244.8776 - mean_squared_error: 244.8776\n",
      "Epoch 12/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 241.4064 - mean_squared_error: 241.4064\n",
      "Epoch 13/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 240.7318 - mean_squared_error: 240.7318\n",
      "Epoch 14/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 238.4311 - mean_squared_error: 238.4311\n",
      "Epoch 15/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 238.0519 - mean_squared_error: 238.0519\n",
      "Epoch 16/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 239.0834 - mean_squared_error: 239.0834\n",
      "Epoch 17/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 239.0034 - mean_squared_error: 239.0034\n",
      "Epoch 18/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 233.1691 - mean_squared_error: 233.1691\n",
      "Epoch 19/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 232.9632 - mean_squared_error: 232.9632\n",
      "Epoch 20/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 236.3280 - mean_squared_error: 236.3280\n",
      "Epoch 21/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 237.8443 - mean_squared_error: 237.8443\n",
      "Epoch 22/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 231.0612 - mean_squared_error: 231.0612\n",
      "Epoch 23/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 233.8368 - mean_squared_error: 233.8368\n",
      "Epoch 24/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 226.2196 - mean_squared_error: 226.2196\n",
      "Epoch 25/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 222.0863 - mean_squared_error: 222.0863\n",
      "Epoch 26/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 223.0253 - mean_squared_error: 223.0253\n",
      "Epoch 27/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 227.8316 - mean_squared_error: 227.8316\n",
      "Epoch 28/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 225.4548 - mean_squared_error: 225.4548\n",
      "Epoch 29/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 226.2397 - mean_squared_error: 226.2397\n",
      "Epoch 30/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 220.1437 - mean_squared_error: 220.1437\n",
      "Epoch 31/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 218.6108 - mean_squared_error: 218.6108\n",
      "Epoch 32/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 219.5450 - mean_squared_error: 219.5450\n",
      "Epoch 33/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 220.9435 - mean_squared_error: 220.9435\n",
      "Epoch 34/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 225.3310 - mean_squared_error: 225.3310\n",
      "Epoch 35/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 211.4151 - mean_squared_error: 211.4151\n",
      "Epoch 36/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 222.7382 - mean_squared_error: 222.7382\n",
      "Epoch 37/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 216.3605 - mean_squared_error: 216.3605\n",
      "Epoch 38/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 212.4320 - mean_squared_error: 212.4320\n",
      "Epoch 39/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 210.8584 - mean_squared_error: 210.8584\n",
      "Epoch 40/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 214.3007 - mean_squared_error: 214.3007\n",
      "Epoch 41/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 207.4464 - mean_squared_error: 207.4464\n",
      "Epoch 42/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 214.7982 - mean_squared_error: 214.7982\n",
      "Epoch 43/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 216.1467 - mean_squared_error: 216.1467\n",
      "Epoch 44/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 207.2226 - mean_squared_error: 207.2226\n",
      "Epoch 45/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 201.5533 - mean_squared_error: 201.5533\n",
      "Epoch 46/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 203.0907 - mean_squared_error: 203.0907\n",
      "Epoch 47/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 204.2756 - mean_squared_error: 204.2756\n",
      "Epoch 48/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 200.8388 - mean_squared_error: 200.8388\n",
      "Epoch 49/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 210.9312 - mean_squared_error: 210.9312\n",
      "Epoch 50/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 199.0052 - mean_squared_error: 199.0052\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14664/14664 [==============================] - 0s 4us/step - loss: 197.6242 - mean_squared_error: 197.6242\n",
      "Epoch 52/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 201.8991 - mean_squared_error: 201.8991\n",
      "Epoch 53/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 197.6516 - mean_squared_error: 197.6516\n",
      "Epoch 54/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 199.3125 - mean_squared_error: 199.3125\n",
      "Epoch 55/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 198.6571 - mean_squared_error: 198.6571\n",
      "Epoch 56/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 204.8935 - mean_squared_error: 204.8935\n",
      "Epoch 57/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 201.4631 - mean_squared_error: 201.4631\n",
      "Epoch 58/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 193.5506 - mean_squared_error: 193.5506\n",
      "Epoch 59/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 199.3456 - mean_squared_error: 199.3456\n",
      "Epoch 60/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 199.2778 - mean_squared_error: 199.2778\n",
      "Epoch 61/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 199.3955 - mean_squared_error: 199.3955\n",
      "Epoch 62/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 196.5514 - mean_squared_error: 196.5514\n",
      "Epoch 63/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 195.4721 - mean_squared_error: 195.4721\n",
      "Epoch 64/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 190.3043 - mean_squared_error: 190.3043\n",
      "Epoch 65/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 194.7460 - mean_squared_error: 194.7460\n",
      "Epoch 66/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 190.0196 - mean_squared_error: 190.0196\n",
      "Epoch 67/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 192.7952 - mean_squared_error: 192.7952\n",
      "Epoch 68/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 186.8435 - mean_squared_error: 186.8435\n",
      "Epoch 69/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 184.0587 - mean_squared_error: 184.0587\n",
      "Epoch 70/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 192.5724 - mean_squared_error: 192.5724\n",
      "Epoch 71/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 185.4155 - mean_squared_error: 185.4155\n",
      "Epoch 72/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 187.5584 - mean_squared_error: 187.5584\n",
      "Epoch 73/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 183.3565 - mean_squared_error: 183.3565\n",
      "Epoch 74/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 180.3622 - mean_squared_error: 180.3622\n",
      "Epoch 75/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 186.4325 - mean_squared_error: 186.4325\n",
      "Epoch 76/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 189.2114 - mean_squared_error: 189.2114\n",
      "Epoch 77/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 187.6764 - mean_squared_error: 187.6764\n",
      "Epoch 78/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 184.1465 - mean_squared_error: 184.1465\n",
      "Epoch 79/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 178.1233 - mean_squared_error: 178.1233\n",
      "Epoch 80/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 180.5085 - mean_squared_error: 180.5085\n",
      "Epoch 81/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 188.8329 - mean_squared_error: 188.8329\n",
      "Epoch 82/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 183.2613 - mean_squared_error: 183.2613\n",
      "Epoch 83/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 183.5894 - mean_squared_error: 183.5894\n",
      "Epoch 84/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 178.3301 - mean_squared_error: 178.3301\n",
      "Epoch 85/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 176.7383 - mean_squared_error: 176.7383\n",
      "Epoch 86/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 183.7078 - mean_squared_error: 183.7078\n",
      "Epoch 87/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 182.2505 - mean_squared_error: 182.2505\n",
      "Epoch 88/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 181.1653 - mean_squared_error: 181.1653\n",
      "Epoch 89/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 173.2270 - mean_squared_error: 173.2270\n",
      "Epoch 90/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 179.2659 - mean_squared_error: 179.2659\n",
      "Epoch 91/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 186.9669 - mean_squared_error: 186.9669\n",
      "Epoch 92/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 171.6279 - mean_squared_error: 171.6279\n",
      "Epoch 93/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 171.3037 - mean_squared_error: 171.3037\n",
      "Epoch 94/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 176.3101 - mean_squared_error: 176.3101\n",
      "Epoch 95/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 178.0659 - mean_squared_error: 178.0659\n",
      "Epoch 96/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 180.6198 - mean_squared_error: 180.6198\n",
      "Epoch 97/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 172.3889 - mean_squared_error: 172.3889\n",
      "Epoch 98/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 173.1740 - mean_squared_error: 173.1740\n",
      "Epoch 99/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 171.7221 - mean_squared_error: 171.7221\n",
      "Epoch 100/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 173.4239 - mean_squared_error: 173.4239\n",
      "3667/3667 [==============================] - 0s 18us/step\n",
      "100/100 [==============================] - 0s 20us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 128)               43136     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 616)               79464     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 616)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 617       \n",
      "=================================================================\n",
      "Total params: 123,217\n",
      "Trainable params: 123,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 12us/step - loss: 3364.2329 - mean_squared_error: 3364.2329\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 504.9574 - mean_squared_error: 504.9574\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 381.3953 - mean_squared_error: 381.3953\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 315.1239 - mean_squared_error: 315.1239\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 284.1978 - mean_squared_error: 284.1978\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 273.3776 - mean_squared_error: 273.3776\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 263.1097 - mean_squared_error: 263.1097\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 254.6360 - mean_squared_error: 254.6360\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.4084 - mean_squared_error: 250.4084\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 245.7969 - mean_squared_error: 245.7969\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 250.8316 - mean_squared_error: 250.8316\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 243.9985 - mean_squared_error: 243.9985\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 243.6723 - mean_squared_error: 243.6723\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 237.1544 - mean_squared_error: 237.1544\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 244.4230 - mean_squared_error: 244.4230\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 239.6650 - mean_squared_error: 239.6650\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 238.0721 - mean_squared_error: 238.0721\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 237.4692 - mean_squared_error: 237.4692\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.2287 - mean_squared_error: 233.2287\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 236.5511 - mean_squared_error: 236.5511\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 233.0860 - mean_squared_error: 233.0860\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 234.9932 - mean_squared_error: 234.9932\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.4033 - mean_squared_error: 233.4033\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.0892 - mean_squared_error: 229.0892\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.9126 - mean_squared_error: 229.9126\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 229.6432 - mean_squared_error: 229.6432\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 223.5229 - mean_squared_error: 223.5229\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 222.7100 - mean_squared_error: 222.7100\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 221.6011 - mean_squared_error: 221.6011\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 222.9416 - mean_squared_error: 222.9416\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.6506 - mean_squared_error: 229.6506\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.8120 - mean_squared_error: 214.8120\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.2932 - mean_squared_error: 220.2932\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.0145 - mean_squared_error: 220.0145\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.8973 - mean_squared_error: 215.8973\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.4223 - mean_squared_error: 215.4223\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 218.5473 - mean_squared_error: 218.5473\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 218.3808 - mean_squared_error: 218.3808\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.9455 - mean_squared_error: 206.9455\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 210.0046 - mean_squared_error: 210.0046\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 215.4111 - mean_squared_error: 215.4111\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.6196 - mean_squared_error: 212.6196\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 210.4410 - mean_squared_error: 210.4410\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 206.4376 - mean_squared_error: 206.4376\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 204.2357 - mean_squared_error: 204.2357\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 202.8716 - mean_squared_error: 202.8716\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 203.3622 - mean_squared_error: 203.3622\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 200.7413 - mean_squared_error: 200.7413\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 204.7306 - mean_squared_error: 204.7306\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 202.0312 - mean_squared_error: 202.0312\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 201.1986 - mean_squared_error: 201.1986\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.0028 - mean_squared_error: 203.0028\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 194.1045 - mean_squared_error: 194.1045\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.2564 - mean_squared_error: 198.2564\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.7949 - mean_squared_error: 197.7949\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.4403 - mean_squared_error: 192.4403\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.7870 - mean_squared_error: 196.7870\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 193.3308 - mean_squared_error: 193.3308\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 198.9681 - mean_squared_error: 198.9681\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 189.4148 - mean_squared_error: 189.4148\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.7285 - mean_squared_error: 192.7285\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.8146 - mean_squared_error: 188.8146\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 184.9043 - mean_squared_error: 184.9043\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 212.9070 - mean_squared_error: 212.9070\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 186.7286 - mean_squared_error: 186.7286\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.9089 - mean_squared_error: 183.9089\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 185.9599 - mean_squared_error: 185.9599\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 179.6309 - mean_squared_error: 179.6309\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 191.0457 - mean_squared_error: 191.0457\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.3803 - mean_squared_error: 179.3803\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 182.3700 - mean_squared_error: 182.3700\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.4128 - mean_squared_error: 183.4128\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.0648 - mean_squared_error: 180.0648\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.4820 - mean_squared_error: 188.4820\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 178.0419 - mean_squared_error: 178.0419\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 181.0162 - mean_squared_error: 181.0162\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 177.0135 - mean_squared_error: 177.0135\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.7750 - mean_squared_error: 172.7750\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.1564 - mean_squared_error: 180.1564\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 180.1444 - mean_squared_error: 180.1444\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 176.7341 - mean_squared_error: 176.7341\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 173.9404 - mean_squared_error: 173.9404\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 178.2818 - mean_squared_error: 178.2818\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.6515 - mean_squared_error: 171.6515\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.6372 - mean_squared_error: 180.6372\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.4140 - mean_squared_error: 173.4140\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.2564 - mean_squared_error: 174.2564\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.4805 - mean_squared_error: 168.4805\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 167.8042 - mean_squared_error: 167.8042\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 175.0080 - mean_squared_error: 175.0080\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 183.6465 - mean_squared_error: 183.6465\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.2737 - mean_squared_error: 166.2737\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.2790 - mean_squared_error: 174.2790\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.1187 - mean_squared_error: 171.1187\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 164.4801 - mean_squared_error: 164.4801\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 166.5063 - mean_squared_error: 166.5063\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 165.6884 - mean_squared_error: 165.6884\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 171.2902 - mean_squared_error: 171.2902\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 165.7540 - mean_squared_error: 165.7540\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.5407 - mean_squared_error: 168.5407\n",
      "3666/3666 [==============================] - 0s 17us/step\n",
      "100/100 [==============================] - 0s 22us/step\n",
      "\n",
      "Experiment on Fold  2\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 128)               43136     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 616)               79464     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 616)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 617       \n",
      "=================================================================\n",
      "Total params: 123,217\n",
      "Trainable params: 123,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 12us/step - loss: 3478.5852 - mean_squared_error: 3478.5852\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 503.8881 - mean_squared_error: 503.8881\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 390.4316 - mean_squared_error: 390.4316\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 320.5251 - mean_squared_error: 320.5251\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 291.0256 - mean_squared_error: 291.0256\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 275.1703 - mean_squared_error: 275.1703\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 266.7659 - mean_squared_error: 266.7659\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 260.2267 - mean_squared_error: 260.2267\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.6033 - mean_squared_error: 255.6033\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 252.1657 - mean_squared_error: 252.1657\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 247.0655 - mean_squared_error: 247.0655\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 250.7238 - mean_squared_error: 250.7238\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 239.8711 - mean_squared_error: 239.8711\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.5077 - mean_squared_error: 242.5077\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.7152 - mean_squared_error: 242.7152\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 247.9062 - mean_squared_error: 247.9062\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 247.3906 - mean_squared_error: 247.3906\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 240.5190 - mean_squared_error: 240.5190\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 244.3272 - mean_squared_error: 244.3272\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 238.6818 - mean_squared_error: 238.6818\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 239.9800 - mean_squared_error: 239.9800\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.1003 - mean_squared_error: 232.1003\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.0238 - mean_squared_error: 234.0238\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 236.3801 - mean_squared_error: 236.3801\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 239.4571 - mean_squared_error: 239.4571\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 228.7106 - mean_squared_error: 228.7106\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 235.9260 - mean_squared_error: 235.9260\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.8530 - mean_squared_error: 229.8530\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 227.9615 - mean_squared_error: 227.9615\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 236.1653 - mean_squared_error: 236.1653\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 228.3294 - mean_squared_error: 228.3294\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 229.0638 - mean_squared_error: 229.0638\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 228.8416 - mean_squared_error: 228.8416\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 225.6659 - mean_squared_error: 225.6659\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.2648 - mean_squared_error: 226.2648\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.2059 - mean_squared_error: 224.2059\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 4us/step - loss: 224.3312 - mean_squared_error: 224.3312\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.8989 - mean_squared_error: 228.8989\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 224.5362 - mean_squared_error: 224.5362\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 217.9347 - mean_squared_error: 217.9347\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.5985 - mean_squared_error: 223.5985\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 218.4346 - mean_squared_error: 218.4346\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.7195 - mean_squared_error: 221.7195\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.1432 - mean_squared_error: 222.1432\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.9306 - mean_squared_error: 219.9306\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 219.0645 - mean_squared_error: 219.0645\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.8314 - mean_squared_error: 213.8314\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.7565 - mean_squared_error: 220.7565\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.4305 - mean_squared_error: 214.4305\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.4445 - mean_squared_error: 216.4445\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 214.0133 - mean_squared_error: 214.0133\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.9190 - mean_squared_error: 213.9190\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.3851 - mean_squared_error: 216.3851\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 212.8387 - mean_squared_error: 212.8387\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 209.8972 - mean_squared_error: 209.8972\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.7231 - mean_squared_error: 205.7231\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.7170 - mean_squared_error: 204.7170\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 209.1889 - mean_squared_error: 209.1889\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 201.3936 - mean_squared_error: 201.3936\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.3371 - mean_squared_error: 201.3371\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 204.8972 - mean_squared_error: 204.8972\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.6742 - mean_squared_error: 210.6742\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 197.9835 - mean_squared_error: 197.9835\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.5948 - mean_squared_error: 205.5948\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 201.7383 - mean_squared_error: 201.7383\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 200.6176 - mean_squared_error: 200.6176\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 200.1276 - mean_squared_error: 200.1276\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 196.9755 - mean_squared_error: 196.9755\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.3909 - mean_squared_error: 203.3909\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.5755 - mean_squared_error: 199.5755\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 196.4647 - mean_squared_error: 196.4647\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.8859 - mean_squared_error: 191.8859\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.9526 - mean_squared_error: 202.9526\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.3177 - mean_squared_error: 191.3177\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.3327 - mean_squared_error: 192.3327\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 188.7376 - mean_squared_error: 188.7376\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 192.7177 - mean_squared_error: 192.7177\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 197.3222 - mean_squared_error: 197.3222\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 189.3242 - mean_squared_error: 189.3242\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.1928 - mean_squared_error: 199.1928\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.6071 - mean_squared_error: 182.6071\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 186.3815 - mean_squared_error: 186.3815\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.9932 - mean_squared_error: 187.9932\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.5261 - mean_squared_error: 189.5261\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 183.6897 - mean_squared_error: 183.6897\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.3109 - mean_squared_error: 193.3109\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.9116 - mean_squared_error: 178.9116\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 187.4313 - mean_squared_error: 187.4313\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.6742 - mean_squared_error: 180.6742\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 178.4141 - mean_squared_error: 178.4141\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.4681 - mean_squared_error: 178.4681\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 183.2712 - mean_squared_error: 183.2712\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.1472 - mean_squared_error: 191.1472\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.5797 - mean_squared_error: 183.5797\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 173.5050 - mean_squared_error: 173.5050\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.3351 - mean_squared_error: 173.3351\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 177.3986 - mean_squared_error: 177.3986\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.9095 - mean_squared_error: 183.9095\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.3978 - mean_squared_error: 179.3978\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 173.6897 - mean_squared_error: 173.6897\n",
      "3666/3666 [==============================] - 0s 17us/step\n",
      "100/100 [==============================] - 0s 20us/step\n",
      "\n",
      "Experiment on Fold  3\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 128)               43136     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 616)               79464     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 616)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 617       \n",
      "=================================================================\n",
      "Total params: 123,217\n",
      "Trainable params: 123,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 12us/step - loss: 3316.9059 - mean_squared_error: 3316.9059\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 509.8255 - mean_squared_error: 509.8255\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 397.6335 - mean_squared_error: 397.6335\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 331.0754 - mean_squared_error: 331.0754\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 294.8046 - mean_squared_error: 294.8046\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 275.9653 - mean_squared_error: 275.9653\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 268.3815 - mean_squared_error: 268.3815\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 259.1739 - mean_squared_error: 259.1739\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 253.6259 - mean_squared_error: 253.6259\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.7491 - mean_squared_error: 250.7491\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 251.1863 - mean_squared_error: 251.1863\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 246.1260 - mean_squared_error: 246.1260\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.7668 - mean_squared_error: 250.7668\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 249.1049 - mean_squared_error: 249.1049\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 239.4515 - mean_squared_error: 239.4515\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.0439 - mean_squared_error: 242.0439\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 236.3144 - mean_squared_error: 236.3144\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 240.7452 - mean_squared_error: 240.7452\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 235.8200 - mean_squared_error: 235.8200\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 237.3761 - mean_squared_error: 237.3761\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 232.3079 - mean_squared_error: 232.3079\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 233.1588 - mean_squared_error: 233.1588\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.9646 - mean_squared_error: 230.9646\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 240.3498 - mean_squared_error: 240.3498\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.0550 - mean_squared_error: 231.0550\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 230.8947 - mean_squared_error: 230.8947\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 229.0778 - mean_squared_error: 229.0778\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 228.3270 - mean_squared_error: 228.3270\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 231.2267 - mean_squared_error: 231.2267\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.3727 - mean_squared_error: 223.3727\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.4972 - mean_squared_error: 226.4972\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.3613 - mean_squared_error: 223.3613\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 229.3928 - mean_squared_error: 229.3928\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 231.7897 - mean_squared_error: 231.7897\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.6452 - mean_squared_error: 220.6452\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 225.7551 - mean_squared_error: 225.7551\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 218.0385 - mean_squared_error: 218.0385\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 220.1742 - mean_squared_error: 220.1742\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 221.9666 - mean_squared_error: 221.9666\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 213.7306 - mean_squared_error: 213.7306\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 223.1286 - mean_squared_error: 223.1286\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.0898 - mean_squared_error: 216.0898\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 215.9203 - mean_squared_error: 215.9203\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 219.0023 - mean_squared_error: 219.0023\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 207.9811 - mean_squared_error: 207.9811\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 216.5645 - mean_squared_error: 216.5645\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 212.7262 - mean_squared_error: 212.7262\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 210.8731 - mean_squared_error: 210.8731\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 219.9521 - mean_squared_error: 219.9521\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 208.6867 - mean_squared_error: 208.6867\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.5875 - mean_squared_error: 214.5875\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 221.6929 - mean_squared_error: 221.6929\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 203.7361 - mean_squared_error: 203.7361\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 212.3175 - mean_squared_error: 212.3175\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 203.7319 - mean_squared_error: 203.7319\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 206.5433 - mean_squared_error: 206.5433\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 202.9381 - mean_squared_error: 202.9381\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 210.4204 - mean_squared_error: 210.4204\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.7571 - mean_squared_error: 203.7571\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.7506 - mean_squared_error: 203.7506\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.5384 - mean_squared_error: 205.5384\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 203.5536 - mean_squared_error: 203.5536\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 197.5441 - mean_squared_error: 197.5441\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 198.2817 - mean_squared_error: 198.2817\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 196.9015 - mean_squared_error: 196.9015\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 207.5431 - mean_squared_error: 207.5431\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 207.7195 - mean_squared_error: 207.7195\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.6176 - mean_squared_error: 195.6176\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 4us/step - loss: 192.4767 - mean_squared_error: 192.4767\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.3083 - mean_squared_error: 192.3083\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.8596 - mean_squared_error: 194.8596\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 192.1233 - mean_squared_error: 192.1233\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.6409 - mean_squared_error: 221.6409\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.6701 - mean_squared_error: 199.6701\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 197.8318 - mean_squared_error: 197.8318\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 192.1817 - mean_squared_error: 192.1817\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.0185 - mean_squared_error: 189.0185\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 189.2361 - mean_squared_error: 189.2361\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.9653 - mean_squared_error: 189.9653\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 184.7838 - mean_squared_error: 184.7838\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.9000 - mean_squared_error: 181.9000\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 192.9611 - mean_squared_error: 192.9611\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 184.0503 - mean_squared_error: 184.0503\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 179.2768 - mean_squared_error: 179.2768\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.0104 - mean_squared_error: 186.0104\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 179.6956 - mean_squared_error: 179.6956\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 311.4106 - mean_squared_error: 311.4106\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 206.1725 - mean_squared_error: 206.1725\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.6482 - mean_squared_error: 200.6482\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 191.6929 - mean_squared_error: 191.6929\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 189.3144 - mean_squared_error: 189.3144\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.3985 - mean_squared_error: 186.3985\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.6637 - mean_squared_error: 180.6637\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 179.5089 - mean_squared_error: 179.5089\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.1891 - mean_squared_error: 175.1891\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 177.7139 - mean_squared_error: 177.7139\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.9157 - mean_squared_error: 175.9157\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.5124 - mean_squared_error: 174.5124\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 171.7125 - mean_squared_error: 171.7125\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 174.9351 - mean_squared_error: 174.9351\n",
      "3666/3666 [==============================] - 0s 21us/step\n",
      "100/100 [==============================] - 0s 21us/step\n",
      "\n",
      "Experiment on Fold  4\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 128)               43136     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 616)               79464     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 616)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 617       \n",
      "=================================================================\n",
      "Total params: 123,217\n",
      "Trainable params: 123,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 12us/step - loss: 3457.7016 - mean_squared_error: 3457.7016\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 502.4842 - mean_squared_error: 502.4842\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 392.8880 - mean_squared_error: 392.8880\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 329.3963 - mean_squared_error: 329.3963\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 296.4663 - mean_squared_error: 296.4663\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 279.9354 - mean_squared_error: 279.9354\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 267.1859 - mean_squared_error: 267.1859\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 260.7933 - mean_squared_error: 260.7933\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 259.1969 - mean_squared_error: 259.1969\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 255.3267 - mean_squared_error: 255.3267\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 251.9731 - mean_squared_error: 251.9731\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 245.0208 - mean_squared_error: 245.0208\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 245.7290 - mean_squared_error: 245.7290\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 247.7622 - mean_squared_error: 247.7622\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 247.4084 - mean_squared_error: 247.4084\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 239.9070 - mean_squared_error: 239.9070\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.5168 - mean_squared_error: 242.5168\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.1392 - mean_squared_error: 242.1392\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 241.1622 - mean_squared_error: 241.1622\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 239.7361 - mean_squared_error: 239.7361\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 236.9973 - mean_squared_error: 236.9973\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 239.3727 - mean_squared_error: 239.3727\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.3824 - mean_squared_error: 236.3824\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.4722 - mean_squared_error: 232.4722\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 240.9406 - mean_squared_error: 240.9406\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.0300 - mean_squared_error: 231.0300\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.9206 - mean_squared_error: 230.9206\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 4us/step - loss: 231.6859 - mean_squared_error: 231.6859\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.4344 - mean_squared_error: 229.4344\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.5227 - mean_squared_error: 227.5227\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 241.3479 - mean_squared_error: 241.3479\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.1335 - mean_squared_error: 230.1335\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 226.3972 - mean_squared_error: 226.3972\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.9161 - mean_squared_error: 226.9161\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 222.7165 - mean_squared_error: 222.7165\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 226.3704 - mean_squared_error: 226.3704\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.2433 - mean_squared_error: 221.2433\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.0687 - mean_squared_error: 220.0687\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 230.2474 - mean_squared_error: 230.2474\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.7079 - mean_squared_error: 226.7079\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 227.2608 - mean_squared_error: 227.2608\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.2428 - mean_squared_error: 221.2428\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.6785 - mean_squared_error: 223.6785\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.3412 - mean_squared_error: 221.3412\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.0502 - mean_squared_error: 221.0502\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.2748 - mean_squared_error: 219.2748\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.7097 - mean_squared_error: 216.7097\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.2039 - mean_squared_error: 217.2039\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.9713 - mean_squared_error: 212.9713\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.9384 - mean_squared_error: 214.9384\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.7719 - mean_squared_error: 211.7719\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.4457 - mean_squared_error: 218.4457\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.9300 - mean_squared_error: 208.9300\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 213.1394 - mean_squared_error: 213.1394\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 209.5293 - mean_squared_error: 209.5293\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 212.6642 - mean_squared_error: 212.6642\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 201.9365 - mean_squared_error: 201.9365\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.2708 - mean_squared_error: 205.2708\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.5561 - mean_squared_error: 206.5561\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.0492 - mean_squared_error: 202.0492\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.4997 - mean_squared_error: 215.4997\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.4623 - mean_squared_error: 203.4623\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.6819 - mean_squared_error: 199.6819\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 203.1585 - mean_squared_error: 203.1585\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.3280 - mean_squared_error: 202.3280\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 196.7841 - mean_squared_error: 196.7841\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.7217 - mean_squared_error: 193.7217\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 194.2351 - mean_squared_error: 194.2351\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 200.4855 - mean_squared_error: 200.4855\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.3294 - mean_squared_error: 196.3294\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 192.6784 - mean_squared_error: 192.6784\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.8321 - mean_squared_error: 194.8321\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.3642 - mean_squared_error: 190.3642\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 194.6708 - mean_squared_error: 194.6708\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 187.4831 - mean_squared_error: 187.4831\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 187.9228 - mean_squared_error: 187.9228\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 190.1744 - mean_squared_error: 190.1744\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.3305 - mean_squared_error: 186.3305\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 183.5796 - mean_squared_error: 183.5796\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 190.4677 - mean_squared_error: 190.4677\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.2773 - mean_squared_error: 189.2773\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 180.1816 - mean_squared_error: 180.1816\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.2841 - mean_squared_error: 185.2841\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 181.3292 - mean_squared_error: 181.3292\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 189.7787 - mean_squared_error: 189.7787\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.5627 - mean_squared_error: 185.5627\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.3905 - mean_squared_error: 186.3905\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 179.9503 - mean_squared_error: 179.9503\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 184.1134 - mean_squared_error: 184.1134\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.6386 - mean_squared_error: 180.6386\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.0523 - mean_squared_error: 182.0523\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 181.6826 - mean_squared_error: 181.6826\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 177.3813 - mean_squared_error: 177.3813\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.8388 - mean_squared_error: 179.8388\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.1030 - mean_squared_error: 180.1030\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 4us/step - loss: 174.9116 - mean_squared_error: 174.9116\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.5143 - mean_squared_error: 171.5143\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 171.8172 - mean_squared_error: 171.8172\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.3124 - mean_squared_error: 171.3124\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.5553 - mean_squared_error: 168.5553\n",
      "3666/3666 [==============================] - 0s 17us/step\n",
      "100/100 [==============================] - 0s 26us/step\n",
      "Testing for yulin/alpha0.4/bestModel_global.json\n",
      "Loading data for dataset 1 with window_size of 24, stride of 1 and maxRUL of 129. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(18331, 336)\n",
      "(18331, 1)\n",
      "Testing data (X, y)\n",
      "(100, 336)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.63253012 -0.18639634 -0.38048616 ... -0.33333333  0.33333333\n",
      "   0.31289699]\n",
      " [-0.43373494 -0.09396119 -0.29473329 ... -0.16666667  0.25581395\n",
      "   0.47638774]\n",
      " [-0.31325301 -0.26095487 -0.25894666 ...  0.          0.11627907\n",
      "   0.43800055]\n",
      " [-0.31325301 -0.48768258 -0.33760972 ... -0.16666667  0.31782946\n",
      "   0.52720243]\n",
      " [-0.30120482 -0.48506649 -0.19074949 ... -0.66666667  0.34883721\n",
      "   0.07677437]]\n",
      "[[129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]]\n",
      "Testing data (X, y)\n",
      "[[-0.19879518 -0.5705254  -0.37069548 ... -0.16666667  0.03875969\n",
      "   0.27312897]\n",
      " [-0.21686747 -0.30237628 -0.12086428 ... -0.5         0.03875969\n",
      "   0.01518917]\n",
      " [-0.04216867 -0.1942446  -0.0209318  ...  0.16666667  0.2248062\n",
      "   0.04888152]\n",
      " [-0.22891566 -0.01722259 -0.13673194 ...  0.16666667 -0.31782946\n",
      "   0.004971  ]\n",
      " [-0.11445783 -0.11968607  0.03511141 ...  0.         -0.05426357\n",
      "   0.42916321]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n",
      "Validation on model:best_models/cmapss/yulin/alpha0.4/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 696)               234552    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 472)               328984    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 473       \n",
      "=================================================================\n",
      "Total params: 564,009\n",
      "Trainable params: 564,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14664/14664 [==============================] - 0s 12us/step - loss: 2376.1080 - mean_squared_error: 2376.1080\n",
      "Epoch 2/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 387.3587 - mean_squared_error: 387.3587\n",
      "Epoch 3/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 305.3042 - mean_squared_error: 305.3042\n",
      "Epoch 4/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 273.7711 - mean_squared_error: 273.7711\n",
      "Epoch 5/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 260.3699 - mean_squared_error: 260.3699\n",
      "Epoch 6/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 258.5193 - mean_squared_error: 258.5193\n",
      "Epoch 7/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 241.6318 - mean_squared_error: 241.6318\n",
      "Epoch 8/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 246.3339 - mean_squared_error: 246.3339\n",
      "Epoch 9/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 246.0530 - mean_squared_error: 246.0530\n",
      "Epoch 10/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 239.2953 - mean_squared_error: 239.2953\n",
      "Epoch 11/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 250.8365 - mean_squared_error: 250.8365\n",
      "Epoch 12/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 238.5491 - mean_squared_error: 238.5491\n",
      "Epoch 13/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 237.2042 - mean_squared_error: 237.2042\n",
      "Epoch 14/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 240.8881 - mean_squared_error: 240.8881\n",
      "Epoch 15/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 241.3713 - mean_squared_error: 241.3713\n",
      "Epoch 16/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 231.1432 - mean_squared_error: 231.1432\n",
      "Epoch 17/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 230.4116 - mean_squared_error: 230.4116\n",
      "Epoch 18/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 235.1535 - mean_squared_error: 235.1535\n",
      "Epoch 19/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 234.8837 - mean_squared_error: 234.8837\n",
      "Epoch 20/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 232.0066 - mean_squared_error: 232.0066\n",
      "Epoch 21/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 225.5969 - mean_squared_error: 225.5969\n",
      "Epoch 22/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 216.7850 - mean_squared_error: 216.7850\n",
      "Epoch 23/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 217.7625 - mean_squared_error: 217.7625\n",
      "Epoch 24/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 235.2461 - mean_squared_error: 235.2461\n",
      "Epoch 25/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 221.5814 - mean_squared_error: 221.5814\n",
      "Epoch 26/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 216.0666 - mean_squared_error: 216.0666\n",
      "Epoch 27/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 218.2797 - mean_squared_error: 218.2797\n",
      "Epoch 28/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 232.2923 - mean_squared_error: 232.2923\n",
      "Epoch 29/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 201.5515 - mean_squared_error: 201.5515\n",
      "Epoch 30/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 219.5341 - mean_squared_error: 219.5341\n",
      "Epoch 31/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 208.7883 - mean_squared_error: 208.7883\n",
      "Epoch 32/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 234.6933 - mean_squared_error: 234.6933\n",
      "Epoch 33/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 203.3478 - mean_squared_error: 203.3478\n",
      "Epoch 34/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 205.8130 - mean_squared_error: 205.8130\n",
      "Epoch 35/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 203.6693 - mean_squared_error: 203.6693\n",
      "Epoch 36/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 203.2810 - mean_squared_error: 203.2810\n",
      "Epoch 37/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 196.0539 - mean_squared_error: 196.0539\n",
      "Epoch 38/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 206.9294 - mean_squared_error: 206.9294\n",
      "Epoch 39/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 195.2740 - mean_squared_error: 195.2740\n",
      "Epoch 40/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 197.4736 - mean_squared_error: 197.4736\n",
      "Epoch 41/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 201.5734 - mean_squared_error: 201.5734\n",
      "Epoch 42/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 188.4900 - mean_squared_error: 188.4900\n",
      "Epoch 43/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 188.9101 - mean_squared_error: 188.9101\n",
      "Epoch 44/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 203.9361 - mean_squared_error: 203.9361\n",
      "Epoch 45/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 188.0266 - mean_squared_error: 188.0266\n",
      "Epoch 46/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 187.7232 - mean_squared_error: 187.7232\n",
      "Epoch 47/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 177.5972 - mean_squared_error: 177.5972\n",
      "Epoch 48/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 181.8361 - mean_squared_error: 181.8361\n",
      "Epoch 49/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 185.7836 - mean_squared_error: 185.7836\n",
      "Epoch 50/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 184.2407 - mean_squared_error: 184.2407\n",
      "Epoch 51/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 176.2680 - mean_squared_error: 176.2680\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14664/14664 [==============================] - 0s 4us/step - loss: 170.8043 - mean_squared_error: 170.8043\n",
      "Epoch 53/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 171.0232 - mean_squared_error: 171.0232\n",
      "Epoch 54/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 174.6420 - mean_squared_error: 174.6420\n",
      "Epoch 55/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 187.2866 - mean_squared_error: 187.2866\n",
      "Epoch 56/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 165.6620 - mean_squared_error: 165.6620\n",
      "Epoch 57/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 166.6723 - mean_squared_error: 166.6723\n",
      "Epoch 58/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 172.7081 - mean_squared_error: 172.7081\n",
      "Epoch 59/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 156.9489 - mean_squared_error: 156.9489\n",
      "Epoch 60/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 172.3130 - mean_squared_error: 172.3130\n",
      "Epoch 61/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 149.3851 - mean_squared_error: 149.3851\n",
      "Epoch 62/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 155.4656 - mean_squared_error: 155.4656\n",
      "Epoch 63/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 172.3396 - mean_squared_error: 172.3396\n",
      "Epoch 64/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 150.0516 - mean_squared_error: 150.0516\n",
      "Epoch 65/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 152.8086 - mean_squared_error: 152.8086\n",
      "Epoch 66/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 150.8236 - mean_squared_error: 150.8236\n",
      "Epoch 67/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 154.5795 - mean_squared_error: 154.5795\n",
      "Epoch 68/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 140.9264 - mean_squared_error: 140.9264\n",
      "Epoch 69/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 139.0245 - mean_squared_error: 139.0245\n",
      "Epoch 70/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 148.5332 - mean_squared_error: 148.5332\n",
      "Epoch 71/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 153.3757 - mean_squared_error: 153.3757\n",
      "Epoch 72/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 143.5186 - mean_squared_error: 143.5186\n",
      "Epoch 73/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 144.2047 - mean_squared_error: 144.2047\n",
      "Epoch 74/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 130.9608 - mean_squared_error: 130.9608\n",
      "Epoch 75/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 123.8167 - mean_squared_error: 123.8167\n",
      "Epoch 76/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 133.1530 - mean_squared_error: 133.1530\n",
      "Epoch 77/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 132.5634 - mean_squared_error: 132.5634\n",
      "Epoch 78/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 124.3397 - mean_squared_error: 124.3397\n",
      "Epoch 79/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 138.7210 - mean_squared_error: 138.7210\n",
      "Epoch 80/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 124.6288 - mean_squared_error: 124.6288\n",
      "Epoch 81/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 123.9253 - mean_squared_error: 123.9253\n",
      "Epoch 82/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 118.5506 - mean_squared_error: 118.5506\n",
      "Epoch 83/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 133.4083 - mean_squared_error: 133.4083\n",
      "Epoch 84/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 121.9974 - mean_squared_error: 121.9974\n",
      "Epoch 85/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 112.3424 - mean_squared_error: 112.3424\n",
      "Epoch 86/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 120.5775 - mean_squared_error: 120.5775\n",
      "Epoch 87/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 132.9423 - mean_squared_error: 132.9423\n",
      "Epoch 88/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 107.4440 - mean_squared_error: 107.4440\n",
      "Epoch 89/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 104.9254 - mean_squared_error: 104.9254\n",
      "Epoch 90/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 108.5298 - mean_squared_error: 108.5298\n",
      "Epoch 91/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 110.7067 - mean_squared_error: 110.7067\n",
      "Epoch 92/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 100.9334 - mean_squared_error: 100.9334\n",
      "Epoch 93/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 123.6967 - mean_squared_error: 123.6967\n",
      "Epoch 94/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 102.1599 - mean_squared_error: 102.1599\n",
      "Epoch 95/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 107.1338 - mean_squared_error: 107.1338\n",
      "Epoch 96/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 110.2432 - mean_squared_error: 110.2432\n",
      "Epoch 97/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 92.7951 - mean_squared_error: 92.7951\n",
      "Epoch 98/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 85.8238 - mean_squared_error: 85.8238\n",
      "Epoch 99/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 94.8202 - mean_squared_error: 94.8202\n",
      "Epoch 100/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 89.1392 - mean_squared_error: 89.1392\n",
      "3667/3667 [==============================] - 0s 18us/step\n",
      "100/100 [==============================] - 0s 21us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 696)               234552    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 472)               328984    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 473       \n",
      "=================================================================\n",
      "Total params: 564,009\n",
      "Trainable params: 564,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 12us/step - loss: 2254.0559 - mean_squared_error: 2254.0559\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 378.2046 - mean_squared_error: 378.2046\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 298.3881 - mean_squared_error: 298.3881\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 269.3303 - mean_squared_error: 269.3303\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 252.5111 - mean_squared_error: 252.5111\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 257.6127 - mean_squared_error: 257.6127\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 257.0593 - mean_squared_error: 257.0593\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 249.6359 - mean_squared_error: 249.6359\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 241.4190 - mean_squared_error: 241.4190\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 243.0473 - mean_squared_error: 243.0473\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 254.5429 - mean_squared_error: 254.5429\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 4us/step - loss: 233.7092 - mean_squared_error: 233.7092\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 246.1141 - mean_squared_error: 246.1141\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 231.2502 - mean_squared_error: 231.2502\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 240.0971 - mean_squared_error: 240.0971\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 243.9018 - mean_squared_error: 243.9018\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.3604 - mean_squared_error: 225.3604\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.7851 - mean_squared_error: 230.7851\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 233.0110 - mean_squared_error: 233.0110\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 228.9419 - mean_squared_error: 228.9419\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 242.3149 - mean_squared_error: 242.3149\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 222.7301 - mean_squared_error: 222.7301\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 214.0853 - mean_squared_error: 214.0853\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 220.4590 - mean_squared_error: 220.4590\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.5501 - mean_squared_error: 236.5501\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 211.7086 - mean_squared_error: 211.7086\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.1065 - mean_squared_error: 220.1065\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 208.1684 - mean_squared_error: 208.1684\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 213.5090 - mean_squared_error: 213.5090\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.3318 - mean_squared_error: 206.3318\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 211.3561 - mean_squared_error: 211.3561\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 200.9040 - mean_squared_error: 200.9040\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 206.6013 - mean_squared_error: 206.6013\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 217.4975 - mean_squared_error: 217.4975\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.1755 - mean_squared_error: 205.1755\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.1004 - mean_squared_error: 201.1004\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.5062 - mean_squared_error: 196.5062\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 202.1572 - mean_squared_error: 202.1572\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.2661 - mean_squared_error: 204.2661\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.1112 - mean_squared_error: 205.1112\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 180.9995 - mean_squared_error: 180.9995\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.6901 - mean_squared_error: 196.6901\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.1449 - mean_squared_error: 193.1449\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.7017 - mean_squared_error: 188.7017\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 187.9322 - mean_squared_error: 187.9322\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 186.1770 - mean_squared_error: 186.1770\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.6196 - mean_squared_error: 168.6196\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.3363 - mean_squared_error: 192.3363\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 178.1892 - mean_squared_error: 178.1892\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 169.5596 - mean_squared_error: 169.5596\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 187.8789 - mean_squared_error: 187.8789\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 176.5519 - mean_squared_error: 176.5519\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 181.5883 - mean_squared_error: 181.5883\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.5777 - mean_squared_error: 169.5777\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.2717 - mean_squared_error: 162.2717\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.2148 - mean_squared_error: 165.2148\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 164.0314 - mean_squared_error: 164.0314\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 173.4733 - mean_squared_error: 173.4733\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.9203 - mean_squared_error: 158.9203\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.2144 - mean_squared_error: 160.2144\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 151.9549 - mean_squared_error: 151.9549\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.3569 - mean_squared_error: 172.3569\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 163.8565 - mean_squared_error: 163.8565\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 144.5524 - mean_squared_error: 144.5524\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.3915 - mean_squared_error: 157.3915\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 157.2773 - mean_squared_error: 157.2773\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 141.4514 - mean_squared_error: 141.4514\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 144.6492 - mean_squared_error: 144.6492\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 136.4415 - mean_squared_error: 136.4415\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 142.5043 - mean_squared_error: 142.5043\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 143.6954 - mean_squared_error: 143.6954\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 132.9518 - mean_squared_error: 132.9518\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 140.5217 - mean_squared_error: 140.5217\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 124.7012 - mean_squared_error: 124.7012\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 136.2489 - mean_squared_error: 136.2489\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 123.7946 - mean_squared_error: 123.7946\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 135.5045 - mean_squared_error: 135.5045\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 124.7014 - mean_squared_error: 124.7014\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 140.5214 - mean_squared_error: 140.5214\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 4us/step - loss: 130.8972 - mean_squared_error: 130.8972\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 134.3673 - mean_squared_error: 134.3673\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 121.2276 - mean_squared_error: 121.2276\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 105.1405 - mean_squared_error: 105.1405\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 110.9849 - mean_squared_error: 110.9849\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 107.5552 - mean_squared_error: 107.5552\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 124.9685 - mean_squared_error: 124.9685\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 115.6063 - mean_squared_error: 115.6063\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 113.7530 - mean_squared_error: 113.7530\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 110.0488 - mean_squared_error: 110.0488\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 103.7976 - mean_squared_error: 103.7976\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 106.4214 - mean_squared_error: 106.4214\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 114.8982 - mean_squared_error: 114.8982\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 98.3760 - mean_squared_error: 98.3760\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 103.1909 - mean_squared_error: 103.1909\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 98.1993 - mean_squared_error: 98.1993\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 109.9571 - mean_squared_error: 109.9571\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 96.5033 - mean_squared_error: 96.5033\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 99.2428 - mean_squared_error: 99.2428\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 96.1220 - mean_squared_error: 96.1220\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 84.5240 - mean_squared_error: 84.5240\n",
      "3666/3666 [==============================] - 0s 16us/step\n",
      "100/100 [==============================] - 0s 21us/step\n",
      "\n",
      "Experiment on Fold  2\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 696)               234552    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 472)               328984    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 473       \n",
      "=================================================================\n",
      "Total params: 564,009\n",
      "Trainable params: 564,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 12us/step - loss: 2337.2298 - mean_squared_error: 2337.2298\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 376.5928 - mean_squared_error: 376.5928\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 300.9210 - mean_squared_error: 300.9210\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 274.1735 - mean_squared_error: 274.1735\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 261.1693 - mean_squared_error: 261.1693\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 251.5488 - mean_squared_error: 251.5488\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.1098 - mean_squared_error: 250.1098\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 243.4292 - mean_squared_error: 243.4292\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 244.1794 - mean_squared_error: 244.1794\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 237.0355 - mean_squared_error: 237.0355\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 243.8926 - mean_squared_error: 243.8926\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 245.0937 - mean_squared_error: 245.0937\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 235.9912 - mean_squared_error: 235.9912\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.2363 - mean_squared_error: 250.2363\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 229.6421 - mean_squared_error: 229.6421\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 235.3195 - mean_squared_error: 235.3195\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 223.6097 - mean_squared_error: 223.6097\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 231.3590 - mean_squared_error: 231.3590\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 226.8341 - mean_squared_error: 226.8341\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 227.3167 - mean_squared_error: 227.3167\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 223.1346 - mean_squared_error: 223.1346\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 221.0885 - mean_squared_error: 221.0885\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 213.9373 - mean_squared_error: 213.9373\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 232.7135 - mean_squared_error: 232.7135\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 211.0879 - mean_squared_error: 211.0879\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 216.1650 - mean_squared_error: 216.1650\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 216.0195 - mean_squared_error: 216.0195\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 204.3591 - mean_squared_error: 204.3591\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 222.0959 - mean_squared_error: 222.0959\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 209.4295 - mean_squared_error: 209.4295\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 212.2565 - mean_squared_error: 212.2565\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.6531 - mean_squared_error: 199.6531\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 208.8240 - mean_squared_error: 208.8240\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 206.9936 - mean_squared_error: 206.9936\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 191.8859 - mean_squared_error: 191.8859\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 208.2351 - mean_squared_error: 208.2351\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 194.0759 - mean_squared_error: 194.0759\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 195.2278 - mean_squared_error: 195.2278\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 189.4732 - mean_squared_error: 189.4732\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 4us/step - loss: 190.4248 - mean_squared_error: 190.4248\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 200.4795 - mean_squared_error: 200.4795\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 184.6816 - mean_squared_error: 184.6816\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 178.3947 - mean_squared_error: 178.3947\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 181.8851 - mean_squared_error: 181.8851\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 177.3616 - mean_squared_error: 177.3616\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 180.4602 - mean_squared_error: 180.4602\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 176.3492 - mean_squared_error: 176.3492\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 187.4652 - mean_squared_error: 187.4652\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 185.8733 - mean_squared_error: 185.8733\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 170.8344 - mean_squared_error: 170.8344\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 187.1304 - mean_squared_error: 187.1304\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 160.2695 - mean_squared_error: 160.2695\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 176.0585 - mean_squared_error: 176.0585\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 172.1473 - mean_squared_error: 172.1473\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.5554 - mean_squared_error: 166.5554\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 168.1709 - mean_squared_error: 168.1709\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 158.6596 - mean_squared_error: 158.6596\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 164.7014 - mean_squared_error: 164.7014\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 153.2401 - mean_squared_error: 153.2401\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 152.1630 - mean_squared_error: 152.1630\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 170.0812 - mean_squared_error: 170.0812\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 160.4193 - mean_squared_error: 160.4193\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 150.0629 - mean_squared_error: 150.0629\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 166.2075 - mean_squared_error: 166.2075\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 146.3594 - mean_squared_error: 146.3594\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 141.7615 - mean_squared_error: 141.7615\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 139.2471 - mean_squared_error: 139.2471\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 142.6894 - mean_squared_error: 142.6894\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 144.0615 - mean_squared_error: 144.0615\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 147.9042 - mean_squared_error: 147.9042\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 132.9228 - mean_squared_error: 132.9228\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 138.9651 - mean_squared_error: 138.9651\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 122.1017 - mean_squared_error: 122.1017\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 142.2848 - mean_squared_error: 142.2848\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 140.8601 - mean_squared_error: 140.8601\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 127.0445 - mean_squared_error: 127.0445\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 137.1662 - mean_squared_error: 137.1662\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 135.4558 - mean_squared_error: 135.4558\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 136.2271 - mean_squared_error: 136.2271\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 126.3564 - mean_squared_error: 126.3564\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 111.3163 - mean_squared_error: 111.3163\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 120.4192 - mean_squared_error: 120.4192\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 111.8862 - mean_squared_error: 111.8862\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 128.8164 - mean_squared_error: 128.8164\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 118.5365 - mean_squared_error: 118.5365\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 109.8193 - mean_squared_error: 109.8193\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 103.0269 - mean_squared_error: 103.0269\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 110.4071 - mean_squared_error: 110.4071\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 117.8796 - mean_squared_error: 117.8796\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 104.3520 - mean_squared_error: 104.3520\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 99.0175 - mean_squared_error: 99.0175\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 116.3326 - mean_squared_error: 116.3326\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 108.9122 - mean_squared_error: 108.9122\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 106.7171 - mean_squared_error: 106.7171\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 101.9098 - mean_squared_error: 101.9098\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 93.9357 - mean_squared_error: 93.9357\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 87.1740 - mean_squared_error: 87.1740\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 110.2189 - mean_squared_error: 110.2189\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 87.7913 - mean_squared_error: 87.7913\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 92.7816 - mean_squared_error: 92.7816\n",
      "3666/3666 [==============================] - 0s 16us/step\n",
      "100/100 [==============================] - 0s 20us/step\n",
      "\n",
      "Experiment on Fold  3\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 696)               234552    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 472)               328984    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 473       \n",
      "=================================================================\n",
      "Total params: 564,009\n",
      "Trainable params: 564,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 12us/step - loss: 2253.9370 - mean_squared_error: 2253.9370\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 384.2071 - mean_squared_error: 384.2071\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 300.2025 - mean_squared_error: 300.2025\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 283.1281 - mean_squared_error: 283.1281\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 262.5746 - mean_squared_error: 262.5746\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.1951 - mean_squared_error: 255.1951\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 246.5495 - mean_squared_error: 246.5495\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 243.4397 - mean_squared_error: 243.4397\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 236.8897 - mean_squared_error: 236.8897\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 249.5533 - mean_squared_error: 249.5533\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 239.5111 - mean_squared_error: 239.5111\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 253.3333 - mean_squared_error: 253.3333\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 235.4698 - mean_squared_error: 235.4698\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 237.4545 - mean_squared_error: 237.4545\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 243.6183 - mean_squared_error: 243.6183\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 223.3318 - mean_squared_error: 223.3318\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 232.8117 - mean_squared_error: 232.8117\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 241.5177 - mean_squared_error: 241.5177\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 230.4769 - mean_squared_error: 230.4769\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 228.6338 - mean_squared_error: 228.6338\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 230.8331 - mean_squared_error: 230.8331\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 230.4573 - mean_squared_error: 230.4573\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.3044 - mean_squared_error: 218.3044\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 215.9089 - mean_squared_error: 215.9089\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 217.1285 - mean_squared_error: 217.1285\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 227.2750 - mean_squared_error: 227.2750\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 212.3766 - mean_squared_error: 212.3766\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 220.1804 - mean_squared_error: 220.1804\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 209.6700 - mean_squared_error: 209.6700\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 218.2694 - mean_squared_error: 218.2694\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 201.9564 - mean_squared_error: 201.9564\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 208.7947 - mean_squared_error: 208.7947\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 210.5710 - mean_squared_error: 210.5710\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 213.4323 - mean_squared_error: 213.4323\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 202.7080 - mean_squared_error: 202.7080\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 205.5574 - mean_squared_error: 205.5574\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 197.9397 - mean_squared_error: 197.9397\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 200.9905 - mean_squared_error: 200.9905\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 194.2575 - mean_squared_error: 194.2575\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 192.6711 - mean_squared_error: 192.6711\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 199.2371 - mean_squared_error: 199.2371\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 188.9762 - mean_squared_error: 188.9762\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 200.5944 - mean_squared_error: 200.5944\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 189.7388 - mean_squared_error: 189.7388\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 181.3393 - mean_squared_error: 181.3393\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 174.5121 - mean_squared_error: 174.5121\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 185.5961 - mean_squared_error: 185.5961\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 181.3642 - mean_squared_error: 181.3642\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 181.7511 - mean_squared_error: 181.7511\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 181.4995 - mean_squared_error: 181.4995\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 182.7751 - mean_squared_error: 182.7751\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 169.7268 - mean_squared_error: 169.7268\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 176.3717 - mean_squared_error: 176.3717\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 167.1799 - mean_squared_error: 167.1799\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 164.4009 - mean_squared_error: 164.4009\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 171.3082 - mean_squared_error: 171.3082\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 165.6819 - mean_squared_error: 165.6819\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 163.7561 - mean_squared_error: 163.7561\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 178.3386 - mean_squared_error: 178.3386\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 153.6532 - mean_squared_error: 153.6532\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 156.2263 - mean_squared_error: 156.2263\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 147.3633 - mean_squared_error: 147.3633\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 146.1643 - mean_squared_error: 146.1643\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 174.6174 - mean_squared_error: 174.6174\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 169.0049 - mean_squared_error: 169.0049\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 148.5375 - mean_squared_error: 148.5375\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 151.8971 - mean_squared_error: 151.8971\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 145.6163 - mean_squared_error: 145.6163\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 4us/step - loss: 150.3409 - mean_squared_error: 150.3409\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 148.5007 - mean_squared_error: 148.5007\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 139.6654 - mean_squared_error: 139.6654\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 135.0776 - mean_squared_error: 135.0776\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 146.6653 - mean_squared_error: 146.6653\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 144.4340 - mean_squared_error: 144.4340\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 150.6566 - mean_squared_error: 150.6566\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 138.2535 - mean_squared_error: 138.2535\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 125.8292 - mean_squared_error: 125.8292\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 130.5901 - mean_squared_error: 130.5901\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 122.7349 - mean_squared_error: 122.7349\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 149.3149 - mean_squared_error: 149.3149\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 115.6195 - mean_squared_error: 115.6195\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 116.8798 - mean_squared_error: 116.8798\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 125.8253 - mean_squared_error: 125.8253\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 108.9718 - mean_squared_error: 108.9718\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 137.2004 - mean_squared_error: 137.2004\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 121.9977 - mean_squared_error: 121.9977\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 121.4709 - mean_squared_error: 121.4709\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 117.1592 - mean_squared_error: 117.1592\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 112.0225 - mean_squared_error: 112.0225\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 104.0237 - mean_squared_error: 104.0237\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 123.6084 - mean_squared_error: 123.6084\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 108.6017 - mean_squared_error: 108.6017\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 117.5364 - mean_squared_error: 117.5364\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 105.0967 - mean_squared_error: 105.0967\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 108.3026 - mean_squared_error: 108.3026\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 104.0206 - mean_squared_error: 104.0206\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 101.3543 - mean_squared_error: 101.3543\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 107.4732 - mean_squared_error: 107.4732\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 96.8044 - mean_squared_error: 96.8044\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 110.6224 - mean_squared_error: 110.6224\n",
      "3666/3666 [==============================] - 0s 16us/step\n",
      "100/100 [==============================] - 0s 24us/step\n",
      "\n",
      "Experiment on Fold  4\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 696)               234552    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 472)               328984    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 473       \n",
      "=================================================================\n",
      "Total params: 564,009\n",
      "Trainable params: 564,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 11us/step - loss: 2222.7962 - mean_squared_error: 2222.7962\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 381.2608 - mean_squared_error: 381.2608\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 294.6240 - mean_squared_error: 294.6240\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 273.4083 - mean_squared_error: 273.4083\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 254.9682 - mean_squared_error: 254.9682\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 241.5469 - mean_squared_error: 241.5469\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 241.3031 - mean_squared_error: 241.3031\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 246.8474 - mean_squared_error: 246.8474\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 237.1277 - mean_squared_error: 237.1277\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 258.1726 - mean_squared_error: 258.1726\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 246.3656 - mean_squared_error: 246.3656\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 233.3076 - mean_squared_error: 233.3076\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 229.7374 - mean_squared_error: 229.7374\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 230.8966 - mean_squared_error: 230.8966\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 225.4237 - mean_squared_error: 225.4237\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 227.1717 - mean_squared_error: 227.1717\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 222.3513 - mean_squared_error: 222.3513\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 239.4863 - mean_squared_error: 239.4863\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 219.1804 - mean_squared_error: 219.1804\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 210.6504 - mean_squared_error: 210.6504\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 237.9077 - mean_squared_error: 237.9077\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 224.2432 - mean_squared_error: 224.2432\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 220.2851 - mean_squared_error: 220.2851\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 219.4483 - mean_squared_error: 219.4483\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 208.5589 - mean_squared_error: 208.5589\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.9362 - mean_squared_error: 207.9362\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.3520 - mean_squared_error: 215.3520\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 199.8252 - mean_squared_error: 199.8252\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.9939 - mean_squared_error: 213.9939\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 205.2458 - mean_squared_error: 205.2458\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 210.3280 - mean_squared_error: 210.3280\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 207.6600 - mean_squared_error: 207.6600\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.5677 - mean_squared_error: 199.5677\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 186.8992 - mean_squared_error: 186.8992\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 195.9748 - mean_squared_error: 195.9748\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 197.8853 - mean_squared_error: 197.8853\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 190.5556 - mean_squared_error: 190.5556\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 203.4535 - mean_squared_error: 203.4535\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 190.2594 - mean_squared_error: 190.2594\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 191.2605 - mean_squared_error: 191.2605\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 181.7631 - mean_squared_error: 181.7631\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 194.9527 - mean_squared_error: 194.9527\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 189.4732 - mean_squared_error: 189.4732\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.2044 - mean_squared_error: 176.2044\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 197.1862 - mean_squared_error: 197.1862\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 168.6227 - mean_squared_error: 168.6227\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 179.0655 - mean_squared_error: 179.0655\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 180.1508 - mean_squared_error: 180.1508\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 189.8044 - mean_squared_error: 189.8044\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 161.6914 - mean_squared_error: 161.6914\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 165.5402 - mean_squared_error: 165.5402\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 175.5581 - mean_squared_error: 175.5581\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 176.4030 - mean_squared_error: 176.4030\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 155.3319 - mean_squared_error: 155.3319\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 159.2419 - mean_squared_error: 159.2419\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 157.9511 - mean_squared_error: 157.9511\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 164.2161 - mean_squared_error: 164.2161\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.3138 - mean_squared_error: 178.3138\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 159.9047 - mean_squared_error: 159.9047\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 148.5610 - mean_squared_error: 148.5610\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 145.3867 - mean_squared_error: 145.3867\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 154.7210 - mean_squared_error: 154.7210\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 148.9087 - mean_squared_error: 148.9087\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 153.6967 - mean_squared_error: 153.6967\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 138.6442 - mean_squared_error: 138.6442\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 146.3572 - mean_squared_error: 146.3572\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 156.3194 - mean_squared_error: 156.3194\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 130.6112 - mean_squared_error: 130.6112\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 137.3552 - mean_squared_error: 137.3552\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 140.6981 - mean_squared_error: 140.6981\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 131.0609 - mean_squared_error: 131.0609\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 134.2340 - mean_squared_error: 134.2340\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 137.4928 - mean_squared_error: 137.4928\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 124.4533 - mean_squared_error: 124.4533\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 133.9953 - mean_squared_error: 133.9953\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 120.6341 - mean_squared_error: 120.6341\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 124.0641 - mean_squared_error: 124.0641\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 132.9405 - mean_squared_error: 132.9405\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 114.9962 - mean_squared_error: 114.9962\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 122.0896 - mean_squared_error: 122.0896\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 118.0580 - mean_squared_error: 118.0580\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 105.9109 - mean_squared_error: 105.9109\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 121.8750 - mean_squared_error: 121.8750\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 114.8313 - mean_squared_error: 114.8313\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 115.0280 - mean_squared_error: 115.0280\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 117.3257 - mean_squared_error: 117.3257\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 105.3940 - mean_squared_error: 105.3940\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 106.7341 - mean_squared_error: 106.7341\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 106.4600 - mean_squared_error: 106.4600\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 90.9997 - mean_squared_error: 90.9997\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 109.9476 - mean_squared_error: 109.9476\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 98.7212 - mean_squared_error: 98.7212\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 101.2622 - mean_squared_error: 101.2622\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 105.9247 - mean_squared_error: 105.9247\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 99.0143 - mean_squared_error: 99.0143\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 85.2629 - mean_squared_error: 85.2629\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 4us/step - loss: 99.5588 - mean_squared_error: 99.5588\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 88.0446 - mean_squared_error: 88.0446\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 88.8845 - mean_squared_error: 88.8845\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 89.1593 - mean_squared_error: 89.1593\n",
      "3666/3666 [==============================] - 0s 16us/step\n",
      "100/100 [==============================] - 0s 20us/step\n",
      "Testing for yulin/alpha0.5/bestModel_global.json\n",
      "Loading data for dataset 1 with window_size of 24, stride of 1 and maxRUL of 129. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(18331, 336)\n",
      "(18331, 1)\n",
      "Testing data (X, y)\n",
      "(100, 336)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.63253012 -0.18639634 -0.38048616 ... -0.33333333  0.33333333\n",
      "   0.31289699]\n",
      " [-0.43373494 -0.09396119 -0.29473329 ... -0.16666667  0.25581395\n",
      "   0.47638774]\n",
      " [-0.31325301 -0.26095487 -0.25894666 ...  0.          0.11627907\n",
      "   0.43800055]\n",
      " [-0.31325301 -0.48768258 -0.33760972 ... -0.16666667  0.31782946\n",
      "   0.52720243]\n",
      " [-0.30120482 -0.48506649 -0.19074949 ... -0.66666667  0.34883721\n",
      "   0.07677437]]\n",
      "[[129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]]\n",
      "Testing data (X, y)\n",
      "[[-0.19879518 -0.5705254  -0.37069548 ... -0.16666667  0.03875969\n",
      "   0.27312897]\n",
      " [-0.21686747 -0.30237628 -0.12086428 ... -0.5         0.03875969\n",
      "   0.01518917]\n",
      " [-0.04216867 -0.1942446  -0.0209318  ...  0.16666667  0.2248062\n",
      "   0.04888152]\n",
      " [-0.22891566 -0.01722259 -0.13673194 ...  0.16666667 -0.31782946\n",
      "   0.004971  ]\n",
      " [-0.11445783 -0.11968607  0.03511141 ...  0.         -0.05426357\n",
      "   0.42916321]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n",
      "Validation on model:best_models/cmapss/yulin/alpha0.5/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 936)               315432    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 937       \n",
      "=================================================================\n",
      "Total params: 316,369\n",
      "Trainable params: 316,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14664/14664 [==============================] - 0s 10us/step - loss: 3833.9013 - mean_squared_error: 3833.9013\n",
      "Epoch 2/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 686.1750 - mean_squared_error: 686.1750\n",
      "Epoch 3/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 535.2724 - mean_squared_error: 535.2724\n",
      "Epoch 4/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 467.6901 - mean_squared_error: 467.6901\n",
      "Epoch 5/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 419.2621 - mean_squared_error: 419.2621\n",
      "Epoch 6/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 374.2774 - mean_squared_error: 374.2774\n",
      "Epoch 7/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 338.4717 - mean_squared_error: 338.4717\n",
      "Epoch 8/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 313.6052 - mean_squared_error: 313.6052\n",
      "Epoch 9/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 298.2367 - mean_squared_error: 298.2367\n",
      "Epoch 10/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 286.1175 - mean_squared_error: 286.1175\n",
      "Epoch 11/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 275.7987 - mean_squared_error: 275.7987\n",
      "Epoch 12/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 269.1971 - mean_squared_error: 269.1971\n",
      "Epoch 13/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 261.0003 - mean_squared_error: 261.0003\n",
      "Epoch 14/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 255.3990 - mean_squared_error: 255.3990\n",
      "Epoch 15/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 251.6164 - mean_squared_error: 251.6164\n",
      "Epoch 16/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 248.4254 - mean_squared_error: 248.4254\n",
      "Epoch 17/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 245.2802 - mean_squared_error: 245.2802\n",
      "Epoch 18/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 244.0409 - mean_squared_error: 244.0409\n",
      "Epoch 19/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 242.2495 - mean_squared_error: 242.2495\n",
      "Epoch 20/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 240.5646 - mean_squared_error: 240.5646\n",
      "Epoch 21/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 237.2016 - mean_squared_error: 237.2016\n",
      "Epoch 22/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 235.0621 - mean_squared_error: 235.0621\n",
      "Epoch 23/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 234.0447 - mean_squared_error: 234.0447\n",
      "Epoch 24/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 235.5017 - mean_squared_error: 235.5017\n",
      "Epoch 25/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 231.3769 - mean_squared_error: 231.3769\n",
      "Epoch 26/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 231.1587 - mean_squared_error: 231.1587\n",
      "Epoch 27/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 229.2527 - mean_squared_error: 229.2527\n",
      "Epoch 28/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 228.8543 - mean_squared_error: 228.8543\n",
      "Epoch 29/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 226.1380 - mean_squared_error: 226.1380\n",
      "Epoch 30/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 226.2003 - mean_squared_error: 226.2003\n",
      "Epoch 31/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 225.1376 - mean_squared_error: 225.1376\n",
      "Epoch 32/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 224.6928 - mean_squared_error: 224.6928\n",
      "Epoch 33/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 223.2173 - mean_squared_error: 223.2173\n",
      "Epoch 34/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 221.6635 - mean_squared_error: 221.6635\n",
      "Epoch 35/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 221.2678 - mean_squared_error: 221.2678\n",
      "Epoch 36/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 220.1694 - mean_squared_error: 220.1694\n",
      "Epoch 37/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 219.1598 - mean_squared_error: 219.1598\n",
      "Epoch 38/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 217.3429 - mean_squared_error: 217.3429\n",
      "Epoch 39/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 216.4620 - mean_squared_error: 216.4620\n",
      "Epoch 40/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 215.9084 - mean_squared_error: 215.9084\n",
      "Epoch 41/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 213.7820 - mean_squared_error: 213.7820\n",
      "Epoch 42/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 214.4941 - mean_squared_error: 214.4941\n",
      "Epoch 43/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 213.5529 - mean_squared_error: 213.5529\n",
      "Epoch 44/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 213.5258 - mean_squared_error: 213.5258\n",
      "Epoch 45/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 210.8350 - mean_squared_error: 210.8350\n",
      "Epoch 46/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 209.5142 - mean_squared_error: 209.5142\n",
      "Epoch 47/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 210.9008 - mean_squared_error: 210.9008\n",
      "Epoch 48/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 208.1305 - mean_squared_error: 208.1305\n",
      "Epoch 49/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 209.2472 - mean_squared_error: 209.2472\n",
      "Epoch 50/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 206.6174 - mean_squared_error: 206.6174\n",
      "Epoch 51/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 207.4545 - mean_squared_error: 207.4545\n",
      "Epoch 52/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 204.6026 - mean_squared_error: 204.6026\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14664/14664 [==============================] - 0s 3us/step - loss: 204.2647 - mean_squared_error: 204.2647\n",
      "Epoch 54/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 206.9707 - mean_squared_error: 206.9707\n",
      "Epoch 55/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 203.2879 - mean_squared_error: 203.2879\n",
      "Epoch 56/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 200.9811 - mean_squared_error: 200.9811\n",
      "Epoch 57/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 203.0492 - mean_squared_error: 203.0492\n",
      "Epoch 58/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 199.0364 - mean_squared_error: 199.0364\n",
      "Epoch 59/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 202.4453 - mean_squared_error: 202.4453\n",
      "Epoch 60/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 202.0149 - mean_squared_error: 202.0149\n",
      "Epoch 61/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 197.9747 - mean_squared_error: 197.9747\n",
      "Epoch 62/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 199.4841 - mean_squared_error: 199.4841\n",
      "Epoch 63/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 200.8177 - mean_squared_error: 200.8177\n",
      "Epoch 64/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 199.4792 - mean_squared_error: 199.4792\n",
      "Epoch 65/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 195.8755 - mean_squared_error: 195.8755\n",
      "Epoch 66/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 195.2176 - mean_squared_error: 195.2176\n",
      "Epoch 67/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 195.8039 - mean_squared_error: 195.8039\n",
      "Epoch 68/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 194.6163 - mean_squared_error: 194.6163\n",
      "Epoch 69/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 193.6323 - mean_squared_error: 193.6323\n",
      "Epoch 70/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 194.2057 - mean_squared_error: 194.2057\n",
      "Epoch 71/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 192.0515 - mean_squared_error: 192.0515\n",
      "Epoch 72/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 194.5608 - mean_squared_error: 194.5608\n",
      "Epoch 73/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 191.7277 - mean_squared_error: 191.7277\n",
      "Epoch 74/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 191.2775 - mean_squared_error: 191.2775\n",
      "Epoch 75/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 192.2611 - mean_squared_error: 192.2611\n",
      "Epoch 76/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 190.4654 - mean_squared_error: 190.4654\n",
      "Epoch 77/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 190.0306 - mean_squared_error: 190.0306\n",
      "Epoch 78/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 190.7460 - mean_squared_error: 190.7460\n",
      "Epoch 79/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 188.7068 - mean_squared_error: 188.7068\n",
      "Epoch 80/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 189.0186 - mean_squared_error: 189.0186\n",
      "Epoch 81/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 189.9908 - mean_squared_error: 189.9908\n",
      "Epoch 82/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 185.0527 - mean_squared_error: 185.0527\n",
      "Epoch 83/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 186.8709 - mean_squared_error: 186.8709\n",
      "Epoch 84/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 184.9688 - mean_squared_error: 184.9688\n",
      "Epoch 85/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 184.2420 - mean_squared_error: 184.2420\n",
      "Epoch 86/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 186.1338 - mean_squared_error: 186.1338\n",
      "Epoch 87/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 181.5413 - mean_squared_error: 181.5413\n",
      "Epoch 88/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 188.2201 - mean_squared_error: 188.2201\n",
      "Epoch 89/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 179.8256 - mean_squared_error: 179.8256\n",
      "Epoch 90/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 185.8276 - mean_squared_error: 185.8276\n",
      "Epoch 91/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 182.2704 - mean_squared_error: 182.2704\n",
      "Epoch 92/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 183.5555 - mean_squared_error: 183.5555\n",
      "Epoch 93/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 180.0241 - mean_squared_error: 180.0241\n",
      "Epoch 94/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 177.6831 - mean_squared_error: 177.6831\n",
      "Epoch 95/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 179.6816 - mean_squared_error: 179.6816\n",
      "Epoch 96/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 182.9620 - mean_squared_error: 182.9620\n",
      "Epoch 97/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 179.3414 - mean_squared_error: 179.3414\n",
      "Epoch 98/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 174.0081 - mean_squared_error: 174.0081\n",
      "Epoch 99/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 176.6309 - mean_squared_error: 176.6309\n",
      "Epoch 100/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 174.3681 - mean_squared_error: 174.3681\n",
      "3667/3667 [==============================] - 0s 16us/step\n",
      "100/100 [==============================] - 0s 19us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 936)               315432    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 937       \n",
      "=================================================================\n",
      "Total params: 316,369\n",
      "Trainable params: 316,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 10us/step - loss: 3951.3071 - mean_squared_error: 3951.3071\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 696.0377 - mean_squared_error: 696.0377\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 525.8401 - mean_squared_error: 525.8401\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 458.6684 - mean_squared_error: 458.6684\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 409.9451 - mean_squared_error: 409.9451\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 368.4044 - mean_squared_error: 368.4044\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 336.4218 - mean_squared_error: 336.4218\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 312.7459 - mean_squared_error: 312.7459\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 296.8341 - mean_squared_error: 296.8341\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 284.9903 - mean_squared_error: 284.9903\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 274.6801 - mean_squared_error: 274.6801\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 268.3841 - mean_squared_error: 268.3841\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 260.9284 - mean_squared_error: 260.9284\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 256.3566 - mean_squared_error: 256.3566\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 251.8015 - mean_squared_error: 251.8015\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 249.2046 - mean_squared_error: 249.2046\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 245.9304 - mean_squared_error: 245.9304\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 245.2471 - mean_squared_error: 245.2471\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 241.3015 - mean_squared_error: 241.3015\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 241.0778 - mean_squared_error: 241.0778\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.3054 - mean_squared_error: 238.3054\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.2024 - mean_squared_error: 236.2024\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.9303 - mean_squared_error: 236.9303\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.5657 - mean_squared_error: 232.5657\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.2183 - mean_squared_error: 232.2183\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.3732 - mean_squared_error: 230.3732\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.1763 - mean_squared_error: 229.1763\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.5863 - mean_squared_error: 227.5863\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.0238 - mean_squared_error: 227.0238\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.7789 - mean_squared_error: 226.7789\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.8457 - mean_squared_error: 223.8457\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.6646 - mean_squared_error: 221.6646\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.1159 - mean_squared_error: 221.1159\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.0036 - mean_squared_error: 221.0036\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.1905 - mean_squared_error: 220.1905\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.5049 - mean_squared_error: 216.5049\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.1082 - mean_squared_error: 216.1082\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.1258 - mean_squared_error: 215.1258\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.4095 - mean_squared_error: 215.4095\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.7369 - mean_squared_error: 213.7369\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.1647 - mean_squared_error: 213.1647\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.3045 - mean_squared_error: 212.3045\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.5470 - mean_squared_error: 210.5470\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.2611 - mean_squared_error: 212.2611\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.7796 - mean_squared_error: 210.7796\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.5552 - mean_squared_error: 207.5552\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.4015 - mean_squared_error: 208.4015\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.4760 - mean_squared_error: 206.4760\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.5479 - mean_squared_error: 205.5479\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.4433 - mean_squared_error: 206.4433\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.1876 - mean_squared_error: 206.1876\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.8175 - mean_squared_error: 205.8175\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.3688 - mean_squared_error: 206.3688\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.7677 - mean_squared_error: 201.7677\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.8516 - mean_squared_error: 204.8516\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.8899 - mean_squared_error: 201.8899\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.7519 - mean_squared_error: 200.7519\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.6049 - mean_squared_error: 199.6049\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.2913 - mean_squared_error: 200.2913\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.7673 - mean_squared_error: 198.7673\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.6095 - mean_squared_error: 197.6095\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.4138 - mean_squared_error: 197.4138\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.7916 - mean_squared_error: 197.7916\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.5627 - mean_squared_error: 198.5627\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.4107 - mean_squared_error: 197.4107\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.4499 - mean_squared_error: 195.4499\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.9168 - mean_squared_error: 195.9168\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.3108 - mean_squared_error: 193.3108\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.6021 - mean_squared_error: 193.6021\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.6174 - mean_squared_error: 196.6174\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.3455 - mean_squared_error: 194.3455\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.3717 - mean_squared_error: 192.3717\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.5872 - mean_squared_error: 190.5872\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.5382 - mean_squared_error: 192.5382\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.3328 - mean_squared_error: 189.3328\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.5352 - mean_squared_error: 188.5352\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.2101 - mean_squared_error: 188.2101\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.9840 - mean_squared_error: 187.9840\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.5168 - mean_squared_error: 186.5168\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.3117 - mean_squared_error: 187.3117\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.4073 - mean_squared_error: 185.4073\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.5488 - mean_squared_error: 188.5488\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.0793 - mean_squared_error: 189.0793\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.0232 - mean_squared_error: 185.0232\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.5766 - mean_squared_error: 183.5766\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.2720 - mean_squared_error: 184.2720\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.8990 - mean_squared_error: 183.8990\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.1260 - mean_squared_error: 182.1260\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.2936 - mean_squared_error: 181.2936\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.1641 - mean_squared_error: 182.1641\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.1862 - mean_squared_error: 181.1862\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.2704 - mean_squared_error: 184.2704\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.1431 - mean_squared_error: 181.1431\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.9057 - mean_squared_error: 176.9057\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.3312 - mean_squared_error: 177.3312\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.9964 - mean_squared_error: 180.9964\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.7359 - mean_squared_error: 176.7359\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.4712 - mean_squared_error: 176.4712\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.3633 - mean_squared_error: 178.3633\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.4797 - mean_squared_error: 172.4797\n",
      "3666/3666 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 24us/step\n",
      "\n",
      "Experiment on Fold  2\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 936)               315432    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 937       \n",
      "=================================================================\n",
      "Total params: 316,369\n",
      "Trainable params: 316,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 9us/step - loss: 3814.8787 - mean_squared_error: 3814.8787\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 682.4137 - mean_squared_error: 682.4137\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 519.9312 - mean_squared_error: 519.9312\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 459.0558 - mean_squared_error: 459.0558\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 413.1377 - mean_squared_error: 413.1377\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 373.9763 - mean_squared_error: 373.9763\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 342.4424 - mean_squared_error: 342.4424\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 320.3145 - mean_squared_error: 320.3145\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 303.3549 - mean_squared_error: 303.3549\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 291.5572 - mean_squared_error: 291.5572\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 282.0764 - mean_squared_error: 282.0764\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 274.1657 - mean_squared_error: 274.1657\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 268.1657 - mean_squared_error: 268.1657\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 263.1641 - mean_squared_error: 263.1641\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 258.3623 - mean_squared_error: 258.3623\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 255.9228 - mean_squared_error: 255.9228\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 252.2471 - mean_squared_error: 252.2471\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 248.2459 - mean_squared_error: 248.2459\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 246.7134 - mean_squared_error: 246.7134\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 244.6322 - mean_squared_error: 244.6322\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 243.1201 - mean_squared_error: 243.1201\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.4133 - mean_squared_error: 242.4133\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 239.4976 - mean_squared_error: 239.4976\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 239.4640 - mean_squared_error: 239.4640\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.1620 - mean_squared_error: 236.1620\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 235.1430 - mean_squared_error: 235.1430\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 235.0751 - mean_squared_error: 235.0751\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.0620 - mean_squared_error: 233.0620\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.7892 - mean_squared_error: 230.7892\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.3481 - mean_squared_error: 230.3481\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.8742 - mean_squared_error: 229.8742\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.1050 - mean_squared_error: 227.1050\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.1912 - mean_squared_error: 230.1912\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.3077 - mean_squared_error: 225.3077\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.6299 - mean_squared_error: 225.6299\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.0671 - mean_squared_error: 223.0671\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.5967 - mean_squared_error: 221.5967\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.5259 - mean_squared_error: 222.5259\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.3122 - mean_squared_error: 220.3122\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.8902 - mean_squared_error: 218.8902\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.4912 - mean_squared_error: 221.4912\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.6835 - mean_squared_error: 216.6835\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.7416 - mean_squared_error: 216.7416\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.5869 - mean_squared_error: 216.5869\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.4918 - mean_squared_error: 214.4918\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.6268 - mean_squared_error: 212.6268\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.5946 - mean_squared_error: 213.5946\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.9405 - mean_squared_error: 212.9405\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.6749 - mean_squared_error: 213.6749\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.6461 - mean_squared_error: 211.6461\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.6210 - mean_squared_error: 208.6210\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.6758 - mean_squared_error: 211.6758\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.7113 - mean_squared_error: 208.7113\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.8965 - mean_squared_error: 205.8965\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.7540 - mean_squared_error: 207.7540\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.3218 - mean_squared_error: 207.3218\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.5425 - mean_squared_error: 203.5425\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.1441 - mean_squared_error: 204.1441\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.8635 - mean_squared_error: 206.8635\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.0891 - mean_squared_error: 203.0891\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.5628 - mean_squared_error: 201.5628\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.2653 - mean_squared_error: 202.2653\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.0518 - mean_squared_error: 203.0518\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.6093 - mean_squared_error: 199.6093\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.5489 - mean_squared_error: 204.5489\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.4155 - mean_squared_error: 197.4155\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.5593 - mean_squared_error: 198.5593\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.8412 - mean_squared_error: 197.8412\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.9750 - mean_squared_error: 196.9750\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.0835 - mean_squared_error: 196.0835\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.9804 - mean_squared_error: 194.9804\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.8999 - mean_squared_error: 195.8999\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.8827 - mean_squared_error: 195.8827\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.3610 - mean_squared_error: 193.3610\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.7022 - mean_squared_error: 193.7022\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.8345 - mean_squared_error: 192.8345\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.9581 - mean_squared_error: 195.9581\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.7732 - mean_squared_error: 191.7732\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.6370 - mean_squared_error: 192.6370\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.7614 - mean_squared_error: 189.7614\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.4500 - mean_squared_error: 190.4500\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.3797 - mean_squared_error: 190.3797\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.2781 - mean_squared_error: 192.2781\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.7977 - mean_squared_error: 190.7977\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.1827 - mean_squared_error: 188.1827\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.1727 - mean_squared_error: 187.1727\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.0170 - mean_squared_error: 187.0170\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.8985 - mean_squared_error: 190.8985\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.3362 - mean_squared_error: 189.3362\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.1226 - mean_squared_error: 187.1226\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.2249 - mean_squared_error: 184.2249\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.7324 - mean_squared_error: 187.7324\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.0305 - mean_squared_error: 189.0305\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.0500 - mean_squared_error: 183.0500\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.1595 - mean_squared_error: 188.1595\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.0373 - mean_squared_error: 182.0373\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.8367 - mean_squared_error: 183.8367\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.8892 - mean_squared_error: 180.8892\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.4144 - mean_squared_error: 178.4144\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.0881 - mean_squared_error: 181.0881\n",
      "3666/3666 [==============================] - 0s 14us/step\n",
      "100/100 [==============================] - 0s 18us/step\n",
      "\n",
      "Experiment on Fold  3\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 936)               315432    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 937       \n",
      "=================================================================\n",
      "Total params: 316,369\n",
      "Trainable params: 316,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 9us/step - loss: 3882.4063 - mean_squared_error: 3882.4063\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 696.3966 - mean_squared_error: 696.3966\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 528.1168 - mean_squared_error: 528.1168\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 461.9585 - mean_squared_error: 461.9585\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 413.1063 - mean_squared_error: 413.1063\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 370.9989 - mean_squared_error: 370.9989\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 338.0442 - mean_squared_error: 338.0442\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 314.2108 - mean_squared_error: 314.2108\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 299.2284 - mean_squared_error: 299.2284\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 287.7559 - mean_squared_error: 287.7559\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 278.2964 - mean_squared_error: 278.2964\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 270.4361 - mean_squared_error: 270.4361\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 263.8136 - mean_squared_error: 263.8136\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 258.6759 - mean_squared_error: 258.6759\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 255.7655 - mean_squared_error: 255.7655\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 250.8937 - mean_squared_error: 250.8937\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 247.0652 - mean_squared_error: 247.0652\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 245.2584 - mean_squared_error: 245.2584\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.7866 - mean_squared_error: 242.7866\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 241.6178 - mean_squared_error: 241.6178\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 239.1631 - mean_squared_error: 239.1631\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.7693 - mean_squared_error: 236.7693\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.6253 - mean_squared_error: 236.6253\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.5295 - mean_squared_error: 234.5295\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.2000 - mean_squared_error: 233.2000\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.5107 - mean_squared_error: 233.5107\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.0394 - mean_squared_error: 232.0394\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.9766 - mean_squared_error: 229.9766\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.3574 - mean_squared_error: 229.3574\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.0671 - mean_squared_error: 229.0671\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.8969 - mean_squared_error: 225.8969\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.6879 - mean_squared_error: 223.6879\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.1423 - mean_squared_error: 224.1423\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.8296 - mean_squared_error: 224.8296\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.8792 - mean_squared_error: 222.8792\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.6366 - mean_squared_error: 219.6366\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.8237 - mean_squared_error: 218.8237\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.0364 - mean_squared_error: 218.0364\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.9376 - mean_squared_error: 217.9376\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.7724 - mean_squared_error: 217.7724\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.3515 - mean_squared_error: 215.3515\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.2892 - mean_squared_error: 217.2892\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.6681 - mean_squared_error: 214.6681\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.6076 - mean_squared_error: 214.6076\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.2380 - mean_squared_error: 212.2380\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.2076 - mean_squared_error: 212.2076\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.9969 - mean_squared_error: 210.9969\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.5929 - mean_squared_error: 211.5929\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.8599 - mean_squared_error: 208.8599\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.2935 - mean_squared_error: 210.2935\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.9077 - mean_squared_error: 207.9077\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.0974 - mean_squared_error: 208.0974\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.7991 - mean_squared_error: 205.7991\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.8477 - mean_squared_error: 203.8477\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.0199 - mean_squared_error: 206.0199\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.9103 - mean_squared_error: 203.9103\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.5325 - mean_squared_error: 205.5325\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.2758 - mean_squared_error: 202.2758\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.8214 - mean_squared_error: 204.8214\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.8872 - mean_squared_error: 200.8872\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.7755 - mean_squared_error: 200.7755\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.8344 - mean_squared_error: 199.8344\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.6276 - mean_squared_error: 201.6276\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.2672 - mean_squared_error: 198.2672\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.0020 - mean_squared_error: 199.0020\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.9840 - mean_squared_error: 198.9840\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.3399 - mean_squared_error: 199.3399\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.1395 - mean_squared_error: 194.1395\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.3735 - mean_squared_error: 196.3735\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.7313 - mean_squared_error: 195.7313\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.0721 - mean_squared_error: 193.0721\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.1997 - mean_squared_error: 194.1997\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.6587 - mean_squared_error: 192.6587\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.6603 - mean_squared_error: 198.6603\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.2514 - mean_squared_error: 195.2514\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.4583 - mean_squared_error: 190.4583\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.8448 - mean_squared_error: 192.8448\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.7876 - mean_squared_error: 192.7876\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.7573 - mean_squared_error: 192.7573\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.1424 - mean_squared_error: 190.1424\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.5009 - mean_squared_error: 192.5009\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.4474 - mean_squared_error: 192.4474\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.5055 - mean_squared_error: 191.5055\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.9147 - mean_squared_error: 189.9147\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.1216 - mean_squared_error: 187.1216\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.2308 - mean_squared_error: 185.2308\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.4520 - mean_squared_error: 189.4520\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.9938 - mean_squared_error: 184.9938\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.0470 - mean_squared_error: 185.0470\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.7327 - mean_squared_error: 186.7327\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.6998 - mean_squared_error: 184.6998\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.1584 - mean_squared_error: 186.1584\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.1514 - mean_squared_error: 182.1514\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.8025 - mean_squared_error: 182.8025\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.9100 - mean_squared_error: 180.9100\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.2638 - mean_squared_error: 184.2638\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.7196 - mean_squared_error: 180.7196\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.8860 - mean_squared_error: 180.8860\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.9123 - mean_squared_error: 178.9123\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.3428 - mean_squared_error: 177.3428\n",
      "3666/3666 [==============================] - 0s 17us/step\n",
      "100/100 [==============================] - 0s 18us/step\n",
      "\n",
      "Experiment on Fold  4\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 936)               315432    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 937       \n",
      "=================================================================\n",
      "Total params: 316,369\n",
      "Trainable params: 316,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 9us/step - loss: 3799.0640 - mean_squared_error: 3799.0640\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 692.9403 - mean_squared_error: 692.9403\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 528.0414 - mean_squared_error: 528.0414\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 461.4835 - mean_squared_error: 461.4835\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 414.2485 - mean_squared_error: 414.2485\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 373.0771 - mean_squared_error: 373.0771\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 341.0221 - mean_squared_error: 341.0221\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 319.4028 - mean_squared_error: 319.4028\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 303.5427 - mean_squared_error: 303.5427\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 290.6407 - mean_squared_error: 290.6407\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 282.7382 - mean_squared_error: 282.7382\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 274.1307 - mean_squared_error: 274.1307\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 268.1518 - mean_squared_error: 268.1518\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 262.6317 - mean_squared_error: 262.6317\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 258.9407 - mean_squared_error: 258.9407\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 255.0913 - mean_squared_error: 255.0913\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 251.9897 - mean_squared_error: 251.9897\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 249.6083 - mean_squared_error: 249.6083\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 248.3037 - mean_squared_error: 248.3037\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 244.9026 - mean_squared_error: 244.9026\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.9768 - mean_squared_error: 242.9768\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.2291 - mean_squared_error: 242.2291\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 239.4850 - mean_squared_error: 239.4850\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.0851 - mean_squared_error: 238.0851\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 235.6938 - mean_squared_error: 235.6938\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 235.1617 - mean_squared_error: 235.1617\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.2675 - mean_squared_error: 233.2675\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.3850 - mean_squared_error: 231.3850\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.6761 - mean_squared_error: 228.6761\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.7252 - mean_squared_error: 228.7252\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.2675 - mean_squared_error: 227.2675\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.5658 - mean_squared_error: 224.5658\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.2517 - mean_squared_error: 227.2517\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.3234 - mean_squared_error: 226.3234\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.7612 - mean_squared_error: 222.7612\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.2820 - mean_squared_error: 222.2820\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.1624 - mean_squared_error: 220.1624\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.7475 - mean_squared_error: 219.7475\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.1116 - mean_squared_error: 222.1116\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.5200 - mean_squared_error: 216.5200\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.6140 - mean_squared_error: 215.6140\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.2381 - mean_squared_error: 215.2381\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.4922 - mean_squared_error: 214.4922\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.3327 - mean_squared_error: 215.3327\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.9486 - mean_squared_error: 213.9486\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.0166 - mean_squared_error: 211.0166\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.3754 - mean_squared_error: 212.3754\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.7584 - mean_squared_error: 211.7584\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.5408 - mean_squared_error: 208.5408\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.1966 - mean_squared_error: 212.1966\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.0334 - mean_squared_error: 209.0334\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.3852 - mean_squared_error: 208.3852\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.1388 - mean_squared_error: 208.1388\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.6129 - mean_squared_error: 206.6129\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.3043 - mean_squared_error: 204.3043\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.9572 - mean_squared_error: 202.9572\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.9815 - mean_squared_error: 204.9815\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.2126 - mean_squared_error: 203.2126\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.4039 - mean_squared_error: 203.4039\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.7792 - mean_squared_error: 200.7792\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.2243 - mean_squared_error: 201.2243\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.2466 - mean_squared_error: 204.2466\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.7529 - mean_squared_error: 199.7529\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.3320 - mean_squared_error: 200.3320\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.5936 - mean_squared_error: 199.5936\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.8062 - mean_squared_error: 199.8062\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.1963 - mean_squared_error: 200.1963\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.5402 - mean_squared_error: 195.5402\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.1214 - mean_squared_error: 196.1214\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.8679 - mean_squared_error: 195.8679\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.0112 - mean_squared_error: 202.0112\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.9199 - mean_squared_error: 195.9199\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.0374 - mean_squared_error: 193.0374\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.1066 - mean_squared_error: 195.1066\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.0026 - mean_squared_error: 195.0026\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.1076 - mean_squared_error: 191.1076\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.2172 - mean_squared_error: 192.2172\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.3310 - mean_squared_error: 191.3310\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.9602 - mean_squared_error: 193.9602\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.0915 - mean_squared_error: 192.0915\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.1850 - mean_squared_error: 192.1850\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.4581 - mean_squared_error: 189.4581\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.9713 - mean_squared_error: 190.9713\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.3033 - mean_squared_error: 190.3033\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.1542 - mean_squared_error: 188.1542\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.8064 - mean_squared_error: 188.8064\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.8208 - mean_squared_error: 191.8208\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.0582 - mean_squared_error: 186.0582\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.9402 - mean_squared_error: 183.9402\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.5540 - mean_squared_error: 183.5540\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.5171 - mean_squared_error: 185.5171\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.4172 - mean_squared_error: 182.4172\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.3071 - mean_squared_error: 184.3071\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.0408 - mean_squared_error: 185.0408\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.6352 - mean_squared_error: 185.6352\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.1076 - mean_squared_error: 182.1076\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.1500 - mean_squared_error: 183.1500\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.8170 - mean_squared_error: 181.8170\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.1971 - mean_squared_error: 180.1971\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.7751 - mean_squared_error: 182.7751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3666/3666 [==============================] - 0s 17us/step\n",
      "100/100 [==============================] - 0s 21us/step\n",
      "Testing for yulin/alpha0.6/bestModel_global.json\n",
      "Loading data for dataset 1 with window_size of 24, stride of 1 and maxRUL of 129. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(18331, 336)\n",
      "(18331, 1)\n",
      "Testing data (X, y)\n",
      "(100, 336)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.63253012 -0.18639634 -0.38048616 ... -0.33333333  0.33333333\n",
      "   0.31289699]\n",
      " [-0.43373494 -0.09396119 -0.29473329 ... -0.16666667  0.25581395\n",
      "   0.47638774]\n",
      " [-0.31325301 -0.26095487 -0.25894666 ...  0.          0.11627907\n",
      "   0.43800055]\n",
      " [-0.31325301 -0.48768258 -0.33760972 ... -0.16666667  0.31782946\n",
      "   0.52720243]\n",
      " [-0.30120482 -0.48506649 -0.19074949 ... -0.66666667  0.34883721\n",
      "   0.07677437]]\n",
      "[[129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]]\n",
      "Testing data (X, y)\n",
      "[[-0.19879518 -0.5705254  -0.37069548 ... -0.16666667  0.03875969\n",
      "   0.27312897]\n",
      " [-0.21686747 -0.30237628 -0.12086428 ... -0.5         0.03875969\n",
      "   0.01518917]\n",
      " [-0.04216867 -0.1942446  -0.0209318  ...  0.16666667  0.2248062\n",
      "   0.04888152]\n",
      " [-0.22891566 -0.01722259 -0.13673194 ...  0.16666667 -0.31782946\n",
      "   0.004971  ]\n",
      " [-0.11445783 -0.11968607  0.03511141 ...  0.         -0.05426357\n",
      "   0.42916321]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n",
      "Validation on model:best_models/cmapss/yulin/alpha0.6/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 184)               62008     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 184)               34040     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 185       \n",
      "=================================================================\n",
      "Total params: 96,233\n",
      "Trainable params: 96,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14664/14664 [==============================] - 0s 11us/step - loss: 3831.9345 - mean_squared_error: 3831.9345\n",
      "Epoch 2/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 544.8034 - mean_squared_error: 544.8034\n",
      "Epoch 3/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 416.7369 - mean_squared_error: 416.7369\n",
      "Epoch 4/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 340.1401 - mean_squared_error: 340.1401\n",
      "Epoch 5/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 298.8532 - mean_squared_error: 298.8532\n",
      "Epoch 6/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 271.9439 - mean_squared_error: 271.9439\n",
      "Epoch 7/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 259.3654 - mean_squared_error: 259.3654\n",
      "Epoch 8/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 247.4813 - mean_squared_error: 247.4813\n",
      "Epoch 9/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 244.1721 - mean_squared_error: 244.1721\n",
      "Epoch 10/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 240.0469 - mean_squared_error: 240.0469\n",
      "Epoch 11/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 238.8025 - mean_squared_error: 238.8025\n",
      "Epoch 12/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 233.3132 - mean_squared_error: 233.3132\n",
      "Epoch 13/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 236.2634 - mean_squared_error: 236.2634\n",
      "Epoch 14/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 233.2128 - mean_squared_error: 233.2128\n",
      "Epoch 15/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 232.4160 - mean_squared_error: 232.4160\n",
      "Epoch 16/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 226.2804 - mean_squared_error: 226.2804\n",
      "Epoch 17/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 229.0152 - mean_squared_error: 229.0152\n",
      "Epoch 18/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 227.7025 - mean_squared_error: 227.7025\n",
      "Epoch 19/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 225.5128 - mean_squared_error: 225.5128\n",
      "Epoch 20/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 222.3587 - mean_squared_error: 222.3587\n",
      "Epoch 21/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 221.0240 - mean_squared_error: 221.0240\n",
      "Epoch 22/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 222.5735 - mean_squared_error: 222.5735\n",
      "Epoch 23/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 222.3542 - mean_squared_error: 222.3542\n",
      "Epoch 24/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 217.9167 - mean_squared_error: 217.9167\n",
      "Epoch 25/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 224.8090 - mean_squared_error: 224.8090\n",
      "Epoch 26/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 215.5395 - mean_squared_error: 215.5395\n",
      "Epoch 27/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 212.5873 - mean_squared_error: 212.5873\n",
      "Epoch 28/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 212.9059 - mean_squared_error: 212.9059\n",
      "Epoch 29/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 212.4005 - mean_squared_error: 212.4005\n",
      "Epoch 30/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 211.9156 - mean_squared_error: 211.9156\n",
      "Epoch 31/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 213.8210 - mean_squared_error: 213.8210\n",
      "Epoch 32/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 207.8287 - mean_squared_error: 207.8287\n",
      "Epoch 33/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 211.3006 - mean_squared_error: 211.3006\n",
      "Epoch 34/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 208.0173 - mean_squared_error: 208.0173\n",
      "Epoch 35/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 204.7950 - mean_squared_error: 204.7950\n",
      "Epoch 36/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 209.4395 - mean_squared_error: 209.4395\n",
      "Epoch 37/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 203.5547 - mean_squared_error: 203.5547\n",
      "Epoch 38/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 206.0992 - mean_squared_error: 206.0992\n",
      "Epoch 39/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 203.1551 - mean_squared_error: 203.1551\n",
      "Epoch 40/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 201.9978 - mean_squared_error: 201.9978\n",
      "Epoch 41/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 197.7833 - mean_squared_error: 197.7833\n",
      "Epoch 42/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 199.1566 - mean_squared_error: 199.1566\n",
      "Epoch 43/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 202.7296 - mean_squared_error: 202.7296\n",
      "Epoch 44/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 192.2984 - mean_squared_error: 192.2984\n",
      "Epoch 45/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 196.6391 - mean_squared_error: 196.6391\n",
      "Epoch 46/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 191.8606 - mean_squared_error: 191.8606\n",
      "Epoch 47/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 197.9650 - mean_squared_error: 197.9650\n",
      "Epoch 48/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 189.8374 - mean_squared_error: 189.8374\n",
      "Epoch 49/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 189.4513 - mean_squared_error: 189.4513\n",
      "Epoch 50/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 187.1685 - mean_squared_error: 187.1685\n",
      "Epoch 51/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 188.1223 - mean_squared_error: 188.1223\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14664/14664 [==============================] - 0s 3us/step - loss: 188.1106 - mean_squared_error: 188.1106\n",
      "Epoch 53/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 183.0362 - mean_squared_error: 183.0362\n",
      "Epoch 54/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 183.7370 - mean_squared_error: 183.7370\n",
      "Epoch 55/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 187.0598 - mean_squared_error: 187.0598\n",
      "Epoch 56/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 179.6794 - mean_squared_error: 179.6794\n",
      "Epoch 57/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 179.6432 - mean_squared_error: 179.6432\n",
      "Epoch 58/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 174.2953 - mean_squared_error: 174.2953\n",
      "Epoch 59/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 174.3320 - mean_squared_error: 174.3320\n",
      "Epoch 60/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 177.6032 - mean_squared_error: 177.6032\n",
      "Epoch 61/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 174.9580 - mean_squared_error: 174.9580\n",
      "Epoch 62/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 177.9838 - mean_squared_error: 177.9838\n",
      "Epoch 63/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 173.6523 - mean_squared_error: 173.6523\n",
      "Epoch 64/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 172.5423 - mean_squared_error: 172.5423\n",
      "Epoch 65/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 174.9729 - mean_squared_error: 174.9729\n",
      "Epoch 66/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 174.8534 - mean_squared_error: 174.8534\n",
      "Epoch 67/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 168.6641 - mean_squared_error: 168.6641\n",
      "Epoch 68/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 177.9058 - mean_squared_error: 177.9058\n",
      "Epoch 69/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 169.8344 - mean_squared_error: 169.8344\n",
      "Epoch 70/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 166.5337 - mean_squared_error: 166.5337\n",
      "Epoch 71/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 176.5149 - mean_squared_error: 176.5149\n",
      "Epoch 72/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 159.6592 - mean_squared_error: 159.6592\n",
      "Epoch 73/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 161.7236 - mean_squared_error: 161.7236\n",
      "Epoch 74/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 160.0605 - mean_squared_error: 160.0605\n",
      "Epoch 75/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 166.8468 - mean_squared_error: 166.8468\n",
      "Epoch 76/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 161.9954 - mean_squared_error: 161.9954\n",
      "Epoch 77/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 158.5757 - mean_squared_error: 158.5757\n",
      "Epoch 78/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 153.6575 - mean_squared_error: 153.6575\n",
      "Epoch 79/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 161.7390 - mean_squared_error: 161.7390\n",
      "Epoch 80/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 151.7844 - mean_squared_error: 151.7844\n",
      "Epoch 81/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 154.1972 - mean_squared_error: 154.1972\n",
      "Epoch 82/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 152.1918 - mean_squared_error: 152.1918\n",
      "Epoch 83/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 149.0283 - mean_squared_error: 149.0283\n",
      "Epoch 84/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 160.3475 - mean_squared_error: 160.3475\n",
      "Epoch 85/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 141.8962 - mean_squared_error: 141.8962\n",
      "Epoch 86/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 153.3655 - mean_squared_error: 153.3655\n",
      "Epoch 87/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 148.5826 - mean_squared_error: 148.5826\n",
      "Epoch 88/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 152.8310 - mean_squared_error: 152.8310\n",
      "Epoch 89/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 144.7193 - mean_squared_error: 144.7193\n",
      "Epoch 90/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 143.9198 - mean_squared_error: 143.9198\n",
      "Epoch 91/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 139.6276 - mean_squared_error: 139.6276\n",
      "Epoch 92/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 152.1996 - mean_squared_error: 152.1996\n",
      "Epoch 93/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 147.2363 - mean_squared_error: 147.2363\n",
      "Epoch 94/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 148.0430 - mean_squared_error: 148.0430\n",
      "Epoch 95/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 140.1598 - mean_squared_error: 140.1598\n",
      "Epoch 96/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 135.3949 - mean_squared_error: 135.3949\n",
      "Epoch 97/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 145.7230 - mean_squared_error: 145.7230\n",
      "Epoch 98/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 137.9967 - mean_squared_error: 137.9967\n",
      "Epoch 99/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 137.1489 - mean_squared_error: 137.1489\n",
      "Epoch 100/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 135.5254 - mean_squared_error: 135.5254\n",
      "3667/3667 [==============================] - 0s 16us/step\n",
      "100/100 [==============================] - 0s 21us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 184)               62008     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 184)               34040     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 185       \n",
      "=================================================================\n",
      "Total params: 96,233\n",
      "Trainable params: 96,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 11us/step - loss: 3868.2470 - mean_squared_error: 3868.2470\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 549.4200 - mean_squared_error: 549.4200\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 419.2125 - mean_squared_error: 419.2125\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 330.4892 - mean_squared_error: 330.4892\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 284.8419 - mean_squared_error: 284.8419\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 271.7140 - mean_squared_error: 271.7140\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 260.3186 - mean_squared_error: 260.3186\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 249.8690 - mean_squared_error: 249.8690\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 246.1278 - mean_squared_error: 246.1278\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.7111 - mean_squared_error: 238.7111\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.1353 - mean_squared_error: 236.1353\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 235.5099 - mean_squared_error: 235.5099\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.9090 - mean_squared_error: 234.9090\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.9605 - mean_squared_error: 230.9605\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.3845 - mean_squared_error: 233.3845\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.9943 - mean_squared_error: 233.9943\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.0777 - mean_squared_error: 232.0777\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.4681 - mean_squared_error: 223.4681\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.4544 - mean_squared_error: 224.4544\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.2092 - mean_squared_error: 224.2092\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.7184 - mean_squared_error: 224.7184\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.1783 - mean_squared_error: 221.1783\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.4815 - mean_squared_error: 218.4815\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.9276 - mean_squared_error: 221.9276\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.6304 - mean_squared_error: 221.6304\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.0882 - mean_squared_error: 219.0882\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.4326 - mean_squared_error: 218.4326\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.0378 - mean_squared_error: 223.0378\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.7033 - mean_squared_error: 216.7033\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.3182 - mean_squared_error: 212.3182\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.0789 - mean_squared_error: 217.0789\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.8233 - mean_squared_error: 212.8233\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.4711 - mean_squared_error: 212.4711\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.5667 - mean_squared_error: 219.5667\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.6393 - mean_squared_error: 210.6393\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.2507 - mean_squared_error: 210.2507\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.8226 - mean_squared_error: 214.8226\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.7616 - mean_squared_error: 207.7616\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.0317 - mean_squared_error: 207.0317\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.6815 - mean_squared_error: 205.6815\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.3408 - mean_squared_error: 212.3408\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.1628 - mean_squared_error: 202.1628\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.8925 - mean_squared_error: 202.8925\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.2025 - mean_squared_error: 213.2025\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.7469 - mean_squared_error: 205.7469\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.3507 - mean_squared_error: 202.3507\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.8324 - mean_squared_error: 194.8324\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.7562 - mean_squared_error: 197.7562\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.5593 - mean_squared_error: 202.5593\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.6080 - mean_squared_error: 197.6080\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.3886 - mean_squared_error: 202.3886\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.2637 - mean_squared_error: 196.2637\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.3046 - mean_squared_error: 191.3046\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.8426 - mean_squared_error: 192.8426\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.5599 - mean_squared_error: 188.5599\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.6386 - mean_squared_error: 198.6386\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.7628 - mean_squared_error: 190.7628\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.2600 - mean_squared_error: 186.2600\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.3241 - mean_squared_error: 187.3241\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.0604 - mean_squared_error: 187.0604\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.1291 - mean_squared_error: 183.1291\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.9975 - mean_squared_error: 189.9975\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.2410 - mean_squared_error: 191.2410\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.2610 - mean_squared_error: 192.2610\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.5107 - mean_squared_error: 181.5107\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.4936 - mean_squared_error: 178.4936\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.4903 - mean_squared_error: 186.4903\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.1757 - mean_squared_error: 176.1757\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.8478 - mean_squared_error: 179.8478\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.5658 - mean_squared_error: 181.5658\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.1541 - mean_squared_error: 179.1541\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.2418 - mean_squared_error: 182.2418\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.2468 - mean_squared_error: 170.2468\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.9782 - mean_squared_error: 165.9782\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.1917 - mean_squared_error: 175.1917\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.6531 - mean_squared_error: 169.6531\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.3527 - mean_squared_error: 175.3527\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.8840 - mean_squared_error: 165.8840\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.5112 - mean_squared_error: 176.5112\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.7822 - mean_squared_error: 172.7822\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.5987 - mean_squared_error: 160.5987\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.7255 - mean_squared_error: 169.7255\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.3572 - mean_squared_error: 165.3572\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.3538 - mean_squared_error: 164.3538\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 153.2988 - mean_squared_error: 153.2988\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.2133 - mean_squared_error: 158.2133\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 153.7604 - mean_squared_error: 153.7604\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.7183 - mean_squared_error: 168.7183\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 155.6284 - mean_squared_error: 155.6284\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 161.2851 - mean_squared_error: 161.2851\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 155.3012 - mean_squared_error: 155.3012\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 153.8219 - mean_squared_error: 153.8219\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.8088 - mean_squared_error: 156.8088\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.9882 - mean_squared_error: 158.9882\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.3841 - mean_squared_error: 156.3841\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.3425 - mean_squared_error: 162.3425\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 145.5641 - mean_squared_error: 145.5641\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 146.4070 - mean_squared_error: 146.4070\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 145.3647 - mean_squared_error: 145.3647\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 145.1806 - mean_squared_error: 145.1806\n",
      "3666/3666 [==============================] - 0s 18us/step\n",
      "100/100 [==============================] - 0s 20us/step\n",
      "\n",
      "Experiment on Fold  2\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 184)               62008     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 184)               34040     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 185       \n",
      "=================================================================\n",
      "Total params: 96,233\n",
      "Trainable params: 96,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 11us/step - loss: 3738.9613 - mean_squared_error: 3738.9613\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 538.4375 - mean_squared_error: 538.4375\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 407.2368 - mean_squared_error: 407.2368\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 322.6158 - mean_squared_error: 322.6158\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 285.7183 - mean_squared_error: 285.7183\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 271.0024 - mean_squared_error: 271.0024\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 256.9992 - mean_squared_error: 256.9992\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 248.0271 - mean_squared_error: 248.0271\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.4246 - mean_squared_error: 242.4246\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 241.3778 - mean_squared_error: 241.3778\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.5456 - mean_squared_error: 236.5456\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.5775 - mean_squared_error: 233.5775\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.6075 - mean_squared_error: 232.6075\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.8911 - mean_squared_error: 230.8911\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.1512 - mean_squared_error: 228.1512\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.8192 - mean_squared_error: 229.8192\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.5945 - mean_squared_error: 226.5945\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.5741 - mean_squared_error: 230.5741\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.2847 - mean_squared_error: 225.2847\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.7678 - mean_squared_error: 226.7678\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.2405 - mean_squared_error: 224.2405\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.0253 - mean_squared_error: 223.0253\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.1158 - mean_squared_error: 224.1158\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.2325 - mean_squared_error: 220.2325\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.2138 - mean_squared_error: 221.2138\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.2029 - mean_squared_error: 220.2029\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.0548 - mean_squared_error: 218.0548\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.8606 - mean_squared_error: 216.8606\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.9676 - mean_squared_error: 217.9676\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.9750 - mean_squared_error: 212.9750\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.8708 - mean_squared_error: 215.8708\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.1282 - mean_squared_error: 216.1282\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.5191 - mean_squared_error: 211.5191\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.7685 - mean_squared_error: 207.7685\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.7700 - mean_squared_error: 210.7700\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.5054 - mean_squared_error: 213.5054\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.8181 - mean_squared_error: 202.8181\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.2666 - mean_squared_error: 204.2666\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.4621 - mean_squared_error: 202.4621\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.3852 - mean_squared_error: 203.3852\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.5913 - mean_squared_error: 208.5913\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.4489 - mean_squared_error: 196.4489\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.2445 - mean_squared_error: 200.2445\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.3531 - mean_squared_error: 200.3531\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.8753 - mean_squared_error: 195.8753\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.3758 - mean_squared_error: 197.3758\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.7344 - mean_squared_error: 193.7344\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.0827 - mean_squared_error: 200.0827\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.7111 - mean_squared_error: 196.7111\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.9989 - mean_squared_error: 194.9989\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 193.8607 - mean_squared_error: 193.8607\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.4699 - mean_squared_error: 191.4699\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.2160 - mean_squared_error: 192.2160\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.5417 - mean_squared_error: 186.5417\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.9738 - mean_squared_error: 185.9738\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.3848 - mean_squared_error: 186.3848\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.8275 - mean_squared_error: 184.8275\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.2994 - mean_squared_error: 185.2994\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.8355 - mean_squared_error: 184.8355\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.4503 - mean_squared_error: 182.4503\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.2729 - mean_squared_error: 179.2729\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.4629 - mean_squared_error: 185.4629\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.2485 - mean_squared_error: 187.2485\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.0329 - mean_squared_error: 180.0329\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.4072 - mean_squared_error: 182.4072\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.7264 - mean_squared_error: 177.7264\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.0529 - mean_squared_error: 180.0529\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.7873 - mean_squared_error: 172.7873\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.7712 - mean_squared_error: 181.7712\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.1980 - mean_squared_error: 169.1980\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.3188 - mean_squared_error: 169.3188\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.5192 - mean_squared_error: 169.5192\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.7328 - mean_squared_error: 174.7328\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.2619 - mean_squared_error: 181.2619\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 161.3458 - mean_squared_error: 161.3458\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.4172 - mean_squared_error: 165.4172\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.9806 - mean_squared_error: 160.9806\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.9926 - mean_squared_error: 168.9926\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.4982 - mean_squared_error: 159.4982\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.6522 - mean_squared_error: 165.6522\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.0849 - mean_squared_error: 162.0849\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.2319 - mean_squared_error: 166.2319\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.3292 - mean_squared_error: 157.3292\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 152.5654 - mean_squared_error: 152.5654\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.4946 - mean_squared_error: 154.4946\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.9441 - mean_squared_error: 158.9441\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.6674 - mean_squared_error: 154.6674\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.8345 - mean_squared_error: 158.8345\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.8652 - mean_squared_error: 157.8652\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.3079 - mean_squared_error: 156.3079\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 146.6547 - mean_squared_error: 146.6547\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.2270 - mean_squared_error: 164.2270\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 146.3826 - mean_squared_error: 146.3826\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 150.2446 - mean_squared_error: 150.2446\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 155.7281 - mean_squared_error: 155.7281\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.1897 - mean_squared_error: 154.1897\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 155.0714 - mean_squared_error: 155.0714\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 150.5176 - mean_squared_error: 150.5176\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 149.4064 - mean_squared_error: 149.4064\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 145.1321 - mean_squared_error: 145.1321\n",
      "3666/3666 [==============================] - 0s 19us/step\n",
      "100/100 [==============================] - 0s 20us/step\n",
      "\n",
      "Experiment on Fold  3\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 184)               62008     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 184)               34040     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 185       \n",
      "=================================================================\n",
      "Total params: 96,233\n",
      "Trainable params: 96,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 11us/step - loss: 4184.5187 - mean_squared_error: 4184.5187\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 559.6555 - mean_squared_error: 559.6555\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 419.5944 - mean_squared_error: 419.5944\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 327.3062 - mean_squared_error: 327.3062\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 287.2380 - mean_squared_error: 287.2380\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 268.0451 - mean_squared_error: 268.0451\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 254.4730 - mean_squared_error: 254.4730\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 250.8186 - mean_squared_error: 250.8186\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 242.7387 - mean_squared_error: 242.7387\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 239.5527 - mean_squared_error: 239.5527\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 237.0571 - mean_squared_error: 237.0571\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 235.2006 - mean_squared_error: 235.2006\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.1393 - mean_squared_error: 231.1393\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.6317 - mean_squared_error: 232.6317\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.4534 - mean_squared_error: 231.4534\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.4626 - mean_squared_error: 227.4626\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.2140 - mean_squared_error: 231.2140\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.8666 - mean_squared_error: 222.8666\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.4582 - mean_squared_error: 224.4582\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.6759 - mean_squared_error: 222.6759\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.0055 - mean_squared_error: 221.0055\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.3997 - mean_squared_error: 221.3997\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.2387 - mean_squared_error: 220.2387\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.2652 - mean_squared_error: 219.2652\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.6600 - mean_squared_error: 217.6600\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.4750 - mean_squared_error: 215.4750\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.2523 - mean_squared_error: 213.2523\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.8357 - mean_squared_error: 217.8357\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.3419 - mean_squared_error: 208.3419\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.8265 - mean_squared_error: 208.8265\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.1827 - mean_squared_error: 209.1827\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.1643 - mean_squared_error: 209.1643\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.5473 - mean_squared_error: 204.5473\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.5878 - mean_squared_error: 207.5878\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.7710 - mean_squared_error: 205.7710\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.0935 - mean_squared_error: 198.0935\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.9343 - mean_squared_error: 201.9343\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.5933 - mean_squared_error: 205.5933\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.0435 - mean_squared_error: 201.0435\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.8004 - mean_squared_error: 203.8004\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.4089 - mean_squared_error: 202.4089\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.9005 - mean_squared_error: 192.9005\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.7510 - mean_squared_error: 191.7510\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.1170 - mean_squared_error: 200.1170\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.2718 - mean_squared_error: 196.2718\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.1553 - mean_squared_error: 192.1553\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.1218 - mean_squared_error: 188.1218\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.8359 - mean_squared_error: 191.8359\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.7108 - mean_squared_error: 188.7108\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.6322 - mean_squared_error: 188.6322\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.8343 - mean_squared_error: 188.8343\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.5763 - mean_squared_error: 179.5763\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.9935 - mean_squared_error: 184.9935\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.1649 - mean_squared_error: 181.1649\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.6550 - mean_squared_error: 184.6550\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.3127 - mean_squared_error: 183.3127\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.0380 - mean_squared_error: 176.0380\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.2978 - mean_squared_error: 175.2978\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.1835 - mean_squared_error: 185.1835\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.9117 - mean_squared_error: 179.9117\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.4880 - mean_squared_error: 172.4880\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.9068 - mean_squared_error: 180.9068\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.8633 - mean_squared_error: 171.8633\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.5975 - mean_squared_error: 165.5975\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.6438 - mean_squared_error: 171.6438\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.4321 - mean_squared_error: 173.4321\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.0852 - mean_squared_error: 171.0852\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.2181 - mean_squared_error: 166.2181\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.4425 - mean_squared_error: 165.4425\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.4184 - mean_squared_error: 157.4184\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.5871 - mean_squared_error: 162.5871\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.2224 - mean_squared_error: 157.2224\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.4442 - mean_squared_error: 159.4442\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.0404 - mean_squared_error: 164.0404\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.5918 - mean_squared_error: 154.5918\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.0651 - mean_squared_error: 156.0651\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 150.2611 - mean_squared_error: 150.2611\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 152.9043 - mean_squared_error: 152.9043\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 161.2938 - mean_squared_error: 161.2938\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.6223 - mean_squared_error: 157.6223\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.0824 - mean_squared_error: 158.0824\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 147.9485 - mean_squared_error: 147.9485\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 152.6941 - mean_squared_error: 152.6941\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 144.9925 - mean_squared_error: 144.9925\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.5132 - mean_squared_error: 154.5132\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.5138 - mean_squared_error: 154.5138\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 146.7796 - mean_squared_error: 146.7796\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 153.2781 - mean_squared_error: 153.2781\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 145.6890 - mean_squared_error: 145.6890\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 143.4783 - mean_squared_error: 143.4783\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 137.9388 - mean_squared_error: 137.9388\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 137.6048 - mean_squared_error: 137.6048\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 133.1782 - mean_squared_error: 133.1782\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 140.3099 - mean_squared_error: 140.3099\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 136.4437 - mean_squared_error: 136.4437\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 129.8093 - mean_squared_error: 129.8093\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 139.3080 - mean_squared_error: 139.3080\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 134.2386 - mean_squared_error: 134.2386\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 131.1402 - mean_squared_error: 131.1402\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 133.9991 - mean_squared_error: 133.9991\n",
      "3666/3666 [==============================] - 0s 18us/step\n",
      "100/100 [==============================] - 0s 18us/step\n",
      "\n",
      "Experiment on Fold  4\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 184)               62008     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 184)               34040     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 185       \n",
      "=================================================================\n",
      "Total params: 96,233\n",
      "Trainable params: 96,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 11us/step - loss: 3977.1813 - mean_squared_error: 3977.1813\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 579.7182 - mean_squared_error: 579.7182\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 438.7506 - mean_squared_error: 438.7506\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 354.6134 - mean_squared_error: 354.6134\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 303.0697 - mean_squared_error: 303.0697\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 272.3685 - mean_squared_error: 272.3685\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 260.1171 - mean_squared_error: 260.1171\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 249.6752 - mean_squared_error: 249.6752\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 243.0477 - mean_squared_error: 243.0477\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 239.9105 - mean_squared_error: 239.9105\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.7553 - mean_squared_error: 234.7553\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.4307 - mean_squared_error: 236.4307\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.3807 - mean_squared_error: 230.3807\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.0294 - mean_squared_error: 230.0294\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.6895 - mean_squared_error: 230.6895\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.3702 - mean_squared_error: 229.3702\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.7012 - mean_squared_error: 225.7012\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.8742 - mean_squared_error: 230.8742\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.3287 - mean_squared_error: 225.3287\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.9962 - mean_squared_error: 223.9962\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.1783 - mean_squared_error: 223.1783\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.9052 - mean_squared_error: 223.9052\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.2449 - mean_squared_error: 222.2449\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.5556 - mean_squared_error: 221.5556\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.1567 - mean_squared_error: 220.1567\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.7255 - mean_squared_error: 218.7255\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.6956 - mean_squared_error: 221.6956\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.6216 - mean_squared_error: 218.6216\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 215.4341 - mean_squared_error: 215.4341\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.0563 - mean_squared_error: 216.0563\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.8521 - mean_squared_error: 213.8521\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.1817 - mean_squared_error: 212.1817\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.4259 - mean_squared_error: 217.4259\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.2439 - mean_squared_error: 211.2439\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.6092 - mean_squared_error: 222.6092\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.2136 - mean_squared_error: 210.2136\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.5331 - mean_squared_error: 214.5331\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.8365 - mean_squared_error: 212.8365\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.5084 - mean_squared_error: 210.5084\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.9024 - mean_squared_error: 210.9024\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.0241 - mean_squared_error: 210.0241\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.7241 - mean_squared_error: 205.7241\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.8477 - mean_squared_error: 205.8477\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.1289 - mean_squared_error: 211.1289\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.4646 - mean_squared_error: 205.4646\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.2975 - mean_squared_error: 202.2975\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.9010 - mean_squared_error: 201.9010\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.5731 - mean_squared_error: 197.5731\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.2941 - mean_squared_error: 202.2941\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.4780 - mean_squared_error: 204.4780\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.7461 - mean_squared_error: 198.7461\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.2311 - mean_squared_error: 201.2311\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.6174 - mean_squared_error: 202.6174\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.1777 - mean_squared_error: 188.1777\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.8809 - mean_squared_error: 198.8809\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.5517 - mean_squared_error: 194.5517\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.6281 - mean_squared_error: 190.6281\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.8534 - mean_squared_error: 188.8534\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.9191 - mean_squared_error: 188.9191\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.7923 - mean_squared_error: 192.7923\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.2880 - mean_squared_error: 188.2880\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.0829 - mean_squared_error: 195.0829\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.9397 - mean_squared_error: 178.9397\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.4164 - mean_squared_error: 187.4164\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.2646 - mean_squared_error: 186.2646\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.7342 - mean_squared_error: 183.7342\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.4521 - mean_squared_error: 181.4521\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.5700 - mean_squared_error: 185.5700\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.5024 - mean_squared_error: 185.5024\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.0869 - mean_squared_error: 195.0869\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.3506 - mean_squared_error: 180.3506\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.8445 - mean_squared_error: 177.8445\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.7686 - mean_squared_error: 180.7686\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.0066 - mean_squared_error: 178.0066\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.3290 - mean_squared_error: 177.3290\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.4283 - mean_squared_error: 176.4283\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.6608 - mean_squared_error: 172.6608\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.3158 - mean_squared_error: 171.3158\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.8736 - mean_squared_error: 170.8736\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.6622 - mean_squared_error: 174.6622\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.9821 - mean_squared_error: 166.9821\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.4571 - mean_squared_error: 179.4571\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.2434 - mean_squared_error: 171.2434\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.9304 - mean_squared_error: 169.9304\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.0356 - mean_squared_error: 162.0356\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.7901 - mean_squared_error: 169.7901\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 161.6891 - mean_squared_error: 161.6891\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.7741 - mean_squared_error: 157.7741\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.2585 - mean_squared_error: 168.2585\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 161.2025 - mean_squared_error: 161.2025\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.9158 - mean_squared_error: 160.9158\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.4374 - mean_squared_error: 157.4374\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 155.5507 - mean_squared_error: 155.5507\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.3504 - mean_squared_error: 162.3504\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 163.9788 - mean_squared_error: 163.9788\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 149.9505 - mean_squared_error: 149.9505\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 150.5942 - mean_squared_error: 150.5942\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 155.6778 - mean_squared_error: 155.6778\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.5459 - mean_squared_error: 159.5459\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.5461 - mean_squared_error: 157.5461\n",
      "3666/3666 [==============================] - 0s 16us/step\n",
      "100/100 [==============================] - 0s 20us/step\n",
      "Testing for yulin/alpha0.7/bestModel_global.json\n",
      "Loading data for dataset 1 with window_size of 24, stride of 1 and maxRUL of 129. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(18331, 336)\n",
      "(18331, 1)\n",
      "Testing data (X, y)\n",
      "(100, 336)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.63253012 -0.18639634 -0.38048616 ... -0.33333333  0.33333333\n",
      "   0.31289699]\n",
      " [-0.43373494 -0.09396119 -0.29473329 ... -0.16666667  0.25581395\n",
      "   0.47638774]\n",
      " [-0.31325301 -0.26095487 -0.25894666 ...  0.          0.11627907\n",
      "   0.43800055]\n",
      " [-0.31325301 -0.48768258 -0.33760972 ... -0.16666667  0.31782946\n",
      "   0.52720243]\n",
      " [-0.30120482 -0.48506649 -0.19074949 ... -0.66666667  0.34883721\n",
      "   0.07677437]]\n",
      "[[129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]]\n",
      "Testing data (X, y)\n",
      "[[-0.19879518 -0.5705254  -0.37069548 ... -0.16666667  0.03875969\n",
      "   0.27312897]\n",
      " [-0.21686747 -0.30237628 -0.12086428 ... -0.5         0.03875969\n",
      "   0.01518917]\n",
      " [-0.04216867 -0.1942446  -0.0209318  ...  0.16666667  0.2248062\n",
      "   0.04888152]\n",
      " [-0.22891566 -0.01722259 -0.13673194 ...  0.16666667 -0.31782946\n",
      "   0.004971  ]\n",
      " [-0.11445783 -0.11968607  0.03511141 ...  0.         -0.05426357\n",
      "   0.42916321]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n",
      "Validation on model:best_models/cmapss/yulin/alpha0.7/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 104)               35048     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 104)               10920     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 105       \n",
      "=================================================================\n",
      "Total params: 46,073\n",
      "Trainable params: 46,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14664/14664 [==============================] - 0s 11us/step - loss: 5649.3281 - mean_squared_error: 5649.3281\n",
      "Epoch 2/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 711.1106 - mean_squared_error: 711.1106\n",
      "Epoch 3/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 537.4039 - mean_squared_error: 537.4039\n",
      "Epoch 4/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 433.9354 - mean_squared_error: 433.9354\n",
      "Epoch 5/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 363.6073 - mean_squared_error: 363.6073\n",
      "Epoch 6/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 313.1042 - mean_squared_error: 313.1042\n",
      "Epoch 7/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 285.7715 - mean_squared_error: 285.7715\n",
      "Epoch 8/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 265.2961 - mean_squared_error: 265.2961\n",
      "Epoch 9/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 256.3126 - mean_squared_error: 256.3126\n",
      "Epoch 10/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 249.6467 - mean_squared_error: 249.6467\n",
      "Epoch 11/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 243.7438 - mean_squared_error: 243.7438\n",
      "Epoch 12/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 240.1724 - mean_squared_error: 240.1724\n",
      "Epoch 13/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 237.0721 - mean_squared_error: 237.0721\n",
      "Epoch 14/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 233.8559 - mean_squared_error: 233.8559\n",
      "Epoch 15/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 232.6659 - mean_squared_error: 232.6659\n",
      "Epoch 16/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 229.9976 - mean_squared_error: 229.9976\n",
      "Epoch 17/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 229.3745 - mean_squared_error: 229.3745\n",
      "Epoch 18/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 228.4125 - mean_squared_error: 228.4125\n",
      "Epoch 19/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 225.7625 - mean_squared_error: 225.7625\n",
      "Epoch 20/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 225.4966 - mean_squared_error: 225.4966\n",
      "Epoch 21/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 223.2182 - mean_squared_error: 223.2182\n",
      "Epoch 22/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 223.3618 - mean_squared_error: 223.3618\n",
      "Epoch 23/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 223.5675 - mean_squared_error: 223.5675\n",
      "Epoch 24/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 222.8557 - mean_squared_error: 222.8557\n",
      "Epoch 25/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 219.0768 - mean_squared_error: 219.0768\n",
      "Epoch 26/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 219.5971 - mean_squared_error: 219.5971\n",
      "Epoch 27/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 218.7308 - mean_squared_error: 218.7308\n",
      "Epoch 28/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 214.9315 - mean_squared_error: 214.9315\n",
      "Epoch 29/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 215.2310 - mean_squared_error: 215.2310\n",
      "Epoch 30/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 212.8855 - mean_squared_error: 212.8855\n",
      "Epoch 31/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 213.8782 - mean_squared_error: 213.8782\n",
      "Epoch 32/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 212.3399 - mean_squared_error: 212.3399\n",
      "Epoch 33/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 209.8471 - mean_squared_error: 209.8471\n",
      "Epoch 34/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 210.1358 - mean_squared_error: 210.1358\n",
      "Epoch 35/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 207.5901 - mean_squared_error: 207.5901\n",
      "Epoch 36/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 204.6785 - mean_squared_error: 204.6785\n",
      "Epoch 37/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 205.1982 - mean_squared_error: 205.1982\n",
      "Epoch 38/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 204.5977 - mean_squared_error: 204.5977\n",
      "Epoch 39/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 202.7997 - mean_squared_error: 202.7997\n",
      "Epoch 40/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 208.0478 - mean_squared_error: 208.0478\n",
      "Epoch 41/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 200.2671 - mean_squared_error: 200.2671\n",
      "Epoch 42/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 199.4624 - mean_squared_error: 199.4624\n",
      "Epoch 43/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 198.4015 - mean_squared_error: 198.4015\n",
      "Epoch 44/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 196.9922 - mean_squared_error: 196.9922\n",
      "Epoch 45/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 196.9404 - mean_squared_error: 196.9404\n",
      "Epoch 46/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 196.8473 - mean_squared_error: 196.8473\n",
      "Epoch 47/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 196.5583 - mean_squared_error: 196.5583\n",
      "Epoch 48/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 193.4410 - mean_squared_error: 193.4410\n",
      "Epoch 49/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 195.9058 - mean_squared_error: 195.9058\n",
      "Epoch 50/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 191.8739 - mean_squared_error: 191.8739\n",
      "Epoch 51/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 192.4828 - mean_squared_error: 192.4828\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14664/14664 [==============================] - 0s 3us/step - loss: 192.9491 - mean_squared_error: 192.9491\n",
      "Epoch 53/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 189.5246 - mean_squared_error: 189.5246\n",
      "Epoch 54/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 191.8929 - mean_squared_error: 191.8929\n",
      "Epoch 55/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 187.1127 - mean_squared_error: 187.1127\n",
      "Epoch 56/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 188.8554 - mean_squared_error: 188.8554\n",
      "Epoch 57/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 184.4552 - mean_squared_error: 184.4552\n",
      "Epoch 58/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 187.6123 - mean_squared_error: 187.6123\n",
      "Epoch 59/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 181.6284 - mean_squared_error: 181.6284\n",
      "Epoch 60/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 185.0992 - mean_squared_error: 185.0992\n",
      "Epoch 61/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 182.6804 - mean_squared_error: 182.6804\n",
      "Epoch 62/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 184.2565 - mean_squared_error: 184.2565\n",
      "Epoch 63/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 187.5732 - mean_squared_error: 187.5732\n",
      "Epoch 64/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 181.8613 - mean_squared_error: 181.8613\n",
      "Epoch 65/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 183.4004 - mean_squared_error: 183.4004\n",
      "Epoch 66/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 179.8461 - mean_squared_error: 179.8461\n",
      "Epoch 67/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 177.6233 - mean_squared_error: 177.6233\n",
      "Epoch 68/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 178.8477 - mean_squared_error: 178.8477\n",
      "Epoch 69/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 184.4169 - mean_squared_error: 184.4169\n",
      "Epoch 70/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 174.5486 - mean_squared_error: 174.5486\n",
      "Epoch 71/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 176.5285 - mean_squared_error: 176.5285\n",
      "Epoch 72/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 177.2438 - mean_squared_error: 177.2438\n",
      "Epoch 73/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 174.1428 - mean_squared_error: 174.1428\n",
      "Epoch 74/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 172.7620 - mean_squared_error: 172.7620\n",
      "Epoch 75/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 176.5342 - mean_squared_error: 176.5342\n",
      "Epoch 76/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 169.2560 - mean_squared_error: 169.2560\n",
      "Epoch 77/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 166.7523 - mean_squared_error: 166.7523\n",
      "Epoch 78/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 168.3534 - mean_squared_error: 168.3534\n",
      "Epoch 79/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 170.1243 - mean_squared_error: 170.1243\n",
      "Epoch 80/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 170.6098 - mean_squared_error: 170.6098\n",
      "Epoch 81/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 163.4098 - mean_squared_error: 163.4098\n",
      "Epoch 82/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 170.0166 - mean_squared_error: 170.0166\n",
      "Epoch 83/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 168.8952 - mean_squared_error: 168.8952\n",
      "Epoch 84/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 173.1940 - mean_squared_error: 173.1940\n",
      "Epoch 85/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 166.4029 - mean_squared_error: 166.4029\n",
      "Epoch 86/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 167.8850 - mean_squared_error: 167.8850\n",
      "Epoch 87/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 164.5371 - mean_squared_error: 164.5371\n",
      "Epoch 88/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 159.2709 - mean_squared_error: 159.2709\n",
      "Epoch 89/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 160.8942 - mean_squared_error: 160.8942\n",
      "Epoch 90/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 160.2023 - mean_squared_error: 160.2023\n",
      "Epoch 91/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 165.4057 - mean_squared_error: 165.4057\n",
      "Epoch 92/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 158.6681 - mean_squared_error: 158.6681\n",
      "Epoch 93/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 163.0503 - mean_squared_error: 163.0503\n",
      "Epoch 94/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 158.1621 - mean_squared_error: 158.1621\n",
      "Epoch 95/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 158.4683 - mean_squared_error: 158.4683\n",
      "Epoch 96/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 160.1554 - mean_squared_error: 160.1554\n",
      "Epoch 97/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 153.9026 - mean_squared_error: 153.9026\n",
      "Epoch 98/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 156.6216 - mean_squared_error: 156.6216\n",
      "Epoch 99/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 160.1171 - mean_squared_error: 160.1171\n",
      "Epoch 100/100\n",
      "14664/14664 [==============================] - 0s 3us/step - loss: 153.3557 - mean_squared_error: 153.3557\n",
      "3667/3667 [==============================] - 0s 16us/step\n",
      "100/100 [==============================] - 0s 19us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 104)               35048     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 104)               10920     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 105       \n",
      "=================================================================\n",
      "Total params: 46,073\n",
      "Trainable params: 46,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 11us/step - loss: 4887.8890 - mean_squared_error: 4887.8890\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 678.8917 - mean_squared_error: 678.8917\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 522.6095 - mean_squared_error: 522.6095\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 437.9872 - mean_squared_error: 437.9872\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 378.1729 - mean_squared_error: 378.1729\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 332.4794 - mean_squared_error: 332.4794\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 300.9573 - mean_squared_error: 300.9573\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 280.7274 - mean_squared_error: 280.7274\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 267.9998 - mean_squared_error: 267.9998\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 259.4397 - mean_squared_error: 259.4397\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 251.5841 - mean_squared_error: 251.5841\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 250.4614 - mean_squared_error: 250.4614\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 245.0008 - mean_squared_error: 245.0008\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 241.8088 - mean_squared_error: 241.8088\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.8287 - mean_squared_error: 238.8287\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.7614 - mean_squared_error: 236.7614\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.5796 - mean_squared_error: 236.5796\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.3384 - mean_squared_error: 233.3384\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.5022 - mean_squared_error: 233.5022\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.2799 - mean_squared_error: 231.2799\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.4384 - mean_squared_error: 230.4384\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.4407 - mean_squared_error: 230.4407\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.2021 - mean_squared_error: 229.2021\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.8090 - mean_squared_error: 227.8090\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.4942 - mean_squared_error: 226.4942\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.9102 - mean_squared_error: 225.9102\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.1220 - mean_squared_error: 227.1220\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.9084 - mean_squared_error: 223.9084\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.8998 - mean_squared_error: 223.8998\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.4617 - mean_squared_error: 223.4617\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.0327 - mean_squared_error: 223.0327\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.8268 - mean_squared_error: 220.8268\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.1826 - mean_squared_error: 220.1826\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.8197 - mean_squared_error: 218.8197\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.3081 - mean_squared_error: 217.3081\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 217.6618 - mean_squared_error: 217.6618\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.4499 - mean_squared_error: 216.4499\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.8598 - mean_squared_error: 214.8598\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.7977 - mean_squared_error: 212.7977\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.9234 - mean_squared_error: 212.9234\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.6127 - mean_squared_error: 212.6127\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.7990 - mean_squared_error: 213.7990\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.6887 - mean_squared_error: 209.6887\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.6463 - mean_squared_error: 210.6463\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 211.8399 - mean_squared_error: 211.8399\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.9204 - mean_squared_error: 208.9204\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.4746 - mean_squared_error: 204.4746\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.0229 - mean_squared_error: 204.0229\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.2588 - mean_squared_error: 204.2588\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.4272 - mean_squared_error: 204.4272\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.5318 - mean_squared_error: 203.5318\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.0450 - mean_squared_error: 204.0450\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.3796 - mean_squared_error: 203.3796\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.9263 - mean_squared_error: 199.9263\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.7769 - mean_squared_error: 199.7769\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.3661 - mean_squared_error: 199.3661\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.4245 - mean_squared_error: 195.4245\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.2464 - mean_squared_error: 199.2464\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.7872 - mean_squared_error: 195.7872\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.9046 - mean_squared_error: 191.9046\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.7900 - mean_squared_error: 195.7900\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.1767 - mean_squared_error: 194.1767\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.2156 - mean_squared_error: 192.2156\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.5489 - mean_squared_error: 195.5489\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.1644 - mean_squared_error: 191.1644\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.8566 - mean_squared_error: 192.8566\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.4143 - mean_squared_error: 191.4143\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.3434 - mean_squared_error: 189.3434\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.4493 - mean_squared_error: 186.4493\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.3647 - mean_squared_error: 185.3647\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.8021 - mean_squared_error: 186.8021\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.2118 - mean_squared_error: 189.2118\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.4745 - mean_squared_error: 185.4745\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.9809 - mean_squared_error: 182.9809\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.3548 - mean_squared_error: 183.3548\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.4745 - mean_squared_error: 184.4745\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.5827 - mean_squared_error: 184.5827\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.1587 - mean_squared_error: 179.1587\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.6799 - mean_squared_error: 178.6799\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.2309 - mean_squared_error: 180.2309\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.0295 - mean_squared_error: 178.0295\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.2010 - mean_squared_error: 177.2010\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.2036 - mean_squared_error: 175.2036\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.3665 - mean_squared_error: 181.3665\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.2245 - mean_squared_error: 172.2245\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.2972 - mean_squared_error: 175.2972\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.5144 - mean_squared_error: 175.5144\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.4596 - mean_squared_error: 176.4596\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.2119 - mean_squared_error: 174.2119\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.2334 - mean_squared_error: 174.2334\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.4171 - mean_squared_error: 171.4171\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.3277 - mean_squared_error: 174.3277\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.2356 - mean_squared_error: 172.2356\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.6321 - mean_squared_error: 169.6321\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.1202 - mean_squared_error: 170.1202\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.7537 - mean_squared_error: 168.7537\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.2891 - mean_squared_error: 166.2891\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 170.0477 - mean_squared_error: 170.0477\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.7249 - mean_squared_error: 173.7249\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.9297 - mean_squared_error: 171.9297\n",
      "3666/3666 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 22us/step\n",
      "\n",
      "Experiment on Fold  2\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 104)               35048     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 104)               10920     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 105       \n",
      "=================================================================\n",
      "Total params: 46,073\n",
      "Trainable params: 46,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 11us/step - loss: 4926.5156 - mean_squared_error: 4926.5156\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 649.9951 - mean_squared_error: 649.9951\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 515.6008 - mean_squared_error: 515.6008\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 419.4870 - mean_squared_error: 419.4870\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 340.6306 - mean_squared_error: 340.6306\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 295.9755 - mean_squared_error: 295.9755\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 275.5343 - mean_squared_error: 275.5343\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 261.9304 - mean_squared_error: 261.9304\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 253.2951 - mean_squared_error: 253.2951\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 247.6996 - mean_squared_error: 247.6996\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 243.2493 - mean_squared_error: 243.2493\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.8847 - mean_squared_error: 238.8847\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 236.4132 - mean_squared_error: 236.4132\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.8224 - mean_squared_error: 234.8224\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.8864 - mean_squared_error: 230.8864\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.2692 - mean_squared_error: 229.2692\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.3222 - mean_squared_error: 229.3222\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 226.7925 - mean_squared_error: 226.7925\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.1889 - mean_squared_error: 225.1889\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.8655 - mean_squared_error: 225.8655\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.1001 - mean_squared_error: 222.1001\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.9196 - mean_squared_error: 224.9196\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.1559 - mean_squared_error: 221.1559\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.4176 - mean_squared_error: 221.4176\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.4647 - mean_squared_error: 219.4647\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.3786 - mean_squared_error: 218.3786\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.9141 - mean_squared_error: 218.9141\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.8363 - mean_squared_error: 218.8363\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.6461 - mean_squared_error: 217.6461\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 217.2650 - mean_squared_error: 217.2650\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.7601 - mean_squared_error: 218.7601\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.4847 - mean_squared_error: 212.4847\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.5033 - mean_squared_error: 213.5033\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.5108 - mean_squared_error: 212.5108\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.2032 - mean_squared_error: 212.2032\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.0828 - mean_squared_error: 214.0828\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.8544 - mean_squared_error: 210.8544\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.7471 - mean_squared_error: 206.7471\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.7590 - mean_squared_error: 207.7590\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.0708 - mean_squared_error: 205.0708\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.4925 - mean_squared_error: 206.4925\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 207.7167 - mean_squared_error: 207.7167\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.9782 - mean_squared_error: 199.9782\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.1796 - mean_squared_error: 199.1796\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.6663 - mean_squared_error: 198.6663\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.6946 - mean_squared_error: 198.6946\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.7140 - mean_squared_error: 195.7140\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.2748 - mean_squared_error: 197.2748\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.7654 - mean_squared_error: 197.7654\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.3911 - mean_squared_error: 196.3911\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.4537 - mean_squared_error: 189.4537\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.5772 - mean_squared_error: 196.5772\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.6219 - mean_squared_error: 188.6219\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.2771 - mean_squared_error: 191.2771\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.7113 - mean_squared_error: 189.7113\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.8998 - mean_squared_error: 192.8998\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.7191 - mean_squared_error: 189.7191\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.4877 - mean_squared_error: 186.4877\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.7815 - mean_squared_error: 185.7815\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.1454 - mean_squared_error: 183.1454\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.7281 - mean_squared_error: 181.7281\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 182.3583 - mean_squared_error: 182.3583\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.0834 - mean_squared_error: 181.0834\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.2988 - mean_squared_error: 175.2988\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.2829 - mean_squared_error: 177.2829\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.2864 - mean_squared_error: 173.2864\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.0364 - mean_squared_error: 183.0364\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.8976 - mean_squared_error: 172.8976\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.1851 - mean_squared_error: 177.1851\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.6883 - mean_squared_error: 172.6883\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.6747 - mean_squared_error: 171.6747\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 173.9978 - mean_squared_error: 173.9978\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.9725 - mean_squared_error: 174.9725\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.2965 - mean_squared_error: 171.2965\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.0980 - mean_squared_error: 168.0980\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.1816 - mean_squared_error: 165.1816\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.3753 - mean_squared_error: 169.3753\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.7956 - mean_squared_error: 164.7956\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 163.4757 - mean_squared_error: 163.4757\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.8102 - mean_squared_error: 162.8102\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 161.1978 - mean_squared_error: 161.1978\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.9537 - mean_squared_error: 160.9537\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.9893 - mean_squared_error: 158.9893\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.8360 - mean_squared_error: 158.8360\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.6871 - mean_squared_error: 160.6871\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.4928 - mean_squared_error: 159.4928\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 157.6258 - mean_squared_error: 157.6258\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 155.7712 - mean_squared_error: 155.7712\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 156.1145 - mean_squared_error: 156.1145\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.0874 - mean_squared_error: 158.0874\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 152.5999 - mean_squared_error: 152.5999\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 151.9969 - mean_squared_error: 151.9969\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 151.9028 - mean_squared_error: 151.9028\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 153.2756 - mean_squared_error: 153.2756\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 147.6000 - mean_squared_error: 147.6000\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 154.1798 - mean_squared_error: 154.1798\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 149.6301 - mean_squared_error: 149.6301\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 150.3345 - mean_squared_error: 150.3345\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 145.1614 - mean_squared_error: 145.1614\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 150.6839 - mean_squared_error: 150.6839\n",
      "3666/3666 [==============================] - 0s 16us/step\n",
      "100/100 [==============================] - 0s 17us/step\n",
      "\n",
      "Experiment on Fold  3\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 104)               35048     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 104)               10920     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 105       \n",
      "=================================================================\n",
      "Total params: 46,073\n",
      "Trainable params: 46,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 11us/step - loss: 5232.2104 - mean_squared_error: 5232.2104\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 663.7091 - mean_squared_error: 663.7091\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 492.5511 - mean_squared_error: 492.5511\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 401.1358 - mean_squared_error: 401.1358\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 337.9065 - mean_squared_error: 337.9065\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 298.2941 - mean_squared_error: 298.2941\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 277.8681 - mean_squared_error: 277.8681\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 265.8935 - mean_squared_error: 265.8935\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 257.7686 - mean_squared_error: 257.7686\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 249.2323 - mean_squared_error: 249.2323\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 246.4885 - mean_squared_error: 246.4885\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 240.6743 - mean_squared_error: 240.6743\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.5871 - mean_squared_error: 238.5871\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.1496 - mean_squared_error: 234.1496\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 232.0402 - mean_squared_error: 232.0402\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.5568 - mean_squared_error: 229.5568\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.8325 - mean_squared_error: 227.8325\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.2138 - mean_squared_error: 227.2138\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.1556 - mean_squared_error: 225.1556\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.9616 - mean_squared_error: 227.9616\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.2193 - mean_squared_error: 225.2193\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.1212 - mean_squared_error: 223.1212\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.4302 - mean_squared_error: 223.4302\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.4024 - mean_squared_error: 223.4024\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.3024 - mean_squared_error: 221.3024\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.4325 - mean_squared_error: 222.4325\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.3992 - mean_squared_error: 221.3992\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 222.3901 - mean_squared_error: 222.3901\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.9471 - mean_squared_error: 218.9471\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.3889 - mean_squared_error: 219.3889\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.3287 - mean_squared_error: 219.3287\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.5710 - mean_squared_error: 219.5710\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.4300 - mean_squared_error: 214.4300\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.2565 - mean_squared_error: 216.2565\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.4309 - mean_squared_error: 214.4309\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.0948 - mean_squared_error: 213.0948\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.7090 - mean_squared_error: 214.7090\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.6481 - mean_squared_error: 210.6481\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.5563 - mean_squared_error: 212.5563\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.3483 - mean_squared_error: 212.3483\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.0247 - mean_squared_error: 212.0247\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.6536 - mean_squared_error: 210.6536\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.9673 - mean_squared_error: 208.9673\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.5723 - mean_squared_error: 205.5723\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.7211 - mean_squared_error: 205.7211\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 204.3212 - mean_squared_error: 204.3212\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.1138 - mean_squared_error: 203.1138\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.0517 - mean_squared_error: 206.0517\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.2635 - mean_squared_error: 203.2635\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.5453 - mean_squared_error: 203.5453\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.6819 - mean_squared_error: 197.6819\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.2192 - mean_squared_error: 199.2192\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.5281 - mean_squared_error: 203.5281\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.2273 - mean_squared_error: 198.2273\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.5130 - mean_squared_error: 199.5130\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 197.2601 - mean_squared_error: 197.2601\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 198.8494 - mean_squared_error: 198.8494\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.7920 - mean_squared_error: 196.7920\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.3408 - mean_squared_error: 191.3408\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.6998 - mean_squared_error: 192.6998\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.6554 - mean_squared_error: 191.6554\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.1856 - mean_squared_error: 192.1856\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.0675 - mean_squared_error: 191.0675\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.6629 - mean_squared_error: 200.6629\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.4059 - mean_squared_error: 191.4059\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 195.1013 - mean_squared_error: 195.1013\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.0859 - mean_squared_error: 191.0859\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 188.2635 - mean_squared_error: 188.2635\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.6505 - mean_squared_error: 187.6505\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.1717 - mean_squared_error: 186.1717\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.1496 - mean_squared_error: 190.1496\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.5618 - mean_squared_error: 185.5618\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.2943 - mean_squared_error: 186.2943\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.8771 - mean_squared_error: 186.8771\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.0865 - mean_squared_error: 181.0865\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 187.1078 - mean_squared_error: 187.1078\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.9366 - mean_squared_error: 180.9366\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.4995 - mean_squared_error: 184.4995\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.0420 - mean_squared_error: 183.0420\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.7346 - mean_squared_error: 180.7346\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.5809 - mean_squared_error: 183.5809\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.8541 - mean_squared_error: 179.8541\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.8355 - mean_squared_error: 178.8355\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.9805 - mean_squared_error: 180.9805\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.7220 - mean_squared_error: 179.7220\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.1936 - mean_squared_error: 177.1936\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.7655 - mean_squared_error: 176.7655\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.2124 - mean_squared_error: 175.2124\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.6851 - mean_squared_error: 179.6851\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.4378 - mean_squared_error: 179.4378\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 176.2201 - mean_squared_error: 176.2201\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.3594 - mean_squared_error: 179.3594\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.4464 - mean_squared_error: 169.4464\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 173.5836 - mean_squared_error: 173.5836\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.9531 - mean_squared_error: 172.9531\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.1742 - mean_squared_error: 169.1742\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.6236 - mean_squared_error: 172.6236\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.3244 - mean_squared_error: 172.3244\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 172.5293 - mean_squared_error: 172.5293\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.7226 - mean_squared_error: 175.7226\n",
      "3666/3666 [==============================] - 0s 16us/step\n",
      "100/100 [==============================] - 0s 20us/step\n",
      "\n",
      "Experiment on Fold  4\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 104)               35048     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 104)               10920     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 105       \n",
      "=================================================================\n",
      "Total params: 46,073\n",
      "Trainable params: 46,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 15us/step - loss: 5087.4135 - mean_squared_error: 5087.4135\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 695.3576 - mean_squared_error: 695.3576\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 549.5668 - mean_squared_error: 549.5668\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 467.4497 - mean_squared_error: 467.4497\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 413.7399 - mean_squared_error: 413.7399\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 367.1503 - mean_squared_error: 367.1503\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 327.7182 - mean_squared_error: 327.7182\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 301.2597 - mean_squared_error: 301.2597\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 281.4585 - mean_squared_error: 281.4585\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 267.5014 - mean_squared_error: 267.5014\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 258.2965 - mean_squared_error: 258.2965\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 251.0659 - mean_squared_error: 251.0659\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 246.2215 - mean_squared_error: 246.2215\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 243.3465 - mean_squared_error: 243.3465\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 238.1101 - mean_squared_error: 238.1101\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 237.5228 - mean_squared_error: 237.5228\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.9966 - mean_squared_error: 234.9966\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 234.7936 - mean_squared_error: 234.7936\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 233.7283 - mean_squared_error: 233.7283\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.9599 - mean_squared_error: 231.9599\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 231.9763 - mean_squared_error: 231.9763\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 230.9620 - mean_squared_error: 230.9620\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.2762 - mean_squared_error: 229.2762\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 229.5472 - mean_squared_error: 229.5472\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 227.9767 - mean_squared_error: 227.9767\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 228.5272 - mean_squared_error: 228.5272\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.2977 - mean_squared_error: 225.2977\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 225.8988 - mean_squared_error: 225.8988\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 224.8396 - mean_squared_error: 224.8396\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 223.1724 - mean_squared_error: 223.1724\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.2874 - mean_squared_error: 221.2874\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 221.8341 - mean_squared_error: 221.8341\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.6603 - mean_squared_error: 220.6603\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 220.7170 - mean_squared_error: 220.7170\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 218.0423 - mean_squared_error: 218.0423\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 219.3354 - mean_squared_error: 219.3354\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 216.6524 - mean_squared_error: 216.6524\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 214.4383 - mean_squared_error: 214.4383\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 213.8875 - mean_squared_error: 213.8875\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.9785 - mean_squared_error: 212.9785\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.0793 - mean_squared_error: 212.0793\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 212.1239 - mean_squared_error: 212.1239\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 210.7401 - mean_squared_error: 210.7401\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 209.5602 - mean_squared_error: 209.5602\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 208.5606 - mean_squared_error: 208.5606\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.4658 - mean_squared_error: 206.4658\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.0556 - mean_squared_error: 206.0556\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 206.4109 - mean_squared_error: 206.4109\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 205.9925 - mean_squared_error: 205.9925\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 202.9377 - mean_squared_error: 202.9377\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 203.3505 - mean_squared_error: 203.3505\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 201.3939 - mean_squared_error: 201.3939\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 200.1644 - mean_squared_error: 200.1644\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 199.7257 - mean_squared_error: 199.7257\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.4727 - mean_squared_error: 196.4727\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 196.7318 - mean_squared_error: 196.7318\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.0747 - mean_squared_error: 194.0747\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.4013 - mean_squared_error: 194.4013\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 194.9840 - mean_squared_error: 194.9840\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 192.2915 - mean_squared_error: 192.2915\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 189.7304 - mean_squared_error: 189.7304\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 190.3593 - mean_squared_error: 190.3593\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 191.2911 - mean_squared_error: 191.2911\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 186.7880 - mean_squared_error: 186.7880\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.7636 - mean_squared_error: 185.7636\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.1923 - mean_squared_error: 185.1923\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 185.3082 - mean_squared_error: 185.3082\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 184.0177 - mean_squared_error: 184.0177\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 181.7885 - mean_squared_error: 181.7885\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.2023 - mean_squared_error: 183.2023\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 180.6038 - mean_squared_error: 180.6038\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 183.2703 - mean_squared_error: 183.2703\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.1328 - mean_squared_error: 177.1328\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.4892 - mean_squared_error: 178.4892\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 179.3004 - mean_squared_error: 179.3004\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 175.7690 - mean_squared_error: 175.7690\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 177.1486 - mean_squared_error: 177.1486\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.4919 - mean_squared_error: 178.4919\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.3344 - mean_squared_error: 174.3344\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 178.6808 - mean_squared_error: 178.6808\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 174.3433 - mean_squared_error: 174.3433\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.5343 - mean_squared_error: 171.5343\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.3472 - mean_squared_error: 168.3472\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.5704 - mean_squared_error: 168.5704\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 168.4718 - mean_squared_error: 168.4718\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 171.6236 - mean_squared_error: 171.6236\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.7328 - mean_squared_error: 166.7328\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 169.4424 - mean_squared_error: 169.4424\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 166.0928 - mean_squared_error: 166.0928\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 167.6212 - mean_squared_error: 167.6212\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.3783 - mean_squared_error: 165.3783\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 163.5280 - mean_squared_error: 163.5280\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 164.4151 - mean_squared_error: 164.4151\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 165.6631 - mean_squared_error: 165.6631\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.1025 - mean_squared_error: 162.1025\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 160.2887 - mean_squared_error: 160.2887\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.9604 - mean_squared_error: 159.9604\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 162.1583 - mean_squared_error: 162.1583\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 158.7913 - mean_squared_error: 158.7913\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 3us/step - loss: 159.9361 - mean_squared_error: 159.9361\n",
      "3666/3666 [==============================] - 0s 16us/step\n",
      "100/100 [==============================] - 0s 19us/step\n",
      "Testing for yulin/alpha0.8/bestModel_global.json\n",
      "Loading data for dataset 1 with window_size of 24, stride of 1 and maxRUL of 129. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(18331, 336)\n",
      "(18331, 1)\n",
      "Testing data (X, y)\n",
      "(100, 336)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.63253012 -0.18639634 -0.38048616 ... -0.33333333  0.33333333\n",
      "   0.31289699]\n",
      " [-0.43373494 -0.09396119 -0.29473329 ... -0.16666667  0.25581395\n",
      "   0.47638774]\n",
      " [-0.31325301 -0.26095487 -0.25894666 ...  0.          0.11627907\n",
      "   0.43800055]\n",
      " [-0.31325301 -0.48768258 -0.33760972 ... -0.16666667  0.31782946\n",
      "   0.52720243]\n",
      " [-0.30120482 -0.48506649 -0.19074949 ... -0.66666667  0.34883721\n",
      "   0.07677437]]\n",
      "[[129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]]\n",
      "Testing data (X, y)\n",
      "[[-0.19879518 -0.5705254  -0.37069548 ... -0.16666667  0.03875969\n",
      "   0.27312897]\n",
      " [-0.21686747 -0.30237628 -0.12086428 ... -0.5         0.03875969\n",
      "   0.01518917]\n",
      " [-0.04216867 -0.1942446  -0.0209318  ...  0.16666667  0.2248062\n",
      "   0.04888152]\n",
      " [-0.22891566 -0.01722259 -0.13673194 ...  0.16666667 -0.31782946\n",
      "   0.004971  ]\n",
      " [-0.11445783 -0.11968607  0.03511141 ...  0.         -0.05426357\n",
      "   0.42916321]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n",
      "Validation on model:best_models/cmapss/yulin/alpha0.8/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 24)                8088      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 320)               8000      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 321       \n",
      "=================================================================\n",
      "Total params: 17,009\n",
      "Trainable params: 17,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14664/14664 [==============================] - 0s 14us/step - loss: 6631.0450 - mean_squared_error: 6631.0450\n",
      "Epoch 2/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 762.7271 - mean_squared_error: 762.7271\n",
      "Epoch 3/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 585.0429 - mean_squared_error: 585.0429\n",
      "Epoch 4/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 479.4712 - mean_squared_error: 479.4712\n",
      "Epoch 5/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 405.1198 - mean_squared_error: 405.1198\n",
      "Epoch 6/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 348.2196 - mean_squared_error: 348.2196\n",
      "Epoch 7/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 320.7013 - mean_squared_error: 320.7013\n",
      "Epoch 8/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 308.1178 - mean_squared_error: 308.1178\n",
      "Epoch 9/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 295.7724 - mean_squared_error: 295.7724\n",
      "Epoch 10/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 292.3289 - mean_squared_error: 292.3289\n",
      "Epoch 11/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 287.6686 - mean_squared_error: 287.6686\n",
      "Epoch 12/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 280.1677 - mean_squared_error: 280.1677\n",
      "Epoch 13/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 281.6237 - mean_squared_error: 281.6237\n",
      "Epoch 14/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 276.5784 - mean_squared_error: 276.5784\n",
      "Epoch 15/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 275.5787 - mean_squared_error: 275.5787\n",
      "Epoch 16/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 276.7643 - mean_squared_error: 276.7643\n",
      "Epoch 17/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 274.5755 - mean_squared_error: 274.5755\n",
      "Epoch 18/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 267.6315 - mean_squared_error: 267.6315\n",
      "Epoch 19/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 280.0150 - mean_squared_error: 280.0150\n",
      "Epoch 20/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 269.7192 - mean_squared_error: 269.7192\n",
      "Epoch 21/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 272.7095 - mean_squared_error: 272.7095\n",
      "Epoch 22/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 266.1682 - mean_squared_error: 266.1682\n",
      "Epoch 23/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 264.2708 - mean_squared_error: 264.2708\n",
      "Epoch 24/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 273.3136 - mean_squared_error: 273.3136\n",
      "Epoch 25/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 265.9483 - mean_squared_error: 265.9483\n",
      "Epoch 26/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 263.4457 - mean_squared_error: 263.4457\n",
      "Epoch 27/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 260.2051 - mean_squared_error: 260.2051\n",
      "Epoch 28/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 260.4753 - mean_squared_error: 260.4753\n",
      "Epoch 29/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 260.3786 - mean_squared_error: 260.3786\n",
      "Epoch 30/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 261.2963 - mean_squared_error: 261.2963\n",
      "Epoch 31/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 258.2259 - mean_squared_error: 258.2259\n",
      "Epoch 32/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 254.7307 - mean_squared_error: 254.7307\n",
      "Epoch 33/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 255.6418 - mean_squared_error: 255.6418\n",
      "Epoch 34/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 257.3650 - mean_squared_error: 257.3650\n",
      "Epoch 35/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 253.2553 - mean_squared_error: 253.2553\n",
      "Epoch 36/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 251.4590 - mean_squared_error: 251.4590\n",
      "Epoch 37/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 254.6260 - mean_squared_error: 254.6260\n",
      "Epoch 38/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 252.6185 - mean_squared_error: 252.6185\n",
      "Epoch 39/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 255.3948 - mean_squared_error: 255.3948\n",
      "Epoch 40/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 258.5145 - mean_squared_error: 258.5145\n",
      "Epoch 41/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 251.2218 - mean_squared_error: 251.2218\n",
      "Epoch 42/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 251.5943 - mean_squared_error: 251.5943\n",
      "Epoch 43/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 250.3734 - mean_squared_error: 250.3734\n",
      "Epoch 44/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 252.3341 - mean_squared_error: 252.3341\n",
      "Epoch 45/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 251.6675 - mean_squared_error: 251.6675\n",
      "Epoch 46/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 252.6200 - mean_squared_error: 252.6200\n",
      "Epoch 47/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 250.8056 - mean_squared_error: 250.8056\n",
      "Epoch 48/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 249.0663 - mean_squared_error: 249.0663\n",
      "Epoch 49/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 248.3254 - mean_squared_error: 248.3254\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14664/14664 [==============================] - 0s 4us/step - loss: 252.1844 - mean_squared_error: 252.1844\n",
      "Epoch 51/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 246.1347 - mean_squared_error: 246.1347\n",
      "Epoch 52/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 242.7886 - mean_squared_error: 242.7886\n",
      "Epoch 53/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 246.6313 - mean_squared_error: 246.6313\n",
      "Epoch 54/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 251.5024 - mean_squared_error: 251.5024\n",
      "Epoch 55/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 249.3121 - mean_squared_error: 249.3121\n",
      "Epoch 56/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 248.2777 - mean_squared_error: 248.2777\n",
      "Epoch 57/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 245.5661 - mean_squared_error: 245.5661\n",
      "Epoch 58/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 244.7906 - mean_squared_error: 244.7906\n",
      "Epoch 59/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 248.4335 - mean_squared_error: 248.4335\n",
      "Epoch 60/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 248.1051 - mean_squared_error: 248.1051\n",
      "Epoch 61/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 244.7005 - mean_squared_error: 244.7005\n",
      "Epoch 62/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 243.5217 - mean_squared_error: 243.5217\n",
      "Epoch 63/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 244.4547 - mean_squared_error: 244.4547\n",
      "Epoch 64/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 245.1668 - mean_squared_error: 245.1668\n",
      "Epoch 65/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 242.9287 - mean_squared_error: 242.9287\n",
      "Epoch 66/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 239.2791 - mean_squared_error: 239.2791\n",
      "Epoch 67/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 240.9365 - mean_squared_error: 240.9365\n",
      "Epoch 68/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 241.9343 - mean_squared_error: 241.9343\n",
      "Epoch 69/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 239.4011 - mean_squared_error: 239.4011\n",
      "Epoch 70/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 243.0562 - mean_squared_error: 243.0562\n",
      "Epoch 71/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 240.8607 - mean_squared_error: 240.8607\n",
      "Epoch 72/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 240.9822 - mean_squared_error: 240.9822\n",
      "Epoch 73/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 240.9700 - mean_squared_error: 240.9700\n",
      "Epoch 74/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 244.4219 - mean_squared_error: 244.4219\n",
      "Epoch 75/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 236.0341 - mean_squared_error: 236.0341\n",
      "Epoch 76/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 241.3879 - mean_squared_error: 241.3879\n",
      "Epoch 77/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 238.1795 - mean_squared_error: 238.1795\n",
      "Epoch 78/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 236.2643 - mean_squared_error: 236.2643\n",
      "Epoch 79/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 238.6405 - mean_squared_error: 238.6405\n",
      "Epoch 80/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 238.8214 - mean_squared_error: 238.8214\n",
      "Epoch 81/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 240.6673 - mean_squared_error: 240.6673\n",
      "Epoch 82/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 237.9697 - mean_squared_error: 237.9697\n",
      "Epoch 83/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 239.3048 - mean_squared_error: 239.3048\n",
      "Epoch 84/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 239.1351 - mean_squared_error: 239.1351\n",
      "Epoch 85/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 237.6955 - mean_squared_error: 237.6955\n",
      "Epoch 86/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 231.5847 - mean_squared_error: 231.5847\n",
      "Epoch 87/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 231.6236 - mean_squared_error: 231.6236\n",
      "Epoch 88/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 233.2801 - mean_squared_error: 233.2801\n",
      "Epoch 89/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 231.9929 - mean_squared_error: 231.9929\n",
      "Epoch 90/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 234.8206 - mean_squared_error: 234.8206\n",
      "Epoch 91/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 236.0295 - mean_squared_error: 236.0295\n",
      "Epoch 92/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 234.6244 - mean_squared_error: 234.6244\n",
      "Epoch 93/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 233.9454 - mean_squared_error: 233.9454\n",
      "Epoch 94/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 234.1681 - mean_squared_error: 234.1681\n",
      "Epoch 95/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 227.9330 - mean_squared_error: 227.9330\n",
      "Epoch 96/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 232.4254 - mean_squared_error: 232.4254\n",
      "Epoch 97/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 228.0387 - mean_squared_error: 228.0387\n",
      "Epoch 98/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 232.8363 - mean_squared_error: 232.8363\n",
      "Epoch 99/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 226.7153 - mean_squared_error: 226.7153\n",
      "Epoch 100/100\n",
      "14664/14664 [==============================] - 0s 4us/step - loss: 233.4643 - mean_squared_error: 233.4643\n",
      "3667/3667 [==============================] - 0s 18us/step\n",
      "100/100 [==============================] - 0s 20us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 24)                8088      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 320)               8000      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 321       \n",
      "=================================================================\n",
      "Total params: 17,009\n",
      "Trainable params: 17,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 14us/step - loss: 6213.0847 - mean_squared_error: 6213.0847\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 774.3947 - mean_squared_error: 774.3947\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 568.6568 - mean_squared_error: 568.6568\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 478.8092 - mean_squared_error: 478.8092\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 417.0878 - mean_squared_error: 417.0878\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 366.8101 - mean_squared_error: 366.8101\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 339.2375 - mean_squared_error: 339.2375\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 4us/step - loss: 318.3233 - mean_squared_error: 318.3233\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 304.8590 - mean_squared_error: 304.8590\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 294.2308 - mean_squared_error: 294.2308\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 292.4908 - mean_squared_error: 292.4908\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 293.6902 - mean_squared_error: 293.6902\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 289.8935 - mean_squared_error: 289.8935\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 282.7742 - mean_squared_error: 282.7742\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 284.9678 - mean_squared_error: 284.9678\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 286.3363 - mean_squared_error: 286.3363\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 278.2851 - mean_squared_error: 278.2851\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 280.9236 - mean_squared_error: 280.9236\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 281.6402 - mean_squared_error: 281.6402\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 281.6527 - mean_squared_error: 281.6527\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 278.9461 - mean_squared_error: 278.9461\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 279.3446 - mean_squared_error: 279.3446\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 273.2765 - mean_squared_error: 273.2765\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 277.4854 - mean_squared_error: 277.4854\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 274.3967 - mean_squared_error: 274.3967\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 276.4936 - mean_squared_error: 276.4936\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 278.2282 - mean_squared_error: 278.2282\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 273.2395 - mean_squared_error: 273.2395\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 277.8739 - mean_squared_error: 277.8739\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 273.6268 - mean_squared_error: 273.6268\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 268.3677 - mean_squared_error: 268.3677\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 273.1955 - mean_squared_error: 273.1955\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 272.1999 - mean_squared_error: 272.1999\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 269.5422 - mean_squared_error: 269.5422\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 270.9790 - mean_squared_error: 270.9790\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 272.2429 - mean_squared_error: 272.2429\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 272.6514 - mean_squared_error: 272.6514\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 268.8659 - mean_squared_error: 268.8659\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 268.5190 - mean_squared_error: 268.5190\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 267.3227 - mean_squared_error: 267.3227\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 268.0842 - mean_squared_error: 268.0842\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 271.0507 - mean_squared_error: 271.0507\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 268.7926 - mean_squared_error: 268.7926\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 271.6637 - mean_squared_error: 271.6637\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 268.9318 - mean_squared_error: 268.9318\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 274.1485 - mean_squared_error: 274.1485\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 269.8645 - mean_squared_error: 269.8645\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 277.1174 - mean_squared_error: 277.1174\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 268.6907 - mean_squared_error: 268.6907\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 264.7149 - mean_squared_error: 264.7149\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 269.4336 - mean_squared_error: 269.4336\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 264.7739 - mean_squared_error: 264.7739\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 266.7042 - mean_squared_error: 266.7042\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 267.4215 - mean_squared_error: 267.4215\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 263.9093 - mean_squared_error: 263.9093\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 264.0438 - mean_squared_error: 264.0438\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 262.9666 - mean_squared_error: 262.9666\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 264.8547 - mean_squared_error: 264.8547\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 266.7242 - mean_squared_error: 266.7242\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 262.8446 - mean_squared_error: 262.8446\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 265.4818 - mean_squared_error: 265.4818\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 260.7591 - mean_squared_error: 260.7591\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 257.7892 - mean_squared_error: 257.7892\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 265.6134 - mean_squared_error: 265.6134\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 260.7895 - mean_squared_error: 260.7895\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 261.7361 - mean_squared_error: 261.7361\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 258.9782 - mean_squared_error: 258.9782\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 257.7223 - mean_squared_error: 257.7223\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 258.8744 - mean_squared_error: 258.8744\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 258.6589 - mean_squared_error: 258.6589\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 259.2718 - mean_squared_error: 259.2718\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 261.0399 - mean_squared_error: 261.0399\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 257.1978 - mean_squared_error: 257.1978\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 256.7441 - mean_squared_error: 256.7441\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 263.2892 - mean_squared_error: 263.2892\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 4us/step - loss: 260.0361 - mean_squared_error: 260.0361\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 254.4002 - mean_squared_error: 254.4002\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 260.9770 - mean_squared_error: 260.9770\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 253.5268 - mean_squared_error: 253.5268\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 256.1455 - mean_squared_error: 256.1455\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.1204 - mean_squared_error: 255.1204\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 262.4592 - mean_squared_error: 262.4592\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.0840 - mean_squared_error: 255.0840\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.8432 - mean_squared_error: 255.8432\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 256.7434 - mean_squared_error: 256.7434\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 257.6071 - mean_squared_error: 257.6071\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 254.1714 - mean_squared_error: 254.1714\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 252.7150 - mean_squared_error: 252.7150\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 249.1898 - mean_squared_error: 249.1898\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 253.5777 - mean_squared_error: 253.5777\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 253.5382 - mean_squared_error: 253.5382\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.5009 - mean_squared_error: 250.5009\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 252.1188 - mean_squared_error: 252.1188\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 251.6138 - mean_squared_error: 251.6138\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 251.8674 - mean_squared_error: 251.8674\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 248.3464 - mean_squared_error: 248.3464\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 252.0587 - mean_squared_error: 252.0587\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 251.3458 - mean_squared_error: 251.3458\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.1695 - mean_squared_error: 250.1695\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.0230 - mean_squared_error: 250.0230\n",
      "3666/3666 [==============================] - 0s 18us/step\n",
      "100/100 [==============================] - 0s 18us/step\n",
      "\n",
      "Experiment on Fold  2\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 24)                8088      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 320)               8000      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 321       \n",
      "=================================================================\n",
      "Total params: 17,009\n",
      "Trainable params: 17,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 14us/step - loss: 6538.7132 - mean_squared_error: 6538.7132\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 680.1844 - mean_squared_error: 680.1844\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 556.1604 - mean_squared_error: 556.1604\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 473.7666 - mean_squared_error: 473.7666\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 402.4456 - mean_squared_error: 402.4456\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 347.4343 - mean_squared_error: 347.4343\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 319.7980 - mean_squared_error: 319.7980\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 300.4968 - mean_squared_error: 300.4968\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 290.0710 - mean_squared_error: 290.0710\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 285.3881 - mean_squared_error: 285.3881\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 278.2343 - mean_squared_error: 278.2343\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 281.8816 - mean_squared_error: 281.8816\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 273.4385 - mean_squared_error: 273.4385\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 276.8337 - mean_squared_error: 276.8337\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 274.2442 - mean_squared_error: 274.2442\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 271.1510 - mean_squared_error: 271.1510\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 275.0666 - mean_squared_error: 275.0666\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 268.0570 - mean_squared_error: 268.0570\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 267.0358 - mean_squared_error: 267.0358\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 266.1151 - mean_squared_error: 266.1151\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 265.3433 - mean_squared_error: 265.3433\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 269.7730 - mean_squared_error: 269.7730\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 267.4425 - mean_squared_error: 267.4425\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 261.9659 - mean_squared_error: 261.9659\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 263.1179 - mean_squared_error: 263.1179\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 262.6684 - mean_squared_error: 262.6684\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 260.3427 - mean_squared_error: 260.3427\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 260.1049 - mean_squared_error: 260.1049\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 260.3322 - mean_squared_error: 260.3322\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 258.6463 - mean_squared_error: 258.6463\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 256.8712 - mean_squared_error: 256.8712\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 261.2226 - mean_squared_error: 261.2226\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 258.8145 - mean_squared_error: 258.8145\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.2515 - mean_squared_error: 255.2515\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 253.1727 - mean_squared_error: 253.1727\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 256.8067 - mean_squared_error: 256.8067\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 252.4797 - mean_squared_error: 252.4797\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 249.6043 - mean_squared_error: 249.6043\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 260.1866 - mean_squared_error: 260.1866\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.3692 - mean_squared_error: 255.3692\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 266.1930 - mean_squared_error: 266.1930\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 248.9186 - mean_squared_error: 248.9186\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 252.3342 - mean_squared_error: 252.3342\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 254.2681 - mean_squared_error: 254.2681\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.1497 - mean_squared_error: 250.1497\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.5094 - mean_squared_error: 250.5094\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 254.8330 - mean_squared_error: 254.8330\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.6447 - mean_squared_error: 250.6447\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.1623 - mean_squared_error: 250.1623\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 248.2833 - mean_squared_error: 248.2833\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 242.0698 - mean_squared_error: 242.0698\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 247.8659 - mean_squared_error: 247.8659\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.9420 - mean_squared_error: 250.9420\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 253.1156 - mean_squared_error: 253.1156\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 247.2302 - mean_squared_error: 247.2302\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 248.9843 - mean_squared_error: 248.9843\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 244.2096 - mean_squared_error: 244.2096\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 245.6365 - mean_squared_error: 245.6365\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 247.3670 - mean_squared_error: 247.3670\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 242.6312 - mean_squared_error: 242.6312\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 243.2908 - mean_squared_error: 243.2908\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 249.1226 - mean_squared_error: 249.1226\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 241.6520 - mean_squared_error: 241.6520\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 243.8698 - mean_squared_error: 243.8698\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 246.1460 - mean_squared_error: 246.1460\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 243.2096 - mean_squared_error: 243.2096\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 244.6248 - mean_squared_error: 244.6248\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 240.8961 - mean_squared_error: 240.8961\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 245.9995 - mean_squared_error: 245.9995\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 246.2725 - mean_squared_error: 246.2725\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 240.9640 - mean_squared_error: 240.9640\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 238.3689 - mean_squared_error: 238.3689\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 239.3791 - mean_squared_error: 239.3791\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 236.4149 - mean_squared_error: 236.4149\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 238.5072 - mean_squared_error: 238.5072\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 236.5871 - mean_squared_error: 236.5871\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 242.5238 - mean_squared_error: 242.5238\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 237.2439 - mean_squared_error: 237.2439\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 242.7327 - mean_squared_error: 242.7327\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 237.9023 - mean_squared_error: 237.9023\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 238.5853 - mean_squared_error: 238.5853\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 243.2375 - mean_squared_error: 243.2375\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 232.6806 - mean_squared_error: 232.6806\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 238.8191 - mean_squared_error: 238.8191\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 232.7608 - mean_squared_error: 232.7608\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 230.8939 - mean_squared_error: 230.8939\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 244.3400 - mean_squared_error: 244.3400\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 233.6214 - mean_squared_error: 233.6214\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 238.1331 - mean_squared_error: 238.1331\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 232.6787 - mean_squared_error: 232.6787\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 227.5182 - mean_squared_error: 227.5182\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 230.6016 - mean_squared_error: 230.6016\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 229.9197 - mean_squared_error: 229.9197\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 228.8356 - mean_squared_error: 228.8356\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 230.8402 - mean_squared_error: 230.8402\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 232.2363 - mean_squared_error: 232.2363\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 230.3602 - mean_squared_error: 230.3602\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 233.5676 - mean_squared_error: 233.5676\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 230.8390 - mean_squared_error: 230.8390\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 229.8415 - mean_squared_error: 229.8415\n",
      "3666/3666 [==============================] - 0s 19us/step\n",
      "100/100 [==============================] - 0s 24us/step\n",
      "\n",
      "Experiment on Fold  3\n",
      "Loaded model from disk\n",
      "Model needs training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 24)                8088      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 320)               8000      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 321       \n",
      "=================================================================\n",
      "Total params: 17,009\n",
      "Trainable params: 17,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 14us/step - loss: 6974.1971 - mean_squared_error: 6974.1971\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 740.5267 - mean_squared_error: 740.5267\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 548.6208 - mean_squared_error: 548.6208\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 419.4559 - mean_squared_error: 419.4559\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 328.1344 - mean_squared_error: 328.1344\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 308.3304 - mean_squared_error: 308.3304\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 297.1953 - mean_squared_error: 297.1953\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 288.6235 - mean_squared_error: 288.6235\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 287.9857 - mean_squared_error: 287.9857\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 284.8567 - mean_squared_error: 284.8567\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 277.0946 - mean_squared_error: 277.0946\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 276.1888 - mean_squared_error: 276.1888\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 271.3838 - mean_squared_error: 271.3838\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 269.6025 - mean_squared_error: 269.6025\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 266.1787 - mean_squared_error: 266.1787\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 270.7863 - mean_squared_error: 270.7863\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 263.1413 - mean_squared_error: 263.1413\n",
      "Epoch 18/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 268.2341 - mean_squared_error: 268.2341\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 259.5618 - mean_squared_error: 259.5618\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 260.2534 - mean_squared_error: 260.2534\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 261.5242 - mean_squared_error: 261.5242\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 264.8430 - mean_squared_error: 264.8430\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 263.9300 - mean_squared_error: 263.9300\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 259.4904 - mean_squared_error: 259.4904\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 259.9823 - mean_squared_error: 259.9823\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 259.6293 - mean_squared_error: 259.6293\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 257.1638 - mean_squared_error: 257.1638\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 258.9403 - mean_squared_error: 258.9403\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.6345 - mean_squared_error: 255.6345\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.3273 - mean_squared_error: 255.3273\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 257.8106 - mean_squared_error: 257.8106\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 252.0266 - mean_squared_error: 252.0266\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 254.2867 - mean_squared_error: 254.2867\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 251.6196 - mean_squared_error: 251.6196\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 251.5534 - mean_squared_error: 251.5534\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 251.7788 - mean_squared_error: 251.7788\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 249.4158 - mean_squared_error: 249.4158\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 244.5353 - mean_squared_error: 244.5353\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.3773 - mean_squared_error: 250.3773\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 248.7692 - mean_squared_error: 248.7692\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 248.3902 - mean_squared_error: 248.3902\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 249.2027 - mean_squared_error: 249.2027\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 251.2641 - mean_squared_error: 251.2641\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 245.6788 - mean_squared_error: 245.6788\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 241.4137 - mean_squared_error: 241.4137\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 252.2555 - mean_squared_error: 252.2555\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 246.2569 - mean_squared_error: 246.2569\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 243.2280 - mean_squared_error: 243.2280\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 247.2187 - mean_squared_error: 247.2187\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 245.4706 - mean_squared_error: 245.4706\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 247.4042 - mean_squared_error: 247.4042\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 243.4126 - mean_squared_error: 243.4126\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 247.0339 - mean_squared_error: 247.0339\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 240.0028 - mean_squared_error: 240.0028\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 241.8472 - mean_squared_error: 241.8472\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 242.2306 - mean_squared_error: 242.2306\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 246.5653 - mean_squared_error: 246.5653\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 245.9725 - mean_squared_error: 245.9725\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 238.4393 - mean_squared_error: 238.4393\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 4us/step - loss: 241.9532 - mean_squared_error: 241.9532\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 245.0427 - mean_squared_error: 245.0427\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 238.0574 - mean_squared_error: 238.0574\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 235.3137 - mean_squared_error: 235.3137\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 244.9681 - mean_squared_error: 244.9681\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 234.5656 - mean_squared_error: 234.5656\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 232.5565 - mean_squared_error: 232.5565\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 240.5496 - mean_squared_error: 240.5496\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 242.8491 - mean_squared_error: 242.8491\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 232.5263 - mean_squared_error: 232.5263\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 245.6266 - mean_squared_error: 245.6266\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 237.4144 - mean_squared_error: 237.4144\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 233.9536 - mean_squared_error: 233.9536\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 235.5411 - mean_squared_error: 235.5411\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 229.5761 - mean_squared_error: 229.5761\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 234.2890 - mean_squared_error: 234.2890\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 237.7412 - mean_squared_error: 237.7412\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 228.2364 - mean_squared_error: 228.2364\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 230.5927 - mean_squared_error: 230.5927\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 227.7313 - mean_squared_error: 227.7313\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 234.3909 - mean_squared_error: 234.3909\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 234.2606 - mean_squared_error: 234.2606\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 232.4511 - mean_squared_error: 232.4511\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 227.9024 - mean_squared_error: 227.9024\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 230.8754 - mean_squared_error: 230.8754\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 230.3271 - mean_squared_error: 230.3271\n",
      "Epoch 86/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 226.9170 - mean_squared_error: 226.9170\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 229.5649 - mean_squared_error: 229.5649\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 229.8798 - mean_squared_error: 229.8798\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 228.3065 - mean_squared_error: 228.3065\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 228.2589 - mean_squared_error: 228.2589\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 222.7268 - mean_squared_error: 222.7268\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 221.8962 - mean_squared_error: 221.8962\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 223.7314 - mean_squared_error: 223.7314\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 226.3973 - mean_squared_error: 226.3973\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 227.1654 - mean_squared_error: 227.1654\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 224.3190 - mean_squared_error: 224.3190\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 223.5880 - mean_squared_error: 223.5880\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 227.9685 - mean_squared_error: 227.9685\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 223.7143 - mean_squared_error: 223.7143\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 225.4012 - mean_squared_error: 225.4012\n",
      "3666/3666 [==============================] - 0s 18us/step\n",
      "100/100 [==============================] - 0s 20us/step\n",
      "\n",
      "Experiment on Fold  4\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 24)                8088      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 320)               8000      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 321       \n",
      "=================================================================\n",
      "Total params: 17,009\n",
      "Trainable params: 17,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14665/14665 [==============================] - 0s 14us/step - loss: 6806.3133 - mean_squared_error: 6806.3133\n",
      "Epoch 2/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 808.4672 - mean_squared_error: 808.4672\n",
      "Epoch 3/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 601.3431 - mean_squared_error: 601.3431\n",
      "Epoch 4/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 501.7564 - mean_squared_error: 501.7564\n",
      "Epoch 5/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 429.7302 - mean_squared_error: 429.7302\n",
      "Epoch 6/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 365.3683 - mean_squared_error: 365.3683\n",
      "Epoch 7/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 330.2099 - mean_squared_error: 330.2099\n",
      "Epoch 8/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 305.3895 - mean_squared_error: 305.3895\n",
      "Epoch 9/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 296.2176 - mean_squared_error: 296.2176\n",
      "Epoch 10/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 293.7110 - mean_squared_error: 293.7110\n",
      "Epoch 11/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 285.1266 - mean_squared_error: 285.1266\n",
      "Epoch 12/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 284.0134 - mean_squared_error: 284.0134\n",
      "Epoch 13/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 279.2782 - mean_squared_error: 279.2782\n",
      "Epoch 14/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 281.2669 - mean_squared_error: 281.2669\n",
      "Epoch 15/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 276.7629 - mean_squared_error: 276.7629\n",
      "Epoch 16/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 279.0159 - mean_squared_error: 279.0159\n",
      "Epoch 17/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 276.1068 - mean_squared_error: 276.1068\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 4us/step - loss: 275.4541 - mean_squared_error: 275.4541\n",
      "Epoch 19/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 269.8118 - mean_squared_error: 269.8118\n",
      "Epoch 20/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 268.6011 - mean_squared_error: 268.6011\n",
      "Epoch 21/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 271.4047 - mean_squared_error: 271.4047\n",
      "Epoch 22/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 274.0759 - mean_squared_error: 274.0759\n",
      "Epoch 23/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 274.4417 - mean_squared_error: 274.4417\n",
      "Epoch 24/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 270.2535 - mean_squared_error: 270.2535\n",
      "Epoch 25/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 269.9862 - mean_squared_error: 269.9862\n",
      "Epoch 26/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 269.9908 - mean_squared_error: 269.9908\n",
      "Epoch 27/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 269.2045 - mean_squared_error: 269.2045\n",
      "Epoch 28/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 268.2457 - mean_squared_error: 268.2457\n",
      "Epoch 29/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 264.8336 - mean_squared_error: 264.8336\n",
      "Epoch 30/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 266.3207 - mean_squared_error: 266.3207\n",
      "Epoch 31/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 266.4723 - mean_squared_error: 266.4723\n",
      "Epoch 32/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 265.3748 - mean_squared_error: 265.3748\n",
      "Epoch 33/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 262.3462 - mean_squared_error: 262.3462\n",
      "Epoch 34/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 267.2087 - mean_squared_error: 267.2087\n",
      "Epoch 35/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 260.0659 - mean_squared_error: 260.0659\n",
      "Epoch 36/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 266.7965 - mean_squared_error: 266.7965\n",
      "Epoch 37/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 262.0631 - mean_squared_error: 262.0631\n",
      "Epoch 38/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 263.5198 - mean_squared_error: 263.5198\n",
      "Epoch 39/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 261.9610 - mean_squared_error: 261.9610\n",
      "Epoch 40/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 263.5164 - mean_squared_error: 263.5164\n",
      "Epoch 41/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 264.2182 - mean_squared_error: 264.2182\n",
      "Epoch 42/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 262.6392 - mean_squared_error: 262.6392\n",
      "Epoch 43/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 258.0210 - mean_squared_error: 258.0210\n",
      "Epoch 44/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 262.2602 - mean_squared_error: 262.2602\n",
      "Epoch 45/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 260.1134 - mean_squared_error: 260.1134\n",
      "Epoch 46/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 258.6674 - mean_squared_error: 258.6674\n",
      "Epoch 47/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 260.3253 - mean_squared_error: 260.3253\n",
      "Epoch 48/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 258.8588 - mean_squared_error: 258.8588\n",
      "Epoch 49/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 261.6460 - mean_squared_error: 261.6460\n",
      "Epoch 50/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 256.4309 - mean_squared_error: 256.4309\n",
      "Epoch 51/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 254.3811 - mean_squared_error: 254.3811\n",
      "Epoch 52/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 258.8548 - mean_squared_error: 258.8548\n",
      "Epoch 53/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 257.0032 - mean_squared_error: 257.0032\n",
      "Epoch 54/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 257.7533 - mean_squared_error: 257.7533\n",
      "Epoch 55/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.2729 - mean_squared_error: 255.2729\n",
      "Epoch 56/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 258.5423 - mean_squared_error: 258.5423\n",
      "Epoch 57/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.9184 - mean_squared_error: 255.9184\n",
      "Epoch 58/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 251.0861 - mean_squared_error: 251.0861\n",
      "Epoch 59/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.6540 - mean_squared_error: 255.6540\n",
      "Epoch 60/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 254.7420 - mean_squared_error: 254.7420\n",
      "Epoch 61/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.3617 - mean_squared_error: 250.3617\n",
      "Epoch 62/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 247.0245 - mean_squared_error: 247.0245\n",
      "Epoch 63/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 253.6299 - mean_squared_error: 253.6299\n",
      "Epoch 64/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 253.0161 - mean_squared_error: 253.0161\n",
      "Epoch 65/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.6560 - mean_squared_error: 255.6560\n",
      "Epoch 66/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.6517 - mean_squared_error: 255.6517\n",
      "Epoch 67/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 248.9800 - mean_squared_error: 248.9800\n",
      "Epoch 68/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 252.3450 - mean_squared_error: 252.3450\n",
      "Epoch 69/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.3746 - mean_squared_error: 250.3746\n",
      "Epoch 70/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 249.3940 - mean_squared_error: 249.3940\n",
      "Epoch 71/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.1457 - mean_squared_error: 250.1457\n",
      "Epoch 72/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.6944 - mean_squared_error: 250.6944\n",
      "Epoch 73/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 244.5462 - mean_squared_error: 244.5462\n",
      "Epoch 74/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 250.6128 - mean_squared_error: 250.6128\n",
      "Epoch 75/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 255.7666 - mean_squared_error: 255.7666\n",
      "Epoch 76/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 249.4212 - mean_squared_error: 249.4212\n",
      "Epoch 77/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 244.9586 - mean_squared_error: 244.9586\n",
      "Epoch 78/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 248.9416 - mean_squared_error: 248.9416\n",
      "Epoch 79/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 242.1324 - mean_squared_error: 242.1324\n",
      "Epoch 80/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 241.8189 - mean_squared_error: 241.8189\n",
      "Epoch 81/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 245.3157 - mean_squared_error: 245.3157\n",
      "Epoch 82/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 241.2386 - mean_squared_error: 241.2386\n",
      "Epoch 83/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 240.2982 - mean_squared_error: 240.2982\n",
      "Epoch 84/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 241.3663 - mean_squared_error: 241.3663\n",
      "Epoch 85/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 242.0725 - mean_squared_error: 242.0725\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14665/14665 [==============================] - 0s 4us/step - loss: 240.3983 - mean_squared_error: 240.3983\n",
      "Epoch 87/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 238.0498 - mean_squared_error: 238.0498\n",
      "Epoch 88/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 234.5830 - mean_squared_error: 234.5830\n",
      "Epoch 89/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 236.0423 - mean_squared_error: 236.0423\n",
      "Epoch 90/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 238.3170 - mean_squared_error: 238.3170\n",
      "Epoch 91/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 236.7354 - mean_squared_error: 236.7354\n",
      "Epoch 92/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 232.1983 - mean_squared_error: 232.1983\n",
      "Epoch 93/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 241.5924 - mean_squared_error: 241.5924\n",
      "Epoch 94/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 229.6319 - mean_squared_error: 229.6319\n",
      "Epoch 95/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 231.2168 - mean_squared_error: 231.2168\n",
      "Epoch 96/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 235.6925 - mean_squared_error: 235.6925\n",
      "Epoch 97/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 227.0957 - mean_squared_error: 227.0957\n",
      "Epoch 98/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 228.3251 - mean_squared_error: 228.3251\n",
      "Epoch 99/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 233.0077 - mean_squared_error: 233.0077\n",
      "Epoch 100/100\n",
      "14665/14665 [==============================] - 0s 4us/step - loss: 230.3810 - mean_squared_error: 230.3810\n",
      "3666/3666 [==============================] - 0s 19us/step\n",
      "100/100 [==============================] - 0s 22us/step\n"
     ]
    }
   ],
   "source": [
    "alpha_values = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "#alpha_values = [0.4]\n",
    "\n",
    "for dataset in test_sets.keys():\n",
    "    for alphaValue in alpha_values:\n",
    "        \n",
    "        model_file_name = 'yulin/alpha{}/bestModel_global.json'.format(alphaValue)\n",
    "        weights_file_name = 'yulin/alpha{}/bestModel_global.h5'.format(alphaValue)\n",
    "        trainable_count = 0\n",
    "        \n",
    "        print(\"Testing for \"+model_file_name)\n",
    "        \n",
    "        results_key = dataset + \"_\" +  str(alphaValue)\n",
    "        \n",
    "        model_location = best_model_folder + '/' + dataset + '/' + model_file_name\n",
    "        \n",
    "        if weights_file_name != \"\":\n",
    "            weights_location = best_model_folder + '/' + dataset + '/' + weights_file_name\n",
    "        \n",
    "        dhandler, data_scaler, problem_type = test_sets[dataset]\n",
    "\n",
    "        #model = load_model(model_location, weights_location, problem_type)   \n",
    "        \n",
    "        data_handler = dhandler(data_scaler=data_scaler)\n",
    "        data_handler.load_data(verbose = 1, unroll=True)\n",
    "        data_handler.print_data()\n",
    "        \n",
    "        folds = list(KFold(n_splits=k, shuffle=True).split(data_handler.X_train))\n",
    "        \n",
    "        print('Validation on model:' + model_location)\n",
    "        \n",
    "        for j, (train_idx, val_idx) in enumerate(folds):\n",
    "\n",
    "            print('\\nExperiment on Fold ', j)\n",
    "            \n",
    "            K.clear_session()  #Clear the previous tensorflow graph \n",
    "\n",
    "            X_train_cv = data_handler.X_train[train_idx]\n",
    "            y_train_cv = data_handler.y_train[train_idx]\n",
    "            X_valid_cv = data_handler.X_train[val_idx]\n",
    "            y_valid_cv = data_handler.y_train[val_idx]\n",
    "\n",
    "            model = load_model(model_location, \"\", problem_type)\n",
    "            model.summary()\n",
    "            trainable_count = int(np.sum([K.count_params(p) for p in set(model.trainable_weights)]))\n",
    "\n",
    "            model.fit(X_train_cv, y_train_cv, batch_size=512, epochs=100, verbose=1)\n",
    "\n",
    "            evaluation_cv = model.evaluate(X_valid_cv, y_valid_cv)\n",
    "            evaluation_test = model.evaluate(data_handler.X_test, data_handler.y_test)\n",
    "\n",
    "            evaluations_cv[j] = evaluation_cv[1]\n",
    "            evaluations_test[j] = evaluation_test[1]\n",
    "            \n",
    "        results[results_key] = (evaluations_cv.copy(), evaluations_test.copy(), trainable_count)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats for: \n",
      "cmapss_0.2\n",
      "\n",
      "Model size: 204857\n",
      "\n",
      "CrossVal stats: \n",
      "[212.27631723 223.63718078 235.97755606 227.31745316 215.6266873 ]\n",
      "DescribeResult(nobs=5, minmax=(212.27631722921763, 235.97755606110735), mean=222.9670389055951, variance=89.20526066451777, skewness=0.2214791873515282, kurtosis=-1.2336953141176457)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=5, minmax=(221.3578779602051, 286.3918865966797), mean=253.0898410949707, variance=746.1178418542241, skewness=0.1850057361206015, kurtosis=-1.5399010788719116)\n",
      "\n",
      "Stats for: \n",
      "cmapss_0.3\n",
      "\n",
      "Model size: 123217\n",
      "\n",
      "CrossVal stats: \n",
      "[241.85084751 221.9894856  224.27111931 239.55319014 213.80363954]\n",
      "DescribeResult(nobs=5, minmax=(213.80363953835445, 241.85084751317441), mean=228.2936564226311, variance=144.1146234321492, skewness=0.09067755680737255, kurtosis=-1.5588714870584253)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=5, minmax=(219.99494476318358, 264.3067074584961), mean=240.87114636230467, variance=288.83323692117614, skewness=0.18322479647595394, kurtosis=-1.1013149829227742)\n",
      "\n",
      "Stats for: \n",
      "cmapss_0.4\n",
      "\n",
      "Model size: 564009\n",
      "\n",
      "CrossVal stats: \n",
      "[332.26063861 245.28823084 232.88564034 230.5191981  235.18486716]\n",
      "DescribeResult(nobs=5, minmax=(230.51919809560988, 332.2606386070782), mean=255.22771500914777, variance=1886.0648805034211, skewness=1.4395149451331126, kurtosis=0.1631109275863074)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=5, minmax=(257.7873406982422, 310.06950439453124), mean=279.65281575775145, variance=522.6183327142336, skewness=0.29913857486304646, kurtosis=-1.481536176230402)\n",
      "\n",
      "Stats for: \n",
      "cmapss_0.5\n",
      "\n",
      "Model size: 316369\n",
      "\n",
      "CrossVal stats: \n",
      "[246.65474637 215.05646227 218.20973753 232.65394624 212.2218057 ]\n",
      "DescribeResult(nobs=5, minmax=(212.22180569529598, 246.6547463747081), mean=224.95933962220334, variance=208.94163097479884, skewness=0.6776368163661535, kurtosis=-1.1169006008316884)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=5, minmax=(239.47139099121094, 267.3246374511719), mean=247.2004666442871, variance=129.78698418677723, skewness=1.4055173972197104, kurtosis=0.13183913162150684)\n",
      "\n",
      "Stats for: \n",
      "cmapss_0.6\n",
      "\n",
      "Model size: 96233\n",
      "\n",
      "CrossVal stats: \n",
      "[220.73773893 252.26273592 236.61950618 241.1834407  245.21086802]\n",
      "DescribeResult(nobs=5, minmax=(220.73773893258016, 252.26273591935927), mean=239.20285794999836, variance=139.55340808472357, skewness=-0.6546097849865818, kurtosis=-0.6459130034225415)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=5, minmax=(233.48522521972657, 305.379133605957), mean=260.0625463104248, variance=817.5422985582256, skewness=0.7961420545334229, kurtosis=-0.718221246211034)\n",
      "\n",
      "Stats for: \n",
      "cmapss_0.7\n",
      "\n",
      "Model size: 46073\n",
      "\n",
      "CrossVal stats: \n",
      "[232.8121323  232.49955307 230.58167373 215.89551943 210.40966883]\n",
      "DescribeResult(nobs=5, minmax=(210.4096688344969, 232.81213230354635), mean=224.43970947356974, variance=110.6568729407313, skewness=-0.490635060585825, kurtosis=-1.6057273053389007)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=5, minmax=(241.73796173095704, 284.45218994140623), mean=263.30700689697267, variance=254.77881232908842, skewness=-0.006715721547529418, kurtosis=-0.9669575626830462)\n",
      "\n",
      "Stats for: \n",
      "cmapss_0.8\n",
      "\n",
      "Model size: 17009\n",
      "\n",
      "CrossVal stats: \n",
      "[221.82856999 211.695814   225.61546764 238.56084171 224.88935388]\n",
      "DescribeResult(nobs=5, minmax=(211.69581400053917, 238.56084170760317), mean=224.51800944329844, variance=92.54630743270901, skewness=0.20190000056434038, kurtosis=-0.5929039213441056)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=5, minmax=(214.46554748535155, 260.7492657470703), mean=245.74909045410158, variance=347.5516247549183, skewness=-1.0926069628840376, kurtosis=-0.33635503204407025)\n"
     ]
    }
   ],
   "source": [
    "model_sizes = []\n",
    "cv_errors = []\n",
    "test_errors = []\n",
    "alphas = []\n",
    "\n",
    "for key in results.keys():\n",
    "    \n",
    "    print(\"\\nStats for: \")\n",
    "    print(key)\n",
    "    evaluations_cv, evaluations_test, model_size = results[key]\n",
    "    \n",
    "    \n",
    "    print(\"\\nModel size: %d\"%model_size)\n",
    "    \n",
    "    print(\"\\nCrossVal stats: \")\n",
    "    print(evaluations_cv)\n",
    "    cv_stats = stats.describe(evaluations_cv)\n",
    "    print(cv_stats)\n",
    "    \n",
    "    print(\"\\nTest stats: \")\n",
    "    test_stats = stats.describe(evaluations_test)\n",
    "    print(test_stats)\n",
    "    \n",
    "    model_sizes.append(model_size)\n",
    "    cv_errors.append(cv_stats[2])\n",
    "    test_errors.append(test_stats[2])\n",
    "    key_alphas = key.split('_')\n",
    "    alphas.append(key_alphas[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8']\n",
      "[222.9670389055951, 228.2936564226311, 255.22771500914777, 224.95933962220334, 239.20285794999836, 224.43970947356974, 224.51800944329844]\n",
      "[253.0898410949707, 240.87114636230467, 279.65281575775145, 247.2004666442871, 260.0625463104248, 263.30700689697267, 245.74909045410158]\n"
     ]
    }
   ],
   "source": [
    "print(alphas)\n",
    "print(cv_errors)\n",
    "print(test_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np_sizes = np.array(model_sizes)\n",
    "\n",
    "#np_cv_errors = 1 - np.array(cv_errors) #Used for accuracy error\n",
    "\n",
    "np_cv_errors = np.sqrt(np.array(cv_errors)) #Used for RMSE\n",
    "\n",
    "np_alphas = np.array(alphas)\n",
    "\n",
    "colors = ['b', 'c', 'y', 'm', 'r', 'g', 'k']\n",
    "n1 = plt.scatter(np_sizes[0], np_cv_errors[0], color = colors[0], label = 'alpha='+np_alphas[0])\n",
    "n2 = plt.scatter(np_sizes[1], np_cv_errors[1], color = colors[1], label = 'alpha='+np_alphas[1])\n",
    "n3 = plt.scatter(np_sizes[2], np_cv_errors[2], color = colors[2], label = 'alpha='+np_alphas[2])\n",
    "n4 = plt.scatter(np_sizes[3], np_cv_errors[3], color = colors[3], label = 'alpha='+np_alphas[3])\n",
    "n5 = plt.scatter(np_sizes[4], np_cv_errors[4], color = colors[4], label = 'alpha='+np_alphas[4])\n",
    "n6 = plt.scatter(np_sizes[5], np_cv_errors[5], color = colors[5], label = 'alpha='+np_alphas[5]) \n",
    "n7 = plt.scatter(np_sizes[6], np_cv_errors[6], color = colors[6], label = 'alpha='+np_alphas[6])\n",
    "\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1),loc=2)\n",
    "plt.xlabel('Model Size')\n",
    "plt.ylabel('Error')\n",
    "\n",
    "#plt.title(r'$\\alpha$'+' effect on AMS. MNIST cross-validation set')\n",
    "#plt.savefig('alpha_ams_mnist_cvset.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.title(r'$\\alpha$'+' effect on AMS. CMAPSS cross-validation set')\n",
    "plt.savefig('alpha_ams_cmapss_cvset.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np_sizes = np.array(model_sizes)\n",
    "\n",
    "#np_test_errors = 1 - np.array(test_errors) #Used for accuracy error\n",
    "\n",
    "np_test_errors = np.sqrt(np.array(test_errors)) #Used for RMSE\n",
    "\n",
    "np_alphas = np.array(alphas)\n",
    "\n",
    "colors = ['b', 'c', 'y', 'm', 'r', 'g', 'k']\n",
    "n1 = plt.scatter(np_sizes[0], np_test_errors[0], color = colors[0], label = 'alpha='+np_alphas[0])\n",
    "n2 = plt.scatter(np_sizes[1], np_test_errors[1], color = colors[1], label = 'alpha='+np_alphas[1])\n",
    "n3 = plt.scatter(np_sizes[2], np_test_errors[2], color = colors[2], label = 'alpha='+np_alphas[2])\n",
    "n4 = plt.scatter(np_sizes[3], np_test_errors[3], color = colors[3], label = 'alpha='+np_alphas[3])\n",
    "n5 = plt.scatter(np_sizes[4], np_test_errors[4], color = colors[4], label = 'alpha='+np_alphas[4])\n",
    "n6 = plt.scatter(np_sizes[5], np_test_errors[5], color = colors[5], label = 'alpha='+np_alphas[5]) \n",
    "n7 = plt.scatter(np_sizes[6], np_test_errors[6], color = colors[6], label = 'alpha='+np_alphas[6])\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1),loc=2)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1),loc=2)\n",
    "plt.xlabel('Model Size')\n",
    "plt.ylabel('Error')\n",
    "\n",
    "plt.title(r'$\\alpha$'+' effect on AMS. MNIST test set')\n",
    "plt.savefig('alpha_ams_mnist_testset.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.title(r'$\\alpha$'+' effect on AMS. CMAPSS test set')\n",
    "plt.savefig('alpha_ams_cmapss_testset.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
