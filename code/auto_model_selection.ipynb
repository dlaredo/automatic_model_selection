{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "\n",
    "#sys.path.append('/Users/davidlaredorazo/Documents/University_of_California/Research/Projects')\n",
    "sys.path.append('/media/controlslab/DATA/Projects')\n",
    "\n",
    "import ann_framework.aux_functions as aux_functions\n",
    "\n",
    "import automatic_model_selection\n",
    "from automatic_model_selection import Configuration\n",
    "from automatic_model_selection import run_experiment\n",
    "from ann_encoding_rules import Layers\n",
    "import fetch_to_keras\n",
    "\n",
    "#Tunable model\n",
    "from ann_framework.tunable_model.tunable_model import SequenceTunableModelRegression, SequenceTunableModelClassification\n",
    "\n",
    "#Data handlers\n",
    "from ann_framework.data_handlers.data_handler_DAMADICS import DamadicsDataHandler\n",
    "\n",
    "learningRate_scheduler = LearningRateScheduler(aux_functions.step_decay)\n",
    "\n",
    "size_scaler = 0.5\n",
    "\n",
    "#Use same configuration for all experiments, just change some of the parameters\n",
    "\n",
    "#Define some random paramaters for the creation of the configuration, this will change for each test model\n",
    "architecture_type = Layers.FullyConnected\n",
    "problem_type = 2  #1 for regression, 2 for classification\n",
    "output_shape = 2 #If regression applies, number of classes\n",
    "\n",
    "features = ['externalControllerOutput', 'undisturbedMediumFlow', 'pressureValveInlet', \n",
    "            'pressureValveOutlet', 'mediumTemperature', 'rodDisplacement', 'disturbedMediumFlow', \n",
    "           'selectedFault', 'faultType', 'faultIntensity']\n",
    "\n",
    "selected_indices = np.array([1,3,4,5,6,7])\n",
    "selected_features = list(features[i] for i in selected_indices-1)\n",
    "\n",
    "#Does not work for sequence sizes larger than 1 given the way I'm generating the test data. \n",
    "#Need to properly define what the test data is going to be like.\n",
    "window_size = 2\n",
    "window_stride = 1\n",
    "\n",
    "start_date = datetime.datetime(2018, 2, 14, 18, 59, 20)\n",
    "time_delta = datetime.timedelta(days=0, seconds=0, microseconds=0, milliseconds=0, minutes=1, hours=0, weeks=0)\n",
    "end_date = start_date + 250000*time_delta #get the first 300 instances\n",
    "\n",
    "input_shape = (window_size * len(selected_features), )\n",
    "\n",
    "config = Configuration(architecture_type, problem_type, input_shape, output_shape, pop_size=5, \n",
    "                       tournament_size=3, max_similar=3, epochs=5, cross_val=0.2, size_scaler=size_scaler,\n",
    "                       max_generations=10, binary_selection=True, mutation_ratio=0.8, \n",
    "                       similarity_threshold=0.2, more_layers_prob=0.4, verbose_individuals=True, \n",
    "                       show_model=True, verbose_training=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given a model get the compiled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model(model, problem_type, optimizer_params=[]):\n",
    "    \"\"\"Obtain a keras compiled model\"\"\"\n",
    "    \n",
    "    #Shared parameters for the models\n",
    "    optimizer = Adam(lr=0.01, beta_1=0.5)\n",
    "    \n",
    "    if problem_type == 1:\n",
    "        lossFunction = \"mean_squared_error\"\n",
    "        metrics = [\"mse\"]\n",
    "    elif problem_type == 2:\n",
    "        lossFunction = \"categorical_crossentropy\"\n",
    "        metrics = [\"accuracy\"]\n",
    "    elif problem_type == 3:\n",
    "        lossFunction = \"binary_crossentropy\"\n",
    "        metrics = [\"accuracy\"]\n",
    "    else:\n",
    "        print(\"Problem type not defined\")\n",
    "        model = None\n",
    "        return\n",
    "    \n",
    "    #Create and compile the models\n",
    "    model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_tunable_model(model_genotype, problem_type, input_shape, data_handler, model_number):\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    model = fetch_to_keras.decode_genotype(model_genotype, problem_type, input_shape, 1)\n",
    "    \n",
    "    model = get_compiled_model(model, problem_type, optimizer_params=[])\n",
    "    \n",
    "    if problem_type == 1:\n",
    "        tModel = SequenceTunableModelRegression('ModelReg_SN_'+str(model_number), model, lib_type='keras', data_handler=data_handler)\n",
    "    else:\n",
    "        tModel = SequenceTunableModelClassification('ModelClass_SN_'+str(model_number), model, lib_type='keras', data_handler=data_handler)\n",
    "        \n",
    "    return tModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to save top models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_models(best_models_list, global_best_model_index, saveto, input_shape, data_handler, \n",
    "                     problem_type=1, data_scaler=None, train_epochs=100, metrics=[], round=0):\n",
    "    \n",
    "    n_models = len(best_models_list)\n",
    "    \n",
    "    for ind_model, i in zip(best_models_list, range(n_models)):\n",
    "        \n",
    "        tModel = create_tunable_model(ind_model.stringModel, problem_type, input_shape, data_handler, i)\n",
    "        kmodel = tModel.model\n",
    "        model_json = kmodel.to_json()\n",
    "        \n",
    "        #Save model's architecture\n",
    "        string_append = str(i) if i != global_best_model_index else 'global'\n",
    "        with open(saveto+\"bestModel_\"+string_append+\".json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "            \n",
    "    #Train the global best, model has to be recompiled\n",
    "    ind_model = best_models_list[global_best_model_index]\n",
    "    tModel = create_tunable_model(ind_model.stringModel, problem_type, input_shape, data_handler, n_models)\n",
    "    \n",
    "    print(tModel.model.summary())\n",
    "    #print(tModel.data_handler)\n",
    "    \n",
    "    if tModel.data_handler.data_scaler != None:\n",
    "        print(\"Using data handler scaler\")\n",
    "    elif tModel.data_scaler != None:\n",
    "        print(\"Using tModel scaler (Overriding data handler scaler)\")\n",
    "    else:\n",
    "        print(\"No data scaling used\")\n",
    "    \n",
    "    if data_scaler != None:\n",
    "        tModel.data_handler.data_scaler = None\n",
    "        tModel.data_scaler = data_scaler\n",
    "        \n",
    "    tModel.load_data(unroll=True, verbose=1, cross_validation_ratio=0.2,test_ratio=0.1)\n",
    "    tModel.print_data()\n",
    "    tModel.epochs = train_epochs\n",
    "\n",
    "    tModel.train_model(verbose=1)\n",
    "    \n",
    "    tModel.evaluate_model(metrics, round=round)\n",
    "    \n",
    "    kmodel = tModel.model\n",
    "            \n",
    "    # serialize weights to HDF5\n",
    "    kmodel.save_weights(saveto+\"bestModel_global.h5\")\n",
    "    \n",
    "    print(\"Saved models for dataset 1 to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get global best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recompute_globals_fitness(best_models, size_scaler, problem_type):\n",
    "    \"\"\"It is necessary to recompute the fiteness of global models since they have differnt normalization factors\"\"\"\n",
    "\n",
    "    #print(\"Before normalization\")\n",
    "    #automatic_model_selection.print_best(best_models)\n",
    "    \n",
    "    normalize_scores(best_models)\n",
    "    \n",
    "    #print(\"After normalization\")\n",
    "    #automatic_model_selection.print_best(best_models)\n",
    "    \n",
    "    global_best_index = compute_fitness(best_models, size_scaler, problem_type)\n",
    "    \n",
    "    print(\"Recomputed fitness\")\n",
    "    automatic_model_selection.print_best(best_models)\n",
    "    print(\"Global best index\")\n",
    "    print(global_best_index)\n",
    "    \n",
    "    return global_best_index\n",
    "\n",
    "\n",
    "def normalize_scores(best_models):\n",
    "    \n",
    "    pop_size = len(best_models)\n",
    "    raw_scores = np.zeros((pop_size,))\n",
    "    \n",
    "    for i in range(pop_size):\n",
    "        model = best_models[i]\n",
    "        raw_scores[i] = model.raw_score\n",
    "        \n",
    "    normalization_factor = np.linalg.norm(raw_scores)\n",
    "    normalized_scores = raw_scores/normalization_factor\n",
    "    \n",
    "    for i in range(pop_size):\n",
    "        model = best_models[i]\n",
    "        model.normalized_score = raw_scores[i]\n",
    "    \n",
    "    \n",
    "def compute_fitness(best_models, size_scaler, problem_type):\n",
    "    \n",
    "    pop_size = len(best_models)\n",
    "    \n",
    "    global_best_index = 0\n",
    "    \n",
    "    for i in range(pop_size):\n",
    "        \n",
    "        round_up_to = 3\n",
    "\n",
    "        #Round up to the first 3 digits before computing log                                                                                                                                                          \n",
    "        rounding_scaler = 10**round_up_to\n",
    "        trainable_count = round(best_models[i].raw_size/rounding_scaler)*rounding_scaler\n",
    "        size_score = math.log10(trainable_count)\n",
    "\n",
    "        scaled_score = best_models[i].normalized_score\n",
    "\n",
    "        #For classification estimate the error which is between 0 and 1                                                                                                                   \n",
    "        if problem_type == 2:\n",
    "            metric_score = (1 - scaled_score)*10 #Multiply by 10 to have a better scaling. I still need to find an appropriate scaling \n",
    "        elif problem_type == 3:\n",
    "            metric_score == (1 - scaled_score)*10\n",
    "        else:\n",
    "            metric_score = scaled_score*10 #Multiply by 10 to have a better scaling. I still need to find an appropiate scaling                                                       \n",
    "    \n",
    "        metric_scaler = 1-size_scaler\n",
    "        print(\"metric_scaler %f\"%metric_scaler)\n",
    "        print(\"size scaler %f\"%size_scaler)\n",
    "    \n",
    "        #Scalarization of multiobjective version of the fitness function                                                                                                                  \n",
    "        best_models[i].fitness = metric_scaler*metric_score + size_scaler*size_score\n",
    "        \n",
    "        if best_models[i].fitness < best_models[global_best_index].fitness:\n",
    "            global_best_index = i\n",
    "            \n",
    "    return global_best_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on DAMADICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def damadics_test(damadics_dhandler, input_shape = 12, size_scaler=0.5, total_experiments=1):\n",
    "\n",
    "    \"\"\"Input can be of 3 types, ANN (1), CNN (2) or RNN (3)\"\"\"\n",
    "    architecture_type = Layers.FullyConnected\n",
    "    problem_type = 2  #1 for regression, 2 for classification\n",
    "    output_shape = 2 #If regression applies, number of classes\n",
    "    input_shape = (window_size * len(selected_features), )\n",
    "    \"\"\"\n",
    "    pop_size = 5\n",
    "    tournament_size = 3\n",
    "    max_similar = 3\n",
    "    \"\"\"\n",
    "    total_experiments = 1\n",
    "    count_experiments = 0\n",
    "    unroll = True\n",
    "\n",
    "    global_best_list = []\n",
    "    global_best = None\n",
    "    global_best_index = 0\n",
    "    \n",
    "    experiment_times = np.zeros((total_experiments,1))\n",
    "    \n",
    "    scaler = None\n",
    "\n",
    "    t = datetime.datetime.now()\n",
    "\n",
    "    logging.basicConfig(filename='logs/nn_evolution_damadics_' + t.strftime('%m%d%Y%H%M%S') + '.log', level=logging.INFO, \n",
    "                            format='%(levelname)s:%(threadName)s:%(message)s', datefmt='%m/%d/%Y %H:%M:%S')\n",
    "    \n",
    "\n",
    "    \n",
    "#     config = Configuration(architecture_type, problem_type, input_shape, output_shape, pop_size, tournament_size, max_similar, \n",
    "#                            epochs=5, cross_val=0.2, size_scaler=size_scaler, max_generations=10, binary_selection=True, \n",
    "#                            mutation_ratio=0.4, similarity_threshold=0.2, more_layers_prob=0.8)\n",
    "    \n",
    "\n",
    "    config.architecture_type = architecture_type\n",
    "    config.problem_type = problem_type\n",
    "    config.input_shape = input_shape\n",
    "    config.output_shape = output_shape\n",
    "\n",
    "    while count_experiments < total_experiments:\n",
    "        print(\"Launching experiment {}\".format(count_experiments+1))\n",
    "        logging.info(\"Launching experiment {}\".format(count_experiments+1))\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        best = automatic_model_selection.run_experiment(config, damadics_dhandler, count_experiments + 1, unroll=unroll,\n",
    "                                                        learningRate_scheduler=learningRate_scheduler, \n",
    "                                                        tModel_scaler=scaler)\n",
    "        \n",
    "        end = time.time()\n",
    "        elapsed_time = (end-start)/60\n",
    "        experiment_times[count_experiments] = elapsed_time\n",
    "        print(\"Experiment time: {} minutes\".format(elapsed_time))\n",
    "        logging.info(\"Experiment time: {} minutes\".format(elapsed_time))\n",
    "        \n",
    "        best.individual_label = count_experiments\n",
    "\n",
    "        global_best_list.append(best)\n",
    "\n",
    "        if global_best == None:\n",
    "            global_best = best\n",
    "        else:\n",
    "            if best.fitness < global_best.fitness:\n",
    "                global_best = best\n",
    "                global_best_index = count_experiments\n",
    "\n",
    "        count_experiments =  count_experiments + 1\n",
    "        \n",
    "    total_experiment_time = experiment_times.sum()\n",
    "\n",
    "    print(\"Global best list\\n\")\n",
    "    logging.info(\"Global best list\\n\")\n",
    "    automatic_model_selection.print_best(global_best_list)\n",
    "\n",
    "    print(\"Global best is\\n\")\n",
    "    print(global_best)\n",
    "    logging.info(\"Global best is\\n\")\n",
    "    logging.info(global_best)\n",
    "    \n",
    "    return global_best_list, global_best_index, total_experiment_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_damadics_test(alphas):\n",
    "\n",
    "    experiments = 1\n",
    "    problem_type = 2\n",
    "\n",
    "    global_best_list = []\n",
    "    global_best_index = 0\n",
    "    total_experiment_time = []\n",
    "    total_experiment_time = 0\n",
    "    avg_experiment_time = 0\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "    #DamadicsDataHandler = DamadicsDataHandler()\n",
    "    input_shape = (window_size * len(selected_features), )\n",
    "    dhandler_damadics_for_best = DamadicsDataHandler(selected_features, window_size, window_stride, \n",
    "                                      start_date=start_date, end_date=end_date, \n",
    "                                                     binary_classes=True, one_hot_encode=True)\n",
    "    dhandler_damadics_for_best.connect_to_db('readOnly', '_readOnly2019', '169.236.181.40', 'damadics')\n",
    "    #dhandler_damadics_for_best.load_data(unroll=True, verbose=1, start_date=start_date, end_date=end_date)\n",
    "    #dhandler_damadics_for_best.print_data(print_top=True)\n",
    "\n",
    "    for size_scaler in alphas:\n",
    "\n",
    "        print(\"Running for alpha={}\".format(size_scaler))\n",
    "\n",
    "        global_best_list, global_best_index, total_experiment_time = damadics_test(damadics_dhandler=dhandler_damadics_for_best, \n",
    "                                                                                input_shape=input_shape,\n",
    "                                                                                size_scaler=size_scaler, \n",
    "                                                                                total_experiments=experiments)\n",
    "\n",
    "        print(global_best_list)\n",
    "        print(global_best_index)\n",
    "\n",
    "        avg_experiment_time = total_experiment_time/experiments\n",
    "\n",
    "        print(\"Total experiment time {}\".format(total_experiment_time))\n",
    "        print(\"Avg experiment time {}\".format(avg_experiment_time))\n",
    "\n",
    "        save_best_models(global_best_list, global_best_index, \n",
    "                         '/media/controlslab/DATA/Projects/ValveActuator-DAMADICS-/code/best_models/alpha{}/'.format(size_scaler), input_shape=input_shape, \n",
    "                         data_handler=dhandler_damadics_for_best, problem_type=problem_type, train_epochs=1 , \n",
    "                         data_scaler=scaler)\n",
    "        \n",
    "        return global_best_list, global_best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to mysql+mysqldb://readOnly:_readOnly2019@169.236.181.40/damadics successfull\n",
      "Running for alpha=0.7\n",
      "Launching experiment 1\n",
      "\n",
      "Generation 1\n",
      "launch new\n",
      "True\n",
      "gen similar\n",
      "False\n",
      "Fetching model 0 to keras\n",
      "Evaluating model 0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 968)               12584     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 856)               829464    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1714      \n",
      "=================================================================\n",
      "Total params: 843,762\n",
      "Trainable params: 843,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Loading data for the first time\n",
      "Reloading data due to parameter change\n",
      "Loading data for DAMADICS with window_size of 2, stride of 1. Cros-Validation ratio 0.2\n",
      "Loading data from database\n",
      "Extracting data from database runtime: 0:00:01.493409\n",
      "Data Splitting: 0:00:00.000070\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 7us/step - loss: 0.6288 - acc: 0.7013 - val_loss: 1.3268 - val_acc: 0.6480\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.6032 - acc: 0.7109 - val_loss: 0.6740 - val_acc: 0.5680\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5989 - acc: 0.7137 - val_loss: 0.6932 - val_acc: 0.6480\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5973 - acc: 0.7195 - val_loss: 0.6725 - val_acc: 0.5680\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5928 - acc: 0.7265 - val_loss: 0.6857 - val_acc: 0.6480\n",
      "250/250 [==============================] - 0s 15us/step\n",
      "Fetching model 1 to keras\n",
      "Evaluating model 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 976)               12688     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 976)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1954      \n",
      "=================================================================\n",
      "Total params: 14,642\n",
      "Trainable params: 14,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5913 - acc: 0.7235 - val_loss: 0.6789 - val_acc: 0.6560\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5769 - acc: 0.7339 - val_loss: 0.6860 - val_acc: 0.6120\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5718 - acc: 0.7363 - val_loss: 0.9369 - val_acc: 0.6480\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5694 - acc: 0.7373 - val_loss: 1.1708 - val_acc: 0.6480\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5683 - acc: 0.7379 - val_loss: 0.7066 - val_acc: 0.4160\n",
      "250/250 [==============================] - 0s 15us/step\n",
      "Fetching model 2 to keras\n",
      "Evaluating model 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 152)               1976      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 152)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 872)               133416    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1746      \n",
      "=================================================================\n",
      "Total params: 137,138\n",
      "Trainable params: 137,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5870 - acc: 0.7290 - val_loss: 1.0183 - val_acc: 0.6480\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5725 - acc: 0.7360 - val_loss: 0.8368 - val_acc: 0.6480\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5697 - acc: 0.7371 - val_loss: 0.9465 - val_acc: 0.6480\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5679 - acc: 0.7377 - val_loss: 0.6967 - val_acc: 0.5960\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5675 - acc: 0.7375 - val_loss: 0.8162 - val_acc: 0.6480\n",
      "250/250 [==============================] - 0s 15us/step\n",
      "Fetching model 3 to keras\n",
      "Evaluating model 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 784)               10192     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 696)               546360    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1394      \n",
      "=================================================================\n",
      "Total params: 557,946\n",
      "Trainable params: 557,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.6209 - acc: 0.7051 - val_loss: 0.6888 - val_acc: 0.6480\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.6019 - acc: 0.7116 - val_loss: 1.1244 - val_acc: 0.6480\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5998 - acc: 0.7134 - val_loss: 1.0033 - val_acc: 0.6480\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5971 - acc: 0.7198 - val_loss: 0.6799 - val_acc: 0.6480\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5915 - acc: 0.7272 - val_loss: 1.1752 - val_acc: 0.3520\n",
      "250/250 [==============================] - 0s 14us/step\n",
      "Fetching model 4 to keras\n",
      "Evaluating model 4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 624)               8112      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 416)               260000    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 832)               346944    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1666      \n",
      "=================================================================\n",
      "Total params: 616,722\n",
      "Trainable params: 616,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197128/197128 [==============================] - 1s 5us/step - loss: 0.5911 - acc: 0.7261 - val_loss: 0.6738 - val_acc: 0.6480\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5751 - acc: 0.7340 - val_loss: 1.0329 - val_acc: 0.6480\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5713 - acc: 0.7365 - val_loss: 0.6871 - val_acc: 0.6440\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5684 - acc: 0.7380 - val_loss: 0.8846 - val_acc: 0.6480\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5690 - acc: 0.7382 - val_loss: 0.6879 - val_acc: 0.6440\n",
      "250/250 [==============================] - 0s 16us/step\n",
      "raw size 843762.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 844.000000\n",
      "trainable_count 844000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 0 score/normalized score/size/fitness 0.6480000023841858/0.6480000023841858/843762/4.723171211391898\n",
      "raw size 14642.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 15.000000\n",
      "trainable_count 15000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 1 score/normalized score/size/fitness 0.4160000002384186/0.4160000002384186/14642/5.008045628335748\n",
      "raw size 137138.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 137.000000\n",
      "trainable_count 137000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 2 score/normalized score/size/fitness 0.6480000023841858/0.6480000023841858/137138/4.328360271657274\n",
      "raw size 557946.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 558.000000\n",
      "trainable_count 558000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 3 score/normalized score/size/fitness 0.3520000007152557/0.3520000007152557/557946/6.11331709589251\n",
      "raw size 616722.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 617.000000\n",
      "trainable_count 617000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 4 score/normalized score/size/fitness 0.6440000023841858/0.6440000023841858/616722/4.675142570095693\n",
      "\n",
      "Generating offsprings\n",
      "Applying Mutation\n",
      "Launch new generation?: True\n",
      "\n",
      "Generation 2\n",
      "launch new\n",
      "True\n",
      "gen similar\n",
      "False\n",
      "Fetching model 0 to keras\n",
      "Evaluating model 0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 152)               1976      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 152)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 624)               95472     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 416)               260000    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 834       \n",
      "=================================================================\n",
      "Total params: 358,282\n",
      "Trainable params: 358,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 5us/step - loss: 0.5921 - acc: 0.7258 - val_loss: 0.7018 - val_acc: 0.4160\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5686 - acc: 0.7345 - val_loss: 0.7666 - val_acc: 0.6440\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5637 - acc: 0.7372 - val_loss: 0.7594 - val_acc: 0.6480\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5629 - acc: 0.7377 - val_loss: 0.6984 - val_acc: 0.4120\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5627 - acc: 0.7372 - val_loss: 0.7845 - val_acc: 0.6440\n",
      "250/250 [==============================] - 0s 16us/step\n",
      "Fetching model 1 to keras\n",
      "Evaluating model 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 416)               5408      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 834       \n",
      "=================================================================\n",
      "Total params: 6,242\n",
      "Trainable params: 6,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5912 - acc: 0.7203 - val_loss: 0.6546 - val_acc: 0.6480\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5753 - acc: 0.7339 - val_loss: 0.8931 - val_acc: 0.6480\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5692 - acc: 0.7370 - val_loss: 0.6841 - val_acc: 0.6000\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5675 - acc: 0.7377 - val_loss: 0.7394 - val_acc: 0.6440\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5660 - acc: 0.7384 - val_loss: 0.9323 - val_acc: 0.3520\n",
      "250/250 [==============================] - 0s 14us/step\n",
      "Fetching model 2 to keras\n",
      "Evaluating model 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 872)               11336     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 872)               761256    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 872)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1746      \n",
      "=================================================================\n",
      "Total params: 774,338\n",
      "Trainable params: 774,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 5us/step - loss: 0.5881 - acc: 0.7279 - val_loss: 0.7301 - val_acc: 0.5040\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5727 - acc: 0.7365 - val_loss: 0.7792 - val_acc: 0.6480\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5699 - acc: 0.7375 - val_loss: 0.7343 - val_acc: 0.6480\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5687 - acc: 0.7380 - val_loss: 0.9300 - val_acc: 0.6480\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5684 - acc: 0.7380 - val_loss: 0.7134 - val_acc: 0.6440\n",
      "250/250 [==============================] - 0s 15us/step\n",
      "Fetching model 3 to keras\n",
      "Evaluating model 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 856)               11128     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 856)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 832)               713024    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1666      \n",
      "=================================================================\n",
      "Total params: 725,818\n",
      "Trainable params: 725,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197128/197128 [==============================] - 1s 5us/step - loss: 0.5888 - acc: 0.7279 - val_loss: 0.7211 - val_acc: 0.6480\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5755 - acc: 0.7353 - val_loss: 0.7286 - val_acc: 0.6480\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5716 - acc: 0.7368 - val_loss: 0.9051 - val_acc: 0.6480\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5710 - acc: 0.7371 - val_loss: 0.8858 - val_acc: 0.6480\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5691 - acc: 0.7374 - val_loss: 0.9915 - val_acc: 0.6480\n",
      "250/250 [==============================] - 0s 16us/step\n",
      "Fetching model 4 to keras\n",
      "Evaluating model 4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 152)               1976      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 152)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 872)               133416    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1746      \n",
      "=================================================================\n",
      "Total params: 137,138\n",
      "Trainable params: 137,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5867 - acc: 0.7272 - val_loss: 0.6722 - val_acc: 0.6320\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5714 - acc: 0.7362 - val_loss: 0.6723 - val_acc: 0.6480\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5689 - acc: 0.7377 - val_loss: 1.0865 - val_acc: 0.3760\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5699 - acc: 0.7362 - val_loss: 0.9138 - val_acc: 0.6480\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5667 - acc: 0.7379 - val_loss: 0.6703 - val_acc: 0.6440\n",
      "250/250 [==============================] - 0s 15us/step\n",
      "raw size 358282.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 358.000000\n",
      "trainable_count 358000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 0 score/normalized score/size/fitness 0.6439999990463257/0.6439999990463257/358282/4.556941518090309\n",
      "raw size 6242.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 6.000000\n",
      "trainable_count 6000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 1 score/normalized score/size/fitness 0.35200000047683716/0.35200000047683716/6242/5.129075622807637\n",
      "raw size 774338.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 774.000000\n",
      "trainable_count 774000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 2 score/normalized score/size/fitness 0.6439999990463257/0.6439999990463257/774338/4.724370485109818\n",
      "raw size 725818.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 726.000000\n",
      "trainable_count 726000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 3 score/normalized score/size/fitness 0.6480000023841858/0.6480000023841858/725818/4.690468298429118\n",
      "raw size 137138.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 137.000000\n",
      "trainable_count 137000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 4 score/normalized score/size/fitness 0.6439999990463257/0.6439999990463257/137138/4.348360288346575\n",
      "\n",
      "Generating offsprings\n",
      "Applying Mutation\n",
      "Launch new generation?: True\n",
      "\n",
      "Generation 3\n",
      "launch new\n",
      "True\n",
      "gen similar\n",
      "False\n",
      "Fetching model 0 to keras\n",
      "Evaluating model 0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 472)               6136      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 946       \n",
      "=================================================================\n",
      "Total params: 7,082\n",
      "Trainable params: 7,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5919 - acc: 0.7196 - val_loss: 0.7096 - val_acc: 0.6480\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5758 - acc: 0.7336 - val_loss: 0.8537 - val_acc: 0.6480\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5696 - acc: 0.7367 - val_loss: 0.6952 - val_acc: 0.6480\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5671 - acc: 0.7379 - val_loss: 1.2138 - val_acc: 0.3600\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5673 - acc: 0.7370 - val_loss: 0.7496 - val_acc: 0.4120\n",
      "250/250 [==============================] - 0s 14us/step\n",
      "Fetching model 1 to keras\n",
      "Evaluating model 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 872)               11336     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 872)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1746      \n",
      "=================================================================\n",
      "Total params: 13,082\n",
      "Trainable params: 13,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5919 - acc: 0.7231 - val_loss: 0.8992 - val_acc: 0.6480\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5769 - acc: 0.7340 - val_loss: 1.1765 - val_acc: 0.6480\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5722 - acc: 0.7360 - val_loss: 0.7337 - val_acc: 0.6480\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5694 - acc: 0.7371 - val_loss: 0.6938 - val_acc: 0.6480\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5687 - acc: 0.7378 - val_loss: 0.6869 - val_acc: 0.6040\n",
      "250/250 [==============================] - 0s 14us/step\n",
      "Fetching model 2 to keras\n",
      "Evaluating model 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 152)               1976      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 152)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 872)               133416    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1746      \n",
      "=================================================================\n",
      "Total params: 137,138\n",
      "Trainable params: 137,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5886 - acc: 0.7266 - val_loss: 0.7229 - val_acc: 0.4040\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5729 - acc: 0.7353 - val_loss: 0.8597 - val_acc: 0.6480\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5692 - acc: 0.7374 - val_loss: 0.8451 - val_acc: 0.3760\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5691 - acc: 0.7366 - val_loss: 0.6913 - val_acc: 0.6120\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5675 - acc: 0.7377 - val_loss: 0.7332 - val_acc: 0.6440\n",
      "250/250 [==============================] - 0s 16us/step\n",
      "Fetching model 3 to keras\n",
      "Evaluating model 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 136)               1768      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 136)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 832)               113984    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 832)               693056    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1666      \n",
      "=================================================================\n",
      "Total params: 810,474\n",
      "Trainable params: 810,474\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 5us/step - loss: 0.5949 - acc: 0.7239 - val_loss: 1.3395 - val_acc: 0.6480\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5756 - acc: 0.7353 - val_loss: 0.9294 - val_acc: 0.6480\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5717 - acc: 0.7363 - val_loss: 0.6740 - val_acc: 0.6440\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5696 - acc: 0.7371 - val_loss: 0.8600 - val_acc: 0.6480\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5690 - acc: 0.7378 - val_loss: 0.8693 - val_acc: 0.3760\n",
      "250/250 [==============================] - 0s 15us/step\n",
      "Fetching model 4 to keras\n",
      "Evaluating model 4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 208)               2704      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 872)               182248    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1746      \n",
      "=================================================================\n",
      "Total params: 186,698\n",
      "Trainable params: 186,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5809 - acc: 0.7307 - val_loss: 0.6809 - val_acc: 0.6280\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5678 - acc: 0.7377 - val_loss: 0.8123 - val_acc: 0.4120\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5676 - acc: 0.7370 - val_loss: 0.9286 - val_acc: 0.6440\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5657 - acc: 0.7382 - val_loss: 0.8666 - val_acc: 0.3920\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5664 - acc: 0.7374 - val_loss: 0.8625 - val_acc: 0.6480\n",
      "250/250 [==============================] - 0s 14us/step\n",
      "raw size 7082.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 7.000000\n",
      "trainable_count 7000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 0 score/normalized score/size/fitness 0.4120000002384186/0.4120000002384186/7082/4.862549018815036\n",
      "raw size 13082.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 13.000000\n",
      "trainable_count 13000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 1 score/normalized score/size/fitness 0.6040000023841858/0.6040000023841858/13082/4.036971664232489\n",
      "raw size 137138.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 137.000000\n",
      "trainable_count 137000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 2 score/normalized score/size/fitness 0.6439999990463257/0.6439999990463257/137138/4.348360288346575\n",
      "raw size 810474.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 810.000000\n",
      "trainable_count 810000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 3 score/normalized score/size/fitness 0.3760000004768372/0.3760000004768372/810474/6.074242507055139\n",
      "raw size 186698.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 187.000000\n",
      "trainable_count 187000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 4 score/normalized score/size/fitness 0.6480000023841858/0.6480000023841858/186698/4.39592079134732\n",
      "\n",
      "Generating offsprings\n",
      "Applying Mutation\n",
      "Launch new generation?: True\n",
      "\n",
      "Generation 4\n",
      "launch new\n",
      "True\n",
      "gen similar\n",
      "False\n",
      "Fetching model 0 to keras\n",
      "Evaluating model 0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 872)               11336     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 872)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1746      \n",
      "=================================================================\n",
      "Total params: 13,082\n",
      "Trainable params: 13,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5929 - acc: 0.7211 - val_loss: 0.7060 - val_acc: 0.6480\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5770 - acc: 0.7342 - val_loss: 1.0415 - val_acc: 0.3520\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5727 - acc: 0.7353 - val_loss: 1.1995 - val_acc: 0.6480\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5710 - acc: 0.7369 - val_loss: 1.0054 - val_acc: 0.6480\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5683 - acc: 0.7377 - val_loss: 0.6990 - val_acc: 0.4840\n",
      "250/250 [==============================] - 0s 18us/step\n",
      "Fetching model 1 to keras\n",
      "Evaluating model 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 152)               1976      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 152)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 306       \n",
      "=================================================================\n",
      "Total params: 2,282\n",
      "Trainable params: 2,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.6067 - acc: 0.7089 - val_loss: 0.6649 - val_acc: 0.6480\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5895 - acc: 0.7255 - val_loss: 0.6890 - val_acc: 0.6480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5810 - acc: 0.7317 - val_loss: 0.6614 - val_acc: 0.6440\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5749 - acc: 0.7346 - val_loss: 0.8630 - val_acc: 0.6480\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5718 - acc: 0.7362 - val_loss: 0.6722 - val_acc: 0.6440\n",
      "250/250 [==============================] - 0s 17us/step\n",
      "Fetching model 2 to keras\n",
      "Evaluating model 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 320)               4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 872)               279912    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 872)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1746      \n",
      "=================================================================\n",
      "Total params: 285,818\n",
      "Trainable params: 285,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5852 - acc: 0.7299 - val_loss: 2.0514 - val_acc: 0.3520\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5757 - acc: 0.7351 - val_loss: 0.7324 - val_acc: 0.6480\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5680 - acc: 0.7380 - val_loss: 0.8712 - val_acc: 0.6480\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5667 - acc: 0.7382 - val_loss: 0.7020 - val_acc: 0.6400\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5666 - acc: 0.7385 - val_loss: 0.7058 - val_acc: 0.4960\n",
      "250/250 [==============================] - 0s 15us/step\n",
      "Fetching model 3 to keras\n",
      "Evaluating model 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 152)               1976      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 306       \n",
      "=================================================================\n",
      "Total params: 2,282\n",
      "Trainable params: 2,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5951 - acc: 0.7160 - val_loss: 0.6569 - val_acc: 0.6440\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5801 - acc: 0.7305 - val_loss: 0.6850 - val_acc: 0.6480\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5715 - acc: 0.7350 - val_loss: 0.7123 - val_acc: 0.6440\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5669 - acc: 0.7372 - val_loss: 0.6837 - val_acc: 0.6440\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5652 - acc: 0.7380 - val_loss: 0.6740 - val_acc: 0.6440\n",
      "250/250 [==============================] - 0s 14us/step\n",
      "Fetching model 4 to keras\n",
      "Evaluating model 4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 872)               11336     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1746      \n",
      "=================================================================\n",
      "Total params: 13,082\n",
      "Trainable params: 13,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5902 - acc: 0.7226 - val_loss: 0.6594 - val_acc: 0.6480\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5742 - acc: 0.7349 - val_loss: 1.0076 - val_acc: 0.6480\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5702 - acc: 0.7358 - val_loss: 0.6874 - val_acc: 0.6440\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5675 - acc: 0.7383 - val_loss: 0.8472 - val_acc: 0.6480\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5664 - acc: 0.7383 - val_loss: 0.7305 - val_acc: 0.6480\n",
      "250/250 [==============================] - 0s 15us/step\n",
      "raw size 13082.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 13.000000\n",
      "trainable_count 13000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 0 score/normalized score/size/fitness 0.4840000011920929/0.4840000011920929/13082/4.636971670192954\n",
      "raw size 2282.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 2.000000\n",
      "trainable_count 2000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 1 score/normalized score/size/fitness 0.6439999990463257/0.6439999990463257/2282/3.4305150026003624\n",
      "raw size 285818.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 286.000000\n",
      "trainable_count 286000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 2 score/normalized score/size/fitness 0.4960000011920929/0.4960000011920929/285818/5.248183010604057\n",
      "raw size 2282.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 2.000000\n",
      "trainable_count 2000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 3 score/normalized score/size/fitness 0.6439999990463257/0.6439999990463257/2282/3.4305150026003624\n",
      "raw size 13082.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 13.000000\n",
      "trainable_count 13000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 4 score/normalized score/size/fitness 0.6480000023841858/0.6480000023841858/13082/3.8169716642324896\n",
      "\n",
      "Generating offsprings\n",
      "Applying Mutation\n",
      "Launch new generation?: True\n",
      "\n",
      "Generation 5\n",
      "launch new\n",
      "True\n",
      "gen similar\n",
      "False\n",
      "Fetching model 0 to keras\n",
      "Evaluating model 0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 872)               11336     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 872)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1746      \n",
      "=================================================================\n",
      "Total params: 13,082\n",
      "Trainable params: 13,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5919 - acc: 0.7215 - val_loss: 0.7973 - val_acc: 0.6480\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5755 - acc: 0.7342 - val_loss: 0.9585 - val_acc: 0.6480\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5709 - acc: 0.7368 - val_loss: 0.7357 - val_acc: 0.6480\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5690 - acc: 0.7376 - val_loss: 0.9250 - val_acc: 0.6480\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5674 - acc: 0.7380 - val_loss: 1.1385 - val_acc: 0.6480\n",
      "250/250 [==============================] - 0s 14us/step\n",
      "Fetching model 1 to keras\n",
      "Evaluating model 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 152)               1976      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 306       \n",
      "=================================================================\n",
      "Total params: 2,282\n",
      "Trainable params: 2,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5966 - acc: 0.7136 - val_loss: 0.6535 - val_acc: 0.6480\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5810 - acc: 0.7302 - val_loss: 0.6971 - val_acc: 0.5520\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5720 - acc: 0.7341 - val_loss: 0.6757 - val_acc: 0.6440\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5678 - acc: 0.7367 - val_loss: 0.7267 - val_acc: 0.6480\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5655 - acc: 0.7378 - val_loss: 1.0949 - val_acc: 0.6480\n",
      "250/250 [==============================] - 0s 14us/step\n",
      "Fetching model 2 to keras\n",
      "Evaluating model 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 872)               11336     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 328)               286344    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 658       \n",
      "=================================================================\n",
      "Total params: 298,338\n",
      "Trainable params: 298,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5853 - acc: 0.7310 - val_loss: 0.6673 - val_acc: 0.6440\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5718 - acc: 0.7366 - val_loss: 0.9703 - val_acc: 0.3600\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5715 - acc: 0.7358 - val_loss: 1.5597 - val_acc: 0.3520\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5718 - acc: 0.7361 - val_loss: 0.6836 - val_acc: 0.6360\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5662 - acc: 0.7385 - val_loss: 0.7315 - val_acc: 0.4120\n",
      "250/250 [==============================] - 0s 15us/step\n",
      "Fetching model 3 to keras\n",
      "Evaluating model 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 368)               4784      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 368)               135792    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 368)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 738       \n",
      "=================================================================\n",
      "Total params: 141,314\n",
      "Trainable params: 141,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5882 - acc: 0.7275 - val_loss: 0.6588 - val_acc: 0.6480\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5727 - acc: 0.7367 - val_loss: 0.6877 - val_acc: 0.6480\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5693 - acc: 0.7378 - val_loss: 1.1013 - val_acc: 0.6480\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5684 - acc: 0.7381 - val_loss: 1.2860 - val_acc: 0.6480\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5687 - acc: 0.7376 - val_loss: 0.7377 - val_acc: 0.4040\n",
      "250/250 [==============================] - 0s 15us/step\n",
      "Fetching model 4 to keras\n",
      "Evaluating model 4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 872)               11336     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 872)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1746      \n",
      "=================================================================\n",
      "Total params: 13,082\n",
      "Trainable params: 13,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5883 - acc: 0.7248 - val_loss: 1.2298 - val_acc: 0.6480\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5760 - acc: 0.7347 - val_loss: 0.6909 - val_acc: 0.6440\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5692 - acc: 0.7369 - val_loss: 0.7359 - val_acc: 0.6480\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5681 - acc: 0.7378 - val_loss: 0.7121 - val_acc: 0.4160\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5667 - acc: 0.7373 - val_loss: 1.2514 - val_acc: 0.6480\n",
      "250/250 [==============================] - 0s 14us/step\n",
      "raw size 13082.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 13.000000\n",
      "trainable_count 13000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 0 score/normalized score/size/fitness 0.6480000023841858/0.6480000023841858/13082/3.8169716642324896\n",
      "raw size 2282.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 2.000000\n",
      "trainable_count 2000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 1 score/normalized score/size/fitness 0.6480000023841858/0.6480000023841858/2282/3.4105149859110617\n",
      "raw size 298338.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 298.000000\n",
      "trainable_count 298000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 2 score/normalized score/size/fitness 0.4120000002384186/0.4120000002384186/298338/5.677108130846035\n",
      "raw size 141314.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 141.000000\n",
      "trainable_count 141000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 3 score/normalized score/size/fitness 0.4040000002384186/0.4040000002384186/141314/5.554609555135597\n",
      "raw size 13082.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 13.000000\n",
      "trainable_count 13000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 4 score/normalized score/size/fitness 0.6480000023841858/0.6480000023841858/13082/3.8169716642324896\n",
      "\n",
      "Generating offsprings\n",
      "Applying Mutation\n",
      "Launch new generation?: True\n",
      "\n",
      "Generation 6\n",
      "launch new\n",
      "False\n",
      "gen similar\n",
      "True\n",
      "Fetching model 0 to keras\n",
      "Evaluating model 0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 872)               11336     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1746      \n",
      "=================================================================\n",
      "Total params: 13,082\n",
      "Trainable params: 13,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5912 - acc: 0.7218 - val_loss: 0.9561 - val_acc: 0.6480\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5757 - acc: 0.7344 - val_loss: 0.9232 - val_acc: 0.3600\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5703 - acc: 0.7359 - val_loss: 0.6992 - val_acc: 0.6440\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5678 - acc: 0.7380 - val_loss: 0.6766 - val_acc: 0.6360\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5669 - acc: 0.7384 - val_loss: 0.8762 - val_acc: 0.6480\n",
      "250/250 [==============================] - 0s 14us/step\n",
      "Fetching model 1 to keras\n",
      "Evaluating model 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 152)               1976      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 152)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 306       \n",
      "=================================================================\n",
      "Total params: 2,282\n",
      "Trainable params: 2,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5967 - acc: 0.7172 - val_loss: 0.7298 - val_acc: 0.6480\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5808 - acc: 0.7303 - val_loss: 0.6575 - val_acc: 0.6440\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5721 - acc: 0.7352 - val_loss: 0.7203 - val_acc: 0.6480\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5683 - acc: 0.7369 - val_loss: 0.8243 - val_acc: 0.6480\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5662 - acc: 0.7378 - val_loss: 0.7835 - val_acc: 0.6480\n",
      "250/250 [==============================] - 0s 14us/step\n",
      "Fetching model 2 to keras\n",
      "Evaluating model 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 152)               1976      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 152)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 306       \n",
      "=================================================================\n",
      "Total params: 2,282\n",
      "Trainable params: 2,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5962 - acc: 0.7181 - val_loss: 0.6820 - val_acc: 0.6480\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5816 - acc: 0.7308 - val_loss: 0.6790 - val_acc: 0.6240\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5733 - acc: 0.7343 - val_loss: 0.6740 - val_acc: 0.6440\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5692 - acc: 0.7366 - val_loss: 0.8896 - val_acc: 0.6480\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5674 - acc: 0.7376 - val_loss: 0.6996 - val_acc: 0.5160\n",
      "250/250 [==============================] - 0s 16us/step\n",
      "Fetching model 3 to keras\n",
      "Evaluating model 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 192)               2496      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 386       \n",
      "=================================================================\n",
      "Total params: 2,882\n",
      "Trainable params: 2,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5909 - acc: 0.7210 - val_loss: 0.8915 - val_acc: 0.6480\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5756 - acc: 0.7329 - val_loss: 0.6627 - val_acc: 0.6480\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5695 - acc: 0.7362 - val_loss: 0.8686 - val_acc: 0.6480\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5668 - acc: 0.7377 - val_loss: 0.7614 - val_acc: 0.6440\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5653 - acc: 0.7381 - val_loss: 0.8661 - val_acc: 0.6480\n",
      "250/250 [==============================] - 0s 14us/step\n",
      "Fetching model 4 to keras\n",
      "Evaluating model 4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 152)               1976      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 152)               23256     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 152)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 306       \n",
      "=================================================================\n",
      "Total params: 25,538\n",
      "Trainable params: 25,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using previously loaded data\n",
      "training with cv\n",
      "Train on 197128 samples, validate on 250 samples\n",
      "Epoch 1/5\n",
      "197128/197128 [==============================] - 1s 4us/step - loss: 0.5919 - acc: 0.7241 - val_loss: 1.2873 - val_acc: 0.6480\n",
      "Epoch 2/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5744 - acc: 0.7363 - val_loss: 0.7087 - val_acc: 0.6440\n",
      "Epoch 3/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5691 - acc: 0.7378 - val_loss: 0.6917 - val_acc: 0.6280\n",
      "Epoch 4/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5679 - acc: 0.7379 - val_loss: 0.9135 - val_acc: 0.6480\n",
      "Epoch 5/5\n",
      "197128/197128 [==============================] - 1s 3us/step - loss: 0.5671 - acc: 0.7383 - val_loss: 0.6943 - val_acc: 0.5680\n",
      "250/250 [==============================] - 0s 15us/step\n",
      "raw size 13082.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 13.000000\n",
      "trainable_count 13000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 0 score/normalized score/size/fitness 0.6480000023841858/0.6480000023841858/13082/3.8169716642324896\n",
      "raw size 2282.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 2.000000\n",
      "trainable_count 2000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 1 score/normalized score/size/fitness 0.6480000023841858/0.6480000023841858/2282/3.4105149859110617\n",
      "raw size 2282.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 2.000000\n",
      "trainable_count 2000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 2 score/normalized score/size/fitness 0.5160000007152558/0.5160000007152558/2282/4.070514994255712\n",
      "raw size 2882.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 3.000000\n",
      "trainable_count 3000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 3 score/normalized score/size/fitness 0.6480000023841858/0.6480000023841858/2882/3.4985606154389024\n",
      "raw size 25538.000000\n",
      "rounding_scaler 1000.000000\n",
      "round 26.000000\n",
      "trainable_count 26000.000000\n",
      "metric_scaler 0.500000\n",
      "size scaler 0.500000\n",
      "Individual 4 score/normalized score/size/fitness 0.5679999985694886/0.5679999985694886/25538/4.367486681137966\n",
      "\n",
      "Generating offsprings\n",
      "Applying Mutation\n",
      "Launch new generation?: False\n",
      "Experiment 1 finished\n",
      "Experiment time: 1.771688958009084 minutes\n",
      "Global best list\n",
      "\n",
      "\n",
      "\n",
      "String Model\n",
      "[[<Layers.FullyConnected: 1>, 152, 1, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 2, 3, 0, 0, 0, 0, 0]]\n",
      "<Individual(label = '0' fitness = 3.4105, raw_score = 0.6480, normalized_score = 0.6480, raw_size = 2282)>\n",
      "Checksum vector: [  2. 154.   4.   0.   0.   0.   0.   0.]\n",
      "Global best is\n",
      "\n",
      "\n",
      "\n",
      "String Model\n",
      "[[<Layers.FullyConnected: 1>, 152, 1, 0, 0, 0, 0, 0], [<Layers.FullyConnected: 1>, 2, 3, 0, 0, 0, 0, 0]]\n",
      "<Individual(label = '0' fitness = 3.4105, raw_score = 0.6480, normalized_score = 0.6480, raw_size = 2282)>\n",
      "Checksum vector: [  2. 154.   4.   0.   0.   0.   0.   0.]\n",
      "[<nn_evolutionary.Individual object at 0x7f98307447f0>]\n",
      "0\n",
      "Total experiment time 1.771688958009084\n",
      "Avg experiment time 1.771688958009084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 152)               1976      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 306       \n",
      "=================================================================\n",
      "Total params: 2,282\n",
      "Trainable params: 2,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "No data scaling used\n",
      "Loading data for the first time\n",
      "Reloading data due to parameter change\n",
      "Loading data for DAMADICS with window_size of 2, stride of 1. Cros-Validation ratio 0.2\n",
      "Loading data from memory\n",
      "Data Splitting: 0:00:00.000070\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9d27f6121069>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mglobal_best_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_best_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_damadics_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-fe4bc02f6611>\u001b[0m in \u001b[0;36mrun_damadics_test\u001b[0;34m(alphas)\u001b[0m\n\u001b[1;32m     41\u001b[0m                          \u001b[0;34m'/media/controlslab/DATA/Projects/ValveActuator-DAMADICS-/code/best_models/alpha{}/'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_scaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                          \u001b[0mdata_handler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdhandler_damadics_for_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproblem_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproblem_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                          data_scaler=scaler)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mglobal_best_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_best_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-9a9be07bc54b>\u001b[0m in \u001b[0;36msave_best_models\u001b[0;34m(best_models_list, global_best_model_index, saveto, input_shape, data_handler, problem_type, data_scaler, train_epochs, metrics, round)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mtModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_scaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_scaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mtModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_validation_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mtModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mtModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/controlslab/DATA/Projects/ann_framework/tunable_model/tunable_model.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self, unroll, cross_validation_ratio, verbose, reload_data, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_unroll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munroll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \t\t\t\tself._data_handler.load_data(unroll=self._data_unroll, verbose=verbose,\n\u001b[0;32m--> 535\u001b[0;31m \t\t\t\t\t\t\t\t\t\t\t cross_validation_ratio=self._cross_validation_ratio, **kwargs)\n\u001b[0m\u001b[1;32m    536\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m                                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Using previously loaded data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/controlslab/DATA/Projects/ann_framework/data_handlers/data_handler_DAMADICS.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self, unroll, cross_validation_ratio, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcross_validation_ratio\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m                         \u001b[0mtrain_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_validation_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/controlslab/DATA/Projects/ann_framework/data_handlers/data_handler_DAMADICS.py\u001b[0m in \u001b[0;36msplit_samples\u001b[0;34m(self, indices, split_ratio, num_samples)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;31m#print(indices_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                 \u001b[0msamples_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                 \u001b[0msamples_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/controlslab/DATA/Projects/ann_framework/data_handlers/data_handler_DAMADICS.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;31m#print(indices_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                 \u001b[0msamples_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                 \u001b[0msamples_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#alphas = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "alphas = [0.7]\n",
    "\n",
    "global_best_list, global_best_index = run_damadics_test(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in global_best_list:\n",
    "    \n",
    "    print(ind)\n",
    "\n",
    "print(global_best_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
