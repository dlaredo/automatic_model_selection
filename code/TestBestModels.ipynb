{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Best Models\n",
    "\n",
    "Test notebook to generate the statistics of the different models found with AMS. First load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import stats\n",
    "\n",
    "#sys.path.append('/Users/davidlaredorazo/Documents/University_of_California/Research/Projects')\n",
    "sys.path.append('/media/controlslab/DATA/Projects')\n",
    "\n",
    "import ann_framework.aux_functions as aux_functions\n",
    "\n",
    "import automatic_model_selection\n",
    "from automatic_model_selection import Configuration\n",
    "from ann_encoding_rules import Layers\n",
    "import fetch_to_keras\n",
    "#from CMAPSAuxFunctions import TrainValTensorBoard\n",
    "\n",
    "#Tunable model\n",
    "from ann_framework.tunable_model.tunable_model import SequenceTunableModelRegression, SequenceTunableModelClassification\n",
    "\n",
    "#Data handlers\n",
    "from ann_framework.data_handlers.data_handler_CMAPSS import CMAPSSDataHandler\n",
    "from ann_framework.data_handlers.data_handler_MNIST import MNISTDataHandler\n",
    "from ann_framework.data_handlers.data_handler_CIFAR10 import CIFAR10DataHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given a model, get the compiled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model(model, problem_type, optimizer_params=[]):\n",
    "    \"\"\"Obtain a keras compiled model\"\"\"\n",
    "    \n",
    "    #Shared parameters for the models\n",
    "    optimizer = Adam(lr=0.001, beta_1=0.5)\n",
    "    \n",
    "    if problem_type == 1:\n",
    "        lossFunction = \"mean_squared_error\"\n",
    "        metrics = [\"mse\"]\n",
    "    elif problem_type == 2:\n",
    "        lossFunction = \"categorical_crossentropy\"\n",
    "        metrics = [\"accuracy\"]\n",
    "    else:\n",
    "        print(\"Problem type not defined\")\n",
    "        model = None\n",
    "        return\n",
    "    \n",
    "    #Create and compile the models\n",
    "    model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_tunable_model(model_genotype, problem_type, input_shape, data_handler, model_number):\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    model = fetch_to_keras.decode_genotype(model_genotype, problem_type, input_shape, 1)\n",
    "    \n",
    "    model = get_compiled_model(model, problem_type, optimizer_params=[])\n",
    "    \n",
    "    if problem_type == 1:\n",
    "        tModel = SequenceTunableModelRegression('ModelReg_SN_'+str(model_number), model, lib_type='keras', data_handler=data_handler)\n",
    "    else:\n",
    "        tModel = SequenceTunableModelClassification('ModelClass_SN_'+str(model_number), model, lib_type='keras', data_handler=data_handler)\n",
    "        \n",
    "    return tModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cmaps data handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmaps_dhandler(data_scaler=None):\n",
    "\n",
    "    #Selected as per CNN paper\n",
    "    features = ['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', 'BPR', \n",
    "    'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "    selected_indices = np.array([2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21])\n",
    "    selected_features = list(features[i] for i in selected_indices-1)\n",
    "    data_folder = '../CMAPSSData'\n",
    "\n",
    "    window_size = 25\n",
    "    window_stride = 1\n",
    "    max_rul = 130\n",
    "\n",
    "    dHandler_cmaps = CMAPSSDataHandler(data_folder, 1, selected_features,\n",
    "                                       max_rul, window_size, window_stride, data_scaler=data_scaler)\n",
    "\n",
    "    input_shape = (len(selected_features)*window_size, )\n",
    "\n",
    "    return dHandler_cmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_file, weights_file=\"\", problem_type=1):\n",
    "    \n",
    "    p_type = \"\"\n",
    "    \n",
    "    # load json and create model\n",
    "    json_file = open(model_file, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    print(\"Loaded model from disk\") \n",
    "        \n",
    "    #Load weights if specified\n",
    "    if weights_file != \"\":\n",
    "        # load weights into new model\n",
    "        loaded_model.load_weights(weights_file)\n",
    "        print(\"Loaded weights from disk\") \n",
    "    else:\n",
    "        print(\"Model needs training\")\n",
    "        \n",
    "    optimizer = Adam(lr=0.001, beta_1=0.5)\n",
    "    \n",
    "    if problem_type == 1:\n",
    "        p_type = \"regression\"\n",
    "        lossFunction = \"mean_squared_error\"\n",
    "        metrics = [\"mse\"]\n",
    "    elif problem_type == 2:\n",
    "        p_type = \"classification\"\n",
    "        lossFunction = \"categorical_crossentropy\"\n",
    "        metrics = [\"accuracy\"]\n",
    "    else:\n",
    "        print(\"Problem type not defined\")\n",
    "        model = None\n",
    "        return\n",
    "    \n",
    "    #Create and compile the models\n",
    "    loaded_model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    print(\"Created model for \" + p_type + \" with loss function \" + lossFunction)\n",
    "\n",
    "    return loaded_model\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load each of the models and test them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_folder = 'best_models'\n",
    "test_sets = {'cifar10':(CIFAR10DataHandler, None, 2), \n",
    "             'cmapss':(cmaps_dhandler, MinMaxScaler(feature_range=(-1, 1)), 1), \n",
    "             'mnist':((MNISTDataHandler), None, 2)}\n",
    "alpha_folders = ['alpha0.6', 'alpha0.8', 'alpha1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data. Cros-Validation ratio 0\n",
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(50000, 3072)\n",
      "(50000, 10)\n",
      "Testing data (X, y)\n",
      "(10000, 3072)\n",
      "(10000, 10)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[0.23137255 0.24313726 0.24705882 ... 0.48235294 0.36078432 0.28235295]\n",
      " [0.6039216  0.69411767 0.73333335 ... 0.56078434 0.52156866 0.5647059 ]\n",
      " [1.         1.         1.         ... 0.3137255  0.3372549  0.32941177]\n",
      " [0.10980392 0.09803922 0.03921569 ... 0.28235295 0.25490198 0.18039216]\n",
      " [0.6666667  0.7058824  0.7764706  ... 0.28627452 0.3019608  0.3137255 ]]\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Testing data (X, y)\n",
      "[[0.61960787 0.4392157  0.19215687 ... 0.08235294 0.2627451  0.43137255]\n",
      " [0.92156863 0.92156863 0.92156863 ... 0.7294118  0.78431374 0.78039217]\n",
      " [0.61960787 0.74509805 0.87058824 ... 0.02745098 0.03137255 0.02745098]\n",
      " [0.60784316 0.6117647  0.58431375 ... 0.28627452 0.26666668 0.19607843]\n",
      " [0.25490198 0.26666668 0.19607843 ... 0.5019608  0.6117647  0.45882353]]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "Validation on model:best_models/cifar10/alpha0.6/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 104)               319592    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1050      \n",
      "=================================================================\n",
      "Total params: 320,642\n",
      "Trainable params: 320,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "25000/25000 [==============================] - 1s 32us/step - loss: 2.0793 - acc: 0.2549\n",
      "Epoch 2/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.8983 - acc: 0.3316\n",
      "Epoch 3/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.8298 - acc: 0.3611\n",
      "Epoch 4/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7934 - acc: 0.3698\n",
      "Epoch 5/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7644 - acc: 0.3819\n",
      "Epoch 6/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7353 - acc: 0.3915\n",
      "Epoch 7/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7130 - acc: 0.4022\n",
      "Epoch 8/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6878 - acc: 0.4125\n",
      "Epoch 9/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6716 - acc: 0.4182\n",
      "Epoch 10/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6590 - acc: 0.4176\n",
      "Epoch 11/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6420 - acc: 0.4253\n",
      "Epoch 12/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6245 - acc: 0.4336\n",
      "Epoch 13/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6131 - acc: 0.4388\n",
      "Epoch 14/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6006 - acc: 0.4418\n",
      "Epoch 15/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5907 - acc: 0.4455\n",
      "Epoch 16/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5672 - acc: 0.4544\n",
      "Epoch 17/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5603 - acc: 0.4560\n",
      "Epoch 18/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5485 - acc: 0.4586\n",
      "Epoch 19/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5372 - acc: 0.4654\n",
      "Epoch 20/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5293 - acc: 0.4664\n",
      "Epoch 21/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5197 - acc: 0.4728\n",
      "Epoch 22/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5059 - acc: 0.4753\n",
      "Epoch 23/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4960 - acc: 0.4791\n",
      "Epoch 24/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4854 - acc: 0.4819\n",
      "Epoch 25/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4775 - acc: 0.4833\n",
      "Epoch 26/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4799 - acc: 0.4833\n",
      "Epoch 27/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4732 - acc: 0.4859\n",
      "Epoch 28/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4580 - acc: 0.4936\n",
      "Epoch 29/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4500 - acc: 0.4941\n",
      "Epoch 30/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4401 - acc: 0.4983\n",
      "Epoch 31/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4350 - acc: 0.5031\n",
      "Epoch 32/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4269 - acc: 0.5069\n",
      "Epoch 33/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4194 - acc: 0.5083\n",
      "Epoch 34/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4069 - acc: 0.5106\n",
      "Epoch 35/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4049 - acc: 0.5108\n",
      "Epoch 36/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3933 - acc: 0.5151\n",
      "Epoch 37/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3798 - acc: 0.5242\n",
      "Epoch 38/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3816 - acc: 0.5215\n",
      "Epoch 39/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3702 - acc: 0.5223\n",
      "Epoch 40/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3690 - acc: 0.5254\n",
      "Epoch 41/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3583 - acc: 0.5298\n",
      "Epoch 42/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3560 - acc: 0.5286\n",
      "Epoch 43/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3497 - acc: 0.5322\n",
      "Epoch 44/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3424 - acc: 0.5358\n",
      "Epoch 45/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3335 - acc: 0.5388\n",
      "Epoch 46/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3291 - acc: 0.5394\n",
      "Epoch 47/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3171 - acc: 0.5438\n",
      "Epoch 48/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3220 - acc: 0.5389\n",
      "Epoch 49/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3108 - acc: 0.5454\n",
      "Epoch 50/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3028 - acc: 0.5472\n",
      "Epoch 51/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2877 - acc: 0.5556\n",
      "Epoch 52/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2929 - acc: 0.5530\n",
      "Epoch 53/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2851 - acc: 0.5537\n",
      "Epoch 54/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2940 - acc: 0.5473\n",
      "Epoch 55/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2759 - acc: 0.5595\n",
      "Epoch 56/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2787 - acc: 0.5562\n",
      "Epoch 57/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2611 - acc: 0.5626\n",
      "Epoch 58/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2569 - acc: 0.5683\n",
      "Epoch 59/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2532 - acc: 0.5676\n",
      "Epoch 60/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2518 - acc: 0.5661\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2409 - acc: 0.5748\n",
      "Epoch 62/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2366 - acc: 0.5744\n",
      "Epoch 63/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2325 - acc: 0.5764\n",
      "Epoch 64/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2255 - acc: 0.5781\n",
      "Epoch 65/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2170 - acc: 0.5787\n",
      "Epoch 66/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2214 - acc: 0.5777\n",
      "Epoch 67/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2167 - acc: 0.5789\n",
      "Epoch 68/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1983 - acc: 0.5885\n",
      "Epoch 69/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1971 - acc: 0.5897\n",
      "Epoch 70/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2004 - acc: 0.5862\n",
      "Epoch 71/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1898 - acc: 0.5891\n",
      "Epoch 72/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1915 - acc: 0.5902\n",
      "Epoch 73/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1837 - acc: 0.5924\n",
      "Epoch 74/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1729 - acc: 0.5973\n",
      "Epoch 75/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1725 - acc: 0.5972\n",
      "Epoch 76/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1672 - acc: 0.5995\n",
      "Epoch 77/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1624 - acc: 0.5988\n",
      "Epoch 78/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1650 - acc: 0.5999\n",
      "Epoch 79/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1518 - acc: 0.6044\n",
      "Epoch 80/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1464 - acc: 0.6075\n",
      "Epoch 81/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1394 - acc: 0.6088\n",
      "Epoch 82/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1410 - acc: 0.6070\n",
      "Epoch 83/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1404 - acc: 0.6094\n",
      "Epoch 84/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1379 - acc: 0.6073\n",
      "Epoch 85/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1314 - acc: 0.6107\n",
      "Epoch 86/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1153 - acc: 0.6196\n",
      "Epoch 87/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1163 - acc: 0.6178\n",
      "Epoch 88/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1213 - acc: 0.6149\n",
      "Epoch 89/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1174 - acc: 0.6158\n",
      "Epoch 90/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1236 - acc: 0.6126\n",
      "Epoch 91/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1103 - acc: 0.6198\n",
      "Epoch 92/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1001 - acc: 0.6222\n",
      "Epoch 93/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0966 - acc: 0.6254\n",
      "Epoch 94/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0931 - acc: 0.6264\n",
      "Epoch 95/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0912 - acc: 0.6258\n",
      "Epoch 96/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0823 - acc: 0.6278\n",
      "Epoch 97/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0926 - acc: 0.6249\n",
      "Epoch 98/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0745 - acc: 0.6330\n",
      "Epoch 99/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0635 - acc: 0.6369\n",
      "Epoch 100/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0595 - acc: 0.6402\n",
      "25000/25000 [==============================] - 0s 16us/step\n",
      "10000/10000 [==============================] - 0s 15us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 104)               319592    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1050      \n",
      "=================================================================\n",
      "Total params: 320,642\n",
      "Trainable params: 320,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "25000/25000 [==============================] - 0s 12us/step - loss: 2.0771 - acc: 0.2492\n",
      "Epoch 2/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.9052 - acc: 0.3281\n",
      "Epoch 3/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.8470 - acc: 0.3483\n",
      "Epoch 4/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.8005 - acc: 0.3666\n",
      "Epoch 5/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7669 - acc: 0.3826\n",
      "Epoch 6/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7549 - acc: 0.3838\n",
      "Epoch 7/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7228 - acc: 0.3973\n",
      "Epoch 8/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7090 - acc: 0.4034\n",
      "Epoch 9/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6896 - acc: 0.4091\n",
      "Epoch 10/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6754 - acc: 0.4148\n",
      "Epoch 11/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6595 - acc: 0.4218\n",
      "Epoch 12/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6478 - acc: 0.4272\n",
      "Epoch 13/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6296 - acc: 0.4328\n",
      "Epoch 14/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6184 - acc: 0.4320\n",
      "Epoch 15/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6011 - acc: 0.4434\n",
      "Epoch 16/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5934 - acc: 0.4421\n",
      "Epoch 17/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5844 - acc: 0.4492\n",
      "Epoch 18/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5734 - acc: 0.4554\n",
      "Epoch 19/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5641 - acc: 0.4546\n",
      "Epoch 20/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5547 - acc: 0.4583\n",
      "Epoch 21/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5454 - acc: 0.4569\n",
      "Epoch 22/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5326 - acc: 0.4637\n",
      "Epoch 23/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5243 - acc: 0.4688\n",
      "Epoch 24/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5180 - acc: 0.4658\n",
      "Epoch 25/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5081 - acc: 0.4766\n",
      "Epoch 26/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5023 - acc: 0.4756\n",
      "Epoch 27/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4920 - acc: 0.4792\n",
      "Epoch 28/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4873 - acc: 0.4811\n",
      "Epoch 29/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4732 - acc: 0.4870\n",
      "Epoch 30/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4661 - acc: 0.4894\n",
      "Epoch 31/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4568 - acc: 0.4946\n",
      "Epoch 32/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4506 - acc: 0.4947\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4463 - acc: 0.4966\n",
      "Epoch 34/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4368 - acc: 0.4980\n",
      "Epoch 35/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4298 - acc: 0.5024\n",
      "Epoch 36/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4274 - acc: 0.5034\n",
      "Epoch 37/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4234 - acc: 0.5021\n",
      "Epoch 38/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4182 - acc: 0.5076\n",
      "Epoch 39/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4086 - acc: 0.5109\n",
      "Epoch 40/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3949 - acc: 0.5150\n",
      "Epoch 41/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3907 - acc: 0.5151\n",
      "Epoch 42/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3886 - acc: 0.5164\n",
      "Epoch 43/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3780 - acc: 0.5206\n",
      "Epoch 44/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3675 - acc: 0.5250\n",
      "Epoch 45/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3601 - acc: 0.5293\n",
      "Epoch 46/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3509 - acc: 0.5288\n",
      "Epoch 47/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3584 - acc: 0.5280\n",
      "Epoch 48/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3515 - acc: 0.5257\n",
      "Epoch 49/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3434 - acc: 0.5342\n",
      "Epoch 50/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3346 - acc: 0.5343\n",
      "Epoch 51/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3279 - acc: 0.5369\n",
      "Epoch 52/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3314 - acc: 0.5364\n",
      "Epoch 53/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3155 - acc: 0.5430\n",
      "Epoch 54/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3125 - acc: 0.5431\n",
      "Epoch 55/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3105 - acc: 0.5452\n",
      "Epoch 56/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2960 - acc: 0.5497\n",
      "Epoch 57/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2971 - acc: 0.5504\n",
      "Epoch 58/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2875 - acc: 0.5545\n",
      "Epoch 59/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2946 - acc: 0.5494\n",
      "Epoch 60/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2810 - acc: 0.5547\n",
      "Epoch 61/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2758 - acc: 0.5578\n",
      "Epoch 62/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2726 - acc: 0.5605\n",
      "Epoch 63/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2598 - acc: 0.5652\n",
      "Epoch 64/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2662 - acc: 0.5596\n",
      "Epoch 65/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2555 - acc: 0.5646\n",
      "Epoch 66/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2459 - acc: 0.5682\n",
      "Epoch 67/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2408 - acc: 0.5705\n",
      "Epoch 68/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2391 - acc: 0.5737\n",
      "Epoch 69/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2307 - acc: 0.5734\n",
      "Epoch 70/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2328 - acc: 0.5686\n",
      "Epoch 71/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2229 - acc: 0.5760\n",
      "Epoch 72/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2210 - acc: 0.5776\n",
      "Epoch 73/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2136 - acc: 0.5774\n",
      "Epoch 74/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2093 - acc: 0.5802\n",
      "Epoch 75/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2060 - acc: 0.5821\n",
      "Epoch 76/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1983 - acc: 0.5854\n",
      "Epoch 77/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1937 - acc: 0.5850\n",
      "Epoch 78/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1967 - acc: 0.5871\n",
      "Epoch 79/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1914 - acc: 0.5848\n",
      "Epoch 80/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1855 - acc: 0.5894\n",
      "Epoch 81/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1826 - acc: 0.5922\n",
      "Epoch 82/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1692 - acc: 0.5953\n",
      "Epoch 83/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1742 - acc: 0.5928\n",
      "Epoch 84/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1732 - acc: 0.5935\n",
      "Epoch 85/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1640 - acc: 0.5987\n",
      "Epoch 86/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1535 - acc: 0.6035\n",
      "Epoch 87/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1496 - acc: 0.6053\n",
      "Epoch 88/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1499 - acc: 0.6014\n",
      "Epoch 89/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1479 - acc: 0.6051\n",
      "Epoch 90/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1383 - acc: 0.6071\n",
      "Epoch 91/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1440 - acc: 0.6045\n",
      "Epoch 92/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1368 - acc: 0.6058\n",
      "Epoch 93/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1300 - acc: 0.6102\n",
      "Epoch 94/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1255 - acc: 0.6102\n",
      "Epoch 95/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1300 - acc: 0.6116\n",
      "Epoch 96/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1158 - acc: 0.6148\n",
      "Epoch 97/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1086 - acc: 0.6193\n",
      "Epoch 98/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1004 - acc: 0.6213\n",
      "Epoch 99/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.1001 - acc: 0.6214\n",
      "Epoch 100/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.0979 - acc: 0.6219\n",
      "25000/25000 [==============================] - 0s 16us/step\n",
      "10000/10000 [==============================] - 0s 15us/step\n",
      "Loading data. Cros-Validation ratio 0\n",
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(50000, 3072)\n",
      "(50000, 10)\n",
      "Testing data (X, y)\n",
      "(10000, 3072)\n",
      "(10000, 10)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[0.23137255 0.24313726 0.24705882 ... 0.48235294 0.36078432 0.28235295]\n",
      " [0.6039216  0.69411767 0.73333335 ... 0.56078434 0.52156866 0.5647059 ]\n",
      " [1.         1.         1.         ... 0.3137255  0.3372549  0.32941177]\n",
      " [0.10980392 0.09803922 0.03921569 ... 0.28235295 0.25490198 0.18039216]\n",
      " [0.6666667  0.7058824  0.7764706  ... 0.28627452 0.3019608  0.3137255 ]]\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Testing data (X, y)\n",
      "[[0.61960787 0.4392157  0.19215687 ... 0.08235294 0.2627451  0.43137255]\n",
      " [0.92156863 0.92156863 0.92156863 ... 0.7294118  0.78431374 0.78039217]\n",
      " [0.61960787 0.74509805 0.87058824 ... 0.02745098 0.03137255 0.02745098]\n",
      " [0.60784316 0.6117647  0.58431375 ... 0.28627452 0.26666668 0.19607843]\n",
      " [0.25490198 0.26666668 0.19607843 ... 0.5019608  0.6117647  0.45882353]]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "Validation on model:best_models/cifar10/alpha0.8/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 56)                172088    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                570       \n",
      "=================================================================\n",
      "Total params: 172,658\n",
      "Trainable params: 172,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "25000/25000 [==============================] - 0s 11us/step - loss: 2.1092 - acc: 0.2368\n",
      "Epoch 2/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.9345 - acc: 0.3241\n",
      "Epoch 3/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.8678 - acc: 0.3496\n",
      "Epoch 4/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.8298 - acc: 0.3634\n",
      "Epoch 5/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7976 - acc: 0.3740\n",
      "Epoch 6/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7751 - acc: 0.3852\n",
      "Epoch 7/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7561 - acc: 0.3880\n",
      "Epoch 8/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7365 - acc: 0.3978\n",
      "Epoch 9/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7257 - acc: 0.3981\n",
      "Epoch 10/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.7055 - acc: 0.4064\n",
      "Epoch 11/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6934 - acc: 0.4091\n",
      "Epoch 12/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6801 - acc: 0.4154\n",
      "Epoch 13/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6678 - acc: 0.4198\n",
      "Epoch 14/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6564 - acc: 0.4258\n",
      "Epoch 15/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6454 - acc: 0.4263\n",
      "Epoch 16/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6336 - acc: 0.4331\n",
      "Epoch 17/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6262 - acc: 0.4352\n",
      "Epoch 18/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6166 - acc: 0.4384\n",
      "Epoch 19/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.6017 - acc: 0.4424\n",
      "Epoch 20/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5919 - acc: 0.4470\n",
      "Epoch 21/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5849 - acc: 0.4454\n",
      "Epoch 22/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5742 - acc: 0.4516\n",
      "Epoch 23/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5694 - acc: 0.4528\n",
      "Epoch 24/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5575 - acc: 0.4607\n",
      "Epoch 25/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5493 - acc: 0.4594\n",
      "Epoch 26/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5459 - acc: 0.4596\n",
      "Epoch 27/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5323 - acc: 0.4661\n",
      "Epoch 28/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5227 - acc: 0.4716\n",
      "Epoch 29/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5186 - acc: 0.4714\n",
      "Epoch 30/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5056 - acc: 0.4730\n",
      "Epoch 31/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5019 - acc: 0.4757\n",
      "Epoch 32/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4927 - acc: 0.4800\n",
      "Epoch 33/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4914 - acc: 0.4812\n",
      "Epoch 34/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4794 - acc: 0.4822\n",
      "Epoch 35/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4766 - acc: 0.4828\n",
      "Epoch 36/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4754 - acc: 0.4850\n",
      "Epoch 37/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4594 - acc: 0.4899\n",
      "Epoch 38/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4553 - acc: 0.4903\n",
      "Epoch 39/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4491 - acc: 0.4926\n",
      "Epoch 40/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4429 - acc: 0.4976\n",
      "Epoch 41/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4411 - acc: 0.4956\n",
      "Epoch 42/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4391 - acc: 0.4983\n",
      "Epoch 43/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4274 - acc: 0.5016\n",
      "Epoch 44/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4245 - acc: 0.5038\n",
      "Epoch 45/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4177 - acc: 0.5027\n",
      "Epoch 46/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4110 - acc: 0.5069\n",
      "Epoch 47/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4027 - acc: 0.5120\n",
      "Epoch 48/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4029 - acc: 0.5116\n",
      "Epoch 49/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3998 - acc: 0.5118\n",
      "Epoch 50/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3952 - acc: 0.5144\n",
      "Epoch 51/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3920 - acc: 0.5151\n",
      "Epoch 52/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3792 - acc: 0.5194\n",
      "Epoch 53/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3825 - acc: 0.5192\n",
      "Epoch 54/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3787 - acc: 0.5192\n",
      "Epoch 55/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3718 - acc: 0.5225\n",
      "Epoch 56/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3635 - acc: 0.5262\n",
      "Epoch 57/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3610 - acc: 0.5259\n",
      "Epoch 58/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3601 - acc: 0.5277\n",
      "Epoch 59/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3572 - acc: 0.5248\n",
      "Epoch 60/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3501 - acc: 0.5304\n",
      "Epoch 61/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3524 - acc: 0.5266\n",
      "Epoch 62/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3400 - acc: 0.5314\n",
      "Epoch 63/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3353 - acc: 0.5354\n",
      "Epoch 64/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3306 - acc: 0.5379\n",
      "Epoch 65/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3274 - acc: 0.5381\n",
      "Epoch 66/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3276 - acc: 0.5379\n",
      "Epoch 67/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3185 - acc: 0.5415\n",
      "Epoch 68/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3189 - acc: 0.5407\n",
      "Epoch 69/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3144 - acc: 0.5427\n",
      "Epoch 70/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3089 - acc: 0.5435\n",
      "Epoch 71/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3039 - acc: 0.5457\n",
      "Epoch 72/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3055 - acc: 0.5466\n",
      "Epoch 73/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2974 - acc: 0.5487\n",
      "Epoch 74/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2951 - acc: 0.5511\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2914 - acc: 0.5518\n",
      "Epoch 76/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2934 - acc: 0.5499\n",
      "Epoch 77/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2887 - acc: 0.5526\n",
      "Epoch 78/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2807 - acc: 0.5550\n",
      "Epoch 79/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2772 - acc: 0.5590\n",
      "Epoch 80/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2719 - acc: 0.5578\n",
      "Epoch 81/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2729 - acc: 0.5575\n",
      "Epoch 82/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2692 - acc: 0.5579\n",
      "Epoch 83/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2718 - acc: 0.5570\n",
      "Epoch 84/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2696 - acc: 0.5590\n",
      "Epoch 85/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2581 - acc: 0.5646\n",
      "Epoch 86/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2560 - acc: 0.5656\n",
      "Epoch 87/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2471 - acc: 0.5697\n",
      "Epoch 88/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2495 - acc: 0.5673\n",
      "Epoch 89/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2468 - acc: 0.5686\n",
      "Epoch 90/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2436 - acc: 0.5702\n",
      "Epoch 91/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2474 - acc: 0.5674\n",
      "Epoch 92/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2412 - acc: 0.5688\n",
      "Epoch 93/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2366 - acc: 0.5737\n",
      "Epoch 94/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2365 - acc: 0.5711\n",
      "Epoch 95/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2330 - acc: 0.5728\n",
      "Epoch 96/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2270 - acc: 0.5762\n",
      "Epoch 97/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2245 - acc: 0.5759\n",
      "Epoch 98/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2146 - acc: 0.5829\n",
      "Epoch 99/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2232 - acc: 0.5760\n",
      "Epoch 100/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2171 - acc: 0.5803\n",
      "25000/25000 [==============================] - 0s 16us/step\n",
      "10000/10000 [==============================] - 0s 15us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 56)                172088    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                570       \n",
      "=================================================================\n",
      "Total params: 172,658\n",
      "Trainable params: 172,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "25000/25000 [==============================] - 0s 11us/step - loss: 2.1051 - acc: 0.2491\n",
      "Epoch 2/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.9328 - acc: 0.3231\n",
      "Epoch 3/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.8708 - acc: 0.3454\n",
      "Epoch 4/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.8278 - acc: 0.3579\n",
      "Epoch 5/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.8003 - acc: 0.3666\n",
      "Epoch 6/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.7765 - acc: 0.3745\n",
      "Epoch 7/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.7528 - acc: 0.3848\n",
      "Epoch 8/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.7337 - acc: 0.3929\n",
      "Epoch 9/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.7182 - acc: 0.3963\n",
      "Epoch 10/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.7008 - acc: 0.4035\n",
      "Epoch 11/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.6869 - acc: 0.4086\n",
      "Epoch 12/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.6728 - acc: 0.4120\n",
      "Epoch 13/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.6604 - acc: 0.4172\n",
      "Epoch 14/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.6444 - acc: 0.4240\n",
      "Epoch 15/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.6379 - acc: 0.4248\n",
      "Epoch 16/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.6230 - acc: 0.4318\n",
      "Epoch 17/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.6154 - acc: 0.4380\n",
      "Epoch 18/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.6049 - acc: 0.4363\n",
      "Epoch 19/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5889 - acc: 0.4433\n",
      "Epoch 20/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5831 - acc: 0.4472\n",
      "Epoch 21/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5724 - acc: 0.4514\n",
      "Epoch 22/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5652 - acc: 0.4536\n",
      "Epoch 23/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5573 - acc: 0.4569\n",
      "Epoch 24/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.5513 - acc: 0.4580\n",
      "Epoch 25/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.5398 - acc: 0.4588\n",
      "Epoch 26/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5315 - acc: 0.4640\n",
      "Epoch 27/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5269 - acc: 0.4660\n",
      "Epoch 28/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.5185 - acc: 0.4719\n",
      "Epoch 29/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5099 - acc: 0.4724\n",
      "Epoch 30/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.5026 - acc: 0.4751\n",
      "Epoch 31/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4960 - acc: 0.4758\n",
      "Epoch 32/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4920 - acc: 0.4772\n",
      "Epoch 33/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.4836 - acc: 0.4800\n",
      "Epoch 34/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4790 - acc: 0.4834\n",
      "Epoch 35/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4705 - acc: 0.4875\n",
      "Epoch 36/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4707 - acc: 0.4866\n",
      "Epoch 37/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4628 - acc: 0.4905\n",
      "Epoch 38/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4569 - acc: 0.4898\n",
      "Epoch 39/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4510 - acc: 0.4943\n",
      "Epoch 40/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4464 - acc: 0.4931\n",
      "Epoch 41/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4347 - acc: 0.4985\n",
      "Epoch 42/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4375 - acc: 0.4995\n",
      "Epoch 43/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4333 - acc: 0.5004\n",
      "Epoch 44/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.4231 - acc: 0.5066\n",
      "Epoch 45/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4168 - acc: 0.5066\n",
      "Epoch 46/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4130 - acc: 0.5087\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.4096 - acc: 0.5095\n",
      "Epoch 48/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4024 - acc: 0.5118\n",
      "Epoch 49/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3992 - acc: 0.5118\n",
      "Epoch 50/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.3980 - acc: 0.5120\n",
      "Epoch 51/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.4004 - acc: 0.5103\n",
      "Epoch 52/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3859 - acc: 0.5140\n",
      "Epoch 53/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3824 - acc: 0.5188\n",
      "Epoch 54/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3767 - acc: 0.5201\n",
      "Epoch 55/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3742 - acc: 0.5209\n",
      "Epoch 56/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3682 - acc: 0.5240\n",
      "Epoch 57/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3674 - acc: 0.5222\n",
      "Epoch 58/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3670 - acc: 0.5231\n",
      "Epoch 59/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3580 - acc: 0.5265\n",
      "Epoch 60/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3584 - acc: 0.5246\n",
      "Epoch 61/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3540 - acc: 0.5286\n",
      "Epoch 62/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3508 - acc: 0.5301\n",
      "Epoch 63/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3440 - acc: 0.5328\n",
      "Epoch 64/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3390 - acc: 0.5329\n",
      "Epoch 65/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3398 - acc: 0.5331\n",
      "Epoch 66/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3382 - acc: 0.5342\n",
      "Epoch 67/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3285 - acc: 0.5392\n",
      "Epoch 68/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3292 - acc: 0.5387\n",
      "Epoch 69/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3211 - acc: 0.5413\n",
      "Epoch 70/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3210 - acc: 0.5398\n",
      "Epoch 71/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3256 - acc: 0.5378\n",
      "Epoch 72/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3103 - acc: 0.5453\n",
      "Epoch 73/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3109 - acc: 0.5442\n",
      "Epoch 74/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3073 - acc: 0.5403\n",
      "Epoch 75/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.3059 - acc: 0.5444\n",
      "Epoch 76/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.2896 - acc: 0.5480\n",
      "Epoch 77/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.2918 - acc: 0.5506\n",
      "Epoch 78/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.2912 - acc: 0.5516\n",
      "Epoch 79/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.2902 - acc: 0.5506\n",
      "Epoch 80/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.2908 - acc: 0.5500\n",
      "Epoch 81/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2854 - acc: 0.5539\n",
      "Epoch 82/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2783 - acc: 0.5566\n",
      "Epoch 83/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2812 - acc: 0.5557\n",
      "Epoch 84/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2677 - acc: 0.5608\n",
      "Epoch 85/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2749 - acc: 0.5570\n",
      "Epoch 86/100\n",
      "25000/25000 [==============================] - 0s 7us/step - loss: 1.2729 - acc: 0.5566\n",
      "Epoch 87/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.2683 - acc: 0.5558\n",
      "Epoch 88/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.2628 - acc: 0.5615\n",
      "Epoch 89/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.2627 - acc: 0.5612\n",
      "Epoch 90/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.2544 - acc: 0.5622\n",
      "Epoch 91/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.2522 - acc: 0.5651\n",
      "Epoch 92/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.2526 - acc: 0.5602\n",
      "Epoch 93/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.2504 - acc: 0.5658\n",
      "Epoch 94/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.2509 - acc: 0.5652\n",
      "Epoch 95/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.2385 - acc: 0.5700\n",
      "Epoch 96/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.2393 - acc: 0.5689\n",
      "Epoch 97/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.2318 - acc: 0.5728\n",
      "Epoch 98/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.2320 - acc: 0.5733\n",
      "Epoch 99/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.2320 - acc: 0.5748\n",
      "Epoch 100/100\n",
      "25000/25000 [==============================] - 0s 6us/step - loss: 1.2322 - acc: 0.5706\n",
      "25000/25000 [==============================] - 0s 16us/step\n",
      "10000/10000 [==============================] - 0s 15us/step\n",
      "Loading data. Cros-Validation ratio 0\n",
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(50000, 3072)\n",
      "(50000, 10)\n",
      "Testing data (X, y)\n",
      "(10000, 3072)\n",
      "(10000, 10)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[0.23137255 0.24313726 0.24705882 ... 0.48235294 0.36078432 0.28235295]\n",
      " [0.6039216  0.69411767 0.73333335 ... 0.56078434 0.52156866 0.5647059 ]\n",
      " [1.         1.         1.         ... 0.3137255  0.3372549  0.32941177]\n",
      " [0.10980392 0.09803922 0.03921569 ... 0.28235295 0.25490198 0.18039216]\n",
      " [0.6666667  0.7058824  0.7764706  ... 0.28627452 0.3019608  0.3137255 ]]\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Testing data (X, y)\n",
      "[[0.61960787 0.4392157  0.19215687 ... 0.08235294 0.2627451  0.43137255]\n",
      " [0.92156863 0.92156863 0.92156863 ... 0.7294118  0.78431374 0.78039217]\n",
      " [0.61960787 0.74509805 0.87058824 ... 0.02745098 0.03137255 0.02745098]\n",
      " [0.60784316 0.6117647  0.58431375 ... 0.28627452 0.26666668 0.19607843]\n",
      " [0.25490198 0.26666668 0.19607843 ... 0.5019608  0.6117647  0.45882353]]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "Validation on model:best_models/cifar10/alpha1/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 32)                98336     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 744)               24552     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 744)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                7450      \n",
      "=================================================================\n",
      "Total params: 131,394\n",
      "Trainable params: 131,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "25000/25000 [==============================] - 0s 15us/step - loss: 2.1585 - acc: 0.1814\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.9883 - acc: 0.2713\n",
      "Epoch 3/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.8922 - acc: 0.3169\n",
      "Epoch 4/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.8463 - acc: 0.3300\n",
      "Epoch 5/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.8086 - acc: 0.3456\n",
      "Epoch 6/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.7691 - acc: 0.3651\n",
      "Epoch 7/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.7974 - acc: 0.3547\n",
      "Epoch 8/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.7237 - acc: 0.3768\n",
      "Epoch 9/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.7140 - acc: 0.3788\n",
      "Epoch 10/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.7094 - acc: 0.3854\n",
      "Epoch 11/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6816 - acc: 0.3959\n",
      "Epoch 12/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6741 - acc: 0.3960\n",
      "Epoch 13/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6604 - acc: 0.3990\n",
      "Epoch 14/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6526 - acc: 0.4052\n",
      "Epoch 15/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6498 - acc: 0.4046\n",
      "Epoch 16/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6303 - acc: 0.4119\n",
      "Epoch 17/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6303 - acc: 0.4108\n",
      "Epoch 18/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6205 - acc: 0.4143\n",
      "Epoch 19/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6124 - acc: 0.4154\n",
      "Epoch 20/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5932 - acc: 0.4251\n",
      "Epoch 21/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5892 - acc: 0.4252\n",
      "Epoch 22/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5800 - acc: 0.4272\n",
      "Epoch 23/100\n",
      "25000/25000 [==============================] - 0s 9us/step - loss: 1.5597 - acc: 0.4382\n",
      "Epoch 24/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5635 - acc: 0.4352\n",
      "Epoch 25/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5477 - acc: 0.4406\n",
      "Epoch 26/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5384 - acc: 0.4441\n",
      "Epoch 27/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5395 - acc: 0.4452\n",
      "Epoch 28/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5305 - acc: 0.4466\n",
      "Epoch 29/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5112 - acc: 0.4541\n",
      "Epoch 30/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5117 - acc: 0.4572\n",
      "Epoch 31/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4950 - acc: 0.4602\n",
      "Epoch 32/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4924 - acc: 0.4609\n",
      "Epoch 33/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4982 - acc: 0.4607\n",
      "Epoch 34/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4770 - acc: 0.4670\n",
      "Epoch 35/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4781 - acc: 0.4690\n",
      "Epoch 36/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4824 - acc: 0.4631\n",
      "Epoch 37/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4737 - acc: 0.4666\n",
      "Epoch 38/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4849 - acc: 0.4660\n",
      "Epoch 39/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4630 - acc: 0.4768\n",
      "Epoch 40/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4463 - acc: 0.4774\n",
      "Epoch 41/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4359 - acc: 0.4816\n",
      "Epoch 42/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4479 - acc: 0.4809\n",
      "Epoch 43/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4500 - acc: 0.4752\n",
      "Epoch 44/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4396 - acc: 0.4844\n",
      "Epoch 45/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4309 - acc: 0.4865\n",
      "Epoch 46/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4337 - acc: 0.4826\n",
      "Epoch 47/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4269 - acc: 0.4897\n",
      "Epoch 48/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4216 - acc: 0.4920\n",
      "Epoch 49/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4293 - acc: 0.4837\n",
      "Epoch 50/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4126 - acc: 0.4929\n",
      "Epoch 51/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4056 - acc: 0.4971\n",
      "Epoch 52/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4145 - acc: 0.4900\n",
      "Epoch 53/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4028 - acc: 0.4942\n",
      "Epoch 54/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3975 - acc: 0.4948\n",
      "Epoch 55/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3981 - acc: 0.4986\n",
      "Epoch 56/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3887 - acc: 0.5014\n",
      "Epoch 57/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3994 - acc: 0.4983\n",
      "Epoch 58/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3906 - acc: 0.4970\n",
      "Epoch 59/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3850 - acc: 0.5018\n",
      "Epoch 60/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3840 - acc: 0.5024\n",
      "Epoch 61/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3767 - acc: 0.5059\n",
      "Epoch 62/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3723 - acc: 0.5069\n",
      "Epoch 63/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3803 - acc: 0.5052\n",
      "Epoch 64/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3567 - acc: 0.5092\n",
      "Epoch 65/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3644 - acc: 0.5084\n",
      "Epoch 66/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3829 - acc: 0.5019\n",
      "Epoch 67/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3546 - acc: 0.5115\n",
      "Epoch 68/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3638 - acc: 0.5088\n",
      "Epoch 69/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3558 - acc: 0.5118\n",
      "Epoch 70/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3536 - acc: 0.5120\n",
      "Epoch 71/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3472 - acc: 0.5112\n",
      "Epoch 72/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3472 - acc: 0.5169\n",
      "Epoch 73/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3506 - acc: 0.5164\n",
      "Epoch 74/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3417 - acc: 0.5164\n",
      "Epoch 75/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3510 - acc: 0.5166\n",
      "Epoch 76/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3252 - acc: 0.5222\n",
      "Epoch 77/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3433 - acc: 0.5152\n",
      "Epoch 78/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3367 - acc: 0.5152\n",
      "Epoch 79/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3361 - acc: 0.5177\n",
      "Epoch 80/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3257 - acc: 0.5188\n",
      "Epoch 81/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3211 - acc: 0.5241\n",
      "Epoch 82/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3309 - acc: 0.5189\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3202 - acc: 0.5254\n",
      "Epoch 84/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3174 - acc: 0.5256\n",
      "Epoch 85/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3177 - acc: 0.5257\n",
      "Epoch 86/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3116 - acc: 0.5218\n",
      "Epoch 87/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3189 - acc: 0.5230\n",
      "Epoch 88/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3036 - acc: 0.5281\n",
      "Epoch 89/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3216 - acc: 0.5248\n",
      "Epoch 90/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3082 - acc: 0.5284\n",
      "Epoch 91/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3029 - acc: 0.5274\n",
      "Epoch 92/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3040 - acc: 0.5300\n",
      "Epoch 93/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3111 - acc: 0.5263\n",
      "Epoch 94/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.2953 - acc: 0.5316\n",
      "Epoch 95/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.2923 - acc: 0.5332\n",
      "Epoch 96/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.2881 - acc: 0.5352\n",
      "Epoch 97/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.2898 - acc: 0.5329\n",
      "Epoch 98/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.2915 - acc: 0.5325\n",
      "Epoch 99/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.2855 - acc: 0.5382\n",
      "Epoch 100/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.2855 - acc: 0.5332\n",
      "25000/25000 [==============================] - 0s 18us/step\n",
      "10000/10000 [==============================] - 0s 17us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 32)                98336     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 744)               24552     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 744)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                7450      \n",
      "=================================================================\n",
      "Total params: 131,394\n",
      "Trainable params: 131,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "25000/25000 [==============================] - 0s 15us/step - loss: 2.1355 - acc: 0.1950\n",
      "Epoch 2/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.9538 - acc: 0.2837\n",
      "Epoch 3/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.8870 - acc: 0.3135\n",
      "Epoch 4/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.8447 - acc: 0.3280\n",
      "Epoch 5/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.8001 - acc: 0.3456\n",
      "Epoch 6/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.7923 - acc: 0.3529\n",
      "Epoch 7/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.7723 - acc: 0.3621\n",
      "Epoch 8/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.7221 - acc: 0.3802\n",
      "Epoch 9/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.7301 - acc: 0.3752\n",
      "Epoch 10/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6965 - acc: 0.3902\n",
      "Epoch 11/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6817 - acc: 0.3952\n",
      "Epoch 12/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6715 - acc: 0.3938\n",
      "Epoch 13/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6763 - acc: 0.3976\n",
      "Epoch 14/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6461 - acc: 0.4065\n",
      "Epoch 15/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6498 - acc: 0.4081\n",
      "Epoch 16/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6369 - acc: 0.4101\n",
      "Epoch 17/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6430 - acc: 0.4086\n",
      "Epoch 18/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6122 - acc: 0.4202\n",
      "Epoch 19/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6058 - acc: 0.4243\n",
      "Epoch 20/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.6071 - acc: 0.4210\n",
      "Epoch 21/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5914 - acc: 0.4294\n",
      "Epoch 22/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5948 - acc: 0.4262\n",
      "Epoch 23/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5758 - acc: 0.4321\n",
      "Epoch 24/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5770 - acc: 0.4328\n",
      "Epoch 25/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5885 - acc: 0.4274\n",
      "Epoch 26/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5748 - acc: 0.4312\n",
      "Epoch 27/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5557 - acc: 0.4410\n",
      "Epoch 28/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5519 - acc: 0.4400\n",
      "Epoch 29/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5552 - acc: 0.4393\n",
      "Epoch 30/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5381 - acc: 0.4466\n",
      "Epoch 31/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5466 - acc: 0.4451\n",
      "Epoch 32/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5429 - acc: 0.4450\n",
      "Epoch 33/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5395 - acc: 0.4455\n",
      "Epoch 34/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5405 - acc: 0.4462\n",
      "Epoch 35/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5281 - acc: 0.4504\n",
      "Epoch 36/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5201 - acc: 0.4520\n",
      "Epoch 37/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5235 - acc: 0.4500\n",
      "Epoch 38/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5106 - acc: 0.4561\n",
      "Epoch 39/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5095 - acc: 0.4576\n",
      "Epoch 40/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5032 - acc: 0.4599\n",
      "Epoch 41/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5107 - acc: 0.4593\n",
      "Epoch 42/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5045 - acc: 0.4566\n",
      "Epoch 43/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5089 - acc: 0.4588\n",
      "Epoch 44/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4931 - acc: 0.4629\n",
      "Epoch 45/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5042 - acc: 0.4605\n",
      "Epoch 46/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4899 - acc: 0.4651\n",
      "Epoch 47/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.5150 - acc: 0.4606\n",
      "Epoch 48/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4800 - acc: 0.4661\n",
      "Epoch 49/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4879 - acc: 0.4668\n",
      "Epoch 50/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4746 - acc: 0.4702\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4727 - acc: 0.4712\n",
      "Epoch 52/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4645 - acc: 0.4737\n",
      "Epoch 53/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4680 - acc: 0.4738\n",
      "Epoch 54/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4669 - acc: 0.4736\n",
      "Epoch 55/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4583 - acc: 0.4732\n",
      "Epoch 56/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4681 - acc: 0.4730\n",
      "Epoch 57/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4565 - acc: 0.4756\n",
      "Epoch 58/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4713 - acc: 0.4738\n",
      "Epoch 59/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4501 - acc: 0.4798\n",
      "Epoch 60/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4617 - acc: 0.4768\n",
      "Epoch 61/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4463 - acc: 0.4802\n",
      "Epoch 62/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4613 - acc: 0.4770\n",
      "Epoch 63/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4482 - acc: 0.4802\n",
      "Epoch 64/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4374 - acc: 0.4786\n",
      "Epoch 65/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4378 - acc: 0.4808\n",
      "Epoch 66/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4380 - acc: 0.4822\n",
      "Epoch 67/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4403 - acc: 0.4813\n",
      "Epoch 68/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4416 - acc: 0.4791\n",
      "Epoch 69/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4336 - acc: 0.4840\n",
      "Epoch 70/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4365 - acc: 0.4830\n",
      "Epoch 71/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4305 - acc: 0.4852\n",
      "Epoch 72/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4244 - acc: 0.4911\n",
      "Epoch 73/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4108 - acc: 0.4897\n",
      "Epoch 74/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4210 - acc: 0.4890\n",
      "Epoch 75/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4171 - acc: 0.4888\n",
      "Epoch 76/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4203 - acc: 0.4864\n",
      "Epoch 77/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4197 - acc: 0.4884\n",
      "Epoch 78/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4075 - acc: 0.4930\n",
      "Epoch 79/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4130 - acc: 0.4917\n",
      "Epoch 80/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4125 - acc: 0.4934\n",
      "Epoch 81/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4115 - acc: 0.4937\n",
      "Epoch 82/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4019 - acc: 0.4952\n",
      "Epoch 83/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4046 - acc: 0.4943\n",
      "Epoch 84/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4039 - acc: 0.4955\n",
      "Epoch 85/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4006 - acc: 0.4945\n",
      "Epoch 86/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4030 - acc: 0.4958\n",
      "Epoch 87/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4060 - acc: 0.4926\n",
      "Epoch 88/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3956 - acc: 0.4971\n",
      "Epoch 89/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3925 - acc: 0.4954\n",
      "Epoch 90/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.4013 - acc: 0.4972\n",
      "Epoch 91/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3955 - acc: 0.4967\n",
      "Epoch 92/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3906 - acc: 0.5023\n",
      "Epoch 93/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3956 - acc: 0.4973\n",
      "Epoch 94/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3862 - acc: 0.4989\n",
      "Epoch 95/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3903 - acc: 0.4969\n",
      "Epoch 96/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3900 - acc: 0.5009\n",
      "Epoch 97/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3787 - acc: 0.5030\n",
      "Epoch 98/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3836 - acc: 0.4996\n",
      "Epoch 99/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3763 - acc: 0.5064\n",
      "Epoch 100/100\n",
      "25000/25000 [==============================] - 0s 8us/step - loss: 1.3745 - acc: 0.5021\n",
      "25000/25000 [==============================] - 0s 18us/step\n",
      "10000/10000 [==============================] - 0s 16us/step\n",
      "Loading data for dataset 1 with window_size of 25, stride of 1 and maxRUL of 130. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(18231, 350)\n",
      "(18231, 1)\n",
      "Testing data (X, y)\n",
      "(100, 350)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.63253012 -0.18639634 -0.38048616 ... -0.16666667  0.25581395\n",
      "   0.47638774]\n",
      " [-0.43373494 -0.09396119 -0.29473329 ...  0.          0.11627907\n",
      "   0.43800055]\n",
      " [-0.31325301 -0.26095487 -0.25894666 ... -0.16666667  0.31782946\n",
      "   0.52720243]\n",
      " [-0.31325301 -0.48768258 -0.33760972 ... -0.66666667  0.34883721\n",
      "   0.07677437]\n",
      " [-0.30120482 -0.48506649 -0.19074949 ... -0.16666667  0.2248062\n",
      "   0.28555648]]\n",
      "[[130.]\n",
      " [130.]\n",
      " [130.]\n",
      " [130.]\n",
      " [130.]]\n",
      "Testing data (X, y)\n",
      "[[-0.45783133 -0.46370177 -0.23733964 ... -0.16666667  0.03875969\n",
      "   0.27312897]\n",
      " [ 0.27710843 -0.16590364 -0.24206617 ... -0.5         0.03875969\n",
      "   0.01518917]\n",
      " [ 0.31325301 -0.19468062 -0.06684673 ...  0.16666667  0.2248062\n",
      "   0.04888152]\n",
      " [-0.23493976 -0.03291912 -0.08845375 ...  0.16666667 -0.31782946\n",
      "   0.004971  ]\n",
      " [ 0.09638554 -0.09439721  0.14280891 ...  0.         -0.05426357\n",
      "   0.42916321]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n",
      "Validation on model:best_models/cmapss/alpha0.6/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 136)               47736     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 136)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 176)               24112     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 177       \n",
      "=================================================================\n",
      "Total params: 72,025\n",
      "Trainable params: 72,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "9115/9115 [==============================] - 0s 17us/step - loss: 6355.9327 - mean_squared_error: 6355.9327\n",
      "Epoch 2/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 905.8074 - mean_squared_error: 905.8074\n",
      "Epoch 3/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 648.1683 - mean_squared_error: 648.1683\n",
      "Epoch 4/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 567.6689 - mean_squared_error: 567.6689\n",
      "Epoch 5/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 506.1923 - mean_squared_error: 506.1923\n",
      "Epoch 6/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 462.1045 - mean_squared_error: 462.1045\n",
      "Epoch 7/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 428.1480 - mean_squared_error: 428.1480\n",
      "Epoch 8/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 385.9545 - mean_squared_error: 385.9545\n",
      "Epoch 9/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 359.5150 - mean_squared_error: 359.5150\n",
      "Epoch 10/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 344.1098 - mean_squared_error: 344.1098\n",
      "Epoch 11/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 325.7470 - mean_squared_error: 325.7470\n",
      "Epoch 12/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 314.1863 - mean_squared_error: 314.1863\n",
      "Epoch 13/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 305.5489 - mean_squared_error: 305.5489\n",
      "Epoch 14/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 297.8749 - mean_squared_error: 297.8749\n",
      "Epoch 15/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 290.7805 - mean_squared_error: 290.7805\n",
      "Epoch 16/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 280.7024 - mean_squared_error: 280.7024\n",
      "Epoch 17/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 277.7504 - mean_squared_error: 277.7504\n",
      "Epoch 18/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 277.5681 - mean_squared_error: 277.5681\n",
      "Epoch 19/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 272.1241 - mean_squared_error: 272.1241\n",
      "Epoch 20/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 274.2854 - mean_squared_error: 274.2854\n",
      "Epoch 21/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 266.5135 - mean_squared_error: 266.5135\n",
      "Epoch 22/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 264.7659 - mean_squared_error: 264.7659\n",
      "Epoch 23/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 266.4687 - mean_squared_error: 266.4687\n",
      "Epoch 24/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 261.7983 - mean_squared_error: 261.7983\n",
      "Epoch 25/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 257.0147 - mean_squared_error: 257.0147\n",
      "Epoch 26/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 257.0197 - mean_squared_error: 257.0197\n",
      "Epoch 27/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 256.6116 - mean_squared_error: 256.6116\n",
      "Epoch 28/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 255.3063 - mean_squared_error: 255.3063\n",
      "Epoch 29/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 259.1038 - mean_squared_error: 259.1038\n",
      "Epoch 30/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 257.5680 - mean_squared_error: 257.5680\n",
      "Epoch 31/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 253.7267 - mean_squared_error: 253.7267\n",
      "Epoch 32/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 247.5619 - mean_squared_error: 247.5619\n",
      "Epoch 33/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 245.2972 - mean_squared_error: 245.2972\n",
      "Epoch 34/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 248.4109 - mean_squared_error: 248.4109\n",
      "Epoch 35/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 245.8980 - mean_squared_error: 245.8980\n",
      "Epoch 36/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 242.2741 - mean_squared_error: 242.2741\n",
      "Epoch 37/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 246.1299 - mean_squared_error: 246.1299\n",
      "Epoch 38/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 242.3692 - mean_squared_error: 242.3692\n",
      "Epoch 39/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 240.7270 - mean_squared_error: 240.7270\n",
      "Epoch 40/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 239.1733 - mean_squared_error: 239.1733\n",
      "Epoch 41/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 244.0944 - mean_squared_error: 244.0944\n",
      "Epoch 42/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 241.5376 - mean_squared_error: 241.5376\n",
      "Epoch 43/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 240.8070 - mean_squared_error: 240.8070\n",
      "Epoch 44/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 242.6002 - mean_squared_error: 242.6002\n",
      "Epoch 45/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 238.9362 - mean_squared_error: 238.9362\n",
      "Epoch 46/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 237.4623 - mean_squared_error: 237.4623\n",
      "Epoch 47/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 239.4418 - mean_squared_error: 239.4418\n",
      "Epoch 48/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 236.8480 - mean_squared_error: 236.8480\n",
      "Epoch 49/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 234.4246 - mean_squared_error: 234.4246\n",
      "Epoch 50/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 233.4980 - mean_squared_error: 233.4980\n",
      "Epoch 51/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 235.6354 - mean_squared_error: 235.6354\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9115/9115 [==============================] - 0s 3us/step - loss: 241.6485 - mean_squared_error: 241.6485\n",
      "Epoch 53/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 234.3960 - mean_squared_error: 234.3960\n",
      "Epoch 54/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 229.9839 - mean_squared_error: 229.9839\n",
      "Epoch 55/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 231.2751 - mean_squared_error: 231.2751\n",
      "Epoch 56/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 229.2395 - mean_squared_error: 229.2395\n",
      "Epoch 57/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 234.2225 - mean_squared_error: 234.2225\n",
      "Epoch 58/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 224.7753 - mean_squared_error: 224.7753\n",
      "Epoch 59/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 228.7940 - mean_squared_error: 228.7940\n",
      "Epoch 60/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 226.9300 - mean_squared_error: 226.9300\n",
      "Epoch 61/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 221.8981 - mean_squared_error: 221.8981\n",
      "Epoch 62/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 225.9695 - mean_squared_error: 225.9695\n",
      "Epoch 63/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 224.0028 - mean_squared_error: 224.0028\n",
      "Epoch 64/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 222.1696 - mean_squared_error: 222.1696\n",
      "Epoch 65/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 220.7248 - mean_squared_error: 220.7248\n",
      "Epoch 66/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 219.5536 - mean_squared_error: 219.5536\n",
      "Epoch 67/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 214.7336 - mean_squared_error: 214.7336\n",
      "Epoch 68/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 217.8378 - mean_squared_error: 217.8378\n",
      "Epoch 69/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 218.4378 - mean_squared_error: 218.4378\n",
      "Epoch 70/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 221.2235 - mean_squared_error: 221.2235\n",
      "Epoch 71/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 220.8343 - mean_squared_error: 220.8343\n",
      "Epoch 72/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 215.8109 - mean_squared_error: 215.8109\n",
      "Epoch 73/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 218.5517 - mean_squared_error: 218.5517\n",
      "Epoch 74/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 216.0208 - mean_squared_error: 216.0208\n",
      "Epoch 75/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 217.7708 - mean_squared_error: 217.7708\n",
      "Epoch 76/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 214.5388 - mean_squared_error: 214.5388\n",
      "Epoch 77/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 210.2829 - mean_squared_error: 210.2829\n",
      "Epoch 78/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 213.7393 - mean_squared_error: 213.7393\n",
      "Epoch 79/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 209.7402 - mean_squared_error: 209.7402\n",
      "Epoch 80/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 211.0755 - mean_squared_error: 211.0755\n",
      "Epoch 81/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 215.5479 - mean_squared_error: 215.5479\n",
      "Epoch 82/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 214.7929 - mean_squared_error: 214.7929\n",
      "Epoch 83/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 211.3037 - mean_squared_error: 211.3037\n",
      "Epoch 84/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 210.4753 - mean_squared_error: 210.4753\n",
      "Epoch 85/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 211.9209 - mean_squared_error: 211.9209\n",
      "Epoch 86/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 210.8064 - mean_squared_error: 210.8064\n",
      "Epoch 87/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 206.4275 - mean_squared_error: 206.4275\n",
      "Epoch 88/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 206.6131 - mean_squared_error: 206.6131\n",
      "Epoch 89/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 204.6994 - mean_squared_error: 204.6994\n",
      "Epoch 90/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 205.4811 - mean_squared_error: 205.4811\n",
      "Epoch 91/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 210.2780 - mean_squared_error: 210.2780\n",
      "Epoch 92/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 206.8929 - mean_squared_error: 206.8929\n",
      "Epoch 93/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 203.3209 - mean_squared_error: 203.3209\n",
      "Epoch 94/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 217.4180 - mean_squared_error: 217.4180\n",
      "Epoch 95/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 201.5858 - mean_squared_error: 201.5858\n",
      "Epoch 96/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 206.7386 - mean_squared_error: 206.7386\n",
      "Epoch 97/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 198.3638 - mean_squared_error: 198.3638\n",
      "Epoch 98/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 198.2854 - mean_squared_error: 198.2854\n",
      "Epoch 99/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 205.1007 - mean_squared_error: 205.1007\n",
      "Epoch 100/100\n",
      "9115/9115 [==============================] - 0s 3us/step - loss: 203.7197 - mean_squared_error: 203.7197\n",
      "9116/9116 [==============================] - 0s 13us/step\n",
      "100/100 [==============================] - 0s 22us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 136)               47736     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 136)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 176)               24112     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 177       \n",
      "=================================================================\n",
      "Total params: 72,025\n",
      "Trainable params: 72,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "9116/9116 [==============================] - 0s 17us/step - loss: 6810.2974 - mean_squared_error: 6810.2974\n",
      "Epoch 2/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 915.3228 - mean_squared_error: 915.3228\n",
      "Epoch 3/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 635.6412 - mean_squared_error: 635.6412\n",
      "Epoch 4/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 548.1150 - mean_squared_error: 548.1150\n",
      "Epoch 5/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 483.0902 - mean_squared_error: 483.0902\n",
      "Epoch 6/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 437.9395 - mean_squared_error: 437.9395\n",
      "Epoch 7/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 396.8421 - mean_squared_error: 396.8421\n",
      "Epoch 8/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 357.0127 - mean_squared_error: 357.0127\n",
      "Epoch 9/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 328.0321 - mean_squared_error: 328.0321\n",
      "Epoch 10/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 313.0479 - mean_squared_error: 313.0479\n",
      "Epoch 11/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 306.6106 - mean_squared_error: 306.6106\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9116/9116 [==============================] - 0s 3us/step - loss: 296.8842 - mean_squared_error: 296.8842\n",
      "Epoch 13/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 285.0012 - mean_squared_error: 285.0012\n",
      "Epoch 14/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 280.8581 - mean_squared_error: 280.8581\n",
      "Epoch 15/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 280.5915 - mean_squared_error: 280.5915\n",
      "Epoch 16/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 277.5021 - mean_squared_error: 277.5021\n",
      "Epoch 17/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 275.4402 - mean_squared_error: 275.4402\n",
      "Epoch 18/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 268.9895 - mean_squared_error: 268.9895\n",
      "Epoch 19/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 270.2507 - mean_squared_error: 270.2507\n",
      "Epoch 20/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 263.6100 - mean_squared_error: 263.6100\n",
      "Epoch 21/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 261.8428 - mean_squared_error: 261.8428\n",
      "Epoch 22/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 267.1648 - mean_squared_error: 267.1648\n",
      "Epoch 23/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 261.1541 - mean_squared_error: 261.1541\n",
      "Epoch 24/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 261.9853 - mean_squared_error: 261.9853\n",
      "Epoch 25/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 260.4103 - mean_squared_error: 260.4103\n",
      "Epoch 26/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 257.6567 - mean_squared_error: 257.6567\n",
      "Epoch 27/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 257.0294 - mean_squared_error: 257.0294\n",
      "Epoch 28/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 261.3627 - mean_squared_error: 261.3627\n",
      "Epoch 29/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 254.7972 - mean_squared_error: 254.7972\n",
      "Epoch 30/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 257.0595 - mean_squared_error: 257.0595\n",
      "Epoch 31/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 253.2076 - mean_squared_error: 253.2076\n",
      "Epoch 32/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 252.8997 - mean_squared_error: 252.8997\n",
      "Epoch 33/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 255.6835 - mean_squared_error: 255.6835\n",
      "Epoch 34/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 250.5224 - mean_squared_error: 250.5224\n",
      "Epoch 35/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 246.0623 - mean_squared_error: 246.0623\n",
      "Epoch 36/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 247.9202 - mean_squared_error: 247.9202\n",
      "Epoch 37/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 249.3783 - mean_squared_error: 249.3783\n",
      "Epoch 38/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 247.6299 - mean_squared_error: 247.6299\n",
      "Epoch 39/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 246.9276 - mean_squared_error: 246.9276\n",
      "Epoch 40/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 244.3966 - mean_squared_error: 244.3966\n",
      "Epoch 41/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 246.1009 - mean_squared_error: 246.1009\n",
      "Epoch 42/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 242.8342 - mean_squared_error: 242.8342\n",
      "Epoch 43/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 241.5622 - mean_squared_error: 241.5622\n",
      "Epoch 44/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 243.7122 - mean_squared_error: 243.7122\n",
      "Epoch 45/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 244.7854 - mean_squared_error: 244.7854\n",
      "Epoch 46/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 242.7567 - mean_squared_error: 242.7567\n",
      "Epoch 47/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 234.6344 - mean_squared_error: 234.6344\n",
      "Epoch 48/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 241.9360 - mean_squared_error: 241.9360\n",
      "Epoch 49/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 240.0355 - mean_squared_error: 240.0355\n",
      "Epoch 50/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 236.9917 - mean_squared_error: 236.9917\n",
      "Epoch 51/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 239.4664 - mean_squared_error: 239.4664\n",
      "Epoch 52/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 240.2041 - mean_squared_error: 240.2041\n",
      "Epoch 53/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 234.2103 - mean_squared_error: 234.2103\n",
      "Epoch 54/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 233.6044 - mean_squared_error: 233.6044\n",
      "Epoch 55/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 230.8905 - mean_squared_error: 230.8905\n",
      "Epoch 56/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 236.7202 - mean_squared_error: 236.7202\n",
      "Epoch 57/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 238.8200 - mean_squared_error: 238.8200\n",
      "Epoch 58/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 229.2226 - mean_squared_error: 229.2226\n",
      "Epoch 59/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 227.2421 - mean_squared_error: 227.2421\n",
      "Epoch 60/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 233.3233 - mean_squared_error: 233.3233\n",
      "Epoch 61/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 229.5868 - mean_squared_error: 229.5868\n",
      "Epoch 62/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 229.1179 - mean_squared_error: 229.1179\n",
      "Epoch 63/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 228.9876 - mean_squared_error: 228.9876\n",
      "Epoch 64/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 235.9376 - mean_squared_error: 235.9376\n",
      "Epoch 65/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 229.3250 - mean_squared_error: 229.3250\n",
      "Epoch 66/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 230.3225 - mean_squared_error: 230.3225\n",
      "Epoch 67/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 227.9614 - mean_squared_error: 227.9614\n",
      "Epoch 68/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 223.9175 - mean_squared_error: 223.9175\n",
      "Epoch 69/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 227.0189 - mean_squared_error: 227.0189\n",
      "Epoch 70/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 228.6619 - mean_squared_error: 228.6619\n",
      "Epoch 71/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 222.8525 - mean_squared_error: 222.8525\n",
      "Epoch 72/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 221.0829 - mean_squared_error: 221.0829\n",
      "Epoch 73/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 224.7880 - mean_squared_error: 224.7880\n",
      "Epoch 74/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 220.6782 - mean_squared_error: 220.6782\n",
      "Epoch 75/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 225.0383 - mean_squared_error: 225.0383\n",
      "Epoch 76/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 219.8784 - mean_squared_error: 219.8784\n",
      "Epoch 77/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 218.7623 - mean_squared_error: 218.7623\n",
      "Epoch 78/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 215.5270 - mean_squared_error: 215.5270\n",
      "Epoch 79/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 221.5211 - mean_squared_error: 221.5211\n",
      "Epoch 80/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 215.5694 - mean_squared_error: 215.5694\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9116/9116 [==============================] - 0s 3us/step - loss: 217.6536 - mean_squared_error: 217.6536\n",
      "Epoch 82/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 216.2253 - mean_squared_error: 216.2253\n",
      "Epoch 83/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 216.7337 - mean_squared_error: 216.7337\n",
      "Epoch 84/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 222.3427 - mean_squared_error: 222.3427\n",
      "Epoch 85/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 219.3445 - mean_squared_error: 219.3445\n",
      "Epoch 86/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 213.2558 - mean_squared_error: 213.2558\n",
      "Epoch 87/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 209.0862 - mean_squared_error: 209.0862\n",
      "Epoch 88/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 211.6629 - mean_squared_error: 211.6629\n",
      "Epoch 89/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 216.1141 - mean_squared_error: 216.1141\n",
      "Epoch 90/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 213.7565 - mean_squared_error: 213.7565\n",
      "Epoch 91/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 212.7627 - mean_squared_error: 212.7627\n",
      "Epoch 92/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 210.0968 - mean_squared_error: 210.0968\n",
      "Epoch 93/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 214.5567 - mean_squared_error: 214.5567\n",
      "Epoch 94/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 210.8244 - mean_squared_error: 210.8244\n",
      "Epoch 95/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 212.7143 - mean_squared_error: 212.7143\n",
      "Epoch 96/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 209.8994 - mean_squared_error: 209.8994\n",
      "Epoch 97/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 212.0980 - mean_squared_error: 212.0980\n",
      "Epoch 98/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 207.8581 - mean_squared_error: 207.8581\n",
      "Epoch 99/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 207.7380 - mean_squared_error: 207.7380\n",
      "Epoch 100/100\n",
      "9116/9116 [==============================] - 0s 3us/step - loss: 215.3960 - mean_squared_error: 215.3960\n",
      "9115/9115 [==============================] - 0s 14us/step\n",
      "100/100 [==============================] - 0s 27us/step\n",
      "Loading data for dataset 1 with window_size of 25, stride of 1 and maxRUL of 130. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(18231, 350)\n",
      "(18231, 1)\n",
      "Testing data (X, y)\n",
      "(100, 350)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.63253012 -0.18639634 -0.38048616 ... -0.16666667  0.25581395\n",
      "   0.47638774]\n",
      " [-0.43373494 -0.09396119 -0.29473329 ...  0.          0.11627907\n",
      "   0.43800055]\n",
      " [-0.31325301 -0.26095487 -0.25894666 ... -0.16666667  0.31782946\n",
      "   0.52720243]\n",
      " [-0.31325301 -0.48768258 -0.33760972 ... -0.66666667  0.34883721\n",
      "   0.07677437]\n",
      " [-0.30120482 -0.48506649 -0.19074949 ... -0.16666667  0.2248062\n",
      "   0.28555648]]\n",
      "[[130.]\n",
      " [130.]\n",
      " [130.]\n",
      " [130.]\n",
      " [130.]]\n",
      "Testing data (X, y)\n",
      "[[-0.45783133 -0.46370177 -0.23733964 ... -0.16666667  0.03875969\n",
      "   0.27312897]\n",
      " [ 0.27710843 -0.16590364 -0.24206617 ... -0.5         0.03875969\n",
      "   0.01518917]\n",
      " [ 0.31325301 -0.19468062 -0.06684673 ...  0.16666667  0.2248062\n",
      "   0.04888152]\n",
      " [-0.23493976 -0.03291912 -0.08845375 ...  0.16666667 -0.31782946\n",
      "   0.004971  ]\n",
      " [ 0.09638554 -0.09439721  0.14280891 ...  0.         -0.05426357\n",
      "   0.42916321]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n",
      "Validation on model:best_models/cmapss/alpha0.8/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 528)               185328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 528)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 264)               139656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 264)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 640)               169600    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 641       \n",
      "=================================================================\n",
      "Total params: 495,225\n",
      "Trainable params: 495,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "9115/9115 [==============================] - 0s 24us/step - loss: 7152.0093 - mean_squared_error: 7152.0093\n",
      "Epoch 2/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 5475.2691 - mean_squared_error: 5475.2691\n",
      "Epoch 3/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 4672.1486 - mean_squared_error: 4672.1486\n",
      "Epoch 4/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 4038.8580 - mean_squared_error: 4038.8580\n",
      "Epoch 5/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 3538.9618 - mean_squared_error: 3538.9618\n",
      "Epoch 6/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 3134.6845 - mean_squared_error: 3134.6845\n",
      "Epoch 7/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 2812.1296 - mean_squared_error: 2812.1296\n",
      "Epoch 8/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 2550.4201 - mean_squared_error: 2550.4201\n",
      "Epoch 9/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 2148.4488 - mean_squared_error: 2148.4488\n",
      "Epoch 10/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 1794.2967 - mean_squared_error: 1794.2967\n",
      "Epoch 11/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 1550.8875 - mean_squared_error: 1550.8875\n",
      "Epoch 12/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 1342.7578 - mean_squared_error: 1342.7578\n",
      "Epoch 13/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 1167.7716 - mean_squared_error: 1167.7716\n",
      "Epoch 14/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 1012.1452 - mean_squared_error: 1012.1452\n",
      "Epoch 15/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 891.1205 - mean_squared_error: 891.1205\n",
      "Epoch 16/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 788.7897 - mean_squared_error: 788.7897\n",
      "Epoch 17/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 705.8966 - mean_squared_error: 705.8966\n",
      "Epoch 18/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 635.5289 - mean_squared_error: 635.5289\n",
      "Epoch 19/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 578.0898 - mean_squared_error: 578.0898\n",
      "Epoch 20/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 530.4853 - mean_squared_error: 530.4853\n",
      "Epoch 21/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 492.1163 - mean_squared_error: 492.1163\n",
      "Epoch 22/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 464.1793 - mean_squared_error: 464.1793\n",
      "Epoch 23/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 434.4078 - mean_squared_error: 434.4078\n",
      "Epoch 24/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 408.3799 - mean_squared_error: 408.3799\n",
      "Epoch 25/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 391.9860 - mean_squared_error: 391.9860\n",
      "Epoch 26/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 370.4540 - mean_squared_error: 370.4540\n",
      "Epoch 27/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 359.3756 - mean_squared_error: 359.3756\n",
      "Epoch 28/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 343.5961 - mean_squared_error: 343.5961\n",
      "Epoch 29/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 334.4503 - mean_squared_error: 334.4503\n",
      "Epoch 30/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 323.2320 - mean_squared_error: 323.2320\n",
      "Epoch 31/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 316.6774 - mean_squared_error: 316.6774\n",
      "Epoch 32/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 307.7090 - mean_squared_error: 307.7090\n",
      "Epoch 33/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 303.9607 - mean_squared_error: 303.9607\n",
      "Epoch 34/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 295.4597 - mean_squared_error: 295.4597\n",
      "Epoch 35/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 289.3969 - mean_squared_error: 289.3969\n",
      "Epoch 36/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 289.3837 - mean_squared_error: 289.3837\n",
      "Epoch 37/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 282.9918 - mean_squared_error: 282.9918\n",
      "Epoch 38/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 282.8005 - mean_squared_error: 282.8005\n",
      "Epoch 39/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 275.5758 - mean_squared_error: 275.5758\n",
      "Epoch 40/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 274.6064 - mean_squared_error: 274.6064\n",
      "Epoch 41/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 269.3688 - mean_squared_error: 269.3688\n",
      "Epoch 42/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 271.9977 - mean_squared_error: 271.9977\n",
      "Epoch 43/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 266.3056 - mean_squared_error: 266.3056\n",
      "Epoch 44/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 262.8637 - mean_squared_error: 262.8637\n",
      "Epoch 45/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 262.6289 - mean_squared_error: 262.6289\n",
      "Epoch 46/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 259.3842 - mean_squared_error: 259.3842\n",
      "Epoch 47/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 259.5460 - mean_squared_error: 259.5460\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9115/9115 [==============================] - 0s 4us/step - loss: 254.1117 - mean_squared_error: 254.1117\n",
      "Epoch 49/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 257.3527 - mean_squared_error: 257.3527\n",
      "Epoch 50/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 253.5000 - mean_squared_error: 253.5000\n",
      "Epoch 51/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 259.2377 - mean_squared_error: 259.2377\n",
      "Epoch 52/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 257.4026 - mean_squared_error: 257.4026\n",
      "Epoch 53/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 251.0351 - mean_squared_error: 251.0351\n",
      "Epoch 54/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 246.2383 - mean_squared_error: 246.2383\n",
      "Epoch 55/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 252.6281 - mean_squared_error: 252.6281\n",
      "Epoch 56/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 243.3598 - mean_squared_error: 243.3598\n",
      "Epoch 57/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 244.9091 - mean_squared_error: 244.9091\n",
      "Epoch 58/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 249.4454 - mean_squared_error: 249.4454\n",
      "Epoch 59/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 243.8555 - mean_squared_error: 243.8555\n",
      "Epoch 60/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 245.8465 - mean_squared_error: 245.8465\n",
      "Epoch 61/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 244.4444 - mean_squared_error: 244.4444\n",
      "Epoch 62/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 242.0727 - mean_squared_error: 242.0727\n",
      "Epoch 63/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 241.0477 - mean_squared_error: 241.0477\n",
      "Epoch 64/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 241.8397 - mean_squared_error: 241.8397\n",
      "Epoch 65/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 239.4777 - mean_squared_error: 239.4777\n",
      "Epoch 66/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 239.9074 - mean_squared_error: 239.9074\n",
      "Epoch 67/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 238.9759 - mean_squared_error: 238.9759\n",
      "Epoch 68/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 240.6825 - mean_squared_error: 240.6825\n",
      "Epoch 69/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 241.5410 - mean_squared_error: 241.5410\n",
      "Epoch 70/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 236.1871 - mean_squared_error: 236.1871\n",
      "Epoch 71/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 237.3538 - mean_squared_error: 237.3538\n",
      "Epoch 72/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 236.3775 - mean_squared_error: 236.3775\n",
      "Epoch 73/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 235.5052 - mean_squared_error: 235.5052\n",
      "Epoch 74/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 235.8259 - mean_squared_error: 235.8259\n",
      "Epoch 75/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 235.7442 - mean_squared_error: 235.7442\n",
      "Epoch 76/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 234.1801 - mean_squared_error: 234.1801\n",
      "Epoch 77/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 234.5256 - mean_squared_error: 234.5256\n",
      "Epoch 78/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 234.0231 - mean_squared_error: 234.0231\n",
      "Epoch 79/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 235.0150 - mean_squared_error: 235.0150\n",
      "Epoch 80/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 231.2877 - mean_squared_error: 231.2877\n",
      "Epoch 81/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 228.5365 - mean_squared_error: 228.5365\n",
      "Epoch 82/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 232.5843 - mean_squared_error: 232.5843\n",
      "Epoch 83/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 231.3297 - mean_squared_error: 231.3297\n",
      "Epoch 84/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 228.6243 - mean_squared_error: 228.6243\n",
      "Epoch 85/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 231.2456 - mean_squared_error: 231.2456\n",
      "Epoch 86/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 227.8198 - mean_squared_error: 227.8198\n",
      "Epoch 87/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 230.5025 - mean_squared_error: 230.5025\n",
      "Epoch 88/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 228.7377 - mean_squared_error: 228.7377\n",
      "Epoch 89/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 230.2311 - mean_squared_error: 230.2311\n",
      "Epoch 90/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 231.3392 - mean_squared_error: 231.3392\n",
      "Epoch 91/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 227.6508 - mean_squared_error: 227.6508\n",
      "Epoch 92/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 226.6954 - mean_squared_error: 226.6954\n",
      "Epoch 93/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 226.6082 - mean_squared_error: 226.6082\n",
      "Epoch 94/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 226.4441 - mean_squared_error: 226.4441\n",
      "Epoch 95/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 225.1563 - mean_squared_error: 225.1563\n",
      "Epoch 96/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 227.4152 - mean_squared_error: 227.4152\n",
      "Epoch 97/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 225.8178 - mean_squared_error: 225.8178\n",
      "Epoch 98/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 226.9490 - mean_squared_error: 226.9490\n",
      "Epoch 99/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 227.0278 - mean_squared_error: 227.0278\n",
      "Epoch 100/100\n",
      "9115/9115 [==============================] - 0s 4us/step - loss: 222.4968 - mean_squared_error: 222.4968\n",
      "9116/9116 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 28us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 528)               185328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 528)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 264)               139656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 264)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 640)               169600    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 641       \n",
      "=================================================================\n",
      "Total params: 495,225\n",
      "Trainable params: 495,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "9116/9116 [==============================] - 0s 24us/step - loss: 6991.9713 - mean_squared_error: 6991.9713\n",
      "Epoch 2/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 5352.2727 - mean_squared_error: 5352.2727\n",
      "Epoch 3/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 4585.2415 - mean_squared_error: 4585.2415\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9116/9116 [==============================] - 0s 4us/step - loss: 3982.2779 - mean_squared_error: 3982.2779\n",
      "Epoch 5/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 3493.1956 - mean_squared_error: 3493.1956\n",
      "Epoch 6/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 3096.0242 - mean_squared_error: 3096.0242\n",
      "Epoch 7/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 2767.2819 - mean_squared_error: 2767.2819\n",
      "Epoch 8/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 2504.3636 - mean_squared_error: 2504.3636\n",
      "Epoch 9/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 2062.8585 - mean_squared_error: 2062.8585\n",
      "Epoch 10/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 1727.5578 - mean_squared_error: 1727.5578\n",
      "Epoch 11/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 1481.9653 - mean_squared_error: 1481.9653\n",
      "Epoch 12/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 1274.0975 - mean_squared_error: 1274.0975\n",
      "Epoch 13/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 1092.7849 - mean_squared_error: 1092.7849\n",
      "Epoch 14/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 944.8767 - mean_squared_error: 944.8767\n",
      "Epoch 15/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 821.3799 - mean_squared_error: 821.3799\n",
      "Epoch 16/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 721.4394 - mean_squared_error: 721.4394\n",
      "Epoch 17/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 636.7368 - mean_squared_error: 636.7368\n",
      "Epoch 18/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 570.3971 - mean_squared_error: 570.3971\n",
      "Epoch 19/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 515.1735 - mean_squared_error: 515.1735\n",
      "Epoch 20/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 470.2932 - mean_squared_error: 470.2932\n",
      "Epoch 21/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 436.6365 - mean_squared_error: 436.6365\n",
      "Epoch 22/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 408.1938 - mean_squared_error: 408.1938\n",
      "Epoch 23/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 375.3777 - mean_squared_error: 375.3777\n",
      "Epoch 24/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 359.2643 - mean_squared_error: 359.2643\n",
      "Epoch 25/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 342.0553 - mean_squared_error: 342.0553\n",
      "Epoch 26/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 329.0631 - mean_squared_error: 329.0631\n",
      "Epoch 27/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 321.2735 - mean_squared_error: 321.2735\n",
      "Epoch 28/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 306.0124 - mean_squared_error: 306.0124\n",
      "Epoch 29/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 298.5641 - mean_squared_error: 298.5641\n",
      "Epoch 30/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 295.2622 - mean_squared_error: 295.2622\n",
      "Epoch 31/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 284.8151 - mean_squared_error: 284.8151\n",
      "Epoch 32/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 281.6868 - mean_squared_error: 281.6868\n",
      "Epoch 33/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 273.4279 - mean_squared_error: 273.4279\n",
      "Epoch 34/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 269.0463 - mean_squared_error: 269.0463\n",
      "Epoch 35/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 268.2007 - mean_squared_error: 268.2007\n",
      "Epoch 36/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 262.7873 - mean_squared_error: 262.7873\n",
      "Epoch 37/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 266.4399 - mean_squared_error: 266.4399\n",
      "Epoch 38/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 261.7440 - mean_squared_error: 261.7440\n",
      "Epoch 39/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 261.9368 - mean_squared_error: 261.9368\n",
      "Epoch 40/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 253.9869 - mean_squared_error: 253.9869\n",
      "Epoch 41/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 252.6804 - mean_squared_error: 252.6804\n",
      "Epoch 42/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 249.1595 - mean_squared_error: 249.1595\n",
      "Epoch 43/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 248.1886 - mean_squared_error: 248.1886\n",
      "Epoch 44/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 247.2369 - mean_squared_error: 247.2369\n",
      "Epoch 45/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 246.3026 - mean_squared_error: 246.3026\n",
      "Epoch 46/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 250.0841 - mean_squared_error: 250.0841\n",
      "Epoch 47/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 245.0805 - mean_squared_error: 245.0805\n",
      "Epoch 48/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 243.9889 - mean_squared_error: 243.9889\n",
      "Epoch 49/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 244.6916 - mean_squared_error: 244.6916\n",
      "Epoch 50/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 244.1931 - mean_squared_error: 244.1931\n",
      "Epoch 51/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 242.9042 - mean_squared_error: 242.9042\n",
      "Epoch 52/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 237.7396 - mean_squared_error: 237.7396\n",
      "Epoch 53/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 235.0557 - mean_squared_error: 235.0557\n",
      "Epoch 54/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 237.2475 - mean_squared_error: 237.2475\n",
      "Epoch 55/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 234.3806 - mean_squared_error: 234.3806\n",
      "Epoch 56/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 237.8472 - mean_squared_error: 237.8472\n",
      "Epoch 57/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 235.4093 - mean_squared_error: 235.4093\n",
      "Epoch 58/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 235.0762 - mean_squared_error: 235.0762\n",
      "Epoch 59/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 229.3914 - mean_squared_error: 229.3914\n",
      "Epoch 60/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 233.2421 - mean_squared_error: 233.2421\n",
      "Epoch 61/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 234.7468 - mean_squared_error: 234.7468\n",
      "Epoch 62/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 230.6354 - mean_squared_error: 230.6354\n",
      "Epoch 63/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 232.1763 - mean_squared_error: 232.1763\n",
      "Epoch 64/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 231.8415 - mean_squared_error: 231.8415\n",
      "Epoch 65/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 233.0382 - mean_squared_error: 233.0382\n",
      "Epoch 66/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 229.1995 - mean_squared_error: 229.1995\n",
      "Epoch 67/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 229.2449 - mean_squared_error: 229.2449\n",
      "Epoch 68/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 231.8555 - mean_squared_error: 231.8555\n",
      "Epoch 69/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 227.9023 - mean_squared_error: 227.9023\n",
      "Epoch 70/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 230.9074 - mean_squared_error: 230.9074\n",
      "Epoch 71/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 229.4393 - mean_squared_error: 229.4393\n",
      "Epoch 72/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 227.1347 - mean_squared_error: 227.1347\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9116/9116 [==============================] - 0s 4us/step - loss: 228.5212 - mean_squared_error: 228.5212\n",
      "Epoch 74/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 226.7608 - mean_squared_error: 226.7608\n",
      "Epoch 75/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 227.2453 - mean_squared_error: 227.2453\n",
      "Epoch 76/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 231.3943 - mean_squared_error: 231.3943\n",
      "Epoch 77/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 224.6745 - mean_squared_error: 224.6745\n",
      "Epoch 78/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 226.2207 - mean_squared_error: 226.2207\n",
      "Epoch 79/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 224.6519 - mean_squared_error: 224.6519\n",
      "Epoch 80/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 223.3599 - mean_squared_error: 223.3599\n",
      "Epoch 81/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 226.1138 - mean_squared_error: 226.1138\n",
      "Epoch 82/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 222.5191 - mean_squared_error: 222.5191\n",
      "Epoch 83/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 224.0099 - mean_squared_error: 224.0099\n",
      "Epoch 84/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 220.7808 - mean_squared_error: 220.7808\n",
      "Epoch 85/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 219.4437 - mean_squared_error: 219.4437\n",
      "Epoch 86/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 221.1386 - mean_squared_error: 221.1386\n",
      "Epoch 87/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 221.3482 - mean_squared_error: 221.3482\n",
      "Epoch 88/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 219.5576 - mean_squared_error: 219.5576\n",
      "Epoch 89/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 221.2610 - mean_squared_error: 221.2610\n",
      "Epoch 90/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 220.9551 - mean_squared_error: 220.9551\n",
      "Epoch 91/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 222.0415 - mean_squared_error: 222.0415\n",
      "Epoch 92/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 215.1068 - mean_squared_error: 215.1068\n",
      "Epoch 93/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 219.8476 - mean_squared_error: 219.8476\n",
      "Epoch 94/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 218.6834 - mean_squared_error: 218.6834\n",
      "Epoch 95/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 220.6003 - mean_squared_error: 220.6003\n",
      "Epoch 96/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 217.9860 - mean_squared_error: 217.9860\n",
      "Epoch 97/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 216.8957 - mean_squared_error: 216.8957\n",
      "Epoch 98/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 215.9505 - mean_squared_error: 215.9505\n",
      "Epoch 99/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 217.1350 - mean_squared_error: 217.1350\n",
      "Epoch 100/100\n",
      "9116/9116 [==============================] - 0s 4us/step - loss: 214.0116 - mean_squared_error: 214.0116\n",
      "9115/9115 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 28us/step\n",
      "Loading data for dataset 1 with window_size of 25, stride of 1 and maxRUL of 130. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(18231, 350)\n",
      "(18231, 1)\n",
      "Testing data (X, y)\n",
      "(100, 350)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.63253012 -0.18639634 -0.38048616 ... -0.16666667  0.25581395\n",
      "   0.47638774]\n",
      " [-0.43373494 -0.09396119 -0.29473329 ...  0.          0.11627907\n",
      "   0.43800055]\n",
      " [-0.31325301 -0.26095487 -0.25894666 ... -0.16666667  0.31782946\n",
      "   0.52720243]\n",
      " [-0.31325301 -0.48768258 -0.33760972 ... -0.66666667  0.34883721\n",
      "   0.07677437]\n",
      " [-0.30120482 -0.48506649 -0.19074949 ... -0.16666667  0.2248062\n",
      "   0.28555648]]\n",
      "[[130.]\n",
      " [130.]\n",
      " [130.]\n",
      " [130.]\n",
      " [130.]]\n",
      "Testing data (X, y)\n",
      "[[-0.45783133 -0.46370177 -0.23733964 ... -0.16666667  0.03875969\n",
      "   0.27312897]\n",
      " [ 0.27710843 -0.16590364 -0.24206617 ... -0.5         0.03875969\n",
      "   0.01518917]\n",
      " [ 0.31325301 -0.19468062 -0.06684673 ...  0.16666667  0.2248062\n",
      "   0.04888152]\n",
      " [-0.23493976 -0.03291912 -0.08845375 ...  0.16666667 -0.31782946\n",
      "   0.004971  ]\n",
      " [ 0.09638554 -0.09439721  0.14280891 ...  0.         -0.05426357\n",
      "   0.42916321]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n",
      "Validation on model:best_models/cmapss/alpha1/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 856)               300456    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 904)               774728    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 904)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 408)               369240    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 408)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 409       \n",
      "=================================================================\n",
      "Total params: 1,444,833\n",
      "Trainable params: 1,444,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "9115/9115 [==============================] - 0s 26us/step - loss: 2494.1072 - mean_squared_error: 2494.1072\n",
      "Epoch 2/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 577.6536 - mean_squared_error: 577.6536\n",
      "Epoch 3/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 385.8122 - mean_squared_error: 385.8122\n",
      "Epoch 4/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 501.8702 - mean_squared_error: 501.8702\n",
      "Epoch 5/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 315.7188 - mean_squared_error: 315.7188\n",
      "Epoch 6/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 366.5623 - mean_squared_error: 366.5623\n",
      "Epoch 7/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 337.9169 - mean_squared_error: 337.9169\n",
      "Epoch 8/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 330.8761 - mean_squared_error: 330.8761\n",
      "Epoch 9/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 328.6549 - mean_squared_error: 328.6549\n",
      "Epoch 10/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 321.5882 - mean_squared_error: 321.5882\n",
      "Epoch 11/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 327.9961 - mean_squared_error: 327.9961\n",
      "Epoch 12/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 309.4948 - mean_squared_error: 309.4948\n",
      "Epoch 13/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 322.5023 - mean_squared_error: 322.5023\n",
      "Epoch 14/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 331.9687 - mean_squared_error: 331.9687\n",
      "Epoch 15/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 280.5291 - mean_squared_error: 280.5291\n",
      "Epoch 16/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 292.2424 - mean_squared_error: 292.2424\n",
      "Epoch 17/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 294.0780 - mean_squared_error: 294.0780\n",
      "Epoch 18/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 310.2507 - mean_squared_error: 310.2507\n",
      "Epoch 19/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 257.6498 - mean_squared_error: 257.6498\n",
      "Epoch 20/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 299.7979 - mean_squared_error: 299.7979\n",
      "Epoch 21/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 300.1997 - mean_squared_error: 300.1997\n",
      "Epoch 22/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 359.7213 - mean_squared_error: 359.7213\n",
      "Epoch 23/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 312.9346 - mean_squared_error: 312.9346\n",
      "Epoch 24/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 248.7394 - mean_squared_error: 248.7394\n",
      "Epoch 25/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 294.8473 - mean_squared_error: 294.8473\n",
      "Epoch 26/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 275.1391 - mean_squared_error: 275.1391\n",
      "Epoch 27/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 294.1448 - mean_squared_error: 294.1448\n",
      "Epoch 28/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 255.2201 - mean_squared_error: 255.2201\n",
      "Epoch 29/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 284.2399 - mean_squared_error: 284.2399\n",
      "Epoch 30/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 239.8623 - mean_squared_error: 239.8623\n",
      "Epoch 31/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 250.7633 - mean_squared_error: 250.7633\n",
      "Epoch 32/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 278.7753 - mean_squared_error: 278.7753\n",
      "Epoch 33/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 247.6851 - mean_squared_error: 247.6851\n",
      "Epoch 34/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 357.7610 - mean_squared_error: 357.7610\n",
      "Epoch 35/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 289.4689 - mean_squared_error: 289.4689\n",
      "Epoch 36/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 236.7150 - mean_squared_error: 236.7150\n",
      "Epoch 37/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 245.8483 - mean_squared_error: 245.8483\n",
      "Epoch 38/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 242.6718 - mean_squared_error: 242.6718\n",
      "Epoch 39/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 218.7027 - mean_squared_error: 218.7027\n",
      "Epoch 40/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 241.9574 - mean_squared_error: 241.9574\n",
      "Epoch 41/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 271.2731 - mean_squared_error: 271.2731\n",
      "Epoch 42/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 234.8496 - mean_squared_error: 234.8496\n",
      "Epoch 43/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 236.8260 - mean_squared_error: 236.8260\n",
      "Epoch 44/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 226.5663 - mean_squared_error: 226.5663\n",
      "Epoch 45/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 248.7265 - mean_squared_error: 248.7265\n",
      "Epoch 46/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 238.9399 - mean_squared_error: 238.9399\n",
      "Epoch 47/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 211.8397 - mean_squared_error: 211.8397\n",
      "Epoch 48/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 238.8357 - mean_squared_error: 238.8357\n",
      "Epoch 49/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 240.0383 - mean_squared_error: 240.0383\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9115/9115 [==============================] - 0s 6us/step - loss: 234.1409 - mean_squared_error: 234.1409\n",
      "Epoch 51/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 201.0928 - mean_squared_error: 201.0928\n",
      "Epoch 52/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 254.0511 - mean_squared_error: 254.0511\n",
      "Epoch 53/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 218.5464 - mean_squared_error: 218.5464\n",
      "Epoch 54/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 236.4601 - mean_squared_error: 236.4601\n",
      "Epoch 55/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 203.7403 - mean_squared_error: 203.7403\n",
      "Epoch 56/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 201.1776 - mean_squared_error: 201.1776\n",
      "Epoch 57/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 226.4529 - mean_squared_error: 226.4529\n",
      "Epoch 58/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 183.9045 - mean_squared_error: 183.9045\n",
      "Epoch 59/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 265.9419 - mean_squared_error: 265.9419\n",
      "Epoch 60/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 200.5292 - mean_squared_error: 200.5292\n",
      "Epoch 61/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 252.7581 - mean_squared_error: 252.7581\n",
      "Epoch 62/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 181.8526 - mean_squared_error: 181.8526\n",
      "Epoch 63/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 182.0566 - mean_squared_error: 182.0566\n",
      "Epoch 64/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 220.7404 - mean_squared_error: 220.7404\n",
      "Epoch 65/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 191.9900 - mean_squared_error: 191.9900\n",
      "Epoch 66/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 168.7211 - mean_squared_error: 168.7211\n",
      "Epoch 67/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 201.2782 - mean_squared_error: 201.2782\n",
      "Epoch 68/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 192.0550 - mean_squared_error: 192.0550\n",
      "Epoch 69/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 160.7906 - mean_squared_error: 160.7906\n",
      "Epoch 70/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 185.1201 - mean_squared_error: 185.1201\n",
      "Epoch 71/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 220.9220 - mean_squared_error: 220.9220\n",
      "Epoch 72/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 152.5377 - mean_squared_error: 152.5377\n",
      "Epoch 73/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 190.2904 - mean_squared_error: 190.2904\n",
      "Epoch 74/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 146.0327 - mean_squared_error: 146.0327\n",
      "Epoch 75/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 184.5443 - mean_squared_error: 184.5443\n",
      "Epoch 76/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 170.4581 - mean_squared_error: 170.4581\n",
      "Epoch 77/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 162.4343 - mean_squared_error: 162.4343\n",
      "Epoch 78/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 170.4554 - mean_squared_error: 170.4554\n",
      "Epoch 79/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 153.8751 - mean_squared_error: 153.8751\n",
      "Epoch 80/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 182.7773 - mean_squared_error: 182.7773\n",
      "Epoch 81/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 168.9095 - mean_squared_error: 168.9095\n",
      "Epoch 82/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 165.3734 - mean_squared_error: 165.3734\n",
      "Epoch 83/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 169.2290 - mean_squared_error: 169.2290\n",
      "Epoch 84/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 146.3172 - mean_squared_error: 146.3172\n",
      "Epoch 85/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 140.1113 - mean_squared_error: 140.1113\n",
      "Epoch 86/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 217.7015 - mean_squared_error: 217.7015\n",
      "Epoch 87/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 142.1861 - mean_squared_error: 142.1861\n",
      "Epoch 88/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 151.2706 - mean_squared_error: 151.2706\n",
      "Epoch 89/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 170.8166 - mean_squared_error: 170.8166\n",
      "Epoch 90/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 157.8198 - mean_squared_error: 157.8198\n",
      "Epoch 91/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 132.2591 - mean_squared_error: 132.2591\n",
      "Epoch 92/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 122.7028 - mean_squared_error: 122.7028\n",
      "Epoch 93/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 131.5442 - mean_squared_error: 131.5442\n",
      "Epoch 94/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 178.8212 - mean_squared_error: 178.8212\n",
      "Epoch 95/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 140.6113 - mean_squared_error: 140.6113\n",
      "Epoch 96/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 122.7848 - mean_squared_error: 122.7848\n",
      "Epoch 97/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 155.6774 - mean_squared_error: 155.6774\n",
      "Epoch 98/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 137.6540 - mean_squared_error: 137.6540\n",
      "Epoch 99/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 167.5757 - mean_squared_error: 167.5757\n",
      "Epoch 100/100\n",
      "9115/9115 [==============================] - 0s 6us/step - loss: 128.2883 - mean_squared_error: 128.2883\n",
      "9116/9116 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 23us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for regression with loss function mean_squared_error\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 856)               300456    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 904)               774728    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 904)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 408)               369240    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 408)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 409       \n",
      "=================================================================\n",
      "Total params: 1,444,833\n",
      "Trainable params: 1,444,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "9116/9116 [==============================] - 0s 26us/step - loss: 2497.0262 - mean_squared_error: 2497.0262\n",
      "Epoch 2/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 495.7833 - mean_squared_error: 495.7833\n",
      "Epoch 3/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 424.4035 - mean_squared_error: 424.4035\n",
      "Epoch 4/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 560.4658 - mean_squared_error: 560.4658\n",
      "Epoch 5/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 316.1009 - mean_squared_error: 316.1009\n",
      "Epoch 6/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 343.2665 - mean_squared_error: 343.2665\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9116/9116 [==============================] - 0s 6us/step - loss: 319.8827 - mean_squared_error: 319.8827\n",
      "Epoch 8/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 294.8972 - mean_squared_error: 294.8972\n",
      "Epoch 9/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 332.3353 - mean_squared_error: 332.3353\n",
      "Epoch 10/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 364.5295 - mean_squared_error: 364.5295\n",
      "Epoch 11/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 309.8067 - mean_squared_error: 309.8067\n",
      "Epoch 12/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 318.3393 - mean_squared_error: 318.3393\n",
      "Epoch 13/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 301.1738 - mean_squared_error: 301.1738\n",
      "Epoch 14/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 302.1049 - mean_squared_error: 302.1049\n",
      "Epoch 15/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 264.8495 - mean_squared_error: 264.8495\n",
      "Epoch 16/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 364.0226 - mean_squared_error: 364.0226\n",
      "Epoch 17/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 282.9066 - mean_squared_error: 282.9066\n",
      "Epoch 18/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 273.9599 - mean_squared_error: 273.9599\n",
      "Epoch 19/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 314.7382 - mean_squared_error: 314.7382\n",
      "Epoch 20/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 280.4425 - mean_squared_error: 280.4425\n",
      "Epoch 21/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 262.3127 - mean_squared_error: 262.3127\n",
      "Epoch 22/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 262.5227 - mean_squared_error: 262.5227\n",
      "Epoch 23/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 316.9747 - mean_squared_error: 316.9747\n",
      "Epoch 24/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 256.0523 - mean_squared_error: 256.0523\n",
      "Epoch 25/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 248.2779 - mean_squared_error: 248.2779\n",
      "Epoch 26/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 335.6300 - mean_squared_error: 335.6300\n",
      "Epoch 27/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 254.3089 - mean_squared_error: 254.3089\n",
      "Epoch 28/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 238.7920 - mean_squared_error: 238.7920\n",
      "Epoch 29/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 288.8519 - mean_squared_error: 288.8519\n",
      "Epoch 30/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 312.1273 - mean_squared_error: 312.1273\n",
      "Epoch 31/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 244.6424 - mean_squared_error: 244.6424\n",
      "Epoch 32/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 244.7297 - mean_squared_error: 244.7297\n",
      "Epoch 33/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 267.9588 - mean_squared_error: 267.9588\n",
      "Epoch 34/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 249.3666 - mean_squared_error: 249.3666\n",
      "Epoch 35/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 240.4046 - mean_squared_error: 240.4046\n",
      "Epoch 36/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 269.0354 - mean_squared_error: 269.0354\n",
      "Epoch 37/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 290.6938 - mean_squared_error: 290.6938\n",
      "Epoch 38/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 223.8298 - mean_squared_error: 223.8298\n",
      "Epoch 39/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 214.5619 - mean_squared_error: 214.5619\n",
      "Epoch 40/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 259.4465 - mean_squared_error: 259.4465\n",
      "Epoch 41/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 271.4114 - mean_squared_error: 271.4114\n",
      "Epoch 42/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 232.2818 - mean_squared_error: 232.2818\n",
      "Epoch 43/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 238.6176 - mean_squared_error: 238.6176\n",
      "Epoch 44/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 244.1686 - mean_squared_error: 244.1686\n",
      "Epoch 45/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 261.7217 - mean_squared_error: 261.7217\n",
      "Epoch 46/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 234.1937 - mean_squared_error: 234.1937\n",
      "Epoch 47/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 207.9038 - mean_squared_error: 207.9038\n",
      "Epoch 48/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 200.8818 - mean_squared_error: 200.8818\n",
      "Epoch 49/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 274.2891 - mean_squared_error: 274.2891\n",
      "Epoch 50/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 228.0590 - mean_squared_error: 228.0590\n",
      "Epoch 51/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 226.0139 - mean_squared_error: 226.0139\n",
      "Epoch 52/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 223.7535 - mean_squared_error: 223.7535\n",
      "Epoch 53/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 217.1538 - mean_squared_error: 217.1538\n",
      "Epoch 54/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 236.3274 - mean_squared_error: 236.3274\n",
      "Epoch 55/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 190.9635 - mean_squared_error: 190.9635\n",
      "Epoch 56/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 181.9072 - mean_squared_error: 181.9072\n",
      "Epoch 57/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 221.8645 - mean_squared_error: 221.8645\n",
      "Epoch 58/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 198.1773 - mean_squared_error: 198.1773\n",
      "Epoch 59/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 212.0890 - mean_squared_error: 212.0890\n",
      "Epoch 60/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 199.0478 - mean_squared_error: 199.0478\n",
      "Epoch 61/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 217.5832 - mean_squared_error: 217.5832\n",
      "Epoch 62/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 188.7075 - mean_squared_error: 188.7075\n",
      "Epoch 63/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 198.6748 - mean_squared_error: 198.6748\n",
      "Epoch 64/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 209.8642 - mean_squared_error: 209.8642\n",
      "Epoch 65/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 188.3844 - mean_squared_error: 188.3844\n",
      "Epoch 66/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 190.4953 - mean_squared_error: 190.4953\n",
      "Epoch 67/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 184.0822 - mean_squared_error: 184.0822\n",
      "Epoch 68/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 190.2778 - mean_squared_error: 190.2778\n",
      "Epoch 69/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 164.5392 - mean_squared_error: 164.5392\n",
      "Epoch 70/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 183.7107 - mean_squared_error: 183.7107\n",
      "Epoch 71/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 175.9381 - mean_squared_error: 175.9381\n",
      "Epoch 72/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 177.2937 - mean_squared_error: 177.2937\n",
      "Epoch 73/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 157.3962 - mean_squared_error: 157.3962\n",
      "Epoch 74/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 173.6026 - mean_squared_error: 173.6026\n",
      "Epoch 75/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 165.9076 - mean_squared_error: 165.9076\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9116/9116 [==============================] - 0s 6us/step - loss: 166.6085 - mean_squared_error: 166.6085\n",
      "Epoch 77/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 167.6622 - mean_squared_error: 167.6622\n",
      "Epoch 78/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 155.1654 - mean_squared_error: 155.1654\n",
      "Epoch 79/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 151.0754 - mean_squared_error: 151.0754\n",
      "Epoch 80/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 148.2922 - mean_squared_error: 148.2922\n",
      "Epoch 81/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 165.7083 - mean_squared_error: 165.7083\n",
      "Epoch 82/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 131.3643 - mean_squared_error: 131.3643\n",
      "Epoch 83/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 163.5707 - mean_squared_error: 163.5707\n",
      "Epoch 84/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 159.5479 - mean_squared_error: 159.5479\n",
      "Epoch 85/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 130.9390 - mean_squared_error: 130.9390\n",
      "Epoch 86/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 246.4483 - mean_squared_error: 246.4483\n",
      "Epoch 87/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 148.8367 - mean_squared_error: 148.8367\n",
      "Epoch 88/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 162.0546 - mean_squared_error: 162.0546\n",
      "Epoch 89/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 159.0331 - mean_squared_error: 159.0331\n",
      "Epoch 90/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 137.7810 - mean_squared_error: 137.7810\n",
      "Epoch 91/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 117.4986 - mean_squared_error: 117.4986\n",
      "Epoch 92/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 155.6579 - mean_squared_error: 155.6579\n",
      "Epoch 93/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 153.1137 - mean_squared_error: 153.1137\n",
      "Epoch 94/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 158.6601 - mean_squared_error: 158.6601\n",
      "Epoch 95/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 139.2275 - mean_squared_error: 139.2275\n",
      "Epoch 96/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 164.7808 - mean_squared_error: 164.7808\n",
      "Epoch 97/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 146.5055 - mean_squared_error: 146.5055\n",
      "Epoch 98/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 128.4266 - mean_squared_error: 128.4266\n",
      "Epoch 99/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 145.5304 - mean_squared_error: 145.5304\n",
      "Epoch 100/100\n",
      "9116/9116 [==============================] - 0s 6us/step - loss: 145.5840 - mean_squared_error: 145.5840\n",
      "9115/9115 [==============================] - 0s 15us/step\n",
      "100/100 [==============================] - 0s 22us/step\n",
      "Loading data. Cross-Validation ratio 0\n",
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(60000, 784)\n",
      "(60000, 10)\n",
      "Testing data (X, y)\n",
      "(10000, 784)\n",
      "(10000, 10)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Testing data (X, y)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "Validation on model:best_models/mnist/alpha0.6/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 72)                56520     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                730       \n",
      "=================================================================\n",
      "Total params: 57,250\n",
      "Trainable params: 57,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "30000/30000 [==============================] - 0s 7us/step - loss: 0.9668 - acc: 0.7561\n",
      "Epoch 2/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.3856 - acc: 0.8982\n",
      "Epoch 3/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.3048 - acc: 0.9157\n",
      "Epoch 4/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2647 - acc: 0.9263\n",
      "Epoch 5/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2373 - acc: 0.9339\n",
      "Epoch 6/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2158 - acc: 0.9403\n",
      "Epoch 7/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1982 - acc: 0.9435\n",
      "Epoch 8/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1835 - acc: 0.9489\n",
      "Epoch 9/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1716 - acc: 0.9510\n",
      "Epoch 10/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1594 - acc: 0.9543\n",
      "Epoch 11/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1496 - acc: 0.9578\n",
      "Epoch 12/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1401 - acc: 0.9608\n",
      "Epoch 13/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1319 - acc: 0.9622\n",
      "Epoch 14/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1247 - acc: 0.9645\n",
      "Epoch 15/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1179 - acc: 0.9670\n",
      "Epoch 16/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1111 - acc: 0.9691\n",
      "Epoch 17/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1052 - acc: 0.9704\n",
      "Epoch 18/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1003 - acc: 0.9723\n",
      "Epoch 19/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0950 - acc: 0.9735\n",
      "Epoch 20/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0905 - acc: 0.9752\n",
      "Epoch 21/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0856 - acc: 0.9771\n",
      "Epoch 22/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0816 - acc: 0.9781\n",
      "Epoch 23/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0778 - acc: 0.9797\n",
      "Epoch 24/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0740 - acc: 0.9802\n",
      "Epoch 25/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0705 - acc: 0.9814\n",
      "Epoch 26/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0673 - acc: 0.9828\n",
      "Epoch 27/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0638 - acc: 0.9833\n",
      "Epoch 28/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0608 - acc: 0.9846\n",
      "Epoch 29/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0583 - acc: 0.9851\n",
      "Epoch 30/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0549 - acc: 0.9860\n",
      "Epoch 31/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0525 - acc: 0.9870\n",
      "Epoch 32/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0502 - acc: 0.9882\n",
      "Epoch 33/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0483 - acc: 0.9882\n",
      "Epoch 34/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0458 - acc: 0.9891\n",
      "Epoch 35/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0435 - acc: 0.9902\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0414 - acc: 0.9910\n",
      "Epoch 37/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0399 - acc: 0.9908\n",
      "Epoch 38/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0377 - acc: 0.9920\n",
      "Epoch 39/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0364 - acc: 0.9921\n",
      "Epoch 40/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0346 - acc: 0.9928\n",
      "Epoch 41/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0334 - acc: 0.9932\n",
      "Epoch 42/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0314 - acc: 0.9938\n",
      "Epoch 43/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0300 - acc: 0.9944\n",
      "Epoch 44/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0290 - acc: 0.9945\n",
      "Epoch 45/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0278 - acc: 0.9946\n",
      "Epoch 46/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0266 - acc: 0.9954\n",
      "Epoch 47/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0253 - acc: 0.9951\n",
      "Epoch 48/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0237 - acc: 0.9963\n",
      "Epoch 49/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0231 - acc: 0.9963\n",
      "Epoch 50/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0222 - acc: 0.9967\n",
      "Epoch 51/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0211 - acc: 0.9969\n",
      "Epoch 52/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0200 - acc: 0.9972\n",
      "Epoch 53/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0194 - acc: 0.9971\n",
      "Epoch 54/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0186 - acc: 0.9973\n",
      "Epoch 55/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0177 - acc: 0.9976\n",
      "Epoch 56/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0169 - acc: 0.9981\n",
      "Epoch 57/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0161 - acc: 0.9980\n",
      "Epoch 58/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0154 - acc: 0.9984\n",
      "Epoch 59/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0147 - acc: 0.9985\n",
      "Epoch 60/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0138 - acc: 0.9987\n",
      "Epoch 61/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0137 - acc: 0.9987\n",
      "Epoch 62/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0128 - acc: 0.9987\n",
      "Epoch 63/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0122 - acc: 0.9988\n",
      "Epoch 64/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0117 - acc: 0.9990\n",
      "Epoch 65/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0112 - acc: 0.9992\n",
      "Epoch 66/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0106 - acc: 0.9991\n",
      "Epoch 67/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0102 - acc: 0.9993\n",
      "Epoch 68/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0097 - acc: 0.9995\n",
      "Epoch 69/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0093 - acc: 0.9995\n",
      "Epoch 70/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0090 - acc: 0.9995\n",
      "Epoch 71/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0086 - acc: 0.9996\n",
      "Epoch 72/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0081 - acc: 0.9997\n",
      "Epoch 73/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0078 - acc: 0.9997\n",
      "Epoch 74/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0075 - acc: 0.9997\n",
      "Epoch 75/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0072 - acc: 0.9997\n",
      "Epoch 76/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0069 - acc: 0.9998\n",
      "Epoch 77/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0067 - acc: 0.9998\n",
      "Epoch 78/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0063 - acc: 0.9999\n",
      "Epoch 79/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0059 - acc: 0.9998\n",
      "Epoch 80/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0058 - acc: 0.9998\n",
      "Epoch 81/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0055 - acc: 0.9998\n",
      "Epoch 82/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0053 - acc: 0.9999\n",
      "Epoch 83/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0050 - acc: 0.9999\n",
      "Epoch 84/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0049 - acc: 0.9999\n",
      "Epoch 85/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0047 - acc: 0.9999\n",
      "Epoch 86/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0044 - acc: 0.9999\n",
      "Epoch 87/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0040 - acc: 0.9999\n",
      "Epoch 90/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0037 - acc: 0.9999\n",
      "Epoch 92/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0036 - acc: 0.9999\n",
      "Epoch 93/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0034 - acc: 0.9999\n",
      "Epoch 94/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0026 - acc: 1.0000\n",
      "30000/30000 [==============================] - 0s 14us/step\n",
      "10000/10000 [==============================] - 0s 13us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 72)                56520     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                730       \n",
      "=================================================================\n",
      "Total params: 57,250\n",
      "Trainable params: 57,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "30000/30000 [==============================] - 0s 7us/step - loss: 0.9393 - acc: 0.7694\n",
      "Epoch 2/100\n",
      "30000/30000 [==============================] - 0s 3us/step - loss: 0.3805 - acc: 0.9004\n",
      "Epoch 3/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.3000 - acc: 0.9187\n",
      "Epoch 4/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2579 - acc: 0.9294\n",
      "Epoch 5/100\n",
      "30000/30000 [==============================] - 0s 3us/step - loss: 0.2294 - acc: 0.9374\n",
      "Epoch 6/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2079 - acc: 0.9430\n",
      "Epoch 7/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1901 - acc: 0.9467\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1756 - acc: 0.9521\n",
      "Epoch 9/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1632 - acc: 0.9543\n",
      "Epoch 10/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1518 - acc: 0.9575\n",
      "Epoch 11/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1419 - acc: 0.9610\n",
      "Epoch 12/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1319 - acc: 0.9637\n",
      "Epoch 13/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1248 - acc: 0.9656\n",
      "Epoch 14/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1168 - acc: 0.9675\n",
      "Epoch 15/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1107 - acc: 0.9698\n",
      "Epoch 16/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1043 - acc: 0.9724\n",
      "Epoch 17/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0979 - acc: 0.9732\n",
      "Epoch 18/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0923 - acc: 0.9752\n",
      "Epoch 19/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0877 - acc: 0.9763\n",
      "Epoch 20/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0821 - acc: 0.9779\n",
      "Epoch 21/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0783 - acc: 0.9797\n",
      "Epoch 22/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0748 - acc: 0.9804\n",
      "Epoch 23/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0707 - acc: 0.9816\n",
      "Epoch 24/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0674 - acc: 0.9821\n",
      "Epoch 25/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0636 - acc: 0.9836\n",
      "Epoch 26/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0607 - acc: 0.9847\n",
      "Epoch 27/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0576 - acc: 0.9854\n",
      "Epoch 28/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0549 - acc: 0.9861\n",
      "Epoch 29/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0521 - acc: 0.9875\n",
      "Epoch 30/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0495 - acc: 0.9877\n",
      "Epoch 31/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0470 - acc: 0.9886\n",
      "Epoch 32/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0448 - acc: 0.9891\n",
      "Epoch 33/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0428 - acc: 0.9896\n",
      "Epoch 34/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0408 - acc: 0.9900\n",
      "Epoch 35/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0388 - acc: 0.9908\n",
      "Epoch 36/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0368 - acc: 0.9915\n",
      "Epoch 37/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0352 - acc: 0.9927\n",
      "Epoch 38/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0332 - acc: 0.9933\n",
      "Epoch 39/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0315 - acc: 0.9934\n",
      "Epoch 40/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0302 - acc: 0.9940\n",
      "Epoch 41/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0288 - acc: 0.9944\n",
      "Epoch 42/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0271 - acc: 0.9952\n",
      "Epoch 43/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0259 - acc: 0.9955\n",
      "Epoch 44/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0247 - acc: 0.9957\n",
      "Epoch 45/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0235 - acc: 0.9962\n",
      "Epoch 46/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0225 - acc: 0.9963\n",
      "Epoch 47/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0215 - acc: 0.9967\n",
      "Epoch 48/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0201 - acc: 0.9972\n",
      "Epoch 49/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0195 - acc: 0.9973\n",
      "Epoch 50/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0182 - acc: 0.9976\n",
      "Epoch 51/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0177 - acc: 0.9980\n",
      "Epoch 52/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0166 - acc: 0.9981\n",
      "Epoch 53/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0159 - acc: 0.9981\n",
      "Epoch 54/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0151 - acc: 0.9981\n",
      "Epoch 55/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0144 - acc: 0.9986\n",
      "Epoch 56/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0138 - acc: 0.9989\n",
      "Epoch 57/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0130 - acc: 0.9987\n",
      "Epoch 58/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0123 - acc: 0.9990\n",
      "Epoch 59/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0120 - acc: 0.9989\n",
      "Epoch 60/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0114 - acc: 0.9991\n",
      "Epoch 61/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0108 - acc: 0.9991\n",
      "Epoch 62/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0101 - acc: 0.9995\n",
      "Epoch 63/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0100 - acc: 0.9994\n",
      "Epoch 64/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0095 - acc: 0.9994\n",
      "Epoch 65/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0089 - acc: 0.9996\n",
      "Epoch 66/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0085 - acc: 0.9997\n",
      "Epoch 67/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0081 - acc: 0.9997\n",
      "Epoch 68/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0077 - acc: 0.9997\n",
      "Epoch 69/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0074 - acc: 0.9998\n",
      "Epoch 70/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0070 - acc: 0.9998\n",
      "Epoch 71/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0066 - acc: 0.9999\n",
      "Epoch 72/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0065 - acc: 0.9999\n",
      "Epoch 73/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0061 - acc: 0.9999\n",
      "Epoch 74/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0059 - acc: 0.9999\n",
      "Epoch 75/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0056 - acc: 0.9999\n",
      "Epoch 76/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0049 - acc: 0.9999\n",
      "Epoch 79/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0045 - acc: 0.9999\n",
      "Epoch 81/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0020 - acc: 1.0000\n",
      "30000/30000 [==============================] - 0s 14us/step\n",
      "10000/10000 [==============================] - 0s 13us/step\n",
      "Loading data. Cross-Validation ratio 0\n",
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(60000, 784)\n",
      "(60000, 10)\n",
      "Testing data (X, y)\n",
      "(10000, 784)\n",
      "(10000, 10)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Testing data (X, y)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "Validation on model:best_models/mnist/alpha0.8/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 48)                37680     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 48)                2352      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                490       \n",
      "=================================================================\n",
      "Total params: 40,522\n",
      "Trainable params: 40,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "30000/30000 [==============================] - 0s 8us/step - loss: 1.0618 - acc: 0.7339\n",
      "Epoch 2/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.4388 - acc: 0.8966\n",
      "Epoch 3/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.3215 - acc: 0.9164\n",
      "Epoch 4/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2694 - acc: 0.9272\n",
      "Epoch 5/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2362 - acc: 0.9347\n",
      "Epoch 6/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2098 - acc: 0.9421\n",
      "Epoch 7/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1900 - acc: 0.9462\n",
      "Epoch 8/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1727 - acc: 0.9517\n",
      "Epoch 9/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1579 - acc: 0.9557\n",
      "Epoch 10/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1449 - acc: 0.9591\n",
      "Epoch 11/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1333 - acc: 0.9623\n",
      "Epoch 12/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1232 - acc: 0.9655\n",
      "Epoch 13/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1136 - acc: 0.9684\n",
      "Epoch 14/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1060 - acc: 0.9705\n",
      "Epoch 15/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0973 - acc: 0.9737\n",
      "Epoch 16/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0901 - acc: 0.9753\n",
      "Epoch 17/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0840 - acc: 0.9773\n",
      "Epoch 18/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0773 - acc: 0.9788\n",
      "Epoch 19/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0709 - acc: 0.9808\n",
      "Epoch 20/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0662 - acc: 0.9828\n",
      "Epoch 21/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0621 - acc: 0.9838\n",
      "Epoch 22/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0568 - acc: 0.9851\n",
      "Epoch 23/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0523 - acc: 0.9872\n",
      "Epoch 24/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0489 - acc: 0.9880\n",
      "Epoch 25/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0454 - acc: 0.9891\n",
      "Epoch 26/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0420 - acc: 0.9904\n",
      "Epoch 27/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0388 - acc: 0.9914\n",
      "Epoch 28/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0358 - acc: 0.9928\n",
      "Epoch 29/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0336 - acc: 0.9927\n",
      "Epoch 30/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0310 - acc: 0.9937\n",
      "Epoch 31/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0285 - acc: 0.9947\n",
      "Epoch 32/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0266 - acc: 0.9951\n",
      "Epoch 33/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0246 - acc: 0.9955\n",
      "Epoch 34/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0226 - acc: 0.9966\n",
      "Epoch 35/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0208 - acc: 0.9968\n",
      "Epoch 36/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0193 - acc: 0.9974\n",
      "Epoch 37/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0182 - acc: 0.9973\n",
      "Epoch 38/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0163 - acc: 0.9983\n",
      "Epoch 39/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0152 - acc: 0.9984\n",
      "Epoch 40/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0139 - acc: 0.9986\n",
      "Epoch 41/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0131 - acc: 0.9988\n",
      "Epoch 42/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0120 - acc: 0.9990\n",
      "Epoch 43/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0110 - acc: 0.9993\n",
      "Epoch 44/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0102 - acc: 0.9994\n",
      "Epoch 45/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0093 - acc: 0.9996\n",
      "Epoch 46/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0087 - acc: 0.9997\n",
      "Epoch 47/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0082 - acc: 0.9997\n",
      "Epoch 48/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0075 - acc: 0.9998\n",
      "Epoch 49/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0071 - acc: 0.9998\n",
      "Epoch 50/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0064 - acc: 0.9999\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0062 - acc: 0.9998\n",
      "Epoch 52/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0057 - acc: 0.9999\n",
      "Epoch 53/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0053 - acc: 0.9999\n",
      "Epoch 54/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0049 - acc: 0.9999\n",
      "Epoch 55/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0043 - acc: 0.9999\n",
      "Epoch 57/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 9.7329e-04 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 9.3908e-04 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 8.9473e-04 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 8.5724e-04 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 8.1158e-04 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 7.8786e-04 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 7.5094e-04 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 7.1602e-04 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 6.9016e-04 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 6.6056e-04 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 6.3428e-04 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 6.0917e-04 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 5.7885e-04 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 5.5824e-04 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 5.3871e-04 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 5.1790e-04 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 4.9540e-04 - acc: 1.0000\n",
      "30000/30000 [==============================] - 0s 14us/step\n",
      "10000/10000 [==============================] - 0s 14us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 48)                37680     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 48)                2352      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                490       \n",
      "=================================================================\n",
      "Total params: 40,522\n",
      "Trainable params: 40,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "30000/30000 [==============================] - 0s 8us/step - loss: 1.0307 - acc: 0.7603\n",
      "Epoch 2/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.4339 - acc: 0.8905\n",
      "Epoch 3/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.3256 - acc: 0.9111\n",
      "Epoch 4/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2749 - acc: 0.9238\n",
      "Epoch 5/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2419 - acc: 0.9315\n",
      "Epoch 6/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2155 - acc: 0.9382\n",
      "Epoch 7/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1941 - acc: 0.9443\n",
      "Epoch 8/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1751 - acc: 0.9501\n",
      "Epoch 9/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1592 - acc: 0.9552\n",
      "Epoch 10/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1458 - acc: 0.9596\n",
      "Epoch 11/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1343 - acc: 0.9622\n",
      "Epoch 12/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1228 - acc: 0.9660\n",
      "Epoch 13/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1139 - acc: 0.9677\n",
      "Epoch 14/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1051 - acc: 0.9706\n",
      "Epoch 15/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0978 - acc: 0.9734\n",
      "Epoch 16/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0904 - acc: 0.9757\n",
      "Epoch 17/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0844 - acc: 0.9770\n",
      "Epoch 18/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0780 - acc: 0.9786\n",
      "Epoch 19/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0732 - acc: 0.9805\n",
      "Epoch 20/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0677 - acc: 0.9823\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0627 - acc: 0.9838\n",
      "Epoch 22/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0583 - acc: 0.9855\n",
      "Epoch 23/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0547 - acc: 0.9863\n",
      "Epoch 24/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0507 - acc: 0.9877\n",
      "Epoch 25/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0473 - acc: 0.9888\n",
      "Epoch 26/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0439 - acc: 0.9901\n",
      "Epoch 27/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0407 - acc: 0.9915\n",
      "Epoch 28/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0382 - acc: 0.9917\n",
      "Epoch 29/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0353 - acc: 0.9929\n",
      "Epoch 30/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0325 - acc: 0.9935\n",
      "Epoch 31/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0303 - acc: 0.9938\n",
      "Epoch 32/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0286 - acc: 0.9950\n",
      "Epoch 33/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0263 - acc: 0.9953\n",
      "Epoch 34/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0242 - acc: 0.9959\n",
      "Epoch 35/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0227 - acc: 0.9964\n",
      "Epoch 36/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0212 - acc: 0.9969\n",
      "Epoch 37/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0194 - acc: 0.9973\n",
      "Epoch 38/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0179 - acc: 0.9978\n",
      "Epoch 39/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0169 - acc: 0.9980\n",
      "Epoch 40/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0156 - acc: 0.9983\n",
      "Epoch 41/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0142 - acc: 0.9986\n",
      "Epoch 42/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0133 - acc: 0.9987\n",
      "Epoch 43/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0122 - acc: 0.9990\n",
      "Epoch 44/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0111 - acc: 0.9992\n",
      "Epoch 45/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0109 - acc: 0.9991\n",
      "Epoch 46/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0098 - acc: 0.9994\n",
      "Epoch 47/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0090 - acc: 0.9996\n",
      "Epoch 48/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0084 - acc: 0.9995\n",
      "Epoch 49/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0079 - acc: 0.9995\n",
      "Epoch 50/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0074 - acc: 0.9996\n",
      "Epoch 51/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0068 - acc: 0.9998\n",
      "Epoch 52/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0063 - acc: 0.9998\n",
      "Epoch 53/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0059 - acc: 0.9998\n",
      "Epoch 54/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0056 - acc: 0.9998\n",
      "Epoch 55/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0051 - acc: 0.9998\n",
      "Epoch 56/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0048 - acc: 0.9999\n",
      "Epoch 57/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0045 - acc: 0.9999\n",
      "Epoch 58/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0042 - acc: 0.9999\n",
      "Epoch 59/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0039 - acc: 0.9999\n",
      "Epoch 60/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0037 - acc: 0.9999\n",
      "Epoch 61/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0034 - acc: 0.9999\n",
      "Epoch 62/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 9.8459e-04 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 9.1931e-04 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 8.9153e-04 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 8.5690e-04 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 8.1643e-04 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 7.7912e-04 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 7.4517e-04 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 7.2046e-04 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 6.8122e-04 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 6.5736e-04 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 6.3095e-04 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 6.0685e-04 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 5.8124e-04 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 5.5827e-04 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 5.3636e-04 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 5.0906e-04 - acc: 1.0000\n",
      "30000/30000 [==============================] - 0s 14us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 14us/step\n",
      "Loading data. Cross-Validation ratio 0\n",
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(60000, 784)\n",
      "(60000, 10)\n",
      "Testing data (X, y)\n",
      "(10000, 784)\n",
      "(10000, 10)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Testing data (X, y)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "Validation on model:best_models/mnist/alpha1/bestModel_global.json\n",
      "\n",
      "Experiment on Fold  0\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 26,506\n",
      "Trainable params: 26,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "30000/30000 [==============================] - 0s 8us/step - loss: 1.1772 - acc: 0.6651\n",
      "Epoch 2/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.4155 - acc: 0.8914\n",
      "Epoch 3/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.3072 - acc: 0.9164\n",
      "Epoch 4/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2631 - acc: 0.9263\n",
      "Epoch 5/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2355 - acc: 0.9343\n",
      "Epoch 6/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2152 - acc: 0.9397\n",
      "Epoch 7/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1993 - acc: 0.9439\n",
      "Epoch 8/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1867 - acc: 0.9482\n",
      "Epoch 9/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1755 - acc: 0.9514\n",
      "Epoch 10/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1652 - acc: 0.9545\n",
      "Epoch 11/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1579 - acc: 0.9564\n",
      "Epoch 12/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1491 - acc: 0.9591\n",
      "Epoch 13/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1415 - acc: 0.9597\n",
      "Epoch 14/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1359 - acc: 0.9614\n",
      "Epoch 15/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1296 - acc: 0.9635\n",
      "Epoch 16/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1243 - acc: 0.9657\n",
      "Epoch 17/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1191 - acc: 0.9656\n",
      "Epoch 18/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1137 - acc: 0.9677\n",
      "Epoch 19/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1084 - acc: 0.9699\n",
      "Epoch 20/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1043 - acc: 0.9714\n",
      "Epoch 21/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1007 - acc: 0.9720\n",
      "Epoch 22/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0964 - acc: 0.9725\n",
      "Epoch 23/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0930 - acc: 0.9740\n",
      "Epoch 24/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0905 - acc: 0.9738\n",
      "Epoch 25/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0865 - acc: 0.9757\n",
      "Epoch 26/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0836 - acc: 0.9760\n",
      "Epoch 27/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0814 - acc: 0.9767\n",
      "Epoch 28/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0779 - acc: 0.9779\n",
      "Epoch 29/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0747 - acc: 0.9797\n",
      "Epoch 30/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0726 - acc: 0.9798\n",
      "Epoch 31/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0713 - acc: 0.9799\n",
      "Epoch 32/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0678 - acc: 0.9811\n",
      "Epoch 33/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0644 - acc: 0.9827\n",
      "Epoch 34/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0633 - acc: 0.9820\n",
      "Epoch 35/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0606 - acc: 0.9833\n",
      "Epoch 36/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0578 - acc: 0.9840\n",
      "Epoch 37/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0568 - acc: 0.9847\n",
      "Epoch 38/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0549 - acc: 0.9847\n",
      "Epoch 39/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0536 - acc: 0.9854\n",
      "Epoch 40/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0511 - acc: 0.9863\n",
      "Epoch 41/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0491 - acc: 0.9874\n",
      "Epoch 42/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0479 - acc: 0.9871\n",
      "Epoch 43/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0457 - acc: 0.9882\n",
      "Epoch 44/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0443 - acc: 0.9887\n",
      "Epoch 45/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0424 - acc: 0.9894\n",
      "Epoch 46/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0411 - acc: 0.9893\n",
      "Epoch 47/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0404 - acc: 0.9896\n",
      "Epoch 48/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0388 - acc: 0.9902\n",
      "Epoch 49/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0369 - acc: 0.9911\n",
      "Epoch 50/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0363 - acc: 0.9910\n",
      "Epoch 51/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 52/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0334 - acc: 0.9922\n",
      "Epoch 53/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0324 - acc: 0.9922\n",
      "Epoch 54/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0311 - acc: 0.9928\n",
      "Epoch 55/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0297 - acc: 0.9925\n",
      "Epoch 56/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0290 - acc: 0.9929\n",
      "Epoch 57/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0274 - acc: 0.9935\n",
      "Epoch 58/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0265 - acc: 0.9939\n",
      "Epoch 59/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0256 - acc: 0.9940\n",
      "Epoch 60/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0247 - acc: 0.9945\n",
      "Epoch 61/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0239 - acc: 0.9947\n",
      "Epoch 62/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0226 - acc: 0.9951\n",
      "Epoch 63/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0218 - acc: 0.9957\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0208 - acc: 0.9955\n",
      "Epoch 65/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0203 - acc: 0.9960\n",
      "Epoch 66/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0191 - acc: 0.9963\n",
      "Epoch 67/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0186 - acc: 0.9965\n",
      "Epoch 68/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0186 - acc: 0.9967\n",
      "Epoch 69/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0176 - acc: 0.9966\n",
      "Epoch 70/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0163 - acc: 0.9972\n",
      "Epoch 71/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0156 - acc: 0.9973\n",
      "Epoch 72/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0156 - acc: 0.9971\n",
      "Epoch 73/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0145 - acc: 0.9978\n",
      "Epoch 74/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0145 - acc: 0.9975\n",
      "Epoch 75/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0136 - acc: 0.9981\n",
      "Epoch 76/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0132 - acc: 0.9982\n",
      "Epoch 77/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0126 - acc: 0.9984\n",
      "Epoch 78/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0120 - acc: 0.9986\n",
      "Epoch 79/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0114 - acc: 0.9987\n",
      "Epoch 80/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0112 - acc: 0.9987\n",
      "Epoch 81/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0112 - acc: 0.9985\n",
      "Epoch 82/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0103 - acc: 0.9990\n",
      "Epoch 83/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0099 - acc: 0.9990\n",
      "Epoch 84/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0096 - acc: 0.9991\n",
      "Epoch 85/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0099 - acc: 0.9989\n",
      "Epoch 86/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0094 - acc: 0.9989\n",
      "Epoch 87/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0089 - acc: 0.9989\n",
      "Epoch 88/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0081 - acc: 0.9993\n",
      "Epoch 89/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0075 - acc: 0.9993\n",
      "Epoch 90/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0070 - acc: 0.9996\n",
      "Epoch 91/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0072 - acc: 0.9996\n",
      "Epoch 92/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0067 - acc: 0.9995\n",
      "Epoch 93/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0066 - acc: 0.9996\n",
      "Epoch 94/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0063 - acc: 0.9997\n",
      "Epoch 95/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0060 - acc: 0.9997\n",
      "Epoch 96/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0054 - acc: 0.9997\n",
      "Epoch 97/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0059 - acc: 0.9994\n",
      "Epoch 98/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0053 - acc: 0.9997\n",
      "Epoch 99/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0050 - acc: 0.9998\n",
      "Epoch 100/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0053 - acc: 0.9996\n",
      "30000/30000 [==============================] - 0s 14us/step\n",
      "10000/10000 [==============================] - 0s 13us/step\n",
      "\n",
      "Experiment on Fold  1\n",
      "Loaded model from disk\n",
      "Model needs training\n",
      "Created model for classification with loss function categorical_crossentropy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 26,506\n",
      "Trainable params: 26,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "30000/30000 [==============================] - 0s 8us/step - loss: 1.1790 - acc: 0.7023\n",
      "Epoch 2/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.4271 - acc: 0.8895\n",
      "Epoch 3/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.3165 - acc: 0.9140\n",
      "Epoch 4/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2714 - acc: 0.9247\n",
      "Epoch 5/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2442 - acc: 0.9305\n",
      "Epoch 6/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2250 - acc: 0.9374\n",
      "Epoch 7/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.2093 - acc: 0.9411\n",
      "Epoch 8/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1963 - acc: 0.9449\n",
      "Epoch 9/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1862 - acc: 0.9477\n",
      "Epoch 10/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1774 - acc: 0.9492\n",
      "Epoch 11/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1686 - acc: 0.9524\n",
      "Epoch 12/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1607 - acc: 0.9546\n",
      "Epoch 13/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1541 - acc: 0.9565\n",
      "Epoch 14/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1471 - acc: 0.9590\n",
      "Epoch 15/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1418 - acc: 0.9599\n",
      "Epoch 16/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1356 - acc: 0.9619\n",
      "Epoch 17/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1299 - acc: 0.9632\n",
      "Epoch 18/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1255 - acc: 0.9643\n",
      "Epoch 19/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1200 - acc: 0.9658\n",
      "Epoch 20/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1161 - acc: 0.9675\n",
      "Epoch 21/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1115 - acc: 0.9682\n",
      "Epoch 22/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1077 - acc: 0.9697\n",
      "Epoch 23/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1039 - acc: 0.9707\n",
      "Epoch 24/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.1008 - acc: 0.9718\n",
      "Epoch 25/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0971 - acc: 0.9728\n",
      "Epoch 26/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0935 - acc: 0.9734\n",
      "Epoch 27/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0913 - acc: 0.9739\n",
      "Epoch 28/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0876 - acc: 0.9756\n",
      "Epoch 29/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0858 - acc: 0.9758\n",
      "Epoch 30/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0819 - acc: 0.9766\n",
      "Epoch 31/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0800 - acc: 0.9774\n",
      "Epoch 32/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0773 - acc: 0.9787\n",
      "Epoch 33/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0739 - acc: 0.9792\n",
      "Epoch 34/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0721 - acc: 0.9799\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0696 - acc: 0.9804\n",
      "Epoch 36/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0683 - acc: 0.9815\n",
      "Epoch 37/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0654 - acc: 0.9825\n",
      "Epoch 38/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0640 - acc: 0.9824\n",
      "Epoch 39/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0618 - acc: 0.9830\n",
      "Epoch 40/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0599 - acc: 0.9843\n",
      "Epoch 41/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0569 - acc: 0.9846\n",
      "Epoch 42/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0561 - acc: 0.9853\n",
      "Epoch 43/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0544 - acc: 0.9848\n",
      "Epoch 44/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0528 - acc: 0.9866\n",
      "Epoch 45/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0514 - acc: 0.9867\n",
      "Epoch 46/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0497 - acc: 0.9862\n",
      "Epoch 47/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0477 - acc: 0.9873\n",
      "Epoch 48/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0461 - acc: 0.9874\n",
      "Epoch 49/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0455 - acc: 0.9886\n",
      "Epoch 50/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0435 - acc: 0.9892\n",
      "Epoch 51/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0422 - acc: 0.9895\n",
      "Epoch 52/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0411 - acc: 0.9895\n",
      "Epoch 53/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0394 - acc: 0.9898\n",
      "Epoch 54/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0384 - acc: 0.9908\n",
      "Epoch 55/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0378 - acc: 0.9904\n",
      "Epoch 56/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0363 - acc: 0.9915\n",
      "Epoch 57/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0353 - acc: 0.9915\n",
      "Epoch 58/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0340 - acc: 0.9920\n",
      "Epoch 59/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0339 - acc: 0.9920\n",
      "Epoch 60/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0313 - acc: 0.9928\n",
      "Epoch 61/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0307 - acc: 0.9927\n",
      "Epoch 62/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0293 - acc: 0.9936\n",
      "Epoch 63/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0290 - acc: 0.9938\n",
      "Epoch 64/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0266 - acc: 0.9947\n",
      "Epoch 65/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0279 - acc: 0.9934\n",
      "Epoch 66/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0271 - acc: 0.9940\n",
      "Epoch 67/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0251 - acc: 0.9949\n",
      "Epoch 68/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0237 - acc: 0.9951\n",
      "Epoch 69/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0234 - acc: 0.9952\n",
      "Epoch 70/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0228 - acc: 0.9955\n",
      "Epoch 71/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0214 - acc: 0.9959\n",
      "Epoch 72/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0210 - acc: 0.9961\n",
      "Epoch 73/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0206 - acc: 0.9958\n",
      "Epoch 74/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0201 - acc: 0.9964\n",
      "Epoch 75/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0196 - acc: 0.9961\n",
      "Epoch 76/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0185 - acc: 0.9967\n",
      "Epoch 77/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0180 - acc: 0.9969\n",
      "Epoch 78/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0178 - acc: 0.9969\n",
      "Epoch 79/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0162 - acc: 0.9979\n",
      "Epoch 80/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0160 - acc: 0.9974\n",
      "Epoch 81/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0151 - acc: 0.9977\n",
      "Epoch 82/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0151 - acc: 0.9976\n",
      "Epoch 83/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0144 - acc: 0.9981\n",
      "Epoch 84/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0138 - acc: 0.9981\n",
      "Epoch 85/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0136 - acc: 0.9981\n",
      "Epoch 86/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0126 - acc: 0.9981\n",
      "Epoch 87/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0127 - acc: 0.9984\n",
      "Epoch 88/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0119 - acc: 0.9984\n",
      "Epoch 89/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0112 - acc: 0.9988\n",
      "Epoch 90/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0109 - acc: 0.9987\n",
      "Epoch 91/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0104 - acc: 0.9986\n",
      "Epoch 92/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0106 - acc: 0.9987\n",
      "Epoch 93/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0095 - acc: 0.9992\n",
      "Epoch 94/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0096 - acc: 0.9991\n",
      "Epoch 95/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0092 - acc: 0.9991\n",
      "Epoch 96/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0089 - acc: 0.9990\n",
      "Epoch 97/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0089 - acc: 0.9992\n",
      "Epoch 98/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0085 - acc: 0.9993\n",
      "Epoch 99/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0082 - acc: 0.9993\n",
      "Epoch 100/100\n",
      "30000/30000 [==============================] - 0s 4us/step - loss: 0.0081 - acc: 0.9995\n",
      "30000/30000 [==============================] - 0s 14us/step\n",
      "10000/10000 [==============================] - 0s 14us/step\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "k = 2  #For 10-fold cross validation\n",
    "\n",
    "model_file_name = 'bestModel_global.json'\n",
    "weights_file_name = 'bestModel_global.h5'\n",
    "\n",
    "for dataset in test_sets.keys():\n",
    "    for alphaValue in alpha_folders:\n",
    "        \n",
    "        results_key = dataset + \"_\" +  alphaValue\n",
    "        \n",
    "        evaluations_cv = np.zeros(k)\n",
    "        evaluations_test = np.zeros(k)\n",
    "        \n",
    "        model_location = best_model_folder + '/' + dataset + '/' + alphaValue + '/' + model_file_name\n",
    "        \n",
    "        if weights_file_name != \"\":\n",
    "            weights_location = best_model_folder + '/' + dataset + '/' + alphaValue + '/' + weights_file_name\n",
    "        \n",
    "        dhandler, data_scaler, problem_type = test_sets[dataset]\n",
    "\n",
    "        #model = load_model(model_location, weights_location, problem_type)   \n",
    "        \n",
    "        data_handler = dhandler(data_scaler=data_scaler)\n",
    "        data_handler.load_data(verbose = 1, )\n",
    "        data_handler.print_data()\n",
    "        \n",
    "        folds = list(KFold(n_splits=k, shuffle=True).split(data_handler.X_train))\n",
    "        \n",
    "        print('Validation on model:' + model_location)\n",
    "        \n",
    "        for j, (train_idx, val_idx) in enumerate(folds):\n",
    "\n",
    "            print('\\nExperiment on Fold ', j)\n",
    "            \n",
    "            K.clear_session()  #Clear the previous tensorflow graph \n",
    "\n",
    "            X_train_cv = data_handler.X_train[train_idx]\n",
    "            y_train_cv = data_handler.y_train[train_idx]\n",
    "            X_valid_cv = data_handler.X_train[val_idx]\n",
    "            y_valid_cv = data_handler.y_train[val_idx]\n",
    "\n",
    "            model = load_model(model_location, \"\", problem_type)\n",
    "            model.summary()\n",
    "\n",
    "            model.fit(X_train_cv, y_train_cv, batch_size=512, epochs=100, verbose=1)\n",
    "\n",
    "            evaluation_cv = model.evaluate(X_valid_cv, y_valid_cv)\n",
    "            evaluation_test = model.evaluate(data_handler.X_test, data_handler.y_test)\n",
    "\n",
    "            evaluations_cv[j] = evaluation_cv[1]\n",
    "            evaluations_test[j] = evaluation_test[1]\n",
    "            \n",
    "        results[results_key] = (evaluations_cv, evaluations_test)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats for: \n",
      "cifar10_alpha0.6\n",
      "\n",
      "CrossVal stats: \n",
      "[0.48228 0.47912]\n",
      "DescribeResult(nobs=2, minmax=(0.47912, 0.48228), mean=0.4807, variance=4.992799999999988e-06, skewness=-5.263841545770484e-14, kurtosis=-2.0)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=2, minmax=(0.4722, 0.4731), mean=0.47265, variance=4.0500000000001073e-07, skewness=0.0, kurtosis=-2.0)\n",
      "\n",
      "Stats for: \n",
      "cifar10_alpha0.8\n",
      "\n",
      "CrossVal stats: \n",
      "[0.45608 0.45384]\n",
      "DescribeResult(nobs=2, minmax=(0.45384, 0.45608), mean=0.45496000000000003, variance=2.50879999999992e-06, skewness=-7.433231620042076e-14, kurtosis=-2.0)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=2, minmax=(0.4573, 0.462), mean=0.45965, variance=1.1045000000000176e-05, skewness=0.0, kurtosis=-2.0)\n",
      "\n",
      "Stats for: \n",
      "cifar10_alpha1\n",
      "\n",
      "CrossVal stats: \n",
      "[0.4702  0.45056]\n",
      "DescribeResult(nobs=2, minmax=(0.45056, 0.4702), mean=0.46038, variance=0.00019286479999999981, skewness=0.0, kurtosis=-2.0)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=2, minmax=(0.4517, 0.4788), mean=0.46525, variance=0.00036720500000000033, skewness=0.0, kurtosis=-2.0)\n",
      "\n",
      "Stats for: \n",
      "cmapss_alpha0.6\n",
      "\n",
      "CrossVal stats: \n",
      "[224.82083023 228.11022107]\n",
      "DescribeResult(nobs=2, minmax=(224.8208302325876, 228.11022107432456), mean=226.4655256534561, variance=5.410046054851447, skewness=-2.5952973261728562e-14, kurtosis=-2.0)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=2, minmax=(219.11973140716552, 237.39974731445312), mean=228.2597393608093, variance=167.07949078534395, skewness=4.615642454380568e-15, kurtosis=-2.0)\n",
      "\n",
      "Stats for: \n",
      "cmapss_alpha0.8\n",
      "\n",
      "CrossVal stats: \n",
      "[227.50490719 241.22934589]\n",
      "DescribeResult(nobs=2, minmax=(227.5049071904074, 241.22934588873315), mean=234.36712653957028, variance=94.18010879205059, skewness=0.0, kurtosis=-2.0)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=2, minmax=(220.53290069580078, 226.41139724731445), mean=223.4721489715576, variance=17.2783608530791, skewness=1.4550728291432453e-14, kurtosis=-1.9999999999999998)\n",
      "\n",
      "Stats for: \n",
      "cmapss_alpha1\n",
      "\n",
      "CrossVal stats: \n",
      "[265.05617487 250.84420467]\n",
      "DescribeResult(nobs=2, minmax=(250.84420467382986, 265.05617486703494), mean=257.9501897704324, variance=100.99004838627476, skewness=-5.940713133734531e-15, kurtosis=-2.0)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=2, minmax=(253.03692817687988, 349.19484130859377), mean=301.11588474273685, variance=4623.172128923116, skewness=-1.7676196594836998e-15, kurtosis=-2.0)\n",
      "\n",
      "Stats for: \n",
      "mnist_alpha0.6\n",
      "\n",
      "CrossVal stats: \n",
      "[0.9645     0.96803333]\n",
      "DescribeResult(nobs=2, minmax=(0.9645, 0.9680333333333333), mean=0.9662666666666666, variance=6.242222222222024e-06, skewness=9.428482173014818e-14, kurtosis=-2.0)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=2, minmax=(0.9678, 0.9694), mean=0.9686, variance=1.2800000000000733e-06, skewness=0.0, kurtosis=-2.0)\n",
      "\n",
      "Stats for: \n",
      "mnist_alpha0.8\n",
      "\n",
      "CrossVal stats: \n",
      "[0.9638     0.96286667]\n",
      "DescribeResult(nobs=2, minmax=(0.9628666666666666, 0.9638), mean=0.9633333333333334, variance=4.3555555555556323e-07, skewness=-3.5685163976084655e-13, kurtosis=-2.0)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=2, minmax=(0.9676, 0.9696), mean=0.9686, variance=2.0000000000000037e-06, skewness=0.0, kurtosis=-2.0)\n",
      "\n",
      "Stats for: \n",
      "mnist_alpha1\n",
      "\n",
      "CrossVal stats: \n",
      "[0.95536667 0.95536667]\n",
      "DescribeResult(nobs=2, minmax=(0.9553666666666667, 0.9553666666666667), mean=0.9553666666666667, variance=0.0, skewness=0.0, kurtosis=-3.0)\n",
      "\n",
      "Test stats: \n",
      "DescribeResult(nobs=2, minmax=(0.9572, 0.9581), mean=0.95765, variance=4.049999999999108e-07, skewness=0.0, kurtosis=-2.0)\n"
     ]
    }
   ],
   "source": [
    "for key in results.keys():\n",
    "    \n",
    "    print(\"\\nStats for: \")\n",
    "    print(key)\n",
    "    evaluations_cv, evaluations_test = results[key]\n",
    "    \n",
    "    print(\"\\nCrossVal stats: \")\n",
    "    print(evaluations_cv)\n",
    "    print(stats.describe(evaluations_cv))\n",
    "    \n",
    "    print(\"\\nTest stats: \")\n",
    "    print(stats.describe(evaluations_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
