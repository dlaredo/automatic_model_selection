{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic model selection\n",
    "\n",
    "Test notebook for automatic model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "#sys.path.append('/Users/davidlaredorazo/Documents/University_of_California/Research/Projects')\n",
    "sys.path.append('/media/controlslab/DATA/Projects')\n",
    "\n",
    "import automatic_model_selection\n",
    "from automatic_model_selection import Configuration\n",
    "from ann_encoding_rules import Layers\n",
    "from CMAPSAuxFunctions import TrainValTensorBoard\n",
    "\n",
    "#Tunable model\n",
    "from ann_framework.tunable_model.tunable_model import SequenceTunableModelRegression\n",
    "#from tunable_model import SequenceTunableModelRegression\n",
    "\n",
    "#Data handlers\n",
    "from ann_framework.data_handlers.data_handler_CMAPS import CMAPSDataHandler\n",
    "from ann_framework.data_handlers.data_handler_MNIST import MNISTDataHandler\n",
    "#from data_handler_MNIST import MNISTDataHandler\n",
    "#from data_handler_CMAPS import CMAPSDataHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cmaps data handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cmaps_dhandler():\n",
    "\n",
    "    #Selected as per CNN paper\n",
    "    features = ['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', 'BPR', \n",
    "    'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "    selected_indices = np.array([2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21])\n",
    "    selected_features = list(features[i] for i in selected_indices-1)\n",
    "    data_folder = '../CMAPSSData'\n",
    "\n",
    "    window_size = 25\n",
    "    window_stride = 1\n",
    "    max_rul = 130\n",
    "\n",
    "    dHandler_cmaps = CMAPSDataHandler(data_folder, 1, selected_features, max_rul, window_size, window_stride)\n",
    "\n",
    "    input_shape = (len(selected_features)*window_size, )\n",
    "\n",
    "    return dHandler_cmaps, input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to save top models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_best_models(best_models_list, global_best_model_index, saveto, train_epochs=100):\n",
    "    \n",
    "    n_models = len(best_models_list)\n",
    "    \n",
    "    for ind_model, i in zip(best_models_list, range(n_models)):\n",
    "        \n",
    "        tModel = ind_model.tModel\n",
    "        kmodel = tModel.model\n",
    "        model_json = kmodel.to_json()\n",
    "        \n",
    "        #Save model's architecture\n",
    "        string_append = str(i) if i != global_best_model_index else 'global'\n",
    "        with open(saveto+\"bestModel_\"+string_append+\".json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "            \n",
    "    #Train the global best\n",
    "    tModel = best_models_list[global_best_model_index].tModel\n",
    "    print(tModel.data_handler.data_scaler)\n",
    "        \n",
    "    tModel.load_data(unroll=True, verbose=1, cross_validation_ratio=0)\n",
    "    tModel.print_data()\n",
    "    tModel.epochs = train_epochs\n",
    "\n",
    "    tModel.train_model(verbose=1)\n",
    "    tModel.evaluate_model(['rhs', 'rmse'], round=2)\n",
    "    kmodel = tModel.model\n",
    "            \n",
    "    # serialize weights to HDF5\n",
    "    kmodel.save_weights(saveto+\"bestModel_global.h5\")\n",
    "    \n",
    "    print(\"Saved models for dataset 1 to disk\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching experiment 1\n",
      "\n",
      "Generation 1\n",
      "Fetching to keras\n",
      "Evaluating population\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 816)               640560    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 816)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               418304    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 264)               135432    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 920)               243800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 920)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 368)               338928    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 368)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 48)                17712     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                490       \n",
      "=================================================================\n",
      "Total params: 1,795,226\n",
      "Trainable params: 1,795,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlaredorazo/anaconda/envs/tensorflow/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 11s 237us/step - loss: 1.9130 - acc: 0.2655 - val_loss: 1.4125 - val_acc: 0.4753\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 11s 219us/step - loss: 1.1427 - acc: 0.6158 - val_loss: 0.8047 - val_acc: 0.7948\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 10s 218us/step - loss: 0.6914 - acc: 0.8297 - val_loss: 0.5017 - val_acc: 0.8821\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 11s 225us/step - loss: 0.4870 - acc: 0.8865 - val_loss: 0.3967 - val_acc: 0.9053\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 11s 224us/step - loss: 0.3804 - acc: 0.9109 - val_loss: 0.3238 - val_acc: 0.9218\n",
      "12000/12000 [==============================] - 2s 176us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 104)               81640     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 104)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 624)               65520     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 624)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                6250      \n",
      "=================================================================\n",
      "Total params: 153,410\n",
      "Trainable params: 153,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 2s 47us/step - loss: 0.7180 - acc: 0.7704 - val_loss: 0.3041 - val_acc: 0.9077\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.3298 - acc: 0.9006 - val_loss: 0.1969 - val_acc: 0.9416\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.2569 - acc: 0.9214 - val_loss: 0.1676 - val_acc: 0.9477\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 2s 39us/step - loss: 0.2201 - acc: 0.9326 - val_loss: 0.1573 - val_acc: 0.9533\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.1989 - acc: 0.9389 - val_loss: 0.1363 - val_acc: 0.9584\n",
      "12000/12000 [==============================] - 1s 51us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 768)               602880    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 48)                36912     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 776)               38024     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 776)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                7770      \n",
      "=================================================================\n",
      "Total params: 685,586\n",
      "Trainable params: 685,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 5s 114us/step - loss: 0.6561 - acc: 0.7829 - val_loss: 0.2519 - val_acc: 0.9233\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 5s 112us/step - loss: 0.2519 - acc: 0.9229 - val_loss: 0.1685 - val_acc: 0.9500\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 5s 112us/step - loss: 0.1816 - acc: 0.9436 - val_loss: 0.1303 - val_acc: 0.9601\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 5s 104us/step - loss: 0.1524 - acc: 0.9532 - val_loss: 0.1202 - val_acc: 0.9635\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 5s 105us/step - loss: 0.1299 - acc: 0.9601 - val_loss: 0.1116 - val_acc: 0.9674\n",
      "12000/12000 [==============================] - 1s 84us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 208)               163280    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 48)                10032     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 568)               27832     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 568)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 216)               122904    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 216)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1016)              220472    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                10170     \n",
      "=================================================================\n",
      "Total params: 1,170,130\n",
      "Trainable params: 1,170,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 10s 202us/step - loss: 2.0431 - acc: 0.2039 - val_loss: 1.3779 - val_acc: 0.4048\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 10s 212us/step - loss: 1.1090 - acc: 0.5676 - val_loss: 0.7226 - val_acc: 0.7376\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 10s 211us/step - loss: 0.6690 - acc: 0.7894 - val_loss: 0.4345 - val_acc: 0.8883\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 9s 178us/step - loss: 0.4721 - acc: 0.8709 - val_loss: 0.3316 - val_acc: 0.9144\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 9s 180us/step - loss: 0.3740 - acc: 0.9016 - val_loss: 0.2927 - val_acc: 0.9267\n",
      "12000/12000 [==============================] - 2s 145us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 248)               194680    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 248)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 464)               115536    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 536)               249240    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 536)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 112)               60144     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                1130      \n",
      "=================================================================\n",
      "Total params: 620,730\n",
      "Trainable params: 620,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 5s 114us/step - loss: 0.7036 - acc: 0.7728 - val_loss: 0.3294 - val_acc: 0.9027\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 4s 92us/step - loss: 0.4033 - acc: 0.8768 - val_loss: 0.2821 - val_acc: 0.9166\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 4s 90us/step - loss: 0.3510 - acc: 0.8933 - val_loss: 0.2312 - val_acc: 0.9304\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 4s 89us/step - loss: 0.3108 - acc: 0.9063 - val_loss: 0.2289 - val_acc: 0.9335\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.2837 - acc: 0.9141 - val_loss: 0.2037 - val_acc: 0.9377\n",
      "12000/12000 [==============================] - 1s 91us/step\n",
      "\n",
      "Generating offsprings\n",
      "Applying Mutation\n",
      "Launch new generation?: True\n",
      "\n",
      "Generation 2\n",
      "Fetching to keras\n",
      "Evaluating population\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 72)                56520     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 624)               45552     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 624)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                6250      \n",
      "=================================================================\n",
      "Total params: 108,322\n",
      "Trainable params: 108,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.6114 - acc: 0.8157 - val_loss: 0.3199 - val_acc: 0.9058\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.2992 - acc: 0.9103 - val_loss: 0.2590 - val_acc: 0.9219\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.2257 - acc: 0.9327 - val_loss: 0.2032 - val_acc: 0.9414\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1811 - acc: 0.9457 - val_loss: 0.1657 - val_acc: 0.9504\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1540 - acc: 0.9526 - val_loss: 0.1541 - val_acc: 0.9538\n",
      "12000/12000 [==============================] - 0s 36us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 768)               602880    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 48)                36912     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                490       \n",
      "=================================================================\n",
      "Total params: 640,282\n",
      "Trainable params: 640,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.6818 - acc: 0.7971 - val_loss: 0.3216 - val_acc: 0.9093\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.3340 - acc: 0.9060 - val_loss: 0.2630 - val_acc: 0.9217\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 4s 86us/step - loss: 0.2679 - acc: 0.9232 - val_loss: 0.2183 - val_acc: 0.9341\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 3s 72us/step - loss: 0.2262 - acc: 0.9355 - val_loss: 0.1691 - val_acc: 0.9499\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 5s 94us/step - loss: 0.1982 - acc: 0.9424 - val_loss: 0.1350 - val_acc: 0.9584\n",
      "12000/12000 [==============================] - 1s 76us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 768)               602880    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                7690      \n",
      "=================================================================\n",
      "Total params: 610,570\n",
      "Trainable params: 610,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 4s 91us/step - loss: 0.5338 - acc: 0.8356 - val_loss: 0.2784 - val_acc: 0.9149\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.2320 - acc: 0.9326 - val_loss: 0.1812 - val_acc: 0.9487\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.1707 - acc: 0.9497 - val_loss: 0.1511 - val_acc: 0.9546\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 3s 67us/step - loss: 0.1353 - acc: 0.9599 - val_loss: 0.1178 - val_acc: 0.9656\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 3s 62us/step - loss: 0.1154 - acc: 0.9656 - val_loss: 0.1088 - val_acc: 0.9672\n",
      "12000/12000 [==============================] - 1s 72us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 536)               420760    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 536)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 568)               305016    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 568)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 216)               122904    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 216)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1016)              220472    \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 10)                10170     \n",
      "=================================================================\n",
      "Total params: 1,694,762\n",
      "Trainable params: 1,694,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 11s 220us/step - loss: 1.6660 - acc: 0.3649 - val_loss: 0.9005 - val_acc: 0.6924\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 9s 197us/step - loss: 0.7034 - acc: 0.7760 - val_loss: 0.5735 - val_acc: 0.8243\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 9s 195us/step - loss: 0.4527 - acc: 0.8749 - val_loss: 0.3131 - val_acc: 0.9141\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 9s 195us/step - loss: 0.3356 - acc: 0.9098 - val_loss: 0.2525 - val_acc: 0.9291\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 9s 195us/step - loss: 0.2553 - acc: 0.9306 - val_loss: 0.2109 - val_acc: 0.9418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000/12000 [==============================] - 2s 158us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 776)               609160    \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 48)                37296     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 776)               38024     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 776)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 10)                7770      \n",
      "=================================================================\n",
      "Total params: 692,250\n",
      "Trainable params: 692,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 8s 158us/step - loss: 0.6473 - acc: 0.7818 - val_loss: 0.2280 - val_acc: 0.9277\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 7s 148us/step - loss: 0.2366 - acc: 0.9272 - val_loss: 0.2060 - val_acc: 0.9318\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 7s 136us/step - loss: 0.1547 - acc: 0.9530 - val_loss: 0.1218 - val_acc: 0.9616\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 7s 146us/step - loss: 0.1268 - acc: 0.9614 - val_loss: 0.1231 - val_acc: 0.9626\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 6s 123us/step - loss: 0.1073 - acc: 0.9667 - val_loss: 0.1117 - val_acc: 0.9656\n",
      "12000/12000 [==============================] - 1s 93us/step\n",
      "\n",
      "Generating offsprings\n",
      "Applying Mutation\n",
      "Launch new generation?: True\n",
      "\n",
      "Generation 3\n",
      "Fetching to keras\n",
      "Evaluating population\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 768)               602880    \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                7690      \n",
      "=================================================================\n",
      "Total params: 610,570\n",
      "Trainable params: 610,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 6s 132us/step - loss: 0.5413 - acc: 0.8377 - val_loss: 0.2545 - val_acc: 0.9267\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 5s 113us/step - loss: 0.2174 - acc: 0.9364 - val_loss: 0.1813 - val_acc: 0.9484\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.1562 - acc: 0.9543 - val_loss: 0.1533 - val_acc: 0.9561\n",
      "Epoch 4/5\n",
      "44544/48000 [==========================>...] - ETA: 0s - loss: 0.1248 - acc: 0.9634- ETA: 0s - loss: 0.1250 - acc: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-70d3d9c9dd69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Launching experiment {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_experiments\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     best = automatic_model_selection.run_experiment(config, dHandler_mnist, count_experiments + 1, \n\u001b[0;32m---> 37\u001b[0;31m                                                     unroll=unroll, verbose_data=0, tModel_scaler=min_max_scaler)\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mglobal_best_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/University_of_California/Research/Projects/automatic_model_selection/code/automatic_model_selection.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(configuration, data_handler, experiment_number, unroll, verbose_data, tModel_scaler)\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0mlaunch_new_generation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_evolutionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch_new_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfiguration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_similar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfiguration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m                 \u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworst_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworst_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_population\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfiguration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtModel_scaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworst_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munroll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nPopulation at generation \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneration_count\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/University_of_California/Research/Projects/automatic_model_selection/code/automatic_model_selection.py\u001b[0m in \u001b[0;36mevaluate_population\u001b[0;34m(population, configuration, data_handler, tModel_scaler, best_model, worst_model, unroll, verbose_data)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindividual\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mindividual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                 \u001b[0mindividual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_fitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfiguration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_validation_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfiguration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_scaler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfiguration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize_scaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munroll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m                 \u001b[0mindividual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindividual_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/University_of_California/Research/Projects/automatic_model_selection/code/nn_evolutionary.py\u001b[0m in \u001b[0;36mcompute_fitness\u001b[0;34m(self, epochs, cross_validation_ratio, size_scaler, verbose_data, unroll)\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainable_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_validation_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mveborse_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munroll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                 \u001b[0mmetric_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/University_of_California/Research/Projects/automatic_model_selection/code/nn_evolutionary.py\u001b[0m in \u001b[0;36mpartial_run\u001b[0;34m(self, cross_validation_ratio, epochs, verbose_data, veborse_train, unroll)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearningRate_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mveborse_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/University_of_California/Research/Projects/ann_framework/tunable_model/tunable_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, verbose, learningRate_scheduler, tf_session, tensorboard)\u001b[0m\n\u001b[1;32m     79\u001b[0m                                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training with cv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                                 \u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X_crossVal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y_crossVal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training without cv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"Input can be of 3 types, ANN (1), CNN (2) or RNN (3)\"\"\"\n",
    "architecture_type = Layers.FullyConnected\n",
    "problem_type = 2  #1 for regression, 2 for classification\n",
    "output_shape = 10 #If regression applies, number of classes\n",
    "input_shape = (784,)\n",
    "pop_size = 5\n",
    "tournament_size = 3\n",
    "max_similar = 3\n",
    "total_experiments = 5\n",
    "count_experiments = 0\n",
    "unroll = True\n",
    "\n",
    "global_best_list = []\n",
    "global_best = None\n",
    "global_best_index = 0\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "t = datetime.datetime.now()\n",
    "\n",
    "logging.basicConfig(filename='logs/nn_evolution_mnist_' + t.strftime('%m%d%Y%H%M%S') + '.log', level=logging.INFO, \n",
    "                        format='%(levelname)s:%(threadName)s:%(message)s', datefmt='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "#cmaps datahandler\n",
    "#dhandler_cmaps, input_shape = cmaps_dhandler()\n",
    "\n",
    "#mnist datahandler\n",
    "dHandler_mnist = MNISTDataHandler()\n",
    "\n",
    "config = Configuration(architecture_type, problem_type, input_shape, output_shape, pop_size, tournament_size, max_similar, epochs=5, cross_val=0.2, size_scaler=0.4,\n",
    "                       max_generations=10, binary_selection=True, mutation_ratio=0.4, similarity_threshold=0.2, more_layers_prob=0.8)\n",
    "\n",
    "while count_experiments < total_experiments:\n",
    "    print(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    logging.info(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    best = automatic_model_selection.run_experiment(config, dHandler_mnist, count_experiments + 1, \n",
    "                                                    unroll=unroll, verbose_data=0, tModel_scaler=min_max_scaler)\n",
    "\n",
    "    global_best_list.append(best)\n",
    "\n",
    "    if global_best == None:\n",
    "        global_best = best\n",
    "    else:\n",
    "        if best.fitness < global_best.fitness:\n",
    "            global_best = best\n",
    "            global_best_index = count_experiments\n",
    "\n",
    "    count_experiments =  count_experiments + 1\n",
    "\n",
    "print(\"Global best list\\n\")\n",
    "logging.info(\"Global best list\\n\")\n",
    "automatic_model_selection.print_best(global_best_list)\n",
    "\n",
    "print(\"Global best is\\n\")\n",
    "print(global_best)\n",
    "logging.info(\"Global best is\\n\")\n",
    "logging.info(global_best)\n",
    "\n",
    "save_best_models(global_best_list, global_best_index, 'best_models/mnist/', train_epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on CMAPSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Input can be of 3 types, ANN (1), CNN (2) or RNN (3)\"\"\"\n",
    "architecture_type = Layers.FullyConnected\n",
    "problem_type = 1  #1 for regression, 2 for classification\n",
    "output_shape = 1 #If regression applies, number of classes\n",
    "input_shape = (784,)\n",
    "pop_size = 5\n",
    "tournament_size = 3\n",
    "max_similar = 3\n",
    "total_experiments = 5\n",
    "count_experiments = 0\n",
    "unroll = True\n",
    "\n",
    "global_best_list = []\n",
    "global_best = None\n",
    "global_best_index = 0\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "t = datetime.datetime.now()\n",
    "\n",
    "logging.basicConfig(filename='logs/nn_evolution_cmaps_' + t.strftime('%m%d%Y%H%M%S') + '.log', level=logging.INFO, \n",
    "                        format='%(levelname)s:%(threadName)s:%(message)s', datefmt='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "#cmaps datahandler\n",
    "dhandler_cmaps, input_shape = cmaps_dhandler()\n",
    "print(input_shape)\n",
    "\n",
    "#mnist datahandler\n",
    "#dHandler_mnist = MNISTDataHandler()\n",
    "\n",
    "config = Configuration(architecture_type, problem_type, input_shape, output_shape, pop_size, tournament_size, max_similar, epochs=5, cross_val=0.2, size_scaler=0.4,\n",
    "                       max_generations=10, binary_selection=True, mutation_ratio=0.4, similarity_threshold=0.2, more_layers_prob=0.8)\n",
    "\n",
    "while count_experiments < total_experiments:\n",
    "    print(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    logging.info(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    best = automatic_model_selection.run_experiment(config, dhandler_cmaps, count_experiments + 1, \n",
    "                                                    unroll=unroll, verbose_data=0, tModel_scaler=min_max_scaler)\n",
    "\n",
    "    global_best_list.append(best)\n",
    "\n",
    "    if global_best == None:\n",
    "        global_best = best\n",
    "    else:\n",
    "        if best.fitness < global_best.fitness:\n",
    "            global_best = best\n",
    "            global_best_index = count_experiments\n",
    "\n",
    "    count_experiments =  count_experiments + 1\n",
    "\n",
    "print(\"Global best list\\n\")\n",
    "logging.info(\"Global best list\\n\")\n",
    "automatic_model_selection.print_best(global_best_list)\n",
    "\n",
    "print(\"Global best is\\n\")\n",
    "print(global_best)\n",
    "logging.info(\"Global best is\\n\")\n",
    "logging.info(global_best)\n",
    "\n",
    "save_best_models(global_best_list, global_best_index, 'best_models/cmapss/', train_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save_best_models(global_best_list, global_best_index, train_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
