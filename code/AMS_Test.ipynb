{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic model selection\n",
    "\n",
    "Test notebook for automatic model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.\n",
      "Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-01-30_17-52-37_8003/logs.\n",
      "Waiting for redis server at 127.0.0.1:61766 to respond...\n",
      "Waiting for redis server at 127.0.0.1:28987 to respond...\n",
      "Starting Redis shard with 10.0 GB max memory.\n",
      "Starting the Plasma object store with 3.435973836 GB memory using /tmp.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': None,\n",
       " 'object_store_address': '/tmp/ray/session_2019-01-30_17-52-37_8003/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2019-01-30_17-52-37_8003/sockets/raylet',\n",
       " 'redis_address': '10.34.5.154:61766',\n",
       " 'webui_url': None}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "#sys.path.append('/Users/davidlaredorazo/Documents/University_of_California/Research/Projects')\n",
    "sys.path.append('/media/controlslab/DATA/Projects')\n",
    "\n",
    "import automatic_model_selection\n",
    "from automatic_model_selection import Configuration\n",
    "from ann_encoding_rules import Layers\n",
    "from CMAPSAuxFunctions import TrainValTensorBoard\n",
    "\n",
    "#Tunable model\n",
    "from ann_framework.tunable_model.tunable_model import SequenceTunableModelRegression\n",
    "#from tunable_model import SequenceTunableModelRegression\n",
    "\n",
    "#Data handlers\n",
    "from ann_framework.data_handlers.data_handler_CMAPS import CMAPSDataHandler\n",
    "from ann_framework.data_handlers.data_handler_MNIST import MNISTDataHandler\n",
    "#from data_handler_MNIST import MNISTDataHandler\n",
    "#from data_handler_CMAPS import CMAPSDataHandler\n",
    "\n",
    "import ray\n",
    "from ray_logger import LoggingActor\n",
    "\n",
    "ray.init(num_cpus=4, include_webui=False, ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cmaps data handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cmaps_dhandler():\n",
    "\n",
    "    #Selected as per CNN paper\n",
    "    features = ['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', 'BPR', \n",
    "    'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "    selected_indices = np.array([2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21])\n",
    "    selected_features = list(features[i] for i in selected_indices-1)\n",
    "    data_folder = '../CMAPSSData'\n",
    "\n",
    "    window_size = 25\n",
    "    window_stride = 1\n",
    "    max_rul = 130\n",
    "\n",
    "    dHandler_cmaps = CMAPSDataHandler(data_folder, 1, selected_features, max_rul, window_size, window_stride)\n",
    "\n",
    "    input_shape = (len(selected_features)*window_size, )\n",
    "\n",
    "    return dHandler_cmaps, input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to save top models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_best_models(best_models_list, global_best_model_index, saveto, train_epochs=100):\n",
    "    \n",
    "    n_models = len(best_models_list)\n",
    "    \n",
    "    for ind_model, i in zip(best_models_list, range(n_models)):\n",
    "        \n",
    "        tModel = ind_model.tModel\n",
    "        kmodel = tModel.model\n",
    "        model_json = kmodel.to_json()\n",
    "        \n",
    "        #Save model's architecture\n",
    "        string_append = str(i) if i != global_best_model_index else 'global'\n",
    "        with open(saveto+\"bestModel_\"+string_append+\".json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "            \n",
    "    #Train the global best\n",
    "    tModel = best_models_list[global_best_model_index].tModel\n",
    "    print(tModel.data_handler.data_scaler)\n",
    "        \n",
    "    tModel.load_data(unroll=True, verbose=1, cross_validation_ratio=0)\n",
    "    tModel.print_data()\n",
    "    tModel.epochs = train_epochs\n",
    "\n",
    "    tModel.train_model(verbose=1)\n",
    "    tModel.evaluate_model(metrics, round=round)\n",
    "    kmodel = tModel.model\n",
    "            \n",
    "    # serialize weights to HDF5\n",
    "    kmodel.save_weights(saveto+\"bestModel_global.h5\")\n",
    "    \n",
    "    print(\"Saved models for dataset 1 to disk\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Launching experiment 1\n",
      "Starting model optimization: Problem type 2, Architecture type Layers.FullyConnected\n",
      "Parameters:\n",
      "Input shape: (784,), Output shape: 10, cross_val ratio: 0.2, Generations: 10, Population size: 5, Tournament size: 3, Binary selection: True, Mutation ratio: 0.4, Size scaler: 0.4\n",
      "\n",
      "\n",
      "Generation 1\n",
      "similar = 0\n",
      "{(0, 1): 0.8275832922793668, (0, 2): 1.0, (0, 3): 0.6551822966972979, (0, 4): 0.7400162056555, (1, 2): 0.7895031001996741, (1, 3): 0.9697768243330709, (1, 4): 0.7082451770739364, (2, 3): 0.4844122741981392, (2, 4): 0.5411669686496219, (3, 4): 0.6312913878979918}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching experiment 1\n",
      "\n",
      "Generation 1\n",
      "Ray fetching to keras and evaluating population\n",
      "[ObjectID(010000007e31931bd8df795b38f04aca07c4f240), ObjectID(010000001d96e834d3fa41e5a1be7e30a07a6f61), ObjectID(010000008f55eff6d13ccc12abf0143706b45e6f), ObjectID(01000000f936b301111034c8a64a09af8b180c51), ObjectID(01000000286231d090f2427533d2b77580688718)]\n",
      "[1, 1, 1, 1, 1]\n",
      "{1: ['scaler', MinMaxScaler(copy=True, feature_range=(-1, 1))], 5: ['scaler', MinMaxScaler(copy=True, feature_range=(-1, 1))], 2: ['scaler', MinMaxScaler(copy=True, feature_range=(-1, 1))], 3: ['scaler', MinMaxScaler(copy=True, feature_range=(-1, 1))], 4: ['scaler', MinMaxScaler(copy=True, feature_range=(-1, 1))]}\n",
      "Exiting run experiment\n",
      "Executed experiments 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"Global best list\\n\")\\nlogging.info(\"Global best list\\n\")\\nautomatic_model_selection.print_best(global_best_list)\\n\\nprint(\"Global best is\\n\")\\nprint(global_best)\\nlogging.info(\"Global best is\\n\")\\nlogging.info(global_best)\\n\\nsave_best_models(global_best_list, global_best_index, \\'best_models/mnist/\\', train_epochs=200)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Input can be of 3 types, ANN (1), CNN (2) or RNN (3)\"\"\"\n",
    "architecture_type = Layers.FullyConnected\n",
    "problem_type = 2  #1 for regression, 2 for classification\n",
    "output_shape = 10 #If regression applies, number of classes\n",
    "input_shape = (784,)\n",
    "pop_size = 5\n",
    "tournament_size = 3\n",
    "max_similar = 3\n",
    "total_experiments = 1\n",
    "count_experiments = 0\n",
    "unroll = True\n",
    "\n",
    "global_best_list = []\n",
    "global_best = None\n",
    "global_best_index = 0\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "t = datetime.datetime.now()\n",
    "\n",
    "logging.basicConfig(filename='logs/nn_evolution_mnist_' + t.strftime('%m%d%Y%H%M%S') + '.log', level=logging.INFO, \n",
    "                        format='%(levelname)s:%(threadName)s:%(message)s', datefmt='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "raylogger = LoggingActor.remote()\n",
    "\n",
    "#cmaps datahandler\n",
    "#dhandler_cmaps, input_shape = cmaps_dhandler()\n",
    "\n",
    "#mnist datahandler\n",
    "dHandler_mnist = MNISTDataHandler()\n",
    "\n",
    "config = Configuration(architecture_type, problem_type, input_shape, output_shape, pop_size, tournament_size, max_similar, epochs=5, cross_val=0.2, size_scaler=0.4,\n",
    "                       max_generations=10, binary_selection=True, mutation_ratio=0.4, similarity_threshold=0.2, more_layers_prob=0.8)\n",
    "\n",
    "while count_experiments < total_experiments:\n",
    "    print(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    logging.info(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    best = automatic_model_selection.run_experiment(config, dHandler_mnist, count_experiments + 1, \n",
    "                                                    unroll=unroll, verbose_data=0, tModel_scaler=min_max_scaler,\n",
    "                                                   logging_actor=raylogger)\n",
    "\n",
    "    \"\"\"\n",
    "    global_best_list.append(best)\n",
    "\n",
    "    if global_best == None:\n",
    "        global_best = best\n",
    "    else:\n",
    "        if best.fitness < global_best.fitness:\n",
    "            global_best = best\n",
    "            global_best_index = count_experiments\n",
    "\n",
    "    \"\"\"\n",
    "    logs = ray.get(raylogger.get_logs.remote())\n",
    "    print(logs)\n",
    "    \n",
    "    print(\"Exiting run experiment\")\n",
    "    count_experiments =  count_experiments + 1\n",
    "    print(\"Executed experiments \" +str(count_experiments))\n",
    "\n",
    "\"\"\"\n",
    "print(\"Global best list\\n\")\n",
    "logging.info(\"Global best list\\n\")\n",
    "automatic_model_selection.print_best(global_best_list)\n",
    "\n",
    "print(\"Global best is\\n\")\n",
    "print(global_best)\n",
    "logging.info(\"Global best is\\n\")\n",
    "logging.info(global_best)\n",
    "\n",
    "save_best_models(global_best_list, global_best_index, 'best_models/mnist/', train_epochs=200)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on CMAPSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\narchitecture_type = Layers.FullyConnected\\nproblem_type = 1  #1 for regression, 2 for classification\\noutput_shape = 1 #If regression applies, number of classes\\ninput_shape = (784,)\\npop_size = 5\\ntournament_size = 3\\nmax_similar = 3\\ntotal_experiments = 5\\ncount_experiments = 0\\nunroll = True\\n\\nglobal_best_list = []\\nglobal_best = None\\nglobal_best_index = 0\\n\\nmin_max_scaler = MinMaxScaler(feature_range=(-1, 1))\\n\\nt = datetime.datetime.now()\\n\\nlogging.basicConfig(filename=\\'logs/nn_evolution_cmaps_\\' + t.strftime(\\'%m%d%Y%H%M%S\\') + \\'.log\\', level=logging.INFO, \\n                        format=\\'%(levelname)s:%(threadName)s:%(message)s\\', datefmt=\\'%m/%d/%Y %H:%M:%S\\')\\n\\n#cmaps datahandler\\ndhandler_cmaps, input_shape = cmaps_dhandler()\\nprint(input_shape)\\n\\n#mnist datahandler\\n#dHandler_mnist = MNISTDataHandler()\\n\\nconfig = Configuration(architecture_type, problem_type, input_shape, output_shape, pop_size, tournament_size, max_similar, epochs=5, cross_val=0.2, size_scaler=0.4,\\n                       max_generations=10, binary_selection=True, mutation_ratio=0.4, similarity_threshold=0.2, more_layers_prob=0.8)\\n\\nwhile count_experiments < total_experiments:\\n    print(\"Launching experiment {}\".format(count_experiments+1))\\n    logging.info(\"Launching experiment {}\".format(count_experiments+1))\\n    best = automatic_model_selection.run_experiment(config, dhandler_cmaps, count_experiments + 1, \\n                                                    unroll=unroll, verbose_data=0, tModel_scaler=min_max_scaler)\\n\\n    global_best_list.append(best)\\n\\n    if global_best == None:\\n        global_best = best\\n    else:\\n        if best.fitness < global_best.fitness:\\n            global_best = best\\n            global_best_index = count_experiments\\n\\n    count_experiments =  count_experiments + 1\\n\\nprint(\"Global best list\\n\")\\nlogging.info(\"Global best list\\n\")\\nautomatic_model_selection.print_best(global_best_list)\\n\\nprint(\"Global best is\\n\")\\nprint(global_best)\\nlogging.info(\"Global best is\\n\")\\nlogging.info(global_best)\\n\\nsave_best_models(global_best_list, global_best_index, \\'best_models/cmapss/\\', train_epochs=200)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Input can be of 3 types, ANN (1), CNN (2) or RNN (3)\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "architecture_type = Layers.FullyConnected\n",
    "problem_type = 1  #1 for regression, 2 for classification\n",
    "output_shape = 1 #If regression applies, number of classes\n",
    "input_shape = (784,)\n",
    "pop_size = 5\n",
    "tournament_size = 3\n",
    "max_similar = 3\n",
    "total_experiments = 5\n",
    "count_experiments = 0\n",
    "unroll = True\n",
    "\n",
    "global_best_list = []\n",
    "global_best = None\n",
    "global_best_index = 0\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "t = datetime.datetime.now()\n",
    "\n",
    "logging.basicConfig(filename='logs/nn_evolution_cmaps_' + t.strftime('%m%d%Y%H%M%S') + '.log', level=logging.INFO, \n",
    "                        format='%(levelname)s:%(threadName)s:%(message)s', datefmt='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "#cmaps datahandler\n",
    "dhandler_cmaps, input_shape = cmaps_dhandler()\n",
    "print(input_shape)\n",
    "\n",
    "#mnist datahandler\n",
    "#dHandler_mnist = MNISTDataHandler()\n",
    "\n",
    "config = Configuration(architecture_type, problem_type, input_shape, output_shape, pop_size, tournament_size, max_similar, epochs=5, cross_val=0.2, size_scaler=0.4,\n",
    "                       max_generations=10, binary_selection=True, mutation_ratio=0.4, similarity_threshold=0.2, more_layers_prob=0.8)\n",
    "\n",
    "while count_experiments < total_experiments:\n",
    "    print(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    logging.info(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    best = automatic_model_selection.run_experiment(config, dhandler_cmaps, count_experiments + 1, \n",
    "                                                    unroll=unroll, verbose_data=0, tModel_scaler=min_max_scaler)\n",
    "\n",
    "    global_best_list.append(best)\n",
    "\n",
    "    if global_best == None:\n",
    "        global_best = best\n",
    "    else:\n",
    "        if best.fitness < global_best.fitness:\n",
    "            global_best = best\n",
    "            global_best_index = count_experiments\n",
    "\n",
    "    count_experiments =  count_experiments + 1\n",
    "\n",
    "print(\"Global best list\\n\")\n",
    "logging.info(\"Global best list\\n\")\n",
    "automatic_model_selection.print_best(global_best_list)\n",
    "\n",
    "print(\"Global best is\\n\")\n",
    "print(global_best)\n",
    "logging.info(\"Global best is\\n\")\n",
    "logging.info(global_best)\n",
    "\n",
    "save_best_models(global_best_list, global_best_index, 'best_models/cmapss/', train_epochs=200)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save_best_models(global_best_list, global_best_index, train_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
