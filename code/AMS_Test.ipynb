{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic model selection\n",
    "\n",
    "Test notebook for automatic model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "\n",
    "#sys.path.append('/Users/davidlaredorazo/Documents/University_of_California/Research/Projects')\n",
    "sys.path.append('/media/controlslab/DATA/Projects')\n",
    "\n",
    "import ann_framework.aux_functions as aux_functions\n",
    "\n",
    "import automatic_model_selection\n",
    "from automatic_model_selection import Configuration\n",
    "from ann_encoding_rules import Layers\n",
    "import fetch_to_keras\n",
    "#from CMAPSAuxFunctions import TrainValTensorBoard\n",
    "\n",
    "#Tunable model\n",
    "from ann_framework.tunable_model.tunable_model import SequenceTunableModelRegression, SequenceTunableModelClassification\n",
    "\n",
    "#Data handlers\n",
    "from ann_framework.data_handlers.data_handler_CMAPSS import CMAPSSDataHandler\n",
    "from ann_framework.data_handlers.data_handler_MNIST import MNISTDataHandler\n",
    "from ann_framework.data_handlers.data_handler_CIFAR10 import CIFAR10DataHandler\n",
    "\n",
    "learningRate_scheduler = LearningRateScheduler(aux_functions.step_decay)\n",
    "\n",
    "size_scaler = 1\n",
    "\n",
    "#Use same configuration for all experiments, just change some of the parameters\n",
    "\n",
    "#Define some random paramaters for the creation of the configuration, this will change for each test model\n",
    "architecture_type = Layers.FullyConnected\n",
    "problem_type = 2  #1 for regression, 2 for classification\n",
    "output_shape = 10 #If regression applies, number of classes\n",
    "input_shape = (784,)\n",
    "\n",
    "config = Configuration(architecture_type, problem_type, input_shape, output_shape, pop_size=5, \n",
    "                       tournament_size=3, max_similar=3, epochs=20, cross_val=0.2, size_scaler=size_scaler,\n",
    "                       max_generations=10, binary_selection=True, mutation_ratio=0.4, \n",
    "                       similarity_threshold=0.2, more_layers_prob=0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given a model, get the compiled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model(model, problem_type, optimizer_params=[]):\n",
    "    \"\"\"Obtain a keras compiled model\"\"\"\n",
    "    \n",
    "    #Shared parameters for the models\n",
    "    optimizer = Adam(lr=0.001, beta_1=0.5)\n",
    "    \n",
    "    if problem_type == 1:\n",
    "        lossFunction = \"mean_squared_error\"\n",
    "        metrics = [\"mse\"]\n",
    "    elif problem_type == 2:\n",
    "        lossFunction = \"categorical_crossentropy\"\n",
    "        metrics = [\"accuracy\"]\n",
    "    else:\n",
    "        print(\"Problem type not defined\")\n",
    "        model = None\n",
    "        return\n",
    "    \n",
    "    #Create and compile the models\n",
    "    model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_tunable_model(model_genotype, problem_type, input_shape, data_handler, model_number):\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    model = fetch_to_keras.decode_genotype(model_genotype, problem_type, input_shape, 1)\n",
    "    \n",
    "    model = get_compiled_model(model, problem_type, optimizer_params=[])\n",
    "    \n",
    "    if problem_type == 1:\n",
    "        tModel = SequenceTunableModelRegression('ModelReg_SN_'+str(model_number), model, lib_type='keras', data_handler=data_handler)\n",
    "    else:\n",
    "        tModel = SequenceTunableModelClassification('ModelClass_SN_'+str(model_number), model, lib_type='keras', data_handler=data_handler)\n",
    "        \n",
    "    return tModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cmaps data handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmaps_dhandler():\n",
    "\n",
    "    #Selected as per CNN paper\n",
    "    features = ['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', 'BPR', \n",
    "    'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "    selected_indices = np.array([2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21])\n",
    "    selected_features = list(features[i] for i in selected_indices-1)\n",
    "    data_folder = '../CMAPSSData'\n",
    "\n",
    "    window_size = 25\n",
    "    window_stride = 1\n",
    "    max_rul = 130\n",
    "\n",
    "    dHandler_cmaps = CMAPSSDataHandler(data_folder, 1, selected_features, max_rul, window_size, window_stride)\n",
    "\n",
    "    input_shape = (len(selected_features)*window_size, )\n",
    "\n",
    "    return dHandler_cmaps, input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to save top models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_models(best_models_list, global_best_model_index, saveto, input_shape, data_handler, \n",
    "                     problem_type=1, data_scaler=None, train_epochs=100, metrics=[], round=0):\n",
    "    \n",
    "    n_models = len(best_models_list)\n",
    "    \n",
    "    for ind_model, i in zip(best_models_list, range(n_models)):\n",
    "        \n",
    "        tModel = create_tunable_model(ind_model.stringModel, problem_type, input_shape, data_handler, i)\n",
    "        kmodel = tModel.model\n",
    "        model_json = kmodel.to_json()\n",
    "        \n",
    "        #Save model's architecture\n",
    "        string_append = str(i) if i != global_best_model_index else 'global'\n",
    "        with open(saveto+\"bestModel_\"+string_append+\".json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "            \n",
    "    #Train the global best, model has to be recompiled\n",
    "    ind_model = best_models_list[global_best_model_index]\n",
    "    tModel = create_tunable_model(ind_model.stringModel, problem_type, input_shape, data_handler, n_models)\n",
    "    \n",
    "    print(tModel.model.summary())\n",
    "    print(tModel.data_handler)\n",
    "    \n",
    "    if tModel.data_handler.data_scaler != None:\n",
    "        print(\"Using data handler scaler\")\n",
    "    elif tModel.data_scaler != None:\n",
    "        print(\"Using tModel scaler (Overriding data handler scaler)\")\n",
    "    else:\n",
    "        print(\"No data scaling used\")\n",
    "    \n",
    "    if data_scaler != None:\n",
    "        tModel.data_handler.data_scaler = None\n",
    "        tModel.data_scaler = data_scaler\n",
    "        \n",
    "    tModel.load_data(unroll=True, verbose=1, cross_validation_ratio=0)\n",
    "    tModel.print_data()\n",
    "    tModel.epochs = train_epochs\n",
    "\n",
    "    tModel.train_model(verbose=1)\n",
    "    \n",
    "    tModel.evaluate_model(metrics, round=round)\n",
    "    \n",
    "    kmodel = tModel.model\n",
    "            \n",
    "    # serialize weights to HDF5\n",
    "    kmodel.save_weights(saveto+\"bestModel_global.h5\")\n",
    "    \n",
    "    print(\"Saved models for dataset 1 to disk\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching experiment 1\n",
      "\n",
      "Generation 1\n",
      "launch new\n",
      "True\n",
      "gen similar\n",
      "False\n",
      "Fetching model 0 to keras\n",
      "Evaluating model 0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 168)               2856      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 168)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 656)               110864    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 656)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 272)               178704    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 272)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 224)               61152     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 440)               99000     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 736)               324576    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 736)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 376)               277112    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 136)               51272     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 136)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 728)               99736     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 728)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 944)               688176    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 776)               733320    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                7770      \n",
      "=================================================================\n",
      "Total params: 2,647,098\n",
      "Trainable params: 2,647,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 1.7581 - acc: 0.2785 - val_loss: 1.4062 - val_acc: 0.3405\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.9728 - acc: 0.5911 - val_loss: 0.8221 - val_acc: 0.7069\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.6396 - acc: 0.7701 - val_loss: 0.5178 - val_acc: 0.8218\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.4181 - acc: 0.8815 - val_loss: 0.3948 - val_acc: 0.8801\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3261 - acc: 0.9123 - val_loss: 0.2729 - val_acc: 0.9294\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2821 - acc: 0.9254 - val_loss: 0.2872 - val_acc: 0.9303\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2486 - acc: 0.9357 - val_loss: 0.2377 - val_acc: 0.9406\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2266 - acc: 0.9417 - val_loss: 0.2381 - val_acc: 0.9437\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2061 - acc: 0.9459 - val_loss: 0.2209 - val_acc: 0.9441\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.1933 - acc: 0.9509 - val_loss: 0.2173 - val_acc: 0.9461\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1822 - acc: 0.9525 - val_loss: 0.2135 - val_acc: 0.9493\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1731 - acc: 0.9556 - val_loss: 0.1830 - val_acc: 0.9537\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1738 - acc: 0.9559 - val_loss: 0.1920 - val_acc: 0.9524\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1581 - acc: 0.9592 - val_loss: 0.1793 - val_acc: 0.9565\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1482 - acc: 0.9624 - val_loss: 0.1935 - val_acc: 0.9521\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1452 - acc: 0.9629 - val_loss: 0.1860 - val_acc: 0.9531\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1395 - acc: 0.9640 - val_loss: 0.1865 - val_acc: 0.9565\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1363 - acc: 0.9648 - val_loss: 0.1728 - val_acc: 0.9598\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1316 - acc: 0.9665 - val_loss: 0.1624 - val_acc: 0.9592\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.1235 - acc: 0.9683 - val_loss: 0.1795 - val_acc: 0.9556\n",
      "12000/12000 [==============================] - 0s 25us/step\n",
      "Fetching model 1 to keras\n",
      "Evaluating model 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 936)               734760    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 936)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                9370      \n",
      "=================================================================\n",
      "Total params: 744,130\n",
      "Trainable params: 744,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 0s 8us/step - loss: 0.4798 - acc: 0.8615 - val_loss: 0.2919 - val_acc: 0.9162\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.3025 - acc: 0.9119 - val_loss: 0.2741 - val_acc: 0.9208\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.2753 - acc: 0.9211 - val_loss: 0.2483 - val_acc: 0.9287\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.2546 - acc: 0.9264 - val_loss: 0.2316 - val_acc: 0.9348\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.2305 - acc: 0.9336 - val_loss: 0.2149 - val_acc: 0.9368\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.2099 - acc: 0.9386 - val_loss: 0.1985 - val_acc: 0.9432\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1920 - acc: 0.9444 - val_loss: 0.1796 - val_acc: 0.9490\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1758 - acc: 0.9481 - val_loss: 0.1671 - val_acc: 0.9509\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1621 - acc: 0.9520 - val_loss: 0.1561 - val_acc: 0.9548\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1558 - acc: 0.9533 - val_loss: 0.1474 - val_acc: 0.9572\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1434 - acc: 0.9571 - val_loss: 0.1399 - val_acc: 0.9595\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1330 - acc: 0.9600 - val_loss: 0.1339 - val_acc: 0.9593\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1275 - acc: 0.9610 - val_loss: 0.1223 - val_acc: 0.9627\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1200 - acc: 0.9632 - val_loss: 0.1219 - val_acc: 0.9639\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1115 - acc: 0.9655 - val_loss: 0.1202 - val_acc: 0.9630\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1055 - acc: 0.9668 - val_loss: 0.1132 - val_acc: 0.9652\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1012 - acc: 0.9684 - val_loss: 0.1100 - val_acc: 0.9659\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0962 - acc: 0.9699 - val_loss: 0.1025 - val_acc: 0.9691\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0903 - acc: 0.9718 - val_loss: 0.1010 - val_acc: 0.9704\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0881 - acc: 0.9722 - val_loss: 0.1005 - val_acc: 0.9693\n",
      "12000/12000 [==============================] - 0s 13us/step\n",
      "Fetching model 2 to keras\n",
      "Evaluating model 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 480)               376800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 480)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 616)               296296    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 56)                34552     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                570       \n",
      "=================================================================\n",
      "Total params: 708,218\n",
      "Trainable params: 708,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.6266 - acc: 0.8125 - val_loss: 0.2870 - val_acc: 0.9154\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.3979 - acc: 0.8850 - val_loss: 0.2617 - val_acc: 0.9200\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.3243 - acc: 0.9080 - val_loss: 0.2065 - val_acc: 0.9364\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.2697 - acc: 0.9245 - val_loss: 0.1702 - val_acc: 0.9485\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.2228 - acc: 0.9388 - val_loss: 0.1491 - val_acc: 0.9562\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.1936 - acc: 0.9459 - val_loss: 0.1328 - val_acc: 0.9589\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.1638 - acc: 0.9541 - val_loss: 0.1381 - val_acc: 0.9589\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.1442 - acc: 0.9594 - val_loss: 0.1192 - val_acc: 0.9656\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1338 - acc: 0.9630 - val_loss: 0.1136 - val_acc: 0.9661\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.1156 - acc: 0.9671 - val_loss: 0.1063 - val_acc: 0.9697\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.1027 - acc: 0.9713 - val_loss: 0.1022 - val_acc: 0.9709\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0952 - acc: 0.9731 - val_loss: 0.1008 - val_acc: 0.9705\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0872 - acc: 0.9746 - val_loss: 0.0963 - val_acc: 0.9702\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0811 - acc: 0.9766 - val_loss: 0.0906 - val_acc: 0.9745\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0723 - acc: 0.9796 - val_loss: 0.0889 - val_acc: 0.9740\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0637 - acc: 0.9821 - val_loss: 0.0960 - val_acc: 0.9738\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0618 - acc: 0.9827 - val_loss: 0.0922 - val_acc: 0.9744\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0568 - acc: 0.9833 - val_loss: 0.0857 - val_acc: 0.9763\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0479 - acc: 0.9865 - val_loss: 0.0853 - val_acc: 0.9767\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0440 - acc: 0.9871 - val_loss: 0.0875 - val_acc: 0.9772\n",
      "12000/12000 [==============================] - 0s 16us/step\n",
      "Fetching model 3 to keras\n",
      "Evaluating model 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 984)               772440    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 664)               654040    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 664)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                6650      \n",
      "=================================================================\n",
      "Total params: 1,433,130\n",
      "Trainable params: 1,433,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.9833 - acc: 0.6915 - val_loss: 0.3926 - val_acc: 0.8894\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.3656 - acc: 0.8930 - val_loss: 0.2927 - val_acc: 0.9164\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.2984 - acc: 0.9111 - val_loss: 0.2591 - val_acc: 0.9251\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.2652 - acc: 0.9211 - val_loss: 0.2378 - val_acc: 0.9307\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.2344 - acc: 0.9299 - val_loss: 0.2185 - val_acc: 0.9352\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.2101 - acc: 0.9377 - val_loss: 0.1934 - val_acc: 0.9428\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.1862 - acc: 0.9436 - val_loss: 0.1750 - val_acc: 0.9480\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.1693 - acc: 0.9496 - val_loss: 0.1670 - val_acc: 0.9498\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.1533 - acc: 0.9542 - val_loss: 0.1601 - val_acc: 0.9519\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.1393 - acc: 0.9580 - val_loss: 0.1441 - val_acc: 0.9559\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.1278 - acc: 0.9616 - val_loss: 0.1339 - val_acc: 0.9597\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.1155 - acc: 0.9656 - val_loss: 0.1280 - val_acc: 0.9609\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.1064 - acc: 0.9679 - val_loss: 0.1234 - val_acc: 0.9628\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0981 - acc: 0.9700 - val_loss: 0.1111 - val_acc: 0.9668\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0898 - acc: 0.9731 - val_loss: 0.1078 - val_acc: 0.9668\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0813 - acc: 0.9755 - val_loss: 0.1074 - val_acc: 0.9686\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0740 - acc: 0.9775 - val_loss: 0.0980 - val_acc: 0.9679\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0688 - acc: 0.9789 - val_loss: 0.1073 - val_acc: 0.9672\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0624 - acc: 0.9814 - val_loss: 0.0900 - val_acc: 0.9704\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 0s 6us/step - loss: 0.0571 - acc: 0.9822 - val_loss: 0.0884 - val_acc: 0.9723\n",
      "12000/12000 [==============================] - 0s 14us/step\n",
      "Fetching model 4 to keras\n",
      "Evaluating model 4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 224)               175840    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 408)               91800     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 568)               232312    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5690      \n",
      "=================================================================\n",
      "Total params: 505,642\n",
      "Trainable params: 505,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.4778 - acc: 0.8556 - val_loss: 0.1995 - val_acc: 0.9391\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1841 - acc: 0.9436 - val_loss: 0.1259 - val_acc: 0.9623\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1310 - acc: 0.9591 - val_loss: 0.0969 - val_acc: 0.9699\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1056 - acc: 0.9672 - val_loss: 0.0849 - val_acc: 0.9737\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0896 - acc: 0.9719 - val_loss: 0.0837 - val_acc: 0.9742\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0762 - acc: 0.9756 - val_loss: 0.0812 - val_acc: 0.9755\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0712 - acc: 0.9769 - val_loss: 0.0792 - val_acc: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0579 - acc: 0.9811 - val_loss: 0.0708 - val_acc: 0.9789\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0534 - acc: 0.9822 - val_loss: 0.0756 - val_acc: 0.9781\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0489 - acc: 0.9842 - val_loss: 0.0791 - val_acc: 0.9778\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0450 - acc: 0.9847 - val_loss: 0.0697 - val_acc: 0.9798\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0426 - acc: 0.9855 - val_loss: 0.0788 - val_acc: 0.9782\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0369 - acc: 0.9874 - val_loss: 0.0841 - val_acc: 0.9781\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0340 - acc: 0.9886 - val_loss: 0.0778 - val_acc: 0.9797\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0349 - acc: 0.9883 - val_loss: 0.0787 - val_acc: 0.9793\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0301 - acc: 0.9900 - val_loss: 0.0745 - val_acc: 0.9811\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0322 - acc: 0.9890 - val_loss: 0.0734 - val_acc: 0.9814\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0283 - acc: 0.9901 - val_loss: 0.0959 - val_acc: 0.9751\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0292 - acc: 0.9901 - val_loss: 0.0761 - val_acc: 0.9812\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0267 - acc: 0.9909 - val_loss: 0.0721 - val_acc: 0.9814\n",
      "12000/12000 [==============================] - 0s 14us/step\n",
      "\n",
      "Generating offsprings\n",
      "Applying Mutation\n",
      "Launch new generation?: True\n",
      "\n",
      "Generation 2\n",
      "launch new\n",
      "True\n",
      "gen similar\n",
      "False\n",
      "Fetching model 0 to keras\n",
      "Evaluating model 0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 936)               734760    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 936)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                9370      \n",
      "=================================================================\n",
      "Total params: 744,130\n",
      "Trainable params: 744,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 0s 8us/step - loss: 0.4765 - acc: 0.8626 - val_loss: 0.3072 - val_acc: 0.9129\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.3042 - acc: 0.9119 - val_loss: 0.2825 - val_acc: 0.9227\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.2762 - acc: 0.9205 - val_loss: 0.2582 - val_acc: 0.9255\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.2527 - acc: 0.9271 - val_loss: 0.2402 - val_acc: 0.9309\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.2292 - acc: 0.9331 - val_loss: 0.2143 - val_acc: 0.9398\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.2099 - acc: 0.9392 - val_loss: 0.2005 - val_acc: 0.9434\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1946 - acc: 0.9429 - val_loss: 0.1954 - val_acc: 0.9427\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1767 - acc: 0.9474 - val_loss: 0.1799 - val_acc: 0.9489\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1663 - acc: 0.9501 - val_loss: 0.1695 - val_acc: 0.9512\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1536 - acc: 0.9542 - val_loss: 0.1530 - val_acc: 0.9560\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1417 - acc: 0.9571 - val_loss: 0.1484 - val_acc: 0.9554\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1341 - acc: 0.9596 - val_loss: 0.1399 - val_acc: 0.9603\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1219 - acc: 0.9634 - val_loss: 0.1299 - val_acc: 0.9625\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1166 - acc: 0.9639 - val_loss: 0.1275 - val_acc: 0.9635\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1113 - acc: 0.9650 - val_loss: 0.1239 - val_acc: 0.9650\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1064 - acc: 0.9665 - val_loss: 0.1190 - val_acc: 0.9664\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1003 - acc: 0.9684 - val_loss: 0.1161 - val_acc: 0.9661\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0932 - acc: 0.9706 - val_loss: 0.1104 - val_acc: 0.9677\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0905 - acc: 0.9712 - val_loss: 0.1099 - val_acc: 0.9696\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0851 - acc: 0.9730 - val_loss: 0.1058 - val_acc: 0.9703\n",
      "12000/12000 [==============================] - 0s 14us/step\n",
      "Fetching model 1 to keras\n",
      "Evaluating model 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 480)               376800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 480)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 616)               296296    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 616)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                6170      \n",
      "=================================================================\n",
      "Total params: 679,266\n",
      "Trainable params: 679,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.4687 - acc: 0.8578 - val_loss: 0.2917 - val_acc: 0.9115\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.3104 - acc: 0.9093 - val_loss: 0.2538 - val_acc: 0.9285\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.2616 - acc: 0.9232 - val_loss: 0.2198 - val_acc: 0.9368\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.2277 - acc: 0.9326 - val_loss: 0.1881 - val_acc: 0.9461\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1963 - acc: 0.9409 - val_loss: 0.1636 - val_acc: 0.9521\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1728 - acc: 0.9476 - val_loss: 0.1546 - val_acc: 0.9539\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1555 - acc: 0.9520 - val_loss: 0.1398 - val_acc: 0.9592\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1439 - acc: 0.9561 - val_loss: 0.1306 - val_acc: 0.9626\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1314 - acc: 0.9588 - val_loss: 0.1216 - val_acc: 0.9643\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1204 - acc: 0.9622 - val_loss: 0.1179 - val_acc: 0.9647\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1120 - acc: 0.9651 - val_loss: 0.1069 - val_acc: 0.9692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1026 - acc: 0.9670 - val_loss: 0.1040 - val_acc: 0.9692\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0959 - acc: 0.9701 - val_loss: 0.1013 - val_acc: 0.9687\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0905 - acc: 0.9706 - val_loss: 0.1023 - val_acc: 0.9678\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0823 - acc: 0.9737 - val_loss: 0.0961 - val_acc: 0.9722\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0792 - acc: 0.9745 - val_loss: 0.0979 - val_acc: 0.9732\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0755 - acc: 0.9754 - val_loss: 0.0877 - val_acc: 0.9748\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0706 - acc: 0.9769 - val_loss: 0.0935 - val_acc: 0.9744\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0663 - acc: 0.9782 - val_loss: 0.0895 - val_acc: 0.9748\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0617 - acc: 0.9792 - val_loss: 0.0896 - val_acc: 0.9738\n",
      "12000/12000 [==============================] - 0s 14us/step\n",
      "Fetching model 2 to keras\n",
      "Evaluating model 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 984)               772440    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 224)               220640    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2250      \n",
      "=================================================================\n",
      "Total params: 995,330\n",
      "Trainable params: 995,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 0s 9us/step - loss: 0.9055 - acc: 0.7739 - val_loss: 0.4125 - val_acc: 0.8936\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.3467 - acc: 0.9045 - val_loss: 0.2939 - val_acc: 0.9176\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.2796 - acc: 0.9198 - val_loss: 0.2601 - val_acc: 0.9222\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.2430 - acc: 0.9292 - val_loss: 0.2327 - val_acc: 0.9302\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.2153 - acc: 0.9376 - val_loss: 0.2101 - val_acc: 0.9382\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1929 - acc: 0.9435 - val_loss: 0.1978 - val_acc: 0.9405\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1721 - acc: 0.9496 - val_loss: 0.1799 - val_acc: 0.9446\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1539 - acc: 0.9549 - val_loss: 0.1674 - val_acc: 0.9483\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1397 - acc: 0.9585 - val_loss: 0.1485 - val_acc: 0.9547\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1260 - acc: 0.9637 - val_loss: 0.1352 - val_acc: 0.9584\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1139 - acc: 0.9675 - val_loss: 0.1346 - val_acc: 0.9580\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1023 - acc: 0.9707 - val_loss: 0.1239 - val_acc: 0.9602\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0930 - acc: 0.9729 - val_loss: 0.1123 - val_acc: 0.9659\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0844 - acc: 0.9759 - val_loss: 0.1089 - val_acc: 0.9647\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0776 - acc: 0.9772 - val_loss: 0.1029 - val_acc: 0.9679\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0681 - acc: 0.9804 - val_loss: 0.1025 - val_acc: 0.9683\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0632 - acc: 0.9821 - val_loss: 0.1024 - val_acc: 0.9673\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0574 - acc: 0.9832 - val_loss: 0.0905 - val_acc: 0.9717\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0508 - acc: 0.9851 - val_loss: 0.0948 - val_acc: 0.9699\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0458 - acc: 0.9875 - val_loss: 0.0979 - val_acc: 0.9685\n",
      "12000/12000 [==============================] - 0s 13us/step\n",
      "Fetching model 3 to keras\n",
      "Evaluating model 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 480)               376800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 480)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                4810      \n",
      "=================================================================\n",
      "Total params: 381,610\n",
      "Trainable params: 381,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 0s 8us/step - loss: 0.5537 - acc: 0.8373 - val_loss: 0.3262 - val_acc: 0.9067\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.3331 - acc: 0.9024 - val_loss: 0.2921 - val_acc: 0.9182\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.3064 - acc: 0.9099 - val_loss: 0.2752 - val_acc: 0.9212\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.2842 - acc: 0.9172 - val_loss: 0.2655 - val_acc: 0.9234\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.2687 - acc: 0.9217 - val_loss: 0.2444 - val_acc: 0.9295\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.2580 - acc: 0.9244 - val_loss: 0.2376 - val_acc: 0.9329\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.2444 - acc: 0.9287 - val_loss: 0.2251 - val_acc: 0.9347\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.2323 - acc: 0.9318 - val_loss: 0.2174 - val_acc: 0.9382\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.2247 - acc: 0.9343 - val_loss: 0.2046 - val_acc: 0.9408\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.2098 - acc: 0.9383 - val_loss: 0.2004 - val_acc: 0.9420\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.2027 - acc: 0.9394 - val_loss: 0.1956 - val_acc: 0.9432\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.1957 - acc: 0.9411 - val_loss: 0.1779 - val_acc: 0.9494\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1914 - acc: 0.9419 - val_loss: 0.1779 - val_acc: 0.9507\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.1828 - acc: 0.9453 - val_loss: 0.1674 - val_acc: 0.9524\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.1756 - acc: 0.9458 - val_loss: 0.1669 - val_acc: 0.9520\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1658 - acc: 0.9495 - val_loss: 0.1600 - val_acc: 0.9525\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1663 - acc: 0.9506 - val_loss: 0.1599 - val_acc: 0.9543\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.1571 - acc: 0.9517 - val_loss: 0.1490 - val_acc: 0.9567\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.1558 - acc: 0.9529 - val_loss: 0.1465 - val_acc: 0.9573\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1505 - acc: 0.9535 - val_loss: 0.1422 - val_acc: 0.9590\n",
      "12000/12000 [==============================] - 0s 13us/step\n",
      "Fetching model 4 to keras\n",
      "Evaluating model 4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 0s 7us/step - loss: 0.9169 - acc: 0.7402 - val_loss: 0.3883 - val_acc: 0.9034\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.3984 - acc: 0.8881 - val_loss: 0.2876 - val_acc: 0.9196\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.3206 - acc: 0.9068 - val_loss: 0.2415 - val_acc: 0.9313\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.2776 - acc: 0.9202 - val_loss: 0.2132 - val_acc: 0.9395\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.2477 - acc: 0.9291 - val_loss: 0.1922 - val_acc: 0.9447\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.2245 - acc: 0.9350 - val_loss: 0.1773 - val_acc: 0.9476\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.2098 - acc: 0.9388 - val_loss: 0.1656 - val_acc: 0.9529\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.1938 - acc: 0.9438 - val_loss: 0.1554 - val_acc: 0.9558\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.1813 - acc: 0.9466 - val_loss: 0.1467 - val_acc: 0.9575\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.1732 - acc: 0.9482 - val_loss: 0.1393 - val_acc: 0.9594\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.1607 - acc: 0.9526 - val_loss: 0.1336 - val_acc: 0.9610\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.1565 - acc: 0.9541 - val_loss: 0.1295 - val_acc: 0.9620\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.1474 - acc: 0.9559 - val_loss: 0.1232 - val_acc: 0.9639\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.1400 - acc: 0.9588 - val_loss: 0.1215 - val_acc: 0.9646\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.1350 - acc: 0.9608 - val_loss: 0.1169 - val_acc: 0.9648\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.1279 - acc: 0.9617 - val_loss: 0.1133 - val_acc: 0.9664\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.1263 - acc: 0.9623 - val_loss: 0.1113 - val_acc: 0.9676\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.1213 - acc: 0.9642 - val_loss: 0.1097 - val_acc: 0.9672\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.1150 - acc: 0.9653 - val_loss: 0.1062 - val_acc: 0.9689\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.1131 - acc: 0.9661 - val_loss: 0.1042 - val_acc: 0.9698\n",
      "12000/12000 [==============================] - 0s 13us/step\n",
      "\n",
      "Generating offsprings\n",
      "Applying Mutation\n",
      "Launch new generation?: True\n",
      "\n",
      "Generation 3\n",
      "launch new\n",
      "True\n",
      "gen similar\n",
      "False\n",
      "Fetching model 0 to keras\n",
      "Evaluating model 0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 440)               345400    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 440)               194040    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                4410      \n",
      "=================================================================\n",
      "Total params: 543,850\n",
      "Trainable params: 543,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 0s 8us/step - loss: 0.4197 - acc: 0.8794 - val_loss: 0.2591 - val_acc: 0.9249\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.2334 - acc: 0.9316 - val_loss: 0.2010 - val_acc: 0.9416\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1669 - acc: 0.9516 - val_loss: 0.1761 - val_acc: 0.9473\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1313 - acc: 0.9620 - val_loss: 0.1337 - val_acc: 0.9599\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.1042 - acc: 0.9697 - val_loss: 0.1214 - val_acc: 0.9639\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0842 - acc: 0.9745 - val_loss: 0.1046 - val_acc: 0.9683\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0698 - acc: 0.9794 - val_loss: 0.0915 - val_acc: 0.9717\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0572 - acc: 0.9828 - val_loss: 0.0902 - val_acc: 0.9715\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0470 - acc: 0.9870 - val_loss: 0.0810 - val_acc: 0.9754\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0395 - acc: 0.9890 - val_loss: 0.0817 - val_acc: 0.9752\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0320 - acc: 0.9916 - val_loss: 0.0769 - val_acc: 0.9760\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0261 - acc: 0.9938 - val_loss: 0.0768 - val_acc: 0.9760\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0218 - acc: 0.9952 - val_loss: 0.0842 - val_acc: 0.9742\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0178 - acc: 0.9963 - val_loss: 0.0756 - val_acc: 0.9786\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0144 - acc: 0.9974 - val_loss: 0.0755 - val_acc: 0.9770\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0116 - acc: 0.9982 - val_loss: 0.0720 - val_acc: 0.9778\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0093 - acc: 0.9988 - val_loss: 0.0743 - val_acc: 0.9781\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0075 - acc: 0.9993 - val_loss: 0.0766 - val_acc: 0.9782\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0064 - acc: 0.9994 - val_loss: 0.0743 - val_acc: 0.9794\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 0s 5us/step - loss: 0.0051 - acc: 0.9996 - val_loss: 0.0763 - val_acc: 0.9784\n",
      "12000/12000 [==============================] - 0s 14us/step\n",
      "Fetching model 1 to keras\n",
      "Evaluating model 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 480)               376800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 480)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                4810      \n",
      "=================================================================\n",
      "Total params: 381,610\n",
      "Trainable params: 381,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with cv\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 0s 8us/step - loss: 0.5568 - acc: 0.8366 - val_loss: 0.3175 - val_acc: 0.9090\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.3332 - acc: 0.9027 - val_loss: 0.2855 - val_acc: 0.9187\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.3078 - acc: 0.9112 - val_loss: 0.2681 - val_acc: 0.9218\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.2895 - acc: 0.9155 - val_loss: 0.2524 - val_acc: 0.9267\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.2763 - acc: 0.9187 - val_loss: 0.2437 - val_acc: 0.9298\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.2615 - acc: 0.9243 - val_loss: 0.2343 - val_acc: 0.9323\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.2490 - acc: 0.9276 - val_loss: 0.2162 - val_acc: 0.9385\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 0s 4us/step - loss: 0.2385 - acc: 0.9307 - val_loss: 0.2051 - val_acc: 0.9418\n",
      "Epoch 9/20\n",
      "  512/48000 [..............................] - ETA: 0s - loss: 0.2179 - acc: 0.9336"
     ]
    }
   ],
   "source": [
    "\"\"\"Input can be of 3 types, ANN (1), CNN (2) or RNN (3)\"\"\"\n",
    "architecture_type = Layers.FullyConnected\n",
    "problem_type = 2  #1 for regression, 2 for classification\n",
    "output_shape = 10 #If regression applies, number of classes\n",
    "input_shape = (784,)\n",
    "\n",
    "\"\"\"\n",
    "pop_size = 5\n",
    "tournament_size = 3\n",
    "max_similar = 3\n",
    "total_experiments = 5\n",
    "count_experiments = 0\n",
    "unroll = True\n",
    "\"\"\"\n",
    "total_experiments = 5\n",
    "count_experiments = 0\n",
    "unroll = True\n",
    "\n",
    "global_best_list = []\n",
    "global_best = None\n",
    "global_best_index = 0\n",
    "\n",
    "scaler = None\n",
    "\n",
    "t = datetime.datetime.now()\n",
    "\n",
    "logging.basicConfig(filename='logs/nn_evolution_mnist_' + t.strftime('%m%d%Y%H%M%S') + '.log', level=logging.INFO, \n",
    "                        format='%(levelname)s:%(threadName)s:%(message)s', datefmt='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "#mnist datahandler\n",
    "dHandler_mnist = MNISTDataHandler()\n",
    "\n",
    "config.architecture_type = architecture_type\n",
    "config.problem_type = problem_type\n",
    "config.input_shape = input_shape\n",
    "config.output_shape = output_shape\n",
    "\n",
    "\"\"\"\n",
    "config = Configuration(architecture_type, problem_type, input_shape, output_shape, pop_size, \n",
    "                       tournament_size, max_similar, epochs=20, cross_val=0.2, size_scaler=size_scaler,\n",
    "                       max_generations=10, binary_selection=True, mutation_ratio=0.4, \n",
    "                       similarity_threshold=0.2, more_layers_prob=0.8)\n",
    "\"\"\"\n",
    "\n",
    "while count_experiments < total_experiments:\n",
    "    print(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    logging.info(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    \n",
    "    best = automatic_model_selection.run_experiment(config, dHandler_mnist, count_experiments + 1, unroll=unroll,\n",
    "                                                    learningRate_scheduler=learningRate_scheduler, \n",
    "                                                    tModel_scaler=scaler, verbose_data=0)\n",
    "\n",
    "    best.individual_label = count_experiments\n",
    "    \n",
    "    global_best_list.append(best)\n",
    "\n",
    "    if global_best == None:\n",
    "        global_best = best\n",
    "    else:\n",
    "        if best.fitness < global_best.fitness:\n",
    "            global_best = best\n",
    "            global_best_index = count_experiments\n",
    "\n",
    "    count_experiments =  count_experiments + 1\n",
    "\n",
    "print(\"Global best list\\n\")\n",
    "logging.info(\"Global best list\\n\")\n",
    "automatic_model_selection.print_best(global_best_list)\n",
    "\n",
    "print(\"Global best is\\n\")\n",
    "print(global_best)\n",
    "logging.info(\"Global best is\\n\")\n",
    "logging.info(global_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_best_models(global_best_list, global_best_index, 'best_models/mnist/alpha{}/'.format(size_scaler), \n",
    "                 input_shape=input_shape, data_handler=dHandler_mnist, problem_type=problem_type, train_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Input can be of 3 types, ANN (1), CNN (2) or RNN (3)\"\"\"\n",
    "architecture_type = Layers.FullyConnected\n",
    "problem_type = 2  #1 for regression, 2 for classification\n",
    "output_shape = 10 #If regression applies, number of classes\n",
    "input_shape = (3072,)\n",
    "\"\"\"\n",
    "pop_size = 5\n",
    "tournament_size = 3\n",
    "max_similar = 3\n",
    "\"\"\"\n",
    "total_experiments = 5\n",
    "count_experiments = 0\n",
    "unroll = True\n",
    "\n",
    "global_best_list = []\n",
    "global_best = None\n",
    "global_best_index = 0\n",
    "\n",
    "scaler = None\n",
    "\n",
    "t = datetime.datetime.now()\n",
    "\n",
    "logging.basicConfig(filename='logs/nn_evolution_cifar10_' + t.strftime('%m%d%Y%H%M%S') + '.log', level=logging.INFO, \n",
    "                        format='%(levelname)s:%(threadName)s:%(message)s', datefmt='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "#mnist datahandler\n",
    "dHandler_cifar = CIFAR10DataHandler()\n",
    "\n",
    "\"\"\"\n",
    "config = Configuration(architecture_type, problem_type, input_shape, output_shape, pop_size, tournament_size, max_similar, \n",
    "                       epochs=5, cross_val=0.2, size_scaler=size_scaler, max_generations=10, binary_selection=True, \n",
    "                       mutation_ratio=0.4, similarity_threshold=0.2, more_layers_prob=0.8)\n",
    "\"\"\"\n",
    "\n",
    "config.architecture_type = architecture_type\n",
    "config.problem_type = problem_type\n",
    "config.input_shape = input_shape\n",
    "config.output_shape = output_shape\n",
    "\n",
    "while count_experiments < total_experiments:\n",
    "    print(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    logging.info(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    \n",
    "    best = automatic_model_selection.run_experiment(config, dHandler_cifar, count_experiments + 1, unroll=unroll,\n",
    "                                                    learningRate_scheduler=learningRate_scheduler, \n",
    "                                                    tModel_scaler=scaler, verbose_data=0)\n",
    "    \n",
    "    best.individual_label = count_experiments\n",
    "\n",
    "    global_best_list.append(best)\n",
    "\n",
    "    if global_best == None:\n",
    "        global_best = best\n",
    "    else:\n",
    "        if best.fitness < global_best.fitness:\n",
    "            global_best = best\n",
    "            global_best_index = count_experiments\n",
    "\n",
    "    count_experiments =  count_experiments + 1\n",
    "\n",
    "print(\"Global best list\\n\")\n",
    "logging.info(\"Global best list\\n\")\n",
    "automatic_model_selection.print_best(global_best_list)\n",
    "\n",
    "print(\"Global best is\\n\")\n",
    "print(global_best)\n",
    "logging.info(\"Global best is\\n\")\n",
    "logging.info(global_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_best_models(global_best_list, global_best_index, 'best_models/cifar10/alpha{}/'.format(size_scaler), \n",
    "                 input_shape=input_shape, data_handler=dHandler_cifar, problem_type=problem_type, train_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test on CMAPSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Input can be of 3 types, ANN (1), CNN (2) or RNN (3)\"\"\"\n",
    "architecture_type = Layers.FullyConnected\n",
    "problem_type = 1  #1 for regression, 2 for classification\n",
    "output_shape = 1 #If regression applies, number of classes\n",
    "input_shape = None\n",
    "\n",
    "\"\"\"\n",
    "pop_size = 5\n",
    "tournament_size = 3\n",
    "max_similar = 3\n",
    "\"\"\"\n",
    "total_experiments = 5\n",
    "count_experiments = 0\n",
    "unroll = True\n",
    "\n",
    "global_best_list = []\n",
    "global_best = None\n",
    "global_best_index = 0\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "t = datetime.datetime.now()\n",
    "\n",
    "logging.basicConfig(filename='logs/nn_evolution_cmaps_' + t.strftime('%m%d%Y%H%M%S') + '.log', level=logging.INFO, \n",
    "                        format='%(levelname)s:%(threadName)s:%(message)s', datefmt='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "#cmaps datahandler\n",
    "dhandler_cmaps, input_shape = cmaps_dhandler()\n",
    "\n",
    "\"\"\"\n",
    "config = Configuration(architecture_type, problem_type, input_shape, output_shape, pop_size, tournament_size, \n",
    "                       max_similar, epochs=5, cross_val=0.2, size_scaler=size_scaler, max_generations=10, \n",
    "                       binary_selection=True, mutation_ratio=0.4, similarity_threshold=0.2, more_layers_prob=0.8)\n",
    "\"\"\"\n",
    "\n",
    "config.architecture_type = architecture_type\n",
    "config.problem_type = problem_type\n",
    "config.input_shape = input_shape\n",
    "config.output_shape = output_shape\n",
    "\n",
    "while count_experiments < total_experiments:\n",
    "    print(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    logging.info(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    \n",
    "    best = automatic_model_selection.run_experiment(config, dhandler_cmaps, count_experiments + 1, unroll=unroll,\n",
    "                                                    learningRate_scheduler=learningRate_scheduler, \n",
    "                                                    tModel_scaler=scaler, verbose_data=0)\n",
    "    \n",
    "    best.individual_label = count_experiments\n",
    "\n",
    "    global_best_list.append(best)\n",
    "\n",
    "    if global_best == None:\n",
    "        global_best = best\n",
    "    else:\n",
    "        if best.fitness < global_best.fitness:\n",
    "            global_best = best\n",
    "            global_best_index = count_experiments\n",
    "\n",
    "    count_experiments =  count_experiments + 1\n",
    "\n",
    "print(\"Global best list\\n\")\n",
    "logging.info(\"Global best list\\n\")\n",
    "automatic_model_selection.print_best(global_best_list)\n",
    "\n",
    "print(\"Global best is\\n\")\n",
    "print(global_best)\n",
    "logging.info(\"Global best is\\n\")\n",
    "logging.info(global_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_best_models(global_best_list, global_best_index, 'best_models/cmapss/alpha{}/'.format(size_scaler), \n",
    "                 input_shape=input_shape, data_handler=dhandler_cmaps, problem_type=problem_type, train_epochs=100, \n",
    "                 data_scaler=scaler, metrics=['rhs', 'rmse'], round=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
