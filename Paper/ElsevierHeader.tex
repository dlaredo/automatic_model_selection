%\runauthor{Laredo, \textit{et al.}}

\begin{frontmatter}

\title{Automatic Model Selection for Neural Networks}

\begin{comment}
\author{David Laredo$^{1}$, Yulin Qin$^{1}$, Oliver Sch\"utze$^{2}$ and Jian-Qiao Sun$^{1}$}
\address{
$^{1}$Department of Mechanical Engineering, School of Engineering\\
University of California, Merced, CA 95343, USA\\
$^{2}$Department of Computer Science, CINVESTAV, Mexico City, Mexico\\
and Rodolfo Quintero Chair, UAM Cuajimalpa, Mexico\\
Corresponding author: Jian-Qiao Sun. Email: jqsun@ucmerced.edu}
\end{comment}

\begin{abstract}
Neural networks and deep learning are changing the way that artificial intelligence is being done. Efficiently choosing a suitable model including hyperparameters for a specific problem is a time-consuming task. Choosing among many different combinations of neural networks available gives rise to a staggering number of possible alternatives. In this paper, we address this problem by proposing a fully automated framework for efficiently selecting a neural network model for a given problem whether it is classification or regression. Our proposal focuses on a distributed decision-making algorithm for keeping the most promising models among a pool of possible models for one of the major neural network architectures, Multi-Layer Perceptrons (MLPs). This work develops Automatic Model Selection (AMS), a modified micro genetic algorithm that automatically and efficiently finds the most suitable neural network model for a given dataset. Our contributions include: a simple list based encoding for neural networks as genotypes in an evolutionary algorithm, new crossover and mutation operators, the introduction of a fitness function that considers both, the accuracy of the model and its complexity and a method to measure the similarity between two neural networks. Our evaluation on two different datasets show that AMS effectively finds suitable neural network models while being efficient in terms of the computational burden. Our results are compared against other state of the art methods such as Auto-Keras and AutoML.
\end{abstract}


\begin{keyword}
artificial neural networks\sep
model selection\sep
hyperparameter tuning\sep
distributed computing\sep
evolutionary algorithms
\end{keyword}

\end{frontmatter}

