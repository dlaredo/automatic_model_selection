{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic model selection\n",
    "\n",
    "Test notebook for automatic model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "\n",
    "#sys.path.append('/Users/davidlaredorazo/Documents/University_of_California/Research/Projects')\n",
    "sys.path.append('/media/controlslab/DATA/Projects')\n",
    "\n",
    "import ann_framework.aux_functions as aux_functions\n",
    "\n",
    "import automatic_model_selection\n",
    "from automatic_model_selection import Configuration\n",
    "from ann_encoding_rules import Layers\n",
    "import fetch_to_keras\n",
    "#from CMAPSAuxFunctions import TrainValTensorBoard\n",
    "\n",
    "#Tunable model\n",
    "from ann_framework.tunable_model.tunable_model import SequenceTunableModelRegression, SequenceTunableModelClassification\n",
    "\n",
    "#Data handlers\n",
    "from ann_framework.data_handlers.data_handler_CMAPSS import CMAPSSDataHandler\n",
    "from ann_framework.data_handlers.data_handler_MNIST import MNISTDataHandler\n",
    "from ann_framework.data_handlers.data_handler_CIFAR10 import CIFAR10DataHandler\n",
    "\n",
    "learningRate_scheduler = LearningRateScheduler(aux_functions.step_decay)\n",
    "\n",
    "size_scaler = 0.8\n",
    "\n",
    "#Use same configuration for all experiments, just change some of the parameters\n",
    "\n",
    "#Define some random paramaters for the creation of the configuration, this will change for each test model\n",
    "architecture_type = Layers.FullyConnected\n",
    "problem_type = 2  #1 for regression, 2 for classification\n",
    "output_shape = 10 #If regression applies, number of classes\n",
    "input_shape = (784,)\n",
    "\n",
    "config = Configuration(architecture_type, problem_type, input_shape, output_shape, pop_size=5, \n",
    "                       tournament_size=3, max_similar=3, epochs=20, cross_val=0.2, size_scaler=size_scaler,\n",
    "                       max_generations=10, binary_selection=True, mutation_ratio=0.4, \n",
    "                       similarity_threshold=0.2, more_layers_prob=0.4, verbose_individuals=True, \n",
    "                       show_model=True, verbose_training=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given a model, get the compiled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model(model, problem_type, optimizer_params=[]):\n",
    "    \"\"\"Obtain a keras compiled model\"\"\"\n",
    "    \n",
    "    #Shared parameters for the models\n",
    "    optimizer = Adam(lr=0.001, beta_1=0.5)\n",
    "    \n",
    "    if problem_type == 1:\n",
    "        lossFunction = \"mean_squared_error\"\n",
    "        metrics = [\"mse\"]\n",
    "    elif problem_type == 2:\n",
    "        lossFunction = \"categorical_crossentropy\"\n",
    "        metrics = [\"accuracy\"]\n",
    "    else:\n",
    "        print(\"Problem type not defined\")\n",
    "        model = None\n",
    "        return\n",
    "    \n",
    "    #Create and compile the models\n",
    "    model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_tunable_model(model_genotype, problem_type, input_shape, data_handler, model_number):\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    model = fetch_to_keras.decode_genotype(model_genotype, problem_type, input_shape, 1)\n",
    "    \n",
    "    model = get_compiled_model(model, problem_type, optimizer_params=[])\n",
    "    \n",
    "    if problem_type == 1:\n",
    "        tModel = SequenceTunableModelRegression('ModelReg_SN_'+str(model_number), model, lib_type='keras', data_handler=data_handler)\n",
    "    else:\n",
    "        tModel = SequenceTunableModelClassification('ModelClass_SN_'+str(model_number), model, lib_type='keras', data_handler=data_handler)\n",
    "        \n",
    "    return tModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cmaps data handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmaps_dhandler():\n",
    "\n",
    "    #Selected as per CNN paper\n",
    "    features = ['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', 'BPR', \n",
    "    'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "    selected_indices = np.array([2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21])\n",
    "    selected_features = list(features[i] for i in selected_indices-1)\n",
    "    data_folder = '../CMAPSSData'\n",
    "\n",
    "    window_size = 24\n",
    "    window_stride = 1\n",
    "    max_rul = 129\n",
    "\n",
    "    dHandler_cmaps = CMAPSSDataHandler(data_folder, 1, selected_features, max_rul, window_size, window_stride)\n",
    "\n",
    "    input_shape = (len(selected_features)*window_size, )\n",
    "\n",
    "    return dHandler_cmaps, input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to save top models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_models(best_models_list, global_best_model_index, saveto, input_shape, data_handler, \n",
    "                     problem_type=1, data_scaler=None, train_epochs=100, metrics=[], round=0):\n",
    "    \n",
    "    n_models = len(best_models_list)\n",
    "    \n",
    "    for ind_model, i in zip(best_models_list, range(n_models)):\n",
    "        \n",
    "        tModel = create_tunable_model(ind_model.stringModel, problem_type, input_shape, data_handler, i)\n",
    "        kmodel = tModel.model\n",
    "        model_json = kmodel.to_json()\n",
    "        \n",
    "        #Save model's architecture\n",
    "        string_append = str(i) if i != global_best_model_index else 'global'\n",
    "        with open(saveto+\"bestModel_\"+string_append+\".json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "            \n",
    "    #Train the global best, model has to be recompiled\n",
    "    ind_model = best_models_list[global_best_model_index]\n",
    "    tModel = create_tunable_model(ind_model.stringModel, problem_type, input_shape, data_handler, n_models)\n",
    "    \n",
    "    print(tModel.model.summary())\n",
    "    print(tModel.data_handler)\n",
    "    \n",
    "    if tModel.data_handler.data_scaler != None:\n",
    "        print(\"Using data handler scaler\")\n",
    "    elif tModel.data_scaler != None:\n",
    "        print(\"Using tModel scaler (Overriding data handler scaler)\")\n",
    "    else:\n",
    "        print(\"No data scaling used\")\n",
    "    \n",
    "    if data_scaler != None:\n",
    "        tModel.data_handler.data_scaler = None\n",
    "        tModel.data_scaler = data_scaler\n",
    "        \n",
    "    tModel.load_data(unroll=True, verbose=1, cross_validation_ratio=0)\n",
    "    tModel.print_data()\n",
    "    tModel.epochs = train_epochs\n",
    "\n",
    "    tModel.train_model(verbose=1)\n",
    "    \n",
    "    tModel.evaluate_model(metrics, round=round)\n",
    "    \n",
    "    kmodel = tModel.model\n",
    "            \n",
    "    # serialize weights to HDF5\n",
    "    kmodel.save_weights(saveto+\"bestModel_global.h5\")\n",
    "    \n",
    "    print(\"Saved models for dataset 1 to disk\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Input can be of 3 types, ANN (1), CNN (2) or RNN (3)\"\"\"\n",
    "architecture_type = Layers.FullyConnected\n",
    "problem_type = 2  #1 for regression, 2 for classification\n",
    "output_shape = 10 #If regression applies, number of classes\n",
    "input_shape = (784,)\n",
    "\n",
    "\"\"\"\n",
    "pop_size = 5\n",
    "tournament_size = 3\n",
    "max_similar = 3\n",
    "total_experiments = 5\n",
    "count_experiments = 0\n",
    "unroll = True\n",
    "\"\"\"\n",
    "total_experiments = 5\n",
    "count_experiments = 0\n",
    "unroll = True\n",
    "\n",
    "global_best_list = []\n",
    "global_best = None\n",
    "global_best_index = 0\n",
    "experiment_times = np.zeros((total_experiments,1))\n",
    "\n",
    "scaler = None\n",
    "\n",
    "t = datetime.datetime.now()\n",
    "\n",
    "logging.basicConfig(filename='logs/nn_evolution_mnist_' + t.strftime('%m%d%Y%H%M%S') + '.log', level=logging.INFO, \n",
    "                        format='%(levelname)s:%(threadName)s:%(message)s', datefmt='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "#mnist datahandler\n",
    "dHandler_mnist = MNISTDataHandler()\n",
    "\n",
    "config.architecture_type = architecture_type\n",
    "config.problem_type = problem_type\n",
    "config.input_shape = input_shape\n",
    "config.output_shape = output_shape\n",
    "\n",
    "\"\"\"\n",
    "config = Configuration(architecture_type, problem_type, input_shape, output_shape, pop_size, \n",
    "                       tournament_size, max_similar, epochs=20, cross_val=0.2, size_scaler=size_scaler,\n",
    "                       max_generations=10, binary_selection=True, mutation_ratio=0.4, \n",
    "                       similarity_threshold=0.2, more_layers_prob=0.8)\n",
    "\"\"\"\n",
    "\n",
    "while count_experiments < total_experiments:\n",
    "    print(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    logging.info(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    best = automatic_model_selection.run_experiment(config, dHandler_mnist, count_experiments + 1, unroll=unroll,\n",
    "                                                    learningRate_scheduler=learningRate_scheduler, \n",
    "                                                    tModel_scaler=scaler)\n",
    "    end = time.time()\n",
    "    elapsed_time = (end-start)/60\n",
    "    experiment_times[count_experiments] = elapsed_time\n",
    "    print(\"Experiment time: {} minutes\".format(elapsed_time))\n",
    "    logging.info(\"Experiment time: {} minutes\".format(elapsed_time))\n",
    "    \n",
    "\n",
    "    best.individual_label = count_experiments\n",
    "    \n",
    "    global_best_list.append(best)\n",
    "\n",
    "    if global_best == None:\n",
    "        global_best = best\n",
    "    else:\n",
    "        if best.fitness < global_best.fitness:\n",
    "            global_best = best\n",
    "            global_best_index = count_experiments\n",
    "\n",
    "    count_experiments =  count_experiments + 1\n",
    "\n",
    "print(\"Global best list\\n\")\n",
    "logging.info(\"Global best list\\n\")\n",
    "automatic_model_selection.print_best(global_best_list)\n",
    "\n",
    "print(\"Global best is\\n\")\n",
    "print(global_best)\n",
    "logging.info(\"Global best is\\n\")\n",
    "logging.info(global_best)\n",
    "\n",
    "print(\"Global time {}\".format(experiment_times.sum()))\n",
    "logging.info(\"Global time {}\".format(experiment_times.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_best_models(global_best_list, global_best_index, 'best_models/mnist/alpha{}/epochs10/'.format(size_scaler), \n",
    "                 input_shape=input_shape, data_handler=dHandler_mnist, problem_type=problem_type, train_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Input can be of 3 types, ANN (1), CNN (2) or RNN (3)\"\"\"\n",
    "architecture_type = Layers.FullyConnected\n",
    "problem_type = 2  #1 for regression, 2 for classification\n",
    "output_shape = 10 #If regression applies, number of classes\n",
    "input_shape = (3072,)\n",
    "\"\"\"\n",
    "pop_size = 5\n",
    "tournament_size = 3\n",
    "max_similar = 3\n",
    "\"\"\"\n",
    "total_experiments = 5\n",
    "count_experiments = 0\n",
    "unroll = True\n",
    "\n",
    "global_best_list = []\n",
    "global_best = None\n",
    "global_best_index = 0\n",
    "\n",
    "scaler = None\n",
    "\n",
    "t = datetime.datetime.now()\n",
    "\n",
    "logging.basicConfig(filename='logs/nn_evolution_cifar10_' + t.strftime('%m%d%Y%H%M%S') + '.log', level=logging.INFO, \n",
    "                        format='%(levelname)s:%(threadName)s:%(message)s', datefmt='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "#mnist datahandler\n",
    "dHandler_cifar = CIFAR10DataHandler()\n",
    "\n",
    "\"\"\"\n",
    "config = Configuration(architecture_type, problem_type, input_shape, output_shape, pop_size, tournament_size, max_similar, \n",
    "                       epochs=5, cross_val=0.2, size_scaler=size_scaler, max_generations=10, binary_selection=True, \n",
    "                       mutation_ratio=0.4, similarity_threshold=0.2, more_layers_prob=0.8)\n",
    "\"\"\"\n",
    "\n",
    "config.architecture_type = architecture_type\n",
    "config.problem_type = problem_type\n",
    "config.input_shape = input_shape\n",
    "config.output_shape = output_shape\n",
    "\n",
    "while count_experiments < total_experiments:\n",
    "    print(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    logging.info(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    \n",
    "    best = automatic_model_selection.run_experiment(config, dHandler_cifar, count_experiments + 1, unroll=unroll,\n",
    "                                                    learningRate_scheduler=learningRate_scheduler, \n",
    "                                                    tModel_scaler=scaler, verbose_data=0)\n",
    "    \n",
    "    best.individual_label = count_experiments\n",
    "\n",
    "    global_best_list.append(best)\n",
    "\n",
    "    if global_best == None:\n",
    "        global_best = best\n",
    "    else:\n",
    "        if best.fitness < global_best.fitness:\n",
    "            global_best = best\n",
    "            global_best_index = count_experiments\n",
    "\n",
    "    count_experiments =  count_experiments + 1\n",
    "\n",
    "print(\"Global best list\\n\")\n",
    "logging.info(\"Global best list\\n\")\n",
    "automatic_model_selection.print_best(global_best_list)\n",
    "\n",
    "print(\"Global best is\\n\")\n",
    "print(global_best)\n",
    "logging.info(\"Global best is\\n\")\n",
    "logging.info(global_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_best_models(global_best_list, global_best_index, 'best_models/cifar10/alpha{}/'.format(size_scaler), \n",
    "                 input_shape=input_shape, data_handler=dHandler_cifar, problem_type=problem_type, train_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test on CMAPSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching experiment 1\n",
      "\n",
      "Generation 1\n",
      "launch new\n",
      "True\n",
      "gen similar\n",
      "False\n",
      "Fetching model 0 to keras\n",
      "Evaluating model 0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 928)               312736    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 848)               787792    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 608)               516192    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 696)               423864    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 224)               156128    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 225       \n",
      "=================================================================\n",
      "Total params: 2,196,937\n",
      "Trainable params: 2,196,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "<ann_framework.data_handlers.data_handler_CMAPSS.CMAPSSDataHandler object at 0x7fcc284d3be0>\n",
      "Data loaded?\n",
      "False\n",
      "Loading data for the first time\n",
      "Reloading data due to parameter change\n",
      "Loading data for dataset 1 with window_size of 24, stride of 1 and maxRUL of 129. Cros-Validation ratio 0.2\n",
      "Loading data from file and computing dataframes\n",
      "Data loaded?\n",
      "True\n",
      "training with cv\n",
      "Train on 15011 samples, validate on 20 samples\n",
      "Epoch 1/20\n",
      "15011/15011 [==============================] - 1s 92us/step - loss: 7755.8351 - mean_squared_error: 7755.8351 - val_loss: 7076.3257 - val_mean_squared_error: 7076.3257\n",
      "Epoch 2/20\n",
      "15011/15011 [==============================] - 1s 75us/step - loss: 7100.9897 - mean_squared_error: 7100.9897 - val_loss: 6595.0454 - val_mean_squared_error: 6595.0454\n",
      "Epoch 3/20\n",
      "15011/15011 [==============================] - 1s 75us/step - loss: 6633.9578 - mean_squared_error: 6633.9578 - val_loss: 6159.0679 - val_mean_squared_error: 6159.0679\n",
      "Epoch 4/20\n",
      "15011/15011 [==============================] - 1s 75us/step - loss: 6191.0141 - mean_squared_error: 6191.0141 - val_loss: 5736.7998 - val_mean_squared_error: 5736.7998\n",
      "Epoch 5/20\n",
      "15011/15011 [==============================] - 1s 76us/step - loss: 5765.1370 - mean_squared_error: 5765.1370 - val_loss: 5333.0938 - val_mean_squared_error: 5333.0938\n",
      "Epoch 6/20\n",
      "15011/15011 [==============================] - 1s 76us/step - loss: 5371.3750 - mean_squared_error: 5371.3750 - val_loss: 4973.3032 - val_mean_squared_error: 4973.3032\n",
      "Epoch 7/20\n",
      "15011/15011 [==============================] - 1s 75us/step - loss: 5016.2976 - mean_squared_error: 5016.2976 - val_loss: 4641.4497 - val_mean_squared_error: 4641.4497\n",
      "Epoch 8/20\n",
      "15011/15011 [==============================] - 1s 75us/step - loss: 4683.8316 - mean_squared_error: 4683.8316 - val_loss: 4335.4443 - val_mean_squared_error: 4335.4443\n",
      "Epoch 9/20\n",
      "15011/15011 [==============================] - 1s 75us/step - loss: 4382.8316 - mean_squared_error: 4382.8316 - val_loss: 4059.9758 - val_mean_squared_error: 4059.9758\n",
      "Epoch 10/20\n",
      "15011/15011 [==============================] - 1s 76us/step - loss: 4109.7186 - mean_squared_error: 4109.7186 - val_loss: 3809.8569 - val_mean_squared_error: 3809.8569\n",
      "Epoch 11/20\n",
      "15011/15011 [==============================] - 1s 77us/step - loss: 3861.2705 - mean_squared_error: 3861.2705 - val_loss: 3583.2117 - val_mean_squared_error: 3583.2117\n",
      "Epoch 12/20\n",
      "15011/15011 [==============================] - 1s 77us/step - loss: 3635.9635 - mean_squared_error: 3635.9635 - val_loss: 3378.3008 - val_mean_squared_error: 3378.3008\n",
      "Epoch 13/20\n",
      "15011/15011 [==============================] - 1s 76us/step - loss: 3431.8873 - mean_squared_error: 3431.8873 - val_loss: 3193.2454 - val_mean_squared_error: 3193.2454\n",
      "Epoch 14/20\n",
      "15011/15011 [==============================] - 1s 75us/step - loss: 3246.8507 - mean_squared_error: 3246.8507 - val_loss: 3026.3772 - val_mean_squared_error: 3026.3772\n",
      "Epoch 15/20\n",
      "15011/15011 [==============================] - 1s 76us/step - loss: 3080.5676 - mean_squared_error: 3080.5676 - val_loss: 2876.7498 - val_mean_squared_error: 2876.7498\n",
      "Epoch 16/20\n",
      "15011/15011 [==============================] - 1s 75us/step - loss: 2930.1999 - mean_squared_error: 2930.1999 - val_loss: 2742.5918 - val_mean_squared_error: 2742.5918\n",
      "Epoch 17/20\n",
      "15011/15011 [==============================] - 1s 75us/step - loss: 2795.7435 - mean_squared_error: 2795.7435 - val_loss: 2623.2944 - val_mean_squared_error: 2623.2944\n",
      "Epoch 18/20\n",
      "15011/15011 [==============================] - 1s 75us/step - loss: 2676.1876 - mean_squared_error: 2676.1876 - val_loss: 2517.5974 - val_mean_squared_error: 2517.5974\n",
      "Epoch 19/20\n",
      "15011/15011 [==============================] - 1s 75us/step - loss: 2569.1134 - mean_squared_error: 2569.1134 - val_loss: 2423.7549 - val_mean_squared_error: 2423.7549\n",
      "Epoch 20/20\n",
      "15011/15011 [==============================] - 1s 75us/step - loss: 2474.1156 - mean_squared_error: 2474.1156 - val_loss: 2340.8071 - val_mean_squared_error: 2340.8071\n",
      "20/20 [==============================] - 0s 93us/step\n",
      "Fetching model 1 to keras\n",
      "Evaluating model 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 928)               312736    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 928)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 929       \n",
      "=================================================================\n",
      "Total params: 313,665\n",
      "Trainable params: 313,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "<ann_framework.data_handlers.data_handler_CMAPSS.CMAPSSDataHandler object at 0x7fcc284d3be0>\n",
      "Data loaded?\n",
      "True\n",
      "Using previously loaded data\n",
      "Data loaded?\n",
      "True\n",
      "training with cv\n",
      "Train on 15011 samples, validate on 20 samples\n",
      "Epoch 1/20\n",
      "15011/15011 [==============================] - 0s 22us/step - loss: 7016.4982 - mean_squared_error: 7016.4982 - val_loss: 5255.0356 - val_mean_squared_error: 5255.0356\n",
      "Epoch 2/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 4131.3974 - mean_squared_error: 4131.3974 - val_loss: 3115.7878 - val_mean_squared_error: 3115.7878\n",
      "Epoch 3/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 2376.5965 - mean_squared_error: 2376.5965 - val_loss: 1950.9196 - val_mean_squared_error: 1950.9196\n",
      "Epoch 4/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 1408.8506 - mean_squared_error: 1408.8506 - val_loss: 1452.0974 - val_mean_squared_error: 1452.0974\n",
      "Epoch 5/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 936.9905 - mean_squared_error: 936.9905 - val_loss: 1296.8927 - val_mean_squared_error: 1296.8927\n",
      "Epoch 6/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 727.5750 - mean_squared_error: 727.5750 - val_loss: 1279.6584 - val_mean_squared_error: 1279.6584\n",
      "Epoch 7/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 637.2029 - mean_squared_error: 637.2029 - val_loss: 1295.0588 - val_mean_squared_error: 1295.0588\n",
      "Epoch 8/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 588.7325 - mean_squared_error: 588.7325 - val_loss: 1299.0260 - val_mean_squared_error: 1299.0260\n",
      "Epoch 9/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 552.8203 - mean_squared_error: 552.8203 - val_loss: 1278.9163 - val_mean_squared_error: 1278.9163\n",
      "Epoch 10/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 517.5696 - mean_squared_error: 517.5696 - val_loss: 1231.1323 - val_mean_squared_error: 1231.1323\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15011/15011 [==============================] - 0s 14us/step - loss: 481.7828 - mean_squared_error: 481.7828 - val_loss: 1160.4836 - val_mean_squared_error: 1160.4836\n",
      "Epoch 12/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 445.7752 - mean_squared_error: 445.7752 - val_loss: 1088.0970 - val_mean_squared_error: 1088.0970\n",
      "Epoch 13/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 414.0134 - mean_squared_error: 414.0134 - val_loss: 1037.4485 - val_mean_squared_error: 1037.4485\n",
      "Epoch 14/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 385.1823 - mean_squared_error: 385.1823 - val_loss: 983.0421 - val_mean_squared_error: 983.0421\n",
      "Epoch 15/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 360.4791 - mean_squared_error: 360.4791 - val_loss: 935.4427 - val_mean_squared_error: 935.4427\n",
      "Epoch 16/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 340.1111 - mean_squared_error: 340.1111 - val_loss: 898.6664 - val_mean_squared_error: 898.6664\n",
      "Epoch 17/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 322.2480 - mean_squared_error: 322.2480 - val_loss: 866.2672 - val_mean_squared_error: 866.2672\n",
      "Epoch 18/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 308.5348 - mean_squared_error: 308.5348 - val_loss: 853.9402 - val_mean_squared_error: 853.9402\n",
      "Epoch 19/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 296.2081 - mean_squared_error: 296.2081 - val_loss: 811.7432 - val_mean_squared_error: 811.7432\n",
      "Epoch 20/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 286.0765 - mean_squared_error: 286.0765 - val_loss: 815.8560 - val_mean_squared_error: 815.8560\n",
      "20/20 [==============================] - 0s 35us/step\n",
      "Fetching model 2 to keras\n",
      "Evaluating model 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 696)               234552    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 792)               552024    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 793       \n",
      "=================================================================\n",
      "Total params: 787,369\n",
      "Trainable params: 787,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "<ann_framework.data_handlers.data_handler_CMAPSS.CMAPSSDataHandler object at 0x7fcc284d3be0>\n",
      "Data loaded?\n",
      "True\n",
      "Using previously loaded data\n",
      "Data loaded?\n",
      "True\n",
      "training with cv\n",
      "Train on 15011 samples, validate on 20 samples\n",
      "Epoch 1/20\n",
      "15011/15011 [==============================] - 1s 38us/step - loss: 4224.5667 - mean_squared_error: 4224.5667 - val_loss: 2505.9634 - val_mean_squared_error: 2505.9634\n",
      "Epoch 2/20\n",
      "15011/15011 [==============================] - 0s 28us/step - loss: 1926.3940 - mean_squared_error: 1926.3940 - val_loss: 1631.5983 - val_mean_squared_error: 1631.5983\n",
      "Epoch 3/20\n",
      "15011/15011 [==============================] - 0s 28us/step - loss: 1121.0918 - mean_squared_error: 1121.0918 - val_loss: 1276.7426 - val_mean_squared_error: 1276.7426\n",
      "Epoch 4/20\n",
      "15011/15011 [==============================] - 0s 28us/step - loss: 672.4948 - mean_squared_error: 672.4948 - val_loss: 891.0651 - val_mean_squared_error: 891.0651\n",
      "Epoch 5/20\n",
      "15011/15011 [==============================] - 0s 28us/step - loss: 426.8819 - mean_squared_error: 426.8819 - val_loss: 781.1614 - val_mean_squared_error: 781.1614\n",
      "Epoch 6/20\n",
      "15011/15011 [==============================] - 0s 28us/step - loss: 326.0147 - mean_squared_error: 326.0147 - val_loss: 780.9233 - val_mean_squared_error: 780.9233\n",
      "Epoch 7/20\n",
      "15011/15011 [==============================] - 0s 28us/step - loss: 281.9396 - mean_squared_error: 281.9396 - val_loss: 776.3633 - val_mean_squared_error: 776.3633\n",
      "Epoch 8/20\n",
      "15011/15011 [==============================] - 0s 28us/step - loss: 261.9253 - mean_squared_error: 261.9253 - val_loss: 689.7874 - val_mean_squared_error: 689.7874\n",
      "Epoch 9/20\n",
      "15011/15011 [==============================] - 0s 28us/step - loss: 239.6245 - mean_squared_error: 239.6245 - val_loss: 686.8808 - val_mean_squared_error: 686.8808\n",
      "Epoch 10/20\n",
      "15011/15011 [==============================] - 0s 28us/step - loss: 239.9712 - mean_squared_error: 239.9712 - val_loss: 677.1943 - val_mean_squared_error: 677.1943\n",
      "Epoch 11/20\n",
      "15011/15011 [==============================] - 0s 28us/step - loss: 231.3919 - mean_squared_error: 231.3919 - val_loss: 761.6696 - val_mean_squared_error: 761.6696\n",
      "Epoch 12/20\n",
      "15011/15011 [==============================] - 0s 28us/step - loss: 222.8515 - mean_squared_error: 222.8515 - val_loss: 689.8995 - val_mean_squared_error: 689.8995\n",
      "Epoch 13/20\n",
      "15011/15011 [==============================] - 0s 28us/step - loss: 224.7243 - mean_squared_error: 224.7243 - val_loss: 654.0714 - val_mean_squared_error: 654.0714\n",
      "Epoch 14/20\n",
      "15011/15011 [==============================] - 0s 28us/step - loss: 218.1753 - mean_squared_error: 218.1753 - val_loss: 610.7153 - val_mean_squared_error: 610.7153\n",
      "Epoch 15/20\n",
      "15011/15011 [==============================] - 0s 28us/step - loss: 214.7155 - mean_squared_error: 214.7155 - val_loss: 676.0698 - val_mean_squared_error: 676.0698\n",
      "Epoch 16/20\n",
      "15011/15011 [==============================] - 0s 28us/step - loss: 210.4561 - mean_squared_error: 210.4561 - val_loss: 693.9279 - val_mean_squared_error: 693.9279\n",
      "Epoch 17/20\n",
      "15011/15011 [==============================] - 0s 28us/step - loss: 210.3363 - mean_squared_error: 210.3363 - val_loss: 685.9772 - val_mean_squared_error: 685.9772\n",
      "Epoch 18/20\n",
      "15011/15011 [==============================] - 0s 28us/step - loss: 206.7792 - mean_squared_error: 206.7792 - val_loss: 608.4381 - val_mean_squared_error: 608.4381\n",
      "Epoch 19/20\n",
      "15011/15011 [==============================] - 0s 28us/step - loss: 200.2832 - mean_squared_error: 200.2832 - val_loss: 636.6310 - val_mean_squared_error: 636.6310\n",
      "Epoch 20/20\n",
      "15011/15011 [==============================] - 0s 28us/step - loss: 198.9087 - mean_squared_error: 198.9087 - val_loss: 591.7516 - val_mean_squared_error: 591.7516\n",
      "20/20 [==============================] - 0s 39us/step\n",
      "Fetching model 3 to keras\n",
      "Evaluating model 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 232)               78184     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 216)               50328     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 176)               38192     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 176)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 648)               114696    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 536)               347864    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 537       \n",
      "=================================================================\n",
      "Total params: 629,801\n",
      "Trainable params: 629,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "<ann_framework.data_handlers.data_handler_CMAPSS.CMAPSSDataHandler object at 0x7fcc284d3be0>\n",
      "Data loaded?\n",
      "True\n",
      "Using previously loaded data\n",
      "Data loaded?\n",
      "True\n",
      "training with cv\n",
      "Train on 15011 samples, validate on 20 samples\n",
      "Epoch 1/20\n",
      "15011/15011 [==============================] - 1s 40us/step - loss: 2172.3516 - mean_squared_error: 2172.3516 - val_loss: 746.7563 - val_mean_squared_error: 746.7563\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15011/15011 [==============================] - 0s 25us/step - loss: 382.5919 - mean_squared_error: 382.5919 - val_loss: 591.9680 - val_mean_squared_error: 591.9680\n",
      "Epoch 3/20\n",
      "15011/15011 [==============================] - 0s 25us/step - loss: 347.3942 - mean_squared_error: 347.3942 - val_loss: 696.6978 - val_mean_squared_error: 696.6978\n",
      "Epoch 4/20\n",
      "15011/15011 [==============================] - 0s 25us/step - loss: 342.6212 - mean_squared_error: 342.6212 - val_loss: 579.8820 - val_mean_squared_error: 579.8820\n",
      "Epoch 5/20\n",
      "15011/15011 [==============================] - 0s 26us/step - loss: 292.5684 - mean_squared_error: 292.5684 - val_loss: 490.3546 - val_mean_squared_error: 490.3546\n",
      "Epoch 6/20\n",
      "15011/15011 [==============================] - 0s 25us/step - loss: 313.2365 - mean_squared_error: 313.2365 - val_loss: 697.9435 - val_mean_squared_error: 697.9435\n",
      "Epoch 7/20\n",
      "15011/15011 [==============================] - 0s 25us/step - loss: 336.1529 - mean_squared_error: 336.1529 - val_loss: 495.1810 - val_mean_squared_error: 495.1810\n",
      "Epoch 8/20\n",
      "15011/15011 [==============================] - 0s 25us/step - loss: 282.3571 - mean_squared_error: 282.3571 - val_loss: 525.4249 - val_mean_squared_error: 525.4249\n",
      "Epoch 9/20\n",
      "15011/15011 [==============================] - 0s 25us/step - loss: 280.5683 - mean_squared_error: 280.5683 - val_loss: 512.6245 - val_mean_squared_error: 512.6245\n",
      "Epoch 10/20\n",
      "15011/15011 [==============================] - 0s 25us/step - loss: 302.4246 - mean_squared_error: 302.4246 - val_loss: 581.0320 - val_mean_squared_error: 581.0320\n",
      "Epoch 11/20\n",
      "15011/15011 [==============================] - 0s 25us/step - loss: 271.8015 - mean_squared_error: 271.8015 - val_loss: 530.6129 - val_mean_squared_error: 530.6129\n",
      "Epoch 12/20\n",
      "15011/15011 [==============================] - 0s 25us/step - loss: 294.5536 - mean_squared_error: 294.5536 - val_loss: 470.3262 - val_mean_squared_error: 470.3262\n",
      "Epoch 13/20\n",
      "15011/15011 [==============================] - 0s 25us/step - loss: 259.2111 - mean_squared_error: 259.2111 - val_loss: 443.9457 - val_mean_squared_error: 443.9457\n",
      "Epoch 14/20\n",
      "15011/15011 [==============================] - 0s 25us/step - loss: 279.1036 - mean_squared_error: 279.1036 - val_loss: 477.4454 - val_mean_squared_error: 477.4454\n",
      "Epoch 15/20\n",
      "15011/15011 [==============================] - 0s 25us/step - loss: 257.5721 - mean_squared_error: 257.5721 - val_loss: 442.6968 - val_mean_squared_error: 442.6968\n",
      "Epoch 16/20\n",
      "15011/15011 [==============================] - 0s 25us/step - loss: 251.3783 - mean_squared_error: 251.3783 - val_loss: 494.4137 - val_mean_squared_error: 494.4137\n",
      "Epoch 17/20\n",
      "15011/15011 [==============================] - 0s 25us/step - loss: 242.7896 - mean_squared_error: 242.7896 - val_loss: 487.2526 - val_mean_squared_error: 487.2526\n",
      "Epoch 18/20\n",
      "15011/15011 [==============================] - 0s 25us/step - loss: 241.8937 - mean_squared_error: 241.8937 - val_loss: 471.4847 - val_mean_squared_error: 471.4847\n",
      "Epoch 19/20\n",
      "15011/15011 [==============================] - 0s 25us/step - loss: 244.0962 - mean_squared_error: 244.0962 - val_loss: 599.4662 - val_mean_squared_error: 599.4662\n",
      "Epoch 20/20\n",
      "15011/15011 [==============================] - 0s 25us/step - loss: 251.3767 - mean_squared_error: 251.3767 - val_loss: 482.0940 - val_mean_squared_error: 482.0940\n",
      "20/20 [==============================] - 0s 39us/step\n",
      "Fetching model 4 to keras\n",
      "Evaluating model 4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 552)               186024    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 992)               548576    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 480)               476640    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 952)               457912    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 952)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 304)               289712    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 328)               100040    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 432)               142128    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 433       \n",
      "=================================================================\n",
      "Total params: 2,201,465\n",
      "Trainable params: 2,201,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "<ann_framework.data_handlers.data_handler_CMAPSS.CMAPSSDataHandler object at 0x7fcc284d3be0>\n",
      "Data loaded?\n",
      "True\n",
      "Using previously loaded data\n",
      "Data loaded?\n",
      "True\n",
      "training with cv\n",
      "Train on 15011 samples, validate on 20 samples\n",
      "Epoch 1/20\n",
      "15011/15011 [==============================] - 2s 103us/step - loss: 6989.8532 - mean_squared_error: 6989.8532 - val_loss: 5804.9351 - val_mean_squared_error: 5804.9351\n",
      "Epoch 2/20\n",
      "15011/15011 [==============================] - 1s 81us/step - loss: 5601.1618 - mean_squared_error: 5601.1618 - val_loss: 4948.6968 - val_mean_squared_error: 4948.6968\n",
      "Epoch 3/20\n",
      "15011/15011 [==============================] - 1s 81us/step - loss: 4807.5246 - mean_squared_error: 4807.5246 - val_loss: 4263.1616 - val_mean_squared_error: 4263.1616\n",
      "Epoch 4/20\n",
      "15011/15011 [==============================] - 1s 81us/step - loss: 4156.3037 - mean_squared_error: 4156.3037 - val_loss: 3686.7273 - val_mean_squared_error: 3686.7273\n",
      "Epoch 5/20\n",
      "15011/15011 [==============================] - 1s 81us/step - loss: 3604.2859 - mean_squared_error: 3604.2859 - val_loss: 3214.8320 - val_mean_squared_error: 3214.8320\n",
      "Epoch 6/20\n",
      "15011/15011 [==============================] - 1s 82us/step - loss: 3165.8615 - mean_squared_error: 3165.8615 - val_loss: 2851.9910 - val_mean_squared_error: 2851.9910\n",
      "Epoch 7/20\n",
      "15011/15011 [==============================] - 1s 81us/step - loss: 2825.5491 - mean_squared_error: 2825.5491 - val_loss: 2571.5654 - val_mean_squared_error: 2571.5654\n",
      "Epoch 8/20\n",
      "15011/15011 [==============================] - 1s 81us/step - loss: 2562.9601 - mean_squared_error: 2562.9601 - val_loss: 2360.2026 - val_mean_squared_error: 2360.2026\n",
      "Epoch 9/20\n",
      "15011/15011 [==============================] - 1s 81us/step - loss: 2364.2504 - mean_squared_error: 2364.2504 - val_loss: 2203.4973 - val_mean_squared_error: 2203.4973\n",
      "Epoch 10/20\n",
      "15011/15011 [==============================] - 1s 80us/step - loss: 2216.1351 - mean_squared_error: 2216.1351 - val_loss: 2089.6931 - val_mean_squared_error: 2089.6931\n",
      "Epoch 11/20\n",
      "15011/15011 [==============================] - 1s 80us/step - loss: 2107.4193 - mean_squared_error: 2107.4193 - val_loss: 2008.9961 - val_mean_squared_error: 2008.9961\n",
      "Epoch 12/20\n",
      "15011/15011 [==============================] - 1s 81us/step - loss: 2029.7489 - mean_squared_error: 2029.7489 - val_loss: 1952.6611 - val_mean_squared_error: 1952.6611\n",
      "Epoch 13/20\n",
      "15011/15011 [==============================] - 1s 81us/step - loss: 1973.7548 - mean_squared_error: 1973.7548 - val_loss: 1914.5312 - val_mean_squared_error: 1914.5312\n",
      "Epoch 14/20\n",
      "15011/15011 [==============================] - 1s 81us/step - loss: 1935.2753 - mean_squared_error: 1935.2753 - val_loss: 1890.0433 - val_mean_squared_error: 1890.0433\n",
      "Epoch 15/20\n",
      "15011/15011 [==============================] - 1s 81us/step - loss: 1909.7629 - mean_squared_error: 1909.7629 - val_loss: 1874.8611 - val_mean_squared_error: 1874.8611\n",
      "Epoch 16/20\n",
      "15011/15011 [==============================] - 1s 80us/step - loss: 1892.6875 - mean_squared_error: 1892.6875 - val_loss: 1865.8871 - val_mean_squared_error: 1865.8871\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15011/15011 [==============================] - 1s 81us/step - loss: 1882.0470 - mean_squared_error: 1882.0470 - val_loss: 1860.9714 - val_mean_squared_error: 1860.9714\n",
      "Epoch 18/20\n",
      "15011/15011 [==============================] - 1s 81us/step - loss: 1874.9906 - mean_squared_error: 1874.9906 - val_loss: 1858.4124 - val_mean_squared_error: 1858.4124\n",
      "Epoch 19/20\n",
      "15011/15011 [==============================] - 1s 81us/step - loss: 1870.6236 - mean_squared_error: 1870.6236 - val_loss: 1857.3591 - val_mean_squared_error: 1857.3591\n",
      "Epoch 20/20\n",
      "15011/15011 [==============================] - 1s 81us/step - loss: 1867.9327 - mean_squared_error: 1867.9327 - val_loss: 1857.1436 - val_mean_squared_error: 1857.1436\n",
      "20/20 [==============================] - 0s 87us/step\n",
      "3190.0730084862616\n",
      "[0.73377854 0.25574838 0.18549782 0.15112319 0.58216334]\n",
      "Individual 0 score/normalized score/size/fitness 2340.80712890625/0.7337785444656637/2196937/12.411249490193045\n",
      "Individual 1 score/normalized score/size/fitness 815.8560180664062/0.2557483844087764/313665/6.955027562546336\n",
      "Individual 2 score/normalized score/size/fitness 591.7515869140625/0.18549781943544222/787369/6.571757980241674\n",
      "Individual 3 score/normalized score/size/fitness 482.093994140625/0.1511231852243363/629801/6.150704291806228\n",
      "Individual 4 score/normalized score/size/fitness 1857.1435546875/0.5821633391295777/2201465/10.895729425338455\n",
      "\n",
      "Generating offsprings\n",
      "Applying Mutation\n",
      "Launch new generation?: True\n",
      "\n",
      "Generation 2\n",
      "launch new\n",
      "True\n",
      "gen similar\n",
      "False\n",
      "Fetching model 0 to keras\n",
      "Evaluating model 0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 552)               186024    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 552)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 992)               548576    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 993       \n",
      "=================================================================\n",
      "Total params: 735,593\n",
      "Trainable params: 735,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "<ann_framework.data_handlers.data_handler_CMAPSS.CMAPSSDataHandler object at 0x7fcc284d3be0>\n",
      "Data loaded?\n",
      "True\n",
      "Using previously loaded data\n",
      "Data loaded?\n",
      "True\n",
      "training with cv\n",
      "Train on 15011 samples, validate on 20 samples\n",
      "Epoch 1/20\n",
      "15011/15011 [==============================] - 1s 39us/step - loss: 5775.7843 - mean_squared_error: 5775.7843 - val_loss: 4134.6528 - val_mean_squared_error: 4134.6528\n",
      "Epoch 2/20\n",
      "15011/15011 [==============================] - 0s 29us/step - loss: 3583.7678 - mean_squared_error: 3583.7678 - val_loss: 2845.8540 - val_mean_squared_error: 2845.8540\n",
      "Epoch 3/20\n",
      "15011/15011 [==============================] - 0s 29us/step - loss: 2445.7996 - mean_squared_error: 2445.7996 - val_loss: 2091.0264 - val_mean_squared_error: 2091.0264\n",
      "Epoch 4/20\n",
      "15011/15011 [==============================] - 0s 29us/step - loss: 1738.9198 - mean_squared_error: 1738.9198 - val_loss: 1677.8997 - val_mean_squared_error: 1677.8997\n",
      "Epoch 5/20\n",
      "15011/15011 [==============================] - 0s 29us/step - loss: 1306.9848 - mean_squared_error: 1306.9848 - val_loss: 1468.2329 - val_mean_squared_error: 1468.2329\n",
      "Epoch 6/20\n",
      "15011/15011 [==============================] - 0s 31us/step - loss: 1043.2021 - mean_squared_error: 1043.2021 - val_loss: 1377.7365 - val_mean_squared_error: 1377.7365\n",
      "Epoch 7/20\n",
      "15011/15011 [==============================] - 0s 29us/step - loss: 876.5290 - mean_squared_error: 876.5290 - val_loss: 1348.8147 - val_mean_squared_error: 1348.8147\n",
      "Epoch 8/20\n",
      "15011/15011 [==============================] - 0s 28us/step - loss: 760.2767 - mean_squared_error: 760.2767 - val_loss: 1328.4297 - val_mean_squared_error: 1328.4297\n",
      "Epoch 9/20\n",
      "15011/15011 [==============================] - 0s 29us/step - loss: 660.6947 - mean_squared_error: 660.6947 - val_loss: 1247.8597 - val_mean_squared_error: 1247.8597\n",
      "Epoch 10/20\n",
      "15011/15011 [==============================] - 0s 29us/step - loss: 533.3522 - mean_squared_error: 533.3522 - val_loss: 933.8932 - val_mean_squared_error: 933.8932\n",
      "Epoch 11/20\n",
      "15011/15011 [==============================] - 0s 29us/step - loss: 426.3625 - mean_squared_error: 426.3625 - val_loss: 853.0444 - val_mean_squared_error: 853.0444\n",
      "Epoch 12/20\n",
      "15011/15011 [==============================] - 0s 29us/step - loss: 358.7508 - mean_squared_error: 358.7508 - val_loss: 760.7627 - val_mean_squared_error: 760.7627\n",
      "Epoch 13/20\n",
      "15011/15011 [==============================] - 0s 29us/step - loss: 321.4810 - mean_squared_error: 321.4810 - val_loss: 701.8124 - val_mean_squared_error: 701.8124\n",
      "Epoch 14/20\n",
      "15011/15011 [==============================] - 0s 29us/step - loss: 297.1699 - mean_squared_error: 297.1699 - val_loss: 701.3062 - val_mean_squared_error: 701.3062\n",
      "Epoch 15/20\n",
      "15011/15011 [==============================] - 0s 29us/step - loss: 282.6631 - mean_squared_error: 282.6631 - val_loss: 728.9507 - val_mean_squared_error: 728.9507\n",
      "Epoch 16/20\n",
      "15011/15011 [==============================] - 0s 29us/step - loss: 268.6007 - mean_squared_error: 268.6007 - val_loss: 671.8409 - val_mean_squared_error: 671.8409\n",
      "Epoch 17/20\n",
      "15011/15011 [==============================] - 0s 29us/step - loss: 263.3078 - mean_squared_error: 263.3078 - val_loss: 779.3825 - val_mean_squared_error: 779.3825\n",
      "Epoch 18/20\n",
      "15011/15011 [==============================] - 0s 29us/step - loss: 256.6217 - mean_squared_error: 256.6217 - val_loss: 706.5717 - val_mean_squared_error: 706.5717\n",
      "Epoch 19/20\n",
      "15011/15011 [==============================] - 0s 29us/step - loss: 249.9074 - mean_squared_error: 249.9074 - val_loss: 663.9200 - val_mean_squared_error: 663.9200\n",
      "Epoch 20/20\n",
      "15011/15011 [==============================] - 0s 29us/step - loss: 249.4297 - mean_squared_error: 249.4297 - val_loss: 739.3486 - val_mean_squared_error: 739.3486\n",
      "20/20 [==============================] - 0s 42us/step\n",
      "Fetching model 1 to keras\n",
      "Evaluating model 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 232)               78184     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 216)               50328     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 217       \n",
      "=================================================================\n",
      "Total params: 128,729\n",
      "Trainable params: 128,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "<ann_framework.data_handlers.data_handler_CMAPSS.CMAPSSDataHandler object at 0x7fcc284d3be0>\n",
      "Data loaded?\n",
      "True\n",
      "Using previously loaded data\n",
      "Data loaded?\n",
      "True\n",
      "training with cv\n",
      "Train on 15011 samples, validate on 20 samples\n",
      "Epoch 1/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 4177.2341 - mean_squared_error: 4177.2341 - val_loss: 1355.6866 - val_mean_squared_error: 1355.6866\n",
      "Epoch 2/20\n",
      "15011/15011 [==============================] - 0s 6us/step - loss: 485.5561 - mean_squared_error: 485.5561 - val_loss: 803.1159 - val_mean_squared_error: 803.1159\n",
      "Epoch 3/20\n",
      "15011/15011 [==============================] - 0s 6us/step - loss: 339.7940 - mean_squared_error: 339.7940 - val_loss: 694.6761 - val_mean_squared_error: 694.6761\n",
      "Epoch 4/20\n",
      "15011/15011 [==============================] - 0s 6us/step - loss: 297.0543 - mean_squared_error: 297.0543 - val_loss: 627.0978 - val_mean_squared_error: 627.0978\n",
      "Epoch 5/20\n",
      "15011/15011 [==============================] - 0s 6us/step - loss: 273.4077 - mean_squared_error: 273.4077 - val_loss: 605.6586 - val_mean_squared_error: 605.6586\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15011/15011 [==============================] - 0s 6us/step - loss: 258.9907 - mean_squared_error: 258.9907 - val_loss: 569.0904 - val_mean_squared_error: 569.0904\n",
      "Epoch 7/20\n",
      "15011/15011 [==============================] - 0s 6us/step - loss: 250.8139 - mean_squared_error: 250.8139 - val_loss: 572.1179 - val_mean_squared_error: 572.1179\n",
      "Epoch 8/20\n",
      "15011/15011 [==============================] - 0s 6us/step - loss: 248.0493 - mean_squared_error: 248.0493 - val_loss: 530.4308 - val_mean_squared_error: 530.4308\n",
      "Epoch 9/20\n",
      "15011/15011 [==============================] - 0s 6us/step - loss: 242.0034 - mean_squared_error: 242.0034 - val_loss: 539.0290 - val_mean_squared_error: 539.0290\n",
      "Epoch 10/20\n",
      "15011/15011 [==============================] - 0s 6us/step - loss: 239.6709 - mean_squared_error: 239.6709 - val_loss: 506.3466 - val_mean_squared_error: 506.3466\n",
      "Epoch 11/20\n",
      "15011/15011 [==============================] - 0s 6us/step - loss: 237.9413 - mean_squared_error: 237.9413 - val_loss: 518.3620 - val_mean_squared_error: 518.3620\n",
      "Epoch 12/20\n",
      "15011/15011 [==============================] - 0s 6us/step - loss: 234.7076 - mean_squared_error: 234.7076 - val_loss: 530.0642 - val_mean_squared_error: 530.0642\n",
      "Epoch 13/20\n",
      "15011/15011 [==============================] - 0s 6us/step - loss: 232.8879 - mean_squared_error: 232.8879 - val_loss: 515.3400 - val_mean_squared_error: 515.3400\n",
      "Epoch 14/20\n",
      "15011/15011 [==============================] - 0s 6us/step - loss: 230.9811 - mean_squared_error: 230.9811 - val_loss: 536.0120 - val_mean_squared_error: 536.0120\n",
      "Epoch 15/20\n",
      "15011/15011 [==============================] - 0s 6us/step - loss: 229.8432 - mean_squared_error: 229.8432 - val_loss: 504.0667 - val_mean_squared_error: 504.0667\n",
      "Epoch 16/20\n",
      "15011/15011 [==============================] - 0s 6us/step - loss: 231.3859 - mean_squared_error: 231.3859 - val_loss: 536.5250 - val_mean_squared_error: 536.5250\n",
      "Epoch 17/20\n",
      "15011/15011 [==============================] - 0s 6us/step - loss: 224.8820 - mean_squared_error: 224.8820 - val_loss: 509.4818 - val_mean_squared_error: 509.4818\n",
      "Epoch 18/20\n",
      "15011/15011 [==============================] - 0s 6us/step - loss: 224.1037 - mean_squared_error: 224.1037 - val_loss: 511.4959 - val_mean_squared_error: 511.4959\n",
      "Epoch 19/20\n",
      "15011/15011 [==============================] - 0s 6us/step - loss: 223.1696 - mean_squared_error: 223.1696 - val_loss: 491.4862 - val_mean_squared_error: 491.4862\n",
      "Epoch 20/20\n",
      "15011/15011 [==============================] - 0s 6us/step - loss: 221.5940 - mean_squared_error: 221.5940 - val_loss: 497.8813 - val_mean_squared_error: 497.8813\n",
      "20/20 [==============================] - 0s 26us/step\n",
      "Fetching model 2 to keras\n",
      "Evaluating model 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (Dense)                   (None, 928)               312736    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 928)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 929       \n",
      "=================================================================\n",
      "Total params: 313,665\n",
      "Trainable params: 313,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "<ann_framework.data_handlers.data_handler_CMAPSS.CMAPSSDataHandler object at 0x7fcc284d3be0>\n",
      "Data loaded?\n",
      "True\n",
      "Using previously loaded data\n",
      "Data loaded?\n",
      "True\n",
      "training with cv\n",
      "Train on 15011 samples, validate on 20 samples\n",
      "Epoch 1/20\n",
      "15011/15011 [==============================] - 0s 22us/step - loss: 6981.8091 - mean_squared_error: 6981.8091 - val_loss: 5235.9194 - val_mean_squared_error: 5235.9194\n",
      "Epoch 2/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 4129.6582 - mean_squared_error: 4129.6582 - val_loss: 3120.5295 - val_mean_squared_error: 3120.5295\n",
      "Epoch 3/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 2366.5265 - mean_squared_error: 2366.5265 - val_loss: 1935.9246 - val_mean_squared_error: 1935.9246\n",
      "Epoch 4/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 1381.9507 - mean_squared_error: 1381.9507 - val_loss: 1438.6941 - val_mean_squared_error: 1438.6941\n",
      "Epoch 5/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 915.8096 - mean_squared_error: 915.8096 - val_loss: 1293.5051 - val_mean_squared_error: 1293.5051\n",
      "Epoch 6/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 719.3243 - mean_squared_error: 719.3243 - val_loss: 1279.8860 - val_mean_squared_error: 1279.8860\n",
      "Epoch 7/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 633.5037 - mean_squared_error: 633.5037 - val_loss: 1295.0066 - val_mean_squared_error: 1295.0066\n",
      "Epoch 8/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 586.7967 - mean_squared_error: 586.7967 - val_loss: 1295.4364 - val_mean_squared_error: 1295.4364\n",
      "Epoch 9/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 551.6396 - mean_squared_error: 551.6396 - val_loss: 1275.1589 - val_mean_squared_error: 1275.1589\n",
      "Epoch 10/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 518.4711 - mean_squared_error: 518.4711 - val_loss: 1231.0271 - val_mean_squared_error: 1231.0271\n",
      "Epoch 11/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 483.4700 - mean_squared_error: 483.4700 - val_loss: 1168.2427 - val_mean_squared_error: 1168.2427\n",
      "Epoch 12/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 448.9834 - mean_squared_error: 448.9834 - val_loss: 1103.5129 - val_mean_squared_error: 1103.5129\n",
      "Epoch 13/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 415.9777 - mean_squared_error: 415.9777 - val_loss: 1032.5540 - val_mean_squared_error: 1032.5540\n",
      "Epoch 14/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 388.3027 - mean_squared_error: 388.3027 - val_loss: 987.4808 - val_mean_squared_error: 987.4808\n",
      "Epoch 15/20\n",
      "15011/15011 [==============================] - 0s 14us/step - loss: 363.4879 - mean_squared_error: 363.4879 - val_loss: 948.1122 - val_mean_squared_error: 948.1122\n",
      "Epoch 16/20\n",
      "12800/15011 [========================>.....] - ETA: 0s - loss: 344.6584 - mean_squared_error: 344.6584"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-55f9e2fe0141>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m     best = automatic_model_selection.run_experiment(config, dhandler_cmaps, count_experiments + 1, unroll=unroll,\n\u001b[1;32m     48\u001b[0m                                                     \u001b[0mlearningRate_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearningRate_scheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                                                     tModel_scaler=scaler)\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/controlslab/DATA/Projects/automatic_model_selection/code/automatic_model_selection.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(configuration, data_handler, experiment_number, unroll, learningRate_scheduler, tModel_scaler)\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;31m#Assess the fitness of the inidividuals in the population\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \t\tbest_model, worst_model, worst_index = evaluate_population(population, configuration, data_handler, tModel_scaler,\n\u001b[0;32m--> 452\u001b[0;31m \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   unroll, learningRate_scheduler)\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m                 \u001b[0;31m#Save worst and best models. Also append best model to elite archive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/controlslab/DATA/Projects/automatic_model_selection/code/automatic_model_selection.py\u001b[0m in \u001b[0;36mevaluate_population\u001b[0;34m(population, configuration, data_handler, tModel_scaler, unroll, learningRate_scheduler)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \t\tevaluate_individual(individual, configuration, data_handler, tModel_scaler, i, unroll,\n\u001b[0;32m--> 236\u001b[0;31m \t\t\t\t\t\t\tlearningRate_scheduler=learningRate_scheduler)\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0mraw_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindividual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/controlslab/DATA/Projects/automatic_model_selection/code/automatic_model_selection.py\u001b[0m in \u001b[0;36mevaluate_individual\u001b[0;34m(individual, configuration, data_handler, tModel_scaler, ind_index, unroll, learningRate_scheduler)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \tindividual.compute_raw_scores(epochs=configuration.epochs, cross_validation_ratio=configuration.cross_val,\n\u001b[0;32m--> 213\u001b[0;31m \t\t\t\t      verbose=configuration.verbose_training, unroll=unroll, learningRate_scheduler=learningRate_scheduler)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mindividual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindividual_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mind_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/controlslab/DATA/Projects/automatic_model_selection/code/nn_evolutionary.py\u001b[0m in \u001b[0;36mcompute_raw_scores\u001b[0;34m(self, epochs, cross_validation_ratio, verbose, unroll, learningRate_scheduler)\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainable_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_validation_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munroll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearningRate_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearningRate_scheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0mmetric_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/controlslab/DATA/Projects/automatic_model_selection/code/nn_evolutionary.py\u001b[0m in \u001b[0;36mpartial_run\u001b[0;34m(self, cross_validation_ratio, epochs, verbose, unroll, learningRate_scheduler)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearningRate_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearningRate_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/controlslab/DATA/Projects/ann_framework/tunable_model/tunable_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, verbose, learningRate_scheduler, tf_session, tensorboard, get_minibatches_function_handle, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m                                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training with cv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                                 \u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X_crossVal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y_crossVal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training without cv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"Input can be of 3 types, ANN (1), CNN (2) or RNN (3)\"\"\"\n",
    "architecture_type = Layers.FullyConnected\n",
    "problem_type = 1  #1 for regression, 2 for classification\n",
    "output_shape = 1 #If regression applies, number of classes\n",
    "input_shape = None\n",
    "\n",
    "\"\"\"\n",
    "pop_size = 5\n",
    "tournament_size = 3\n",
    "max_similar = 3\n",
    "\"\"\"\n",
    "total_experiments = 5\n",
    "count_experiments = 0\n",
    "unroll = True\n",
    "\n",
    "global_best_list = []\n",
    "global_best = None\n",
    "global_best_index = 0\n",
    "experiment_times = np.zeros((total_experiments,1))\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "t = datetime.datetime.now()\n",
    "\n",
    "logging.basicConfig(filename='logs/nn_evolution_cmaps_' + t.strftime('%m%d%Y%H%M%S') + '.log', level=logging.INFO, \n",
    "                        format='%(levelname)s:%(threadName)s:%(message)s', datefmt='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "#cmaps datahandler\n",
    "dhandler_cmaps, input_shape = cmaps_dhandler()\n",
    "\n",
    "\"\"\"\n",
    "config = Configuration(architecture_type, problem_type, input_shape, output_shape, pop_size, tournament_size, \n",
    "                       max_similar, epochs=5, cross_val=0.2, size_scaler=size_scaler, max_generations=10, \n",
    "                       binary_selection=True, mutation_ratio=0.4, similarity_threshold=0.2, more_layers_prob=0.8)\n",
    "\"\"\"\n",
    "\n",
    "config.architecture_type = architecture_type\n",
    "config.problem_type = problem_type\n",
    "config.input_shape = input_shape\n",
    "config.output_shape = output_shape\n",
    "\n",
    "while count_experiments < total_experiments:\n",
    "    print(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    logging.info(\"Launching experiment {}\".format(count_experiments+1))\n",
    "    \n",
    "    start = time.time()\n",
    "    best = automatic_model_selection.run_experiment(config, dhandler_cmaps, count_experiments + 1, unroll=unroll,\n",
    "                                                    learningRate_scheduler=learningRate_scheduler, \n",
    "                                                    tModel_scaler=scaler)\n",
    "    end = time.time()\n",
    "    elapsed_time = (end-start)/60\n",
    "    experiment_times[count_experiments] = elapsed_time\n",
    "    print(\"Experiment time: {} minutes\".format(elapsed_time))\n",
    "    logging.info(\"Experiment time: {} minutes\".format(elapsed_time))\n",
    "    \n",
    "    best.individual_label = count_experiments\n",
    "\n",
    "    global_best_list.append(best)\n",
    "\n",
    "    if global_best == None:\n",
    "        global_best = best\n",
    "    else:\n",
    "        if best.fitness < global_best.fitness:\n",
    "            global_best = best\n",
    "            global_best_index = count_experiments\n",
    "\n",
    "    count_experiments =  count_experiments + 1\n",
    "\n",
    "print(\"Global best list\\n\")\n",
    "logging.info(\"Global best list\\n\")\n",
    "automatic_model_selection.print_best(global_best_list)\n",
    "\n",
    "print(\"Global best is\\n\")\n",
    "print(global_best)\n",
    "logging.info(\"Global best is\\n\")\n",
    "logging.info(global_best)\n",
    "\n",
    "print(\"Global time {}\".format(experiment_times.sum()))\n",
    "logging.info(\"Global time {}\".format(experiment_times.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_best_models(global_best_list, global_best_index, 'best_models/cmapss/alpha{}/smaller_'.format(size_scaler), \n",
    "                 input_shape=input_shape, data_handler=dhandler_cmaps, problem_type=problem_type, train_epochs=100, \n",
    "                 data_scaler=scaler, metrics=['rhs', 'rmse'], round=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
